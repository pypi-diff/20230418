# Comparing `tmp/chatgpt_pre_commit_hooks-0.1.0-py3-none-any.whl.zip` & `tmp/chatgpt_pre_commit_hooks-0.1.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,13 +1,17 @@
-Zip file size: 13604 bytes, number of entries: 11
--rw-r--r--  2.0 unx       12 b- defN 23-Apr-17 07:52 build/lib/chatgpt_pre_commit_hooks/__init__.py
--rw-r--r--  2.0 unx    11483 b- defN 23-Apr-17 07:52 build/lib/chatgpt_pre_commit_hooks/chatgpt_commit_message.py
--rw-r--r--  2.0 unx       12 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks/__init__.py
--rw-r--r--  2.0 unx    11483 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks/chatgpt_commit_message.py
--rw-r--r--  2.0 unx     3578 b- defN 23-Apr-17 07:52 docs/chatgpt_commit_message.md
--rw-r--r--  2.0 unx     1073 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     6302 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       96 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       41 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1088 b- defN 23-Apr-17 07:52 chatgpt_pre_commit_hooks-0.1.0.dist-info/RECORD
-11 files, 35260 bytes uncompressed, 11700 bytes compressed:  66.8%
+Zip file size: 507206 bytes, number of entries: 15
+-rw-r--r--  2.0 unx    80425 b- defN 23-Apr-18 06:13 assets/images/azure-openai-service-key-endpoint.png
+-rw-r--r--  2.0 unx   158116 b- defN 23-Apr-18 06:13 assets/images/azure-openai-service-models.png
+-rw-r--r--  2.0 unx   161351 b- defN 23-Apr-18 06:13 assets/images/openai-platform-api-key.png
+-rw-r--r--  2.0 unx   112924 b- defN 23-Apr-18 06:13 assets/images/openai-platform-org-id.png
+-rw-r--r--  2.0 unx       12 b- defN 23-Apr-18 06:13 build/lib/chatgpt_pre_commit_hooks/__init__.py
+-rw-r--r--  2.0 unx    11193 b- defN 23-Apr-18 06:13 build/lib/chatgpt_pre_commit_hooks/chatgpt_commit_message.py
+-rw-r--r--  2.0 unx       12 b- defN 23-Apr-18 06:13 chatgpt_pre_commit_hooks/__init__.py
+-rw-r--r--  2.0 unx    11193 b- defN 23-Apr-18 06:13 chatgpt_pre_commit_hooks/chatgpt_commit_message.py
+-rw-r--r--  2.0 unx     4845 b- defN 23-Apr-18 06:13 docs/chatgpt_commit_message.md
+-rw-r--r--  2.0 unx     1073 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx    14089 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       96 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       48 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1501 b- defN 23-Apr-18 06:14 chatgpt_pre_commit_hooks-0.1.1.dist-info/RECORD
+15 files, 556970 bytes uncompressed, 504644 bytes compressed:  9.4%
```

## zipnote {}

```diff
@@ -1,7 +1,19 @@
+Filename: assets/images/azure-openai-service-key-endpoint.png
+Comment: 
+
+Filename: assets/images/azure-openai-service-models.png
+Comment: 
+
+Filename: assets/images/openai-platform-api-key.png
+Comment: 
+
+Filename: assets/images/openai-platform-org-id.png
+Comment: 
+
 Filename: build/lib/chatgpt_pre_commit_hooks/__init__.py
 Comment: 
 
 Filename: build/lib/chatgpt_pre_commit_hooks/chatgpt_commit_message.py
 Comment: 
 
 Filename: chatgpt_pre_commit_hooks/__init__.py
@@ -9,26 +21,26 @@
 
 Filename: chatgpt_pre_commit_hooks/chatgpt_commit_message.py
 Comment: 
 
 Filename: docs/chatgpt_commit_message.md
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/LICENSE
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/LICENSE
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/METADATA
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/METADATA
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/WHEEL
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/entry_points.txt
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/top_level.txt
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: chatgpt_pre_commit_hooks-0.1.0.dist-info/RECORD
+Filename: chatgpt_pre_commit_hooks-0.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## build/lib/chatgpt_pre_commit_hooks/chatgpt_commit_message.py

```diff
@@ -1,144 +1,124 @@
 #!/usr/bin/env python3
 """chatgpt-commit-message pre-commit-hook.
 
 A pre-commit hook that utilizes ChatGPT to summarize changes made to the codebase on the 'git commit' event.
 The commit message is then used to populate the commit message automatically.
 """
 
+import argparse
 import logging
 import os
 import sys
-from argparse import ArgumentParser, BooleanOptionalAction, Namespace
 from pathlib import Path
 from typing import Dict, List, Optional
 
 import openai
 import tiktoken
 from git.repo import Repo
 
-logging.basicConfig(level=logging.NOTSET)
-# logging.basicConfig(level=logging.DEBUG, filename="debug.log", filemode="w")  # noqa: ERA001
+logger = logging.getLogger(__name__)
 
 
-def get_args() -> Namespace:
+def get_args() -> argparse.Namespace:
     """Get input arguments."""
-    logging.debug(f"SYS_ARGV: {sys.argv}")
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument("commit_msg_filename", nargs="?", default=None)  # args.commit_msg_filename
     parser.add_argument("prepare_commit_message_source", nargs="?", default=None)  # args.prepare_commit_message_source
     parser.add_argument("commit_object_name", nargs="?", default=None)  # args.commit_object_name
     parser.add_argument("--max-char-count", type=int, default=10000)  # args.max_char_count
-    parser.add_argument("--emoji", action=BooleanOptionalAction, default=False)  # args.emoji
-    parser.add_argument("--description", action=BooleanOptionalAction, default=False)  # args.description
+    parser.add_argument("--emoji", action=argparse.BooleanOptionalAction, default=False)  # args.emoji
+    parser.add_argument("--description", action=argparse.BooleanOptionalAction, default=False)  # args.description
+    parser.add_argument("--log-level", choices=[key.lower() for key in logging._nameToLevel], default="warning", required=False)  # args.log_level  # noqa: SLF001
     parser.add_argument("--env-prefix", type=str, default=None, required=False)  # args.env_prefix
-    parser.add_argument("--openai-chat-model", type=str, default="gpt-3.5-turbo")  # args.openai_chat_model
-    parser.add_argument("--openai-organization", type=str, default=None, required=False)  # args.openai_organization
-    parser.add_argument("--openai-api-base", type=str, default=None, required=False)  # args.openai_api_base
-    parser.add_argument("--openai-api-type", type=str, default=None, required=False)  # args.openai_api_type
-    parser.add_argument("--openai-proxy", type=str, default=None, required=False)  # args.openai_proxy
-    args = parser.parse_args()
-    logging.debug(f"ARGS: {args}")
-    return args
+
+    temp_args = parser.parse_args()
+    env_prefix = ""
+    if temp_args.env_prefix is not None and temp_args.env_prefix:
+        env_prefix = f"{temp_args.env_prefix.upper()}__"
+
+    parser.add_argument("--openai-model", type=str, default=os.environ.get(f"{env_prefix}OPENAI_MODEL", "gpt-3.5-turbo"))  # args.openai_model
+    parser.add_argument("--openai-max-tokens", type=int, default=os.environ.get(f"{env_prefix}OPENAI_MAX_TOKENS", "1024"))  # args.openai_max_tokens
+    parser.add_argument("--openai-api-base", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_BASE", openai.api_base))  # args.openai_api_base
+    parser.add_argument("--openai-api-type", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_TYPE", openai.api_type))  # args.openai_api_type
+    parser.add_argument("--openai-proxy", type=str, default=os.environ.get(f"{env_prefix}OPENAI_PROXY", None), required=False)  # args.openai_proxy
+    parser.add_argument("--openai-api-key", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_KEY", openai.api_key), help=argparse.SUPPRESS)  # args.openai_api_key
+
+    openai_api_type = parser.parse_args().openai_api_type
+    if openai_api_type == openai.api_type:
+        parser.add_argument(
+            "--openai-organization",
+            type=str,
+            default=os.environ.get(f"{env_prefix}OPENAI_ORGANIZATION", openai.organization),
+            help=argparse.SUPPRESS,
+            required=False,
+        )  # args.openai_organization
+
+    return parser.parse_args()
 
 
 def get_git_diff(max_char_count: int, git_repo_path: str) -> str:
     """Get git diff of staged changes - full or stat only.
 
     - full - if length of diff is less than max_char_count
     - stat - if length of diff is more than max_char_count
     """
     repo = Repo(git_repo_path)
     diff = repo.git.diff(staged=True)
     if len(diff) > max_char_count:
         diff = repo.git.diff(staged=True, stat=True)
-    logging.debug(f"GIT_DIFF: {diff}")
+    logger.debug(f"GIT_DIFF: {diff}")
     return diff
 
 
 def get_user_commit_message(commit_msg_file_path: str, prepare_commit_message_source: Optional[str]) -> Optional[str]:
     """Get user commit message (if specified)."""
-    logging.debug(f"PREPARE_COMMIT_MESSAGE_SOURCE: {prepare_commit_message_source}")
+    logger.debug(f"PREPARE_COMMIT_MESSAGE_SOURCE: {prepare_commit_message_source}")
     user_commit_message = None
     if prepare_commit_message_source == "message" or prepare_commit_message_source is None:
         commit_msg_file = Path(commit_msg_file_path)
         commit_msg_file_wrapper = commit_msg_file.open(encoding="utf-8")
         lines = [line for line in commit_msg_file_wrapper.readlines() if not line.startswith("#") and line.strip()]
         commit_msg_file_wrapper.close()
         logging.debug(f"USER_COMMIT_MESSAGE_LINES: {lines}")
         if lines != []:
             user_commit_message = "".join(lines).strip()
 
-    logging.debug(f"USER_COMMIT_MESSAGE: {user_commit_message}")
+    logger.debug(f"USER_COMMIT_MESSAGE: {user_commit_message}")
 
     if user_commit_message is not None:
         skip_keywords = ["#no-ai", "#no-openai", "#no-chatgpt", "#no-gpt", "#skip-ai", "#skip-openai", "#skip-chatgpt", "#skip-gpt"]
         if any(skip_keyword.casefold() in user_commit_message.casefold() for skip_keyword in skip_keywords):
             logging.debug(f"USER_COMMIT_MESSAGE: {user_commit_message} - SKIPPED")
             sys.exit(0)
 
     return user_commit_message
 
 
-def _get_openai_config(args: Namespace) -> Dict[str, Optional[str]]:
-    """Get OpenAI API Key from environment variable."""
-    env_prefix = ""
-    if args.env_prefix is not None:
-        env_prefix = f"{args.env_prefix.upper()}__"
-
-    # https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety
-    openai_api_key = os.environ.get(f"{env_prefix}OPENAI_API_KEY", openai.api_key)  # $env:OPENAI_API_KEY
-    if openai_api_key is None or not openai_api_key:
-        raise ValueError(f"`{env_prefix}OPENAI_API_KEY` environment variable is not set.")
-
-    openai_organization = os.environ.get(f"{env_prefix}OPENAI_ORGANIZATION", openai.organization)  # $env:OPENAI_ORGANIZATION
-    if args.openai_organization is not None:
-        openai_organization = args.openai_organization
-
-    openai_api_base = os.environ.get(f"{env_prefix}OPENAI_API_BASE", openai.api_base)  # $env:OPENAI_API_BASE
-    if args.openai_api_base is not None:
-        openai_api_base = args.openai_api_base
-
-    openai_api_type = os.environ.get(f"{env_prefix}OPENAI_API_TYPE", openai.api_type)  # $env:OPENAI_API_TYPE
-    if args.openai_api_type is not None:
-        openai_api_type = args.openai_api_type
-
-    openai_proxy = os.environ.get(f"{env_prefix}OPENAI_PROXY", openai.api_version)  # $env:OPENAI_PROXY
-    if args.openai_proxy is not None:
-        openai_proxy = args.openai_proxy
-
-    return {
-        "openai_api_key": openai_api_key,
-        "openai_organization": openai_organization,
-        "openai_api_base": openai_api_base,
-        "openai_api_type": openai_api_type,
-        "openai_proxy": openai_proxy,
-    }
-
-
-def get_openai_chat_prompt_messages(user_commit_message: Optional[str], git_diff: str, args: Namespace) -> List[Dict[str, str]]:
+def get_openai_chat_prompt_messages(user_commit_message: Optional[str], git_diff: str, emoji: bool, description: bool) -> List[Dict[str, str]]:  # noqa: FBT001
     """Get prompt messages."""
     role_system = [
         "You are a software engineer assistant to write a 'Commit message with scope'.",
         "You aim to suggest a clean commit message in the 'Conventional Commits' convention.",
         "You will get an output from the 'git diff --staged' or 'git diff --staged --stat' command, and you will suggest a commit message.",
     ]
     role_user = [git_diff]
 
     # GitMoji
-    if args.emoji is True:
+    if emoji is True:
         role_system.append("Use the 'GitMoji convention' to preface the commit with the UNICODE characters format.")
         role_system.append("Do not use shortcode representation.")
     else:
         role_system.append("Do not preface the commit message with anything.")
 
     # description
-    if args.description is True:
+    if description is True:
         role_system.append("Add a short description to the commit message in the body section of why these changes were made.")
         role_system.append('Omit "This commit" at the beginning - briefly describe changes.')
+        role_system.append("Each sentence of the description should be in new line.")
     else:
         role_system.append("Do not describe changes; just simply output without any explanation - the final commit message MUST have only one line!")
 
     # User message
     if user_commit_message is not None:
         role_system.append("The user has already specified the commit message; please consider it as a suggestion if applicable.")
         role_system.append("The user's message starts after the 'USER-MESSAGE:' marker.")
@@ -147,57 +127,61 @@
 
     role_system.append("Use the present tense.")
     role_system.append("Lines must be at most 72 characters.")
 
     role_system_prompt = " ".join(role_system)
     role_user_prompt = " ".join(role_user)
 
-    logging.debug(f"ROLE_SYSTEM_PROMPT: {role_system_prompt}")
-    logging.debug(f"ROLE_USER_PROMPT: {role_user_prompt}")
+    logger.debug(f"ROLE_SYSTEM_PROMPT: {role_system_prompt}")
+    logger.debug(f"ROLE_USER_PROMPT: {role_user_prompt}")
 
     return [
         {"role": "system", "content": role_system_prompt},
         {"role": "user", "content": role_user_prompt},
     ]
 
 
-def get_openai_chat_response(messages: List[Dict[str, str]], args: Namespace) -> str:
+def get_openai_chat_response(messages: List[Dict[str, str]], args: argparse.Namespace) -> str:
     """Get OpenAI Chat Response."""
-    config = _get_openai_config(args)
-    openai.api_key = config["openai_api_key"]
-    openai.organization = config["openai_organization"]
-    openai.api_base = config["openai_api_base"]
-    openai.api_type = config["openai_api_type"]
-    openai.proxy = config["openai_proxy"]
+    if logger.isEnabledFor(logging.DEBUG):
+        _num_tokens_from_messages(messages, str(args.openai_model))
+        openai.debug = True
+
+    openai.api_key = args.openai_api_key
+    openai.organization = args.openai_organization
+    openai.api_base = args.openai_api_base
+    openai.api_type = args.openai_api_type
+    openai.proxy = args.openai_proxy
 
     # ref: https://platform.openai.com/docs/api-reference/chat-completions/create
     # ref: https://platform.openai.com/docs/guides/chat
     response = openai.ChatCompletion.create(
-        model=args.openai_chat_model,
+        model=args.openai_model,
         messages=messages,
+        max_tokens=int(args.openai_max_tokens),
         temperature=0,
         top_p=0.1,
     )
-    logging.debug(f"OPENAI_CHAT_RESPONSE: {response}")
+    logger.debug(f"OPENAI_CHAT_RESPONSE: {response}")
 
-    return response.choices[0].message.content
+    return response["choices"][0]["message"]["content"]
 
 
-def num_tokens_from_messages(messages: List[Dict[str, str]], model: str) -> int:
+def _num_tokens_from_messages(messages: List[Dict[str, str]], model: str) -> int:
     """Return the number of tokens used by a list of messages."""
     try:
         encoding = tiktoken.encoding_for_model(model)
     except KeyError:
         encoding = tiktoken.get_encoding("cl100k_base")
     if model == "gpt-3.5-turbo":
         # Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.
-        return num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301")
+        return _num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301")
     if model == "gpt-4":
         # Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.
-        return num_tokens_from_messages(messages, model="gpt-4-0314")
+        return _num_tokens_from_messages(messages, model="gpt-4-0314")
     if model == "gpt-3.5-turbo-0301":
         tokens_per_message = 4  # every message follows <|start|>{role/name}\n{content}<|end|>\n
         tokens_per_name = -1  # if there's a name, the role is omitted
     elif model == "gpt-4-0314":
         tokens_per_message = 3
         tokens_per_name = 1
     else:
@@ -209,40 +193,48 @@
     for message in messages:
         num_tokens += tokens_per_message
         for key, value in message.items():
             num_tokens += len(encoding.encode(value))
             if key == "name":
                 num_tokens += tokens_per_name
     num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>
-    logging.debug(f"NUM_TOKENS: {num_tokens}")
+    logger.debug(f"NUM_TOKENS: {num_tokens}")
     return num_tokens
 
 
 def set_commit_message(commit_msg_file_path: str, commit_msg: str) -> None:
     """Set the suggested commit message."""
     commit_msg_file = Path(commit_msg_file_path)
     commit_msg_file_wrapper = commit_msg_file.open("r+", encoding="utf-8")
     current_content = commit_msg_file_wrapper.read().strip()
     commit_msg_file_wrapper.seek(0, 0)
     commit_msg_file_wrapper.write(f"{commit_msg}\n\n{current_content}")
     commit_msg_file_wrapper.close()
 
 
-def main() -> int:
+def main(args: argparse.Namespace) -> int:
     """Main function of module."""
     try:
-        args = get_args()
         user_commit_message = get_user_commit_message(args.commit_msg_filename, args.prepare_commit_message_source)
         git_diff = get_git_diff(args.max_char_count, ".")
-        openai_chat_prompt_messages = get_openai_chat_prompt_messages(user_commit_message, git_diff, args)
-        if logging.getLogger().isEnabledFor(logging.DEBUG):
-            num_tokens_from_messages(openai_chat_prompt_messages, args.openai_chat_model)
+        openai_chat_prompt_messages = get_openai_chat_prompt_messages(user_commit_message, git_diff, args.emoji, args.description)
         openai_chat_response = get_openai_chat_response(openai_chat_prompt_messages, args)
         set_commit_message(args.commit_msg_filename, openai_chat_response)
     except Exception as error:
         raise Exception(f"Sorry, something went wrong: {error}") from error  # noqa: TRY002
     else:
         return 0
 
 
 if __name__ == "__main__":
-    sys.exit(main())
+    args = get_args()
+    logger = logging.getLogger(__name__)
+    logger.setLevel(args.log_level.upper())
+
+    if logger.isEnabledFor(logging.DEBUG):
+        fh = logging.FileHandler(filename="debug.log", mode="w")
+        logger.addHandler(fh)
+
+    logger.debug(f"SYS_ARGV: {sys.argv}")
+    logger.debug(f"ARGS: {args}")
+
+    sys.exit(main(args))
```

## chatgpt_pre_commit_hooks/chatgpt_commit_message.py

```diff
@@ -1,144 +1,124 @@
 #!/usr/bin/env python3
 """chatgpt-commit-message pre-commit-hook.
 
 A pre-commit hook that utilizes ChatGPT to summarize changes made to the codebase on the 'git commit' event.
 The commit message is then used to populate the commit message automatically.
 """
 
+import argparse
 import logging
 import os
 import sys
-from argparse import ArgumentParser, BooleanOptionalAction, Namespace
 from pathlib import Path
 from typing import Dict, List, Optional
 
 import openai
 import tiktoken
 from git.repo import Repo
 
-logging.basicConfig(level=logging.NOTSET)
-# logging.basicConfig(level=logging.DEBUG, filename="debug.log", filemode="w")  # noqa: ERA001
+logger = logging.getLogger(__name__)
 
 
-def get_args() -> Namespace:
+def get_args() -> argparse.Namespace:
     """Get input arguments."""
-    logging.debug(f"SYS_ARGV: {sys.argv}")
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument("commit_msg_filename", nargs="?", default=None)  # args.commit_msg_filename
     parser.add_argument("prepare_commit_message_source", nargs="?", default=None)  # args.prepare_commit_message_source
     parser.add_argument("commit_object_name", nargs="?", default=None)  # args.commit_object_name
     parser.add_argument("--max-char-count", type=int, default=10000)  # args.max_char_count
-    parser.add_argument("--emoji", action=BooleanOptionalAction, default=False)  # args.emoji
-    parser.add_argument("--description", action=BooleanOptionalAction, default=False)  # args.description
+    parser.add_argument("--emoji", action=argparse.BooleanOptionalAction, default=False)  # args.emoji
+    parser.add_argument("--description", action=argparse.BooleanOptionalAction, default=False)  # args.description
+    parser.add_argument("--log-level", choices=[key.lower() for key in logging._nameToLevel], default="warning", required=False)  # args.log_level  # noqa: SLF001
     parser.add_argument("--env-prefix", type=str, default=None, required=False)  # args.env_prefix
-    parser.add_argument("--openai-chat-model", type=str, default="gpt-3.5-turbo")  # args.openai_chat_model
-    parser.add_argument("--openai-organization", type=str, default=None, required=False)  # args.openai_organization
-    parser.add_argument("--openai-api-base", type=str, default=None, required=False)  # args.openai_api_base
-    parser.add_argument("--openai-api-type", type=str, default=None, required=False)  # args.openai_api_type
-    parser.add_argument("--openai-proxy", type=str, default=None, required=False)  # args.openai_proxy
-    args = parser.parse_args()
-    logging.debug(f"ARGS: {args}")
-    return args
+
+    temp_args = parser.parse_args()
+    env_prefix = ""
+    if temp_args.env_prefix is not None and temp_args.env_prefix:
+        env_prefix = f"{temp_args.env_prefix.upper()}__"
+
+    parser.add_argument("--openai-model", type=str, default=os.environ.get(f"{env_prefix}OPENAI_MODEL", "gpt-3.5-turbo"))  # args.openai_model
+    parser.add_argument("--openai-max-tokens", type=int, default=os.environ.get(f"{env_prefix}OPENAI_MAX_TOKENS", "1024"))  # args.openai_max_tokens
+    parser.add_argument("--openai-api-base", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_BASE", openai.api_base))  # args.openai_api_base
+    parser.add_argument("--openai-api-type", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_TYPE", openai.api_type))  # args.openai_api_type
+    parser.add_argument("--openai-proxy", type=str, default=os.environ.get(f"{env_prefix}OPENAI_PROXY", None), required=False)  # args.openai_proxy
+    parser.add_argument("--openai-api-key", type=str, default=os.environ.get(f"{env_prefix}OPENAI_API_KEY", openai.api_key), help=argparse.SUPPRESS)  # args.openai_api_key
+
+    openai_api_type = parser.parse_args().openai_api_type
+    if openai_api_type == openai.api_type:
+        parser.add_argument(
+            "--openai-organization",
+            type=str,
+            default=os.environ.get(f"{env_prefix}OPENAI_ORGANIZATION", openai.organization),
+            help=argparse.SUPPRESS,
+            required=False,
+        )  # args.openai_organization
+
+    return parser.parse_args()
 
 
 def get_git_diff(max_char_count: int, git_repo_path: str) -> str:
     """Get git diff of staged changes - full or stat only.
 
     - full - if length of diff is less than max_char_count
     - stat - if length of diff is more than max_char_count
     """
     repo = Repo(git_repo_path)
     diff = repo.git.diff(staged=True)
     if len(diff) > max_char_count:
         diff = repo.git.diff(staged=True, stat=True)
-    logging.debug(f"GIT_DIFF: {diff}")
+    logger.debug(f"GIT_DIFF: {diff}")
     return diff
 
 
 def get_user_commit_message(commit_msg_file_path: str, prepare_commit_message_source: Optional[str]) -> Optional[str]:
     """Get user commit message (if specified)."""
-    logging.debug(f"PREPARE_COMMIT_MESSAGE_SOURCE: {prepare_commit_message_source}")
+    logger.debug(f"PREPARE_COMMIT_MESSAGE_SOURCE: {prepare_commit_message_source}")
     user_commit_message = None
     if prepare_commit_message_source == "message" or prepare_commit_message_source is None:
         commit_msg_file = Path(commit_msg_file_path)
         commit_msg_file_wrapper = commit_msg_file.open(encoding="utf-8")
         lines = [line for line in commit_msg_file_wrapper.readlines() if not line.startswith("#") and line.strip()]
         commit_msg_file_wrapper.close()
         logging.debug(f"USER_COMMIT_MESSAGE_LINES: {lines}")
         if lines != []:
             user_commit_message = "".join(lines).strip()
 
-    logging.debug(f"USER_COMMIT_MESSAGE: {user_commit_message}")
+    logger.debug(f"USER_COMMIT_MESSAGE: {user_commit_message}")
 
     if user_commit_message is not None:
         skip_keywords = ["#no-ai", "#no-openai", "#no-chatgpt", "#no-gpt", "#skip-ai", "#skip-openai", "#skip-chatgpt", "#skip-gpt"]
         if any(skip_keyword.casefold() in user_commit_message.casefold() for skip_keyword in skip_keywords):
             logging.debug(f"USER_COMMIT_MESSAGE: {user_commit_message} - SKIPPED")
             sys.exit(0)
 
     return user_commit_message
 
 
-def _get_openai_config(args: Namespace) -> Dict[str, Optional[str]]:
-    """Get OpenAI API Key from environment variable."""
-    env_prefix = ""
-    if args.env_prefix is not None:
-        env_prefix = f"{args.env_prefix.upper()}__"
-
-    # https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety
-    openai_api_key = os.environ.get(f"{env_prefix}OPENAI_API_KEY", openai.api_key)  # $env:OPENAI_API_KEY
-    if openai_api_key is None or not openai_api_key:
-        raise ValueError(f"`{env_prefix}OPENAI_API_KEY` environment variable is not set.")
-
-    openai_organization = os.environ.get(f"{env_prefix}OPENAI_ORGANIZATION", openai.organization)  # $env:OPENAI_ORGANIZATION
-    if args.openai_organization is not None:
-        openai_organization = args.openai_organization
-
-    openai_api_base = os.environ.get(f"{env_prefix}OPENAI_API_BASE", openai.api_base)  # $env:OPENAI_API_BASE
-    if args.openai_api_base is not None:
-        openai_api_base = args.openai_api_base
-
-    openai_api_type = os.environ.get(f"{env_prefix}OPENAI_API_TYPE", openai.api_type)  # $env:OPENAI_API_TYPE
-    if args.openai_api_type is not None:
-        openai_api_type = args.openai_api_type
-
-    openai_proxy = os.environ.get(f"{env_prefix}OPENAI_PROXY", openai.api_version)  # $env:OPENAI_PROXY
-    if args.openai_proxy is not None:
-        openai_proxy = args.openai_proxy
-
-    return {
-        "openai_api_key": openai_api_key,
-        "openai_organization": openai_organization,
-        "openai_api_base": openai_api_base,
-        "openai_api_type": openai_api_type,
-        "openai_proxy": openai_proxy,
-    }
-
-
-def get_openai_chat_prompt_messages(user_commit_message: Optional[str], git_diff: str, args: Namespace) -> List[Dict[str, str]]:
+def get_openai_chat_prompt_messages(user_commit_message: Optional[str], git_diff: str, emoji: bool, description: bool) -> List[Dict[str, str]]:  # noqa: FBT001
     """Get prompt messages."""
     role_system = [
         "You are a software engineer assistant to write a 'Commit message with scope'.",
         "You aim to suggest a clean commit message in the 'Conventional Commits' convention.",
         "You will get an output from the 'git diff --staged' or 'git diff --staged --stat' command, and you will suggest a commit message.",
     ]
     role_user = [git_diff]
 
     # GitMoji
-    if args.emoji is True:
+    if emoji is True:
         role_system.append("Use the 'GitMoji convention' to preface the commit with the UNICODE characters format.")
         role_system.append("Do not use shortcode representation.")
     else:
         role_system.append("Do not preface the commit message with anything.")
 
     # description
-    if args.description is True:
+    if description is True:
         role_system.append("Add a short description to the commit message in the body section of why these changes were made.")
         role_system.append('Omit "This commit" at the beginning - briefly describe changes.')
+        role_system.append("Each sentence of the description should be in new line.")
     else:
         role_system.append("Do not describe changes; just simply output without any explanation - the final commit message MUST have only one line!")
 
     # User message
     if user_commit_message is not None:
         role_system.append("The user has already specified the commit message; please consider it as a suggestion if applicable.")
         role_system.append("The user's message starts after the 'USER-MESSAGE:' marker.")
@@ -147,57 +127,61 @@
 
     role_system.append("Use the present tense.")
     role_system.append("Lines must be at most 72 characters.")
 
     role_system_prompt = " ".join(role_system)
     role_user_prompt = " ".join(role_user)
 
-    logging.debug(f"ROLE_SYSTEM_PROMPT: {role_system_prompt}")
-    logging.debug(f"ROLE_USER_PROMPT: {role_user_prompt}")
+    logger.debug(f"ROLE_SYSTEM_PROMPT: {role_system_prompt}")
+    logger.debug(f"ROLE_USER_PROMPT: {role_user_prompt}")
 
     return [
         {"role": "system", "content": role_system_prompt},
         {"role": "user", "content": role_user_prompt},
     ]
 
 
-def get_openai_chat_response(messages: List[Dict[str, str]], args: Namespace) -> str:
+def get_openai_chat_response(messages: List[Dict[str, str]], args: argparse.Namespace) -> str:
     """Get OpenAI Chat Response."""
-    config = _get_openai_config(args)
-    openai.api_key = config["openai_api_key"]
-    openai.organization = config["openai_organization"]
-    openai.api_base = config["openai_api_base"]
-    openai.api_type = config["openai_api_type"]
-    openai.proxy = config["openai_proxy"]
+    if logger.isEnabledFor(logging.DEBUG):
+        _num_tokens_from_messages(messages, str(args.openai_model))
+        openai.debug = True
+
+    openai.api_key = args.openai_api_key
+    openai.organization = args.openai_organization
+    openai.api_base = args.openai_api_base
+    openai.api_type = args.openai_api_type
+    openai.proxy = args.openai_proxy
 
     # ref: https://platform.openai.com/docs/api-reference/chat-completions/create
     # ref: https://platform.openai.com/docs/guides/chat
     response = openai.ChatCompletion.create(
-        model=args.openai_chat_model,
+        model=args.openai_model,
         messages=messages,
+        max_tokens=int(args.openai_max_tokens),
         temperature=0,
         top_p=0.1,
     )
-    logging.debug(f"OPENAI_CHAT_RESPONSE: {response}")
+    logger.debug(f"OPENAI_CHAT_RESPONSE: {response}")
 
-    return response.choices[0].message.content
+    return response["choices"][0]["message"]["content"]
 
 
-def num_tokens_from_messages(messages: List[Dict[str, str]], model: str) -> int:
+def _num_tokens_from_messages(messages: List[Dict[str, str]], model: str) -> int:
     """Return the number of tokens used by a list of messages."""
     try:
         encoding = tiktoken.encoding_for_model(model)
     except KeyError:
         encoding = tiktoken.get_encoding("cl100k_base")
     if model == "gpt-3.5-turbo":
         # Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.
-        return num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301")
+        return _num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301")
     if model == "gpt-4":
         # Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.
-        return num_tokens_from_messages(messages, model="gpt-4-0314")
+        return _num_tokens_from_messages(messages, model="gpt-4-0314")
     if model == "gpt-3.5-turbo-0301":
         tokens_per_message = 4  # every message follows <|start|>{role/name}\n{content}<|end|>\n
         tokens_per_name = -1  # if there's a name, the role is omitted
     elif model == "gpt-4-0314":
         tokens_per_message = 3
         tokens_per_name = 1
     else:
@@ -209,40 +193,48 @@
     for message in messages:
         num_tokens += tokens_per_message
         for key, value in message.items():
             num_tokens += len(encoding.encode(value))
             if key == "name":
                 num_tokens += tokens_per_name
     num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>
-    logging.debug(f"NUM_TOKENS: {num_tokens}")
+    logger.debug(f"NUM_TOKENS: {num_tokens}")
     return num_tokens
 
 
 def set_commit_message(commit_msg_file_path: str, commit_msg: str) -> None:
     """Set the suggested commit message."""
     commit_msg_file = Path(commit_msg_file_path)
     commit_msg_file_wrapper = commit_msg_file.open("r+", encoding="utf-8")
     current_content = commit_msg_file_wrapper.read().strip()
     commit_msg_file_wrapper.seek(0, 0)
     commit_msg_file_wrapper.write(f"{commit_msg}\n\n{current_content}")
     commit_msg_file_wrapper.close()
 
 
-def main() -> int:
+def main(args: argparse.Namespace) -> int:
     """Main function of module."""
     try:
-        args = get_args()
         user_commit_message = get_user_commit_message(args.commit_msg_filename, args.prepare_commit_message_source)
         git_diff = get_git_diff(args.max_char_count, ".")
-        openai_chat_prompt_messages = get_openai_chat_prompt_messages(user_commit_message, git_diff, args)
-        if logging.getLogger().isEnabledFor(logging.DEBUG):
-            num_tokens_from_messages(openai_chat_prompt_messages, args.openai_chat_model)
+        openai_chat_prompt_messages = get_openai_chat_prompt_messages(user_commit_message, git_diff, args.emoji, args.description)
         openai_chat_response = get_openai_chat_response(openai_chat_prompt_messages, args)
         set_commit_message(args.commit_msg_filename, openai_chat_response)
     except Exception as error:
         raise Exception(f"Sorry, something went wrong: {error}") from error  # noqa: TRY002
     else:
         return 0
 
 
 if __name__ == "__main__":
-    sys.exit(main())
+    args = get_args()
+    logger = logging.getLogger(__name__)
+    logger.setLevel(args.log_level.upper())
+
+    if logger.isEnabledFor(logging.DEBUG):
+        fh = logging.FileHandler(filename="debug.log", mode="w")
+        logger.addHandler(fh)
+
+    logger.debug(f"SYS_ARGV: {sys.argv}")
+    logger.debug(f"ARGS: {args}")
+
+    sys.exit(main(args))
```

## docs/chatgpt_commit_message.md

```diff
@@ -1,62 +1,87 @@
 # chatgpt-commit-message
 
-[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)
+[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&style=flat-square)](https://github.com/pre-commit/pre-commit)
 
 Hook that uses OpenAI's ChatGPT API to generate a summary of changes made to a codebase and use it to populate the commit message automatically.
 
 Commit message structure based on [`Commit message with scope`](https://www.conventionalcommits.org/en/v1.0.0/#commit-message-with-scope) convention from [Conventional Commits](https://www.conventionalcommits.org).
 
+- [Setup](#setup)
+- [Configuration](#configuration)
+- [Usage](#usage)
+- [Skip suggestions](#skip-suggestions)
+- [References](#references)
+
 ## Setup
 
 This hook runs on the `prepare-commit-msg` stage and requires to be explicitly enabled. Unfortunately, the standard `pre-commit install` does not support the hook. To enable prepare-commit-msg support, please run the following:
 
 ```shell
 pre-commit install --hook-type prepare-commit-msg
 ```
 
 Add to your `.pre-commit-config.yaml`
 
 ```yaml
 repos:
   - repo: https://github.com/DariuszPorowski/chatgpt-pre-commit-hooks
-    rev: v0.0.1 # Use the ref you want to point at, see ‚ö†Ô∏è NOTE below!
+    rev: v0.1.1 # Use the ref you want to point at, see ‚ö†Ô∏è NOTE below!
     hooks:
       - id: chatgpt-commit-message
 ```
 
 > ‚ö†Ô∏è **NOTE**
 >
 > For the `rev:` always try to use the latest version. You can check the latest release under [GitHub Releases](https://github.com/DariuszPorowski/chatgpt-pre-commit-hooks/releases/latest)
 
 ## Configuration
 
-The hook can take optional arguments.
+The hook uses global configuration settings or arguments specified in the [üì• Prerequisites setup](https://github.com/DariuszPorowski/chatgpt-pre-commit-hooks/blob/main/README.md#-prerequisites-setup) and [üõ†Ô∏è Advanced configuration](https://github.com/DariuszPorowski/chatgpt-pre-commit-hooks/blob/main/README.md#Ô∏è-advanced-configuration) sections and takes own optional arguments listed below:
 
-| Name               | Type | Default | Description                                                                                                                                                                                             |
-|:-------------------|:----:|:-------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
-| `--max-char-count` | int  |  10000  | Send `git diff --staged --stat` results instead of the full diff of staged changes if the diff length is more than NNN characters                                                                       |
-| `--emoji`          | bool |  false  | Use [GitMoji](https://gitmoji.dev) to preface commit message üí•                                                                                                                                         |
-| `--description`    | bool |  false  | Add short changes summary description to the commit (see, [Commit message with description](https://www.conventionalcommits.org/en/v1.0.0/#commit-message-with-description-and-breaking-change-footer)) |
+| Name               | Type | Default | Description                                                                                                                                                                                                                                           |
+|:-------------------|:----:|:-------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| `--max-char-count` | int  |  10000  | Send `git diff --staged --stat` results instead of the full diff of staged changes if the diff length is more than NNN characters                                                                                                                     |
+| `--emoji`          | bool |  false  | Use [GitMoji](https://gitmoji.dev) to preface commit message. Flag type argument, if it exists, it's True.üí•                                                                                                                                          |
+| `--description`    | bool |  false  | Add short changes summary description to the commit (see, [Commit message with description](https://www.conventionalcommits.org/en/v1.0.0/#commit-message-with-description-and-breaking-change-footer)). Flag type argument, if it exists, it's True. |
 
 Example:
 
 ```yaml
 repos:
   - repo: https://github.com/DariuszPorowski/chatgpt-pre-commit-hooks
-    rev: v0.0.1 # Use the ref you want to point at, see ‚ö†Ô∏è NOTE below!
+    rev: v0.1.1 # Use the ref you want to point at, see ‚ö†Ô∏è NOTE below!
     hooks:
       - id: chatgpt-commit-message
         args:
+          - "--emoji"
           - "--max-char-count"
           - "500"
-          - "--emoji"
           - "--description"
 ```
 
+## Usage
+
+Staged changes and commit:
+
+```shell
+git add <files...>
+git commit
+```
+
+Example commit message prefaced with GitMoji and description:
+
+```md
+‚ú® feat(scope): add pre-commit hooks and VSCode settings
+
+This commit adds pre-commit hooks and VSCode settings to improve code quality and consistency.
+The `.pre-commit-hooks.yaml` file contains hooks for linting, formatting, and checking for security vulnerabilities.
+The `.vscode/settings.json` file includes settings for linting and formatting on save.
+```
+
 ## Skip suggestions
 
 If your **commit message** includes one of the keywords: `#no-ai`, `#no-openai`, `#no-chatgpt`, `#no-gpt`, `#skip-ai`, `#skip-openai`, `#skip-chatgpt`, `#skip-gpt`, then the commit suggestion will be skipped without any request to OpenAI service, and the pre-commit hook will pass.OpenAI service, and pre-commit hook will pass.
 
 Example:
 
 ```text
```

## Comparing `chatgpt_pre_commit_hooks-0.1.0.dist-info/LICENSE` & `chatgpt_pre_commit_hooks-0.1.1.dist-info/LICENSE`

 * *Files identical despite different names*

