# Comparing `tmp/otx-1.1.2rc1.tar.gz` & `tmp/otx-1.2.0rc1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "otx-1.1.2rc1.tar", last modified: Tue Apr  4 14:10:57 2023, max compression
+gzip compressed data, was "otx-1.2.0rc1.tar", last modified: Tue Apr 18 01:20:06 2023, max compression
```

## Comparing `otx-1.1.2rc1.tar` & `otx-1.2.0rc1.tar`

### file list

```diff
@@ -1,2656 +1,2552 @@
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10254 2022-03-10 20:00:18.000000 otx-1.1.2rc1/LICENSE
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      182 2023-04-04 07:33:45.000000 otx-1.1.2rc1/MANIFEST.in
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10704 2023-04-04 14:10:57.648256 otx-1.1.2rc1/PKG-INFO
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9865 2023-04-04 14:09:57.000000 otx-1.1.2rc1/README.md
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      669 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      171 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      184 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      723 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      411 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      841 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5835 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/cls_dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14035 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/det_dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      705 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2185 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/loading.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      443 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      443 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    29494 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/backbones/movinet.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/detectors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/detectors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4811 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/detectors/fast_rcnn.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      256 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2617 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/movinet_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1336 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/roi_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      227 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1678 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/movinet_recognizer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      363 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3970 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/config_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4722 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/det_eval_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5451 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/export_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9452 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/dataloader.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      713 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7245 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/model_wrappers/openvino_models.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/configs/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2815 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/base/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/configs/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      119 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10915 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2732 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      124 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1880 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1425 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2717 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      120 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1899 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1413 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/configs/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2643 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/ava_data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/base_detection_dynamic.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      824 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/base_detection_static.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2546 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4166 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/faster_rcnn_config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10915 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      647 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      120 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2444 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1453 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      839 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21513 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/action/tasks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15513 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/tasks/openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10169 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/action/tasks/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6378 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/tools/sample_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4202 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/tools/sample_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/action/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13043 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/utils/convert_public_data_to_cvat.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7588 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/action/utils/data.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      611 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      114 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      765 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8073 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5246 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/progress.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/config/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      801 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/config/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4653 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/config/anomalib_config.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      705 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9651 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/create_mvtec_ad_json_annotations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10895 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13301 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6963 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/mvtec.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      412 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1709 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1486 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1501 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1949 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/base.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/logger/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      655 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/logger/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3089 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/logger/logger.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      852 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4700 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1672 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/configuration_enums.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/draem/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      220 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/draem/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3750 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/draem/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.504256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      718 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/padim/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1843 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/padim/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      718 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/stfpm/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4165 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/stfpm/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      628 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      688 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/template_experimental.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/transform_config.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/pot_optimization_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      868 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      623 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      678 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/template_experimental.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      609 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/transform_config.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/pot_optimization_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      803 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      926 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      626 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      684 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/template_experimental.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/transform_config.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.508256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/pot_optimization_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      809 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      932 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      825 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16615 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9360 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    20885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5187 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tasks/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/anomaly/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1558 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tools/README.md
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      643 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15297 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/anomaly/tools/sample.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      621 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      616 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1149 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1163 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    18559 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/otx_datasets.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      714 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5114 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/otx_pipelines.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      491 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9416 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/augmix.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2458 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/otx_transforms.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6236 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/random_augment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      980 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/twocrop_transform.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      700 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1219 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      981 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8899 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/byol.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13149 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      424 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1740 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1725 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_multilabel_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1304 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/supcon_classifier.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1937 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1100 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1672 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/contrastive_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2990 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/conv_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3896 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7145 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_linear_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8458 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_non_linear_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5164 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_linear_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5410 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_non_linear_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3317 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/mmov_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3438 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/non_linear_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9446 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11985 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_multilabel_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3793 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/supcon_cls_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.512256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1066 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4450 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_angular_loss_with_ignore.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4079 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_loss_with_ignore.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2195 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/barlowtwins_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1990 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/cross_entropy_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2397 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/ib_loss.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      731 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      881 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/mmov_neck.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3968 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/selfsl_mlp.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      211 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6053 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/patches.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      615 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/registers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/optimizer/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      676 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/optimizer/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5757 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/optimizer/lars.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      267 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1502 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/evaluator.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3753 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/explainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2513 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/exporter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      261 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/incremental/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      673 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/incremental/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3956 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/incremental/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/incremental/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5356 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/inferrer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      327 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      649 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/semisl/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      838 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/semisl/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/semisl/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7788 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4755 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/trainer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      294 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1381 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2896 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/config_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      627 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      685 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7534 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/openvino_models.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      710 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2391 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1901 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2124 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/selfsl/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2575 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/semisl/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2025 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/supcon/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/deployments/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      126 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/deployments/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      326 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/deployments/base_classification_dynamic.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      601 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/deployments/base_classification_static.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.516256 otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      615 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/efficientnet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      382 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/efficientnet_v2.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      455 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/mobilenet_v3.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10286 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1850 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      724 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      493 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      519 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_hierarchical.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      683 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      687 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      521 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      898 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      741 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1424 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1550 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      727 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      275 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      441 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      510 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_hierarchical.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      574 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      683 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      693 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      469 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      904 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      741 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1432 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      660 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1850 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      725 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      274 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      414 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      606 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_hierarchical.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      603 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      688 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      743 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      719 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.520256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1208 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/template_experiment.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1850 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      268 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      276 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      538 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      564 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_hierarchical.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      731 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      690 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      728 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      566 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      919 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      738 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      728 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1443 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1850 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      291 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      477 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model_hierarchical.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      474 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      686 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      641 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      642 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      738 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      639 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1189 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/template_experiment.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1230 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22145 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/tasks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3953 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/tasks/nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    18146 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/tasks/openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7109 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/classification/tasks/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14157 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/tools/classification_sample.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/classification/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      425 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/classification/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4567 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/classification/utils/cls_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3815 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/classification/utils/convert_coco_to_multilabel.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/common/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/common/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1758 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.524256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      639 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      641 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      233 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/efficientnet_b2b.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1959 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_18.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1982 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_s.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2073 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_x.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      147 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      195 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/resnet18.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      257 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/resnet50.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2959 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5508 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/adaptive_training_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3188 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/cancel_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6782 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/checkpoint_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1872 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/composed_dataloaders_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4272 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/custom_model_ema_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5452 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/dual_model_ema_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    17466 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/early_stopping_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5065 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/eval_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1358 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/force_train_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3967 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/fp16_sam_optimizer_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1367 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/ib_loss_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2824 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/logger_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4704 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/model_ema_v2_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2917 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/no_bias_decay_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4174 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/progress_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9741 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/recording_forward_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3708 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/sam_optimizer_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2514 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/semisl_cls_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2802 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/task_adapt_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3608 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/two_crop_transform_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2144 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/unbiased_teacher_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3968 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/workflow_hook.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      875 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      859 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    43270 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3916 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnetv2.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12125 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/mobilenetv3.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9658 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/torchvision_backbones.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      862 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/builder.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      258 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      986 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1549 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/patches.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7201 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/runners.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9695 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      105 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8618 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/augments.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      115 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4231 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14827 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6020 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/runner.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.528256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      916 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4176 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4150 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/exporter_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      218 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/registry.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21862 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      226 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/version.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3771 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/workflow.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1333 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2369 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_builder_build_data_parallel.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2157 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_keys.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2386 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_pairs.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    19011 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/config_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      192 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11678 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/apis.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      345 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2181 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/mmdeploy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1698 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/onnx.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      313 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/operations_domain.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2117 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1070 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2927 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/compression.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4808 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2307 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/patches.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      524 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3525 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/utils/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      197 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2127 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/composed_dataloader.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      292 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4791 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/balanced_sampler.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5221 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/cls_incr_sampler.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      852 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/configs/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/configs/configuration_enums.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13039 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/configs/training_base.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      695 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13221 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/tasks/nncf_base.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    28004 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/tasks/training_base.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/tools/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/common/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1266 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4852 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/utils/callback.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7540 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/utils/data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      528 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/utils/distance_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      707 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/utils/ext_loader.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/common/utils/ir.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4146 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/utils/logger.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1803 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/common/utils/mask_to_bbox.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5905 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/utils/mo_wrapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3821 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/common/utils/task_adapt.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3011 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/common/utils/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      112 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      612 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      487 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      845 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16450 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      703 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3553 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/load_pipelines.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5488 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/torchvision2mmdet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2792 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/task_adapt_dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    19125 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/tiling.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.532256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/evaluation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      183 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/evaluation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10691 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/evaluation/mean_ap_seg.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/hooks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      210 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/hooks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5629 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/hooks/det_saliency_map_hook.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      122 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      231 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6164 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/imgclsmob.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      311 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3319 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_rpn_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5550 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_ssd_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2887 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_yolov3_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      822 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5443 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_atss_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5920 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8444 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_single_stage_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3745 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_two_stage_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2928 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_vfnet_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6964 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_yolox_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      938 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/l2sp_detector_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      466 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/sam_detector_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8502 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/unbiased_teacher.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      743 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10471 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/cross_dataset_detector_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2436 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_anchor_generator.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9132 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_atss_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3021 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_retina_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8491 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_roi_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7056 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_ssd_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9589 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_vfnet_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_yolox_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      254 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3813 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/cross_focal_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3368 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/l2sp_loss.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      306 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3014 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_fpn.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7849 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_ssd_neck.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2465 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_yolov3_neck.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      196 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4090 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/mmov_bbox_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      196 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2228 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/mmov_mask_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      224 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2278 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9261 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5678 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/patches.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.536256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      840 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6535 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/explainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2527 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/exporter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      284 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/incremental/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      711 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/incremental/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1607 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/incremental/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      702 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/incremental/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8229 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/inferrer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      433 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      769 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/exporter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      807 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1974 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      682 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/semisl/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12309 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4688 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/trainer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      484 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1530 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11485 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/config_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6225 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/openvino_models.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      704 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3190 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      426 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_detection_dynamic.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      904 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_detection_static.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      579 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_dynamic.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      294 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_static.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      626 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      764 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      786 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1215 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/single_stage_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      823 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/unbiased_teacher.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      114 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13095 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      667 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3121 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      272 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      288 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1600 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      646 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      667 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4205 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1695 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1479 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3415 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      637 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1741 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2577 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      285 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2701 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.540256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1741 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4204 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2799 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1479 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1859 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2523 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3023 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      644 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1847 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4082 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3121 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1474 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2914 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3015 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1117 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/template_experimental.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3037 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      633 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13104 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      669 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      886 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2629 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      367 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4860 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1506 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3042 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      662 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2448 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      360 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5285 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1485 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3040 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      127 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12668 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      163 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      886 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2132 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      372 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4363 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1518 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3042 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.544256 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1951 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      365 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4788 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1497 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/template.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3040 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/tile_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/detection/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1092 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22839 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/tasks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4957 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/tasks/nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    26441 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/tasks/openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10463 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/detection/tasks/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/detection/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13421 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/tools/detection_sample.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11060 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/tools/detection_semisl_sample.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15484 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/detection/tools/instance_segmentation_sample.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/detection/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1073 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/detection/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    19578 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/detection/utils/data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4510 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/algorithms/detection/utils/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      115 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      616 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1661 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1038 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10268 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      911 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4681 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/compose.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2128 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/loads.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12487 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/transforms.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1389 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      752 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    48294 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/litehrnet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      779 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      754 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      888 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/custom_fcn_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11615 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2673 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mmov_decode_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      773 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5488 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_pixel_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4014 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_weighted_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2329 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/cross_entropy_loss_with_ignore.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7671 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/detcon_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2652 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/otx_pixel_base.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      685 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3900 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/selfsl_mlp.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      856 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/base.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      691 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/constant.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1933 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/poly.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1734 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/step.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.548256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      886 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4121 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/class_incr_encoder_decoder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21559 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/detcon.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4764 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mean_teacher_segmentor.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7452 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2352 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/otx_encoder_decoder.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      844 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6642 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/aggregator.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1043 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/angular_pw_conv.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2919 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/asymmetric_position_attention.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      991 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/channel_shuffle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2106 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/local_attention.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2016 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/loss_equalizer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1248 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/normalize.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      879 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/psp_layer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      770 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6519 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5324 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      406 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/patches.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      673 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2505 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/exporter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      249 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      586 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1375 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7006 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/inferrer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1065 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/exporter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1019 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1363 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5823 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4468 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/trainer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1139 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2073 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12092 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/config_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9553 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/data_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      706 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4136 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/blur.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      117 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6231 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/configuration.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      969 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/configuration_enums.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2269 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2311 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/selfsl/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      137 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2236 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/semisl/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/supcon/data_pipeline.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/deployments/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      131 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/deployments/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      347 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_dynamic.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      609 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_static.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/models/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11193 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/configuration.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.552256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1379 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1735 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2128 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/pot_optimization_config.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1764 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1959 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1327 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1404 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1795 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5948 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/pot_optimization_config.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1769 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2024 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2458 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1554 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1375 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      282 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2052 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4678 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/pot_optimization_config.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1763 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2233 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2712 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1589 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.556256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1379 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/compression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      331 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/deployment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/hpo_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1950 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11279 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/pot_optimization_config.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1769 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2183 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/data_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/hparam.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2616 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1570 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1125 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12118 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4066 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16768 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7892 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tasks/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15211 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/tools/segmentation_sample.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/algorithms/segmentation/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      654 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/algorithms/segmentation/utils/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      118 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/configuration/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1293 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/api/configuration/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1164 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/configurable_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3092 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/default_model_parameters.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/configuration/elements/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2259 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/configurable_enum.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2267 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/metadata_keys.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8015 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/parameter_group.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21228 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/primitive_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10385 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/elements/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/configuration/enums/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/enums/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1276 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/enums/auto_hpo_state.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2572 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/enums/config_element_type.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2320 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/enums/model_lifecycle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      608 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/enums/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/configuration/helper/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      647 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2398 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/config_element_mapping.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6091 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/convert.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16158 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/create.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8876 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/substitute.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6520 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1081 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/helper/validate.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      397 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/model_lifecycle.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.560256 otx-1.1.2rc1/otx/api/configuration/ui_rules/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      290 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/ui_rules/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3897 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/ui_rules/rules.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1088 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/ui_rules/types.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/configuration/ui_rules/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/entities/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11281 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/annotation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4820 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/color.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1221 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/coordinate.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    19779 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/api/entities/dataset_item.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15135 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/datasets.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4689 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/graph.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2218 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/id.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4156 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/image.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1589 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/inference_parameters.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/entities/interfaces/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       96 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/interfaces/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2195 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/interfaces/graph_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6910 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/label.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    29681 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/label_schema.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1659 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/api/entities/media.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3656 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/metadata.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    24787 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/metrics.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15509 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    24344 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/model_template.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1482 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/optimization_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4793 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/api/entities/result_media.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6161 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/resultset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4032 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/scored_label.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/entities/shapes/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      219 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/shapes/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9894 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/shapes/ellipse.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8460 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/shapes/polygon.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11336 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/shapes/rectangle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6675 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/shapes/shape.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      569 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/subset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5151 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/task_environment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1462 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/tensor.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2350 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/api/entities/train_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3857 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/entities/url.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/py.typed
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/serialization/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      140 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/serialization/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      897 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/serialization/datetime_mapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      521 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/serialization/id_mapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6329 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/serialization/label_mapper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      210 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      138 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/adapters/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1812 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/adapters/model_adapter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/evaluation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13620 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/accuracy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4574 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/anomaly_metrics.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      304 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/averaging.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6011 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/basic_operations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8622 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/dice.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    37276 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/f_measure.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3667 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/metrics_helper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      505 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/evaluation/performance_provider_interface.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/exportable_code/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      118 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10254 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/LICENSE
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4906 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/README.md
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      105 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3180 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.564256 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      451 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      317 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2643 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/asynchronous.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3509 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/sync_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1605 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/synchronous.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4480 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/model_container.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1744 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/requirements.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      818 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/setup.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/exportable_code/inference/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      358 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/inference/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13198 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/inference/inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    20321 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/prediction_to_annotation_converter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/exportable_code/streamer/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      513 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/streamer/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10472 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/streamer/streamer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      282 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2495 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/anomaly_visualizer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2946 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/visualizer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/reporting/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      430 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/reporting/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2556 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/reporting/callback.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6662 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/api/usecases/reporting/time_monitor_callback.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/exceptions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      601 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/image_computer_vision.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/image_deep_learning_task.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/deployment_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1146 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/evaluate_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      853 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/explain_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1125 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/export_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1810 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/inference_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1320 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/optimization_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2174 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/training_interface.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      848 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/unload_interface.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/api/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      161 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3106 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/anomaly_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    18278 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/argument_checks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9844 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/dataset_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1580 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/detection_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      973 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/importing.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      625 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/labels_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2123 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/nms.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10883 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/segmentation_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    25788 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/shape_drawer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7691 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/shape_factory.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6553 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/tiler.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5895 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/time_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      874 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/api/utils/vis_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/cli/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      224 2023-03-17 02:05:10.000000 otx-1.1.2rc1/otx/cli/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/cli/builder/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      673 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/builder/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10855 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/builder/builder.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/cli/builder/supported_backbone/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7692 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmcls.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4855 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmdet.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4712 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmseg.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1714 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/omz.mmcls.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      604 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/otx.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13954 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/cli/builder/supported_backbone/torchvision.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/cli/manager/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      192 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/manager/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    23952 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/manager/config_manager.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.568256 otx-1.1.2rc1/otx/cli/registry/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/registry/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4852 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/registry/registry.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/cli/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      603 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4263 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/build.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2365 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/cli/tools/cli.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5964 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/demo.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3380 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/deploy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5598 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/eval.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5456 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/explain.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4207 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/export.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4749 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/cli/tools/find.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5825 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/optimize.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9695 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/tools/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/cli/tools/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      607 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/tools/utils/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/cli/tools/utils/demo/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      625 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/tools/utils/demo/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6805 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/tools/utils/demo/images_capture.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6585 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/tools/utils/demo/visualization.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/cli/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3190 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/utils/config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/utils/errors.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    32272 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/utils/hpo.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4220 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/cli/utils/importing.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8128 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/utils/io.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11473 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/cli/utils/multi_gpu.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1572 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/utils/nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8855 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/cli/utils/parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/cli/utils/telemetry.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      598 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      605 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/data/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/data/adapter/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4641 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/data/adapter/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10257 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/data/adapter/action_dataset_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10539 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/data/adapter/anomaly_dataset_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12227 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/data/adapter/base_dataset_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4237 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/adapter/classification_dataset_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2906 2023-03-24 16:15:11.000000 otx-1.1.2rc1/otx/core/data/adapter/detection_dataset_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10333 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/data/adapter/segmentation_dataset_adapter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/data/caching/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      310 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/caching/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6345 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/data/caching/mem_cache_handler.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1110 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/caching/mem_cache_hook.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/data/manager/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      611 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/data/manager/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4951 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/manager/dataset_manager.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/data/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3306 2023-03-22 04:37:38.000000 otx-1.1.2rc1/otx/core/data/pipelines/load_image_from_otx_dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/ov/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      180 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/ov/graph/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    23734 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/graph.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/ov/graph/parsers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      168 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/parsers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/parsers/builder.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.572256 otx-1.1.2rc1/otx/core/ov/graph/parsers/cls/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      197 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/parsers/cls/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3134 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/parsers/cls/cls_base_parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      605 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/parsers/parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11467 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/graph/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/core/ov/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      338 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/models/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2120 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/models/mmov_model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    18664 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/models/ov_model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2517 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/models/parser_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14075 2023-04-04 14:09:57.000000 otx-1.1.2rc1/otx/core/ov/omz_wrapper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/core/ov/ops/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2929 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7882 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/activations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3656 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/arithmetics.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2030 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3610 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/convolutions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      931 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/generation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4827 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/image_processings.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8400 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/infrastructures.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1332 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/matmuls.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/core/ov/ops/modules/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      185 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/modules/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3214 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/modules/op_module.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15619 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/movements.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6203 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/normalizations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6465 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/object_detections.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2915 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/op.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5286 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/poolings.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3241 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/reductions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4374 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/shape_manipulations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2985 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/sorting_maximization.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1855 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/type_conversions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1094 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/ops/utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1687 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/registry.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4004 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/core/ov/utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8161 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/core/patcher.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/hpo/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      777 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/hpo/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11558 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/hpo/hpo_base.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7636 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/hpo/hpo_runner.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    37708 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/hpo/hyperband.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8161 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/hpo/resource_manager.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    17281 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/hpo/search_space.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3194 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/hpo/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/stages/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/stages/_base_/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/stages/_base_/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      962 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      963 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_inst_seg.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      958 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_otx.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1333 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_ubt.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/custom_seg.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      115 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      788 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/data_seg.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1066 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_inst_seg_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1092 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_otx_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      984 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_resize_hflip_pad.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1391 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/incr_seg.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      947 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/twocrop_pipeline.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3091 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/ubt.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      453 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/seg_semisl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1633 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/selfsl_cls_data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1696 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/selfsl_seg_data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      489 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/data/twocrop_data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      142 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/default.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.576256 otx-1.1.2rc1/otx/recipes/stages/_base_/dist/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/dist/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       57 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/dist/dist.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/logs/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/logs/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       19 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/logs/log.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      180 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/logs/tensorboard_logger.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      145 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/logs/text_logger.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/models/classifiers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/classifiers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      341 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/classifiers/classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      181 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/cls_semisl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      604 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/cls_supcon.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/models/detectors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/detectors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       92 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/detectors/detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      131 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      686 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/encoder_decoder.ote.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/seg_class_incr.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       95 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/segmentor.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       67 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/adam.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/lars.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       86 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/optimizer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/optimizers/sgd.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      104 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/epoch_runner.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/epoch_runner_cancel.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/iter_runner.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       53 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/runners/runner.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/1cycle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/cos_anneal.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      258 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/plateau.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       57 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/_base_/schedules/schedule.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      454 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/finetune.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      327 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/incremental.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/classification/multilabel/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      126 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/multilabel/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      371 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/multilabel/incremental.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      305 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/recipes/stages/classification/multilabel/semisl.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/multilabel/train.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      804 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/selfsl.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      352 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/semisl.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      354 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/supcon.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      313 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/classification/train.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      481 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/detection/finetune.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      850 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/detection/incremental.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/recipes/stages/detection/semisl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      925 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/detection/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/incremental.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      817 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.580256 otx-1.1.2rc1/otx/recipes/stages/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       68 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/finetune.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      914 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/incremental.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      864 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/selfsl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      926 2023-04-04 07:33:45.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/semisl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      117 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/supcon.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      779 2023-03-09 02:44:59.000000 otx-1.1.2rc1/otx/recipes/stages/segmentation/train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.500256 otx-1.1.2rc1/otx.egg-info/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10704 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/PKG-INFO
--rw-rw-r--   0 songkich  (1000) songkich  (1000)   126655 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/SOURCES.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)        1 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/dependency_links.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      308 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/entry_points.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2500 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/requires.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       10 2023-04-04 14:10:57.000000 otx-1.1.2rc1/otx.egg-info/top_level.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3804 2023-04-04 07:33:45.000000 otx-1.1.2rc1/pyproject.toml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/requirements/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      170 2023-03-22 04:37:38.000000 otx-1.1.2rc1/requirements/action.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      170 2023-04-04 07:33:45.000000 otx-1.1.2rc1/requirements/anomaly.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      411 2023-04-04 07:33:45.000000 otx-1.1.2rc1/requirements/api.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      315 2023-04-04 07:33:45.000000 otx-1.1.2rc1/requirements/base.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      230 2023-04-04 14:09:57.000000 otx-1.1.2rc1/requirements/classification.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      252 2023-03-17 02:05:10.000000 otx-1.1.2rc1/requirements/detection.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      240 2023-03-09 02:44:59.000000 otx-1.1.2rc1/requirements/dev.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      146 2023-03-09 02:44:59.000000 otx-1.1.2rc1/requirements/docs.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      288 2023-03-09 02:44:59.000000 otx-1.1.2rc1/requirements/openvino.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      250 2023-04-04 14:09:57.000000 otx-1.1.2rc1/requirements/segmentation.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       38 2023-04-04 14:10:57.648256 otx-1.1.2rc1/setup.cfg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6551 2023-04-04 07:33:45.000000 otx-1.1.2rc1/setup.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/.pytest_cache/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       37 2023-03-24 14:35:28.000000 otx-1.1.2rc1/tests/.pytest_cache/.gitignore
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      191 2023-03-24 14:35:28.000000 otx-1.1.2rc1/tests/.pytest_cache/CACHEDIR.TAG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      302 2023-03-24 14:35:28.000000 otx-1.1.2rc1/tests/.pytest_cache/README.md
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/.pytest_cache/v/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/.pytest_cache/v/cache/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      915 2023-03-24 14:35:28.000000 otx-1.1.2rc1/tests/.pytest_cache/v/cache/nodeids
--rw-rw-r--   0 songkich  (1000) songkich  (1000)        2 2023-03-24 14:35:28.000000 otx-1.1.2rc1/tests/.pytest_cache/v/cache/stepwise
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      649 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      164 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_atr.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      186 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_atr.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       89 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       88 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_parts_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      164 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_atr.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_000_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_001_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_002_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2639 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_000_ADE_val_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_001_ADE_val_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_002_ADE_val_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_003_ADE_val_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3118 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_parts_2.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.584256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       74 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_000_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_001_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_002_ADE_train_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2639 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1_parts_1.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1_seg.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/anomaly/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1506 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/classification/test.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1022 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/classification/train.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1016 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/classification/val.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2032 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/detection/test.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1038 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/detection/train.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1357 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/detection/val.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)   124161 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/segmentation/test.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1037 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/segmentation/train.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    96123 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/segmentation/val.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/anomaly/shapes/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      454 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/000_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      385 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/001_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      462 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/002_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      402 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/003_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      303 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/004_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      411 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/005_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      378 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/006_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      465 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/007_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      446 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/008_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/hexagon/009_mask.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      571 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/000_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      596 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/001_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      555 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/002_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/003_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      491 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/004_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      609 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/005_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      474 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/006_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      575 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/007_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      578 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/008_mask.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      452 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/ground_truth/star/009_mask.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      784 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/000.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      732 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      731 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/003.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      775 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/004.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      719 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/005.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/006.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      802 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/007.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/008.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      493 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/good/009.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.588256 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1446 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/000.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1225 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1077 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1017 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/003.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1049 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/004.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      981 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/005.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1097 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/006.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1384 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/007.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1223 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/008.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1094 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/hexagon/009.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1640 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/000.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1416 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1632 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1953 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/003.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1590 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/004.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1540 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/005.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1087 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/006.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1431 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/007.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1829 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/008.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1170 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/test/star/009.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      845 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/000.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      911 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/003.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      853 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/004.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      921 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/005.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      877 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/006.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      756 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/007.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      805 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/008.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      900 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/009.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      795 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/010.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      759 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/011.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      968 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/012.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      896 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/013.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      901 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/014.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      821 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/015.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      931 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/016.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      978 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/017.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      977 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/018.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      735 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/assets/anomaly/shapes/train/good/019.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/car_tree_bug/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/car_tree_bug/annotations/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7119 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/annotations/instances_train.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2247 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/annotations/instances_val.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/car_tree_bug/images/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    26804 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide4.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    31177 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide5.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21277 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide6.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    32317 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide7.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22874 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide8.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    26796 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide9.PNG
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide3.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6123 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide4.PNG
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10729 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide5.PNG
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/defaultcity_000001_000031_gtFine_instanceIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/defaultcity_000001_000032_gtFine_instanceIds.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_instanceIds.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/defaultcity/defaultcity_000001_000019_gtFine_instanceIds.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/defaultcity_000001_000031_leftImg8bit.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/defaultcity_000001_000032_leftImg8bit.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000002_000045_leftImg8bit.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.480256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.592256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/defaultcity/defaultcity_000001_000019_leftImg8bit.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000019_gtFine_instanceIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       69 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000019_gtFine_labelTrainIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000031_gtFine_instanceIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000031_gtFine_labelTrainIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000032_gtFine_instanceIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000032_gtFine_labelTrainIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_instanceIds.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_labelTrainIds.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000019_leftImg8bit.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000031_leftImg8bit.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000032_leftImg8bit.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000002_000045_leftImg8bit.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       75 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0003.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0003.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      385 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      502 2023-03-24 15:11:40.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0003.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       46 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-27 11:15:04.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-27 11:15:04.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-27 11:15:04.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0003.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       23 2023-03-27 11:15:04.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0003.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      492 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      531 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0002.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      487 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0003.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       46 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/dataset_meta.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/images/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/images/0002.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      420 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0001.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0002.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cvat_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00020.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00021.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00022.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00023.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00024.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00025.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00026.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00027.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00028.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00029.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.596256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00020.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00021.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00022.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00023.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00024.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00025.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00026.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00027.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00028.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00029.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00020.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00021.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00022.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00023.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00024.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00025.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00026.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00027.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00028.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00029.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2471 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000020.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000021.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000022.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000023.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000024.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000025.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000026.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000027.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000028.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000029.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2468 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000020.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000021.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000022.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000023.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000024.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000025.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000026.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000027.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000028.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000029.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2470 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/annotations.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000020.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000021.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000022.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000023.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000024.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000025.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000026.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000027.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000028.png
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000029.png
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)      307 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train.pkl
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/datumaro_h-label/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_h-label/annotations/
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)     4092 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_h-label/annotations/train.json
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)     3066 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_h-label/annotations/validation.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/train/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/train/a.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/train/b.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/validation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_h-label/images/validation/d.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/datumaro_multilabel/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_multilabel/annotations/
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)     1137 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_multilabel/annotations/train.json
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)      914 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_multilabel/annotations/validation.json
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/train/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/train/a.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/train/b.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.600256 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/validation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/validation/d.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/imagenet_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_3.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_3.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_3.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_4.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_3.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_4.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_2.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_3.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_4.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/voc_dataset/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1195 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/2007_000001.xml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/test.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/train.txt
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/test.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/train.txt
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/aeroplane_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/background_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bicycle_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bird_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/boat_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bottle_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bus_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/car_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/cat_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/chair_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/cow_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/diningtable_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/dog_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/horse_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/ignored_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/motorbike_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/person_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/pottedplant_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/sheep_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/sofa_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/test.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/train_train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/tvmonitor_train.txt
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/test.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/val.txt
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000001.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000002.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationClass/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       97 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationClass/2007_000001.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationObject/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       94 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationObject/2007_000001.png
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.484256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/Main/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       25 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/Main/train.txt
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.604256 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/2007_000001.jpg
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/assets/yolo_dataset/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       92 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/yolo_dataset/obj.data
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       80 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/yolo_dataset/obj.names
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/assets/yolo_dataset/obj_train_data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/yolo_dataset/obj_train_data/1.jpg
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/yolo_dataset/obj_train_data/1.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       34 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/assets/yolo_dataset/train.txt
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2639 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/conftest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/action/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3837 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/action/test_action_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3970 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/action/test_action_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.488256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      113 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/nncf_quantization.dot
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      113 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/nncf_quantization.dot
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/nncf_quantization.dot
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/nncf_quantization.dot
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      111 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/nncf_quantization.dot
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      111 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/nncf_quantization.dot
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6187 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6173 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6181 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_segmentation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/classification/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.488256 otx-1.1.2rc1/tests/e2e/cli/classification/reference/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficientNet-V2-S/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      356 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficientNet-V2-S/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficinetNet-B0/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      354 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficinetNet-B0/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_MobileNet-V3-large-1x/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      353 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_MobileNet-V3-large-1x/compressed_model.yml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    37660 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/classification/test_classification.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/detection/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.488256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      236 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      233 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_ATSS/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      214 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_ATSS/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_SSD/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      211 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_SSD/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_YOLOX/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      211 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_YOLOX/compressed_model.yml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14234 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/detection/test_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12582 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/detection/test_instance_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11261 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/detection/test_tiling_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11390 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/detection/test_tiling_instseg.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.488256 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/compressed_model.yml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.608256 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/compressed_model.yml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16206 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/e2e/cli/segmentation/test_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3541 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/e2e/cli/test_cli.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/fuzzing/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/fuzzing/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.488256 otx-1.1.2rc1/tests/fuzzing/assets/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/fuzzing/assets/cli/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       74 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/fuzzing/assets/cli/operations.dict
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1101 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/fuzzing/cli_fuzzing.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/fuzzing/helper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/action/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9452 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/api/action/test_api_action_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9497 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/api/action/test_api_action_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/classification/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12210 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/classification/test_api_classification.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11263 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/api/detection/test_api_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12882 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/api/segmentation/test_api_segmentation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/api/xai/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/xai/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8325 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/api/xai/test_api_xai_sanity.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4210 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/integration/api/xai/test_api_xai_validity.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/action/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2869 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/integration/cli/action/test_action_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2844 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/integration/cli/action/test_action_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/anomaly/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/anomaly/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3209 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3195 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3203 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_segmentation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/classification/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    17264 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/classification/test_classification.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7667 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/detection/test_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6226 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/detection/test_instance_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4683 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/detection/test_tiling_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4756 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/detection/test_tiling_instseg.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/integration/cli/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/integration/cli/segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8725 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/segmentation/test_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7288 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/integration/cli/test_cli.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       82 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/pytest.ini
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/regression/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5946 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/action/test_action_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3546 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/regression/action/test_action_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/anomaly/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10124 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_classificaiton.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9974 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10058 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_segmentation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/regression/classification/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    36030 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/classification/test_classification.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/regression/detection/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13253 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/detection/test_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10924 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/detection/test_instnace_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8803 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/detection/test_tiling_detection.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8818 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/detection/test_tiling_instnace_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    68568 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/regression_config.json
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5299 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/regression/regression_test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.612256 otx-1.1.2rc1/tests/regression/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/regression/segmentation/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16357 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/regression/segmentation/test_segmentation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7731 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/regression/summarize_test_results.py
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)      614 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/run_code_checks.sh
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2172 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/run_model_templates_tests.py
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)      281 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/run_model_templates_tests.sh
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15505 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/test_suite/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    72985 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/ARCHITECTURE.md
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9626 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/QUICK_HOWTO.md
--rw-rw-r--   0 songkich  (1000) songkich  (1000)        0 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3920 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/e2e_test_system.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    16669 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/fixtures.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      764 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/logging.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4648 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/test_suite/pytest_insertions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    35548 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/test_suite/run_test_command.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4460 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/training_test_case.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    31071 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/training_tests_actions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2298 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/training_tests_common.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14396 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/training_tests_helper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    20104 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/test_suite/training_tests_stage.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)     2382 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/test_action_loading.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3185 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_cls_dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5115 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_det_dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6653 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_movinet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      675 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_register_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7524 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/test_action_fast_rcnn.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      934 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_movinet_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2550 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_roi_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2265 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/test_action_movinet_recognizer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_config_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2464 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_det_eval_utils.py
--rwxrwxr-x   0 songkich  (1000) songkich  (1000)     5867 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_export_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12257 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/test_action_dataloader.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7300 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/test_action_openvino_models.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15997 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14257 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8504 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_train.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4278 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tools/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3695 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tools/test_action_sample_classification.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3698 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/action/tools/test_action_sample_detection.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.616256 otx-1.1.2rc1/tests/unit/algorithms/action/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6019 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/action/utils/test_action_convert_public_data_to_cvat.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4768 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/action/utils/test_action_data.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1516 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_inference_callback.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2084 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_progress_callback.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1384 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/data/test_dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/config/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/config/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2713 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/config/test_model_config_load.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1443 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/conftest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7456 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/dummy_dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1569 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/dummy_model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1534 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      101 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3963 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2195 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3473 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2115 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      139 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6540 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_datasets.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3498 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_pipelines.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      158 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4991 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_byol.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4427 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_sam_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1065 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1169 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_mlc_classifier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      934 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_supcon_classifier.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1894 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_contrastive_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1923 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3380 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_hierarchical_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2483 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_multilabel_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2853 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_multilabel_semisl.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4331 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_semisl_cls_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2565 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_asymmetric_multilabel.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1598 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_cross_entropy.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5577 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/test_selfsl_mlp.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1927 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      402 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_patches.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      563 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_registers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.620256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      149 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2556 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/test_lars.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2053 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/incremental/test_cls_incremental_stage.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1490 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/semisl/test_cls_semisl_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1139 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_evaluator.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2040 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_explanier.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1416 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_exporter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1959 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3073 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1801 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1314 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/test_cls_config_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4837 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/test_mmcls_data_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/openvino/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3081 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/openvino/test_openvino_models.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3820 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/openvino/test_openvino_models_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6608 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5971 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_inference_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3280 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5311 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_nncf_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9732 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_openvino_task.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14937 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_openvino_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2691 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_train_task.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3779 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_train_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7239 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/test_helper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/classification/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3201 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/classification/utils/test_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      116 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      125 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      130 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2764 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_adaptive_training_hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1597 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_cancel_interface_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_checkpoint_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_composed_dataloader_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9000 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_early_stopping_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      792 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ema_v2_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6562 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_eval_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_fp16_sam_optimizer_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      519 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ib_loss_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_logger_replace_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3127 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_model_ema_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1758 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_no_bias_decay_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3766 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_recording_forward_hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      551 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_save_initial_weight_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_semisl_cls_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_task_adapt_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      573 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_unbiased_teacher_hook.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1468 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_workflow_hooks.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10187 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_helpers.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1478 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      643 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_runners.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5042 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.624256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      140 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      151 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3704 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augments.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5256 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augmix.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1871 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_otx_transforms.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2987 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_random_augment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1433 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_twocrop_transform.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1301 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2878 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_export_mixin.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1122 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_helpers.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8506 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      260 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_version.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1046 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_workflow.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7305 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/test_hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    20585 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/test_mmcv_hooks_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4809 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/test_mmcv_runner_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7658 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/test_mmcv_utils_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       72 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7832 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_deploy_apis.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2197 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1092 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_mmdeploy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1977 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_onnx.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      382 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_operations_domain.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2872 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2967 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_compression.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4175 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1118 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_patches.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2543 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.492256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      143 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1288 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_balanced_sampler.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1098 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_cls_incr_sampler.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/common/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2013 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/common/utils/test_common_utils_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6257 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/test_torchvision2mmdet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4772 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/test_detection_dataset.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3247 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_saliency_map_hook.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1644 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/test_ov_mmdet_mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2053 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_rpn_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2598 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_ssd_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3606 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_yolov3_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4333 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_atss_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6229 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_single_stage_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9029 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_two_stage_detector.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3940 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_vfnet_detector.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.628256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1667 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_cross_focal_loss.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3193 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_l2sp_loss.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1465 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/test_ov_mmdet_mmov_ssd_neck.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      930 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/test_ov_mmdet_single_level_roi_extractor.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2263 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      391 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_patches.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      902 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/incremental/test_det_incremental_stage.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1425 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/semisl/test_det_semisl_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2199 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_exporter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4361 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5606 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3044 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_trainer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8048 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/test_detection_dataset_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5036 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/test_detection_pipelines_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      937 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8798 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_config_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6023 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/test_detection_openvino_models.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/conftest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6779 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5833 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_inference_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3981 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5205 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_nncf_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11259 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    19867 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_openvino_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3267 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_train.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3036 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_train_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4699 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/tiling/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tiling/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7454 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/tiling/test_tiling_detection_unittest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10494 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_config_utils_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2952 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_data.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21737 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_data_utils_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      707 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_mask_to_bbox.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4014 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      137 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      146 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6161 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_compose.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_loads.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3096 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_pipelines_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10665 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_transforms.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4049 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9658 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.632256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3051 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_litehrnet.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1652 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_mmseg_mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      150 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2010 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_mmseg_mmov_decode_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      151 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2181 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/test_detcon_loss.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      150 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5527 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/test_selfsl_mlp.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4125 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/test_schedulers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      155 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9962 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/test_detcon.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      829 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/test_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1912 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4844 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_hooks.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      397 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_patches.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/incremental/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/incremental/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      911 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/incremental/test_seg_incremental_stage.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1173 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/test_seg_semisl_inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1494 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/test_seg_semisl_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1683 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_exporter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2636 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_inferrer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3962 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_stage.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1964 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_trainer.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3677 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12081 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3077 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    12641 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils_params_validation.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2011 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/test_blur.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4462 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/test_blur_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/conftest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6412 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_inference.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5893 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_inference_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2705 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5255 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_nncf_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8301 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_openvino.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14169 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_openvino_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2300 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_train.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3069 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_train_task_params_validation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3837 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/algorithms/segmentation/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/api/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.636256 otx-1.1.2rc1/tests/unit/api/configuration/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)        0 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/dummy_broken_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6162 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/dummy_config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3431 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/dummy_config.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/configuration/elements/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    18494 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/elements/test_elements_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4489 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/elements/test_metadata_keys.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    26713 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/elements/test_primitive_parameters.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/configuration/enums/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4832 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/enums/test_config_element_type.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1139 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/enums/test_enum_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1402 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/enums/test_model_lifecycle.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/configuration/helper/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5113 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/helper/test_config_element_mapping.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    29023 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/helper/test_create.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15725 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/helper/test_helper_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8893 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/test_configurable_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    21587 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/test_configuration_helper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1203 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/configuration/test_model_configuration.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/constants/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/constants/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      386 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/constants/components.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      208 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/constants/requirements.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/entities/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3546 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/dummy_config.yaml
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      627 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/dummy_template.yaml
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/entities/interfaces/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1818 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/interfaces/test_graph_interface.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/entities/shapes/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10810 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/shapes/test_ellipse.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9962 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/shapes/test_polygon.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    25946 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/api/entities/shapes/test_rectangle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13460 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/shapes/test_shape.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    20545 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_annotation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2730 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_color.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3189 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_coordinate.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    47885 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_dataset_item.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    28328 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_datasets.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    41363 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_graph.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2294 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_id.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5673 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_image.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3391 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_inference_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5604 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_label.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    89448 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_label_schema.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2364 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_media.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8321 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/api/entities/test_metadata.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    49221 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_metrics.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14661 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_model.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    56549 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_model_template.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3500 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_optimization_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1183 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_pickle.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    11302 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_result_media.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4290 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_resultset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2954 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_scored_label.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3642 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_subset.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15594 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_task_environment.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5513 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_tensor.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2265 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_train_parameters.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10153 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/entities/test_url.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/fixtures/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/fixtures/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/fixtures/general.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/parameters_validation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3058 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/parameters_validation/validation_helper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/serialization/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1130 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/serialization/test_datetime_mapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1256 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/serialization/test_id_mapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13738 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/serialization/test_label_mapper.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.496256 otx-1.1.2rc1/tests/unit/api/usecases/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.640256 otx-1.1.2rc1/tests/unit/api/usecases/adapters/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8590 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/adapters/test_model_adapter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/api/usecases/evaluation/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    29069 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_accuracy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10528 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_basic_operations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    23497 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_dice.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    77705 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_f_measure.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    45324 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_prediction_to_annotation_converter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10950 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_streamer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6863 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_visualization.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/api/usecases/reporting/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3278 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/usecases/reporting/test_callback.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22380 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/api/usecases/reporting/test_time_monitor_callback.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.496256 otx-1.1.2rc1/tests/unit/api/usecases/tasks/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/api/usecases/tasks/interfaces/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    10061 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/api/usecases/tasks/interfaces/test_interfaces.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/api/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22733 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/utils/test_segmentation_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    54212 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/utils/test_shape_drawer.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5985 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/api/utils/test_shape_factory.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/builder/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    13345 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/cli/builder/test_cli_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/conftest.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/manager/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22499 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/cli/manager/test_config_manager.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/registry/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4581 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/registry/test_cli_registry.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/tools/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3626 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_build.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1261 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_cli.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3121 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_deploy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4079 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_eval.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2500 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_export.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2416 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_find.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4379 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_optimize.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4578 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/tools/test_train.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/cli/utils/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3314 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_config.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    27415 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_hpo.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1688 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_importing.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     8495 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_io.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    15437 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_multi_gpu.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1481 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_nncf.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7191 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4434 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/cli/utils/test_telemetry.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/core/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/data/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/core/data/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/data/adapter/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3444 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_action_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4917 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_anomaly_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5374 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_classification_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4553 2023-03-24 16:15:11.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_detection_adapter.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2454 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_init.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6246 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/core/data/adapter/test_segmentation_adapter.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/data/manager/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4028 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/core/data/manager/test_dataset_manager.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4644 2023-03-22 04:37:38.000000 otx-1.1.2rc1/tests/unit/core/data/test_caching.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4998 2023-04-04 14:09:57.000000 otx-1.1.2rc1/tests/unit/core/data/test_helpers.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/ov/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/ov/graph/
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/ov/graph/parsers/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      915 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_cls_parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_parser.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6358 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/graph/test_ov_graph_grapy.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1466 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/graph/test_ov_graph_utils.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.644256 otx-1.1.2rc1/tests/unit/core/ov/models/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/backbones/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1366 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/backbones/test_ov_mmcls_mmov_backbone.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      873 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_cls_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1163 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_conv_head.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1283 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_mmcv_cls_head.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/necks/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      572 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/necks/test_ov_mmcls_mmov_neck.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1117 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/test_helpers.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1703 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/models/test_ov_models_ov_model.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/core/ov/ops/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     7249 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_activations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5307 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_arithmetics.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1678 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_builder.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3657 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_convolutions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      873 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_generation.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2953 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_image_processings.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3851 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_infrastructures.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2096 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_matmuls.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1705 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_module.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     9440 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_movements.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5022 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_normalizations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3270 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_object_detections.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_op.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     3991 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_poolings.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     4015 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_reductions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_shape_manipulations.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1438 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_sorting_maximization.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2280 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_type_conversions.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1162 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     1350 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/test_ov_omz_wrapper.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)      823 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/test_ov_registry.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2611 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/core/ov/test_ov_utils.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    14233 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/core/test_core_patcher.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/hpo/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     5551 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/hpo/test_hpo_base.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    45592 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/hpo/test_hyperband.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     6268 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/hpo/test_resource_manager.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)    22348 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/hpo/test_search_space.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/mpa/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-03-09 02:44:59.000000 otx-1.1.2rc1/tests/unit/mpa/__init__.py
-drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-04 14:10:57.648256 otx-1.1.2rc1/tests/unit/mpa/deploy/
--rw-rw-r--   0 songkich  (1000) songkich  (1000)       72 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/mpa/deploy/__init__.py
--rw-rw-r--   0 songkich  (1000) songkich  (1000)     2437 2023-04-04 07:33:45.000000 otx-1.1.2rc1/tests/unit/mpa/test_augments.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.614991 otx-1.2.0rc1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10254 2022-03-10 20:00:18.000000 otx-1.2.0rc1/LICENSE
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      182 2023-04-14 02:57:02.000000 otx-1.2.0rc1/MANIFEST.in
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10258 2023-04-18 01:20:06.614991 otx-1.2.0rc1/PKG-INFO
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9368 2023-04-17 06:37:58.000000 otx-1.2.0rc1/README.md
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      227 2023-04-18 01:14:22.000000 otx-1.2.0rc1/otx/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      171 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      302 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      723 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      343 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      841 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5642 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/cls_dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13842 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/det_dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      705 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2185 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/loading.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      443 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      443 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    29494 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/backbones/movinet.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/detectors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/detectors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4811 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/detectors/fast_rcnn.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      256 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2617 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/movinet_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1336 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/roi_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      227 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1678 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/movinet_recognizer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20482 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      224 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4722 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/det_eval_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5451 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/export_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9452 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/dataloader.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      713 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6903 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/model_wrappers/openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15048 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/configs/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3026 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/base/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/configs/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      119 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx/algorithms/action/configs/classification/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      148 2023-04-18 01:14:22.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      214 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/base/base_classification_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      543 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/base/base_classification_static.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1395 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/base/supervised.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10915 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.266991 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2723 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      124 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1257 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1456 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.274991 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2717 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      120 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1290 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1444 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.274991 otx-1.2.0rc1/otx/algorithms/action/configs/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.282991 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2643 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/ava_data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/base_detection_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      824 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/base_detection_static.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2546 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4166 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/faster_rcnn_config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1385 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/supervised.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10915 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      647 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      120 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1717 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1484 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    19870 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/action/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6378 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/tools/sample_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4202 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/action/tools/sample_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/action/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13043 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/algorithms/action/utils/convert_public_data_to_cvat.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7487 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/action/utils/data.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/anomaly/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      611 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      114 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      765 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8073 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/inference.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5246 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/progress.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.290991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/config/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      801 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/config/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4722 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/config/anomalib_config.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      705 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9651 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/create_mvtec_ad_json_annotations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10895 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13319 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6963 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/mvtec.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      412 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1709 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1486 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1501 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1949 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/base.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/logger/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      655 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/logger/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3089 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/logger/logger.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      852 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4700 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1672 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/configuration_enums.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/draem/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      220 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/draem/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3750 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/draem/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      718 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/padim/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1843 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/padim/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      718 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/stfpm/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4165 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/stfpm/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.294991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      628 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.298991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      688 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/template_experimental.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/transform_config.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.298991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/pot_optimization_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      778 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      893 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      868 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      623 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      678 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/template_experimental.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      609 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/transform_config.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/pot_optimization_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      803 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      878 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      926 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      626 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      751 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6747 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      684 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/template_experimental.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/transform_config.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1057 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4829 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      373 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/pot_optimization_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      809 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.302991 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      772 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      768 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8314 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      932 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      825 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16642 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/inference.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9410 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/nncf.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20885 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/openvino.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5187 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tasks/train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/anomaly/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1558 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tools/README.md
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      643 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15297 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/anomaly/tools/sample.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      730 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      616 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1296 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    28322 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/configurer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1163 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    19020 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/otx_datasets.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      714 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4939 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/otx_pipelines.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      491 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9416 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/augmix.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2458 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/otx_transforms.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6236 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/random_augment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      980 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/twocrop_transform.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      700 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1219 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      981 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9019 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/byol.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5545 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13251 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1740 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1725 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_multilabel_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1304 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/supcon_classifier.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1937 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1100 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1672 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/contrastive_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2974 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/conv_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3896 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7145 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_linear_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8458 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_non_linear_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5164 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_linear_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5410 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_non_linear_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3317 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/mmov_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3438 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/non_linear_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9447 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11908 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_multilabel_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3838 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/supcon_cls_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.306991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1066 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4560 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_angular_loss_with_ignore.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4177 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_loss_with_ignore.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2195 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/barlowtwins_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1990 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/cross_entropy_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2779 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/ib_loss.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      731 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      881 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/mmov_neck.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3968 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/selfsl_mlp.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      282 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6053 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      350 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      615 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/registers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4691 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/optimizer/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      676 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/optimizer/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5757 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/optimizer/lars.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    27461 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      294 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1381 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2822 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/config_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2498 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/exporter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      685 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7207 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    17763 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      710 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2812 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1901 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2124 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/selfsl/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2575 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/semisl/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2025 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/supcon/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/deployments/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      126 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/deployments/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      326 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/deployments/base_classification_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      601 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/deployments/base_classification_static.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      615 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/efficientnet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      382 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/efficientnet_v2.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      455 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/mobilenet_v3.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10752 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.310991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1853 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      724 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      493 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      519 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_hierarchical.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      568 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      683 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      687 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      521 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      898 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      741 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      715 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1466 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      766 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      727 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      275 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      441 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      510 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_hierarchical.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      574 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      683 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      693 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      469 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      904 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      741 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1474 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      660 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1853 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      725 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      274 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      414 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      606 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_hierarchical.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      603 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      688 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      743 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      719 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.314991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1250 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/template_experiment.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1853 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      268 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      276 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      538 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      564 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_hierarchical.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      731 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      690 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      728 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      566 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      919 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      738 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      728 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1485 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1853 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      721 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      291 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      263 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      477 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model_hierarchical.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      474 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/model_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      686 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      739 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      595 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      641 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      642 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      738 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      639 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1231 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/template_experiment.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21593 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      650 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14157 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/tools/classification_sample.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.326991 otx-1.2.0rc1/otx/algorithms/classification/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      425 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/classification/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4466 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/utils/cls_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3799 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/classification/utils/convert_coco_to_multilabel.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1758 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      639 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      641 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      233 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/efficientnet_b2b.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1959 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_18.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1982 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_s.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2073 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_x.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      147 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      195 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/resnet18.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      257 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/resnet50.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2983 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5600 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/adaptive_training_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3048 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/cancel_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6676 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/checkpoint_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1864 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/composed_dataloaders_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4272 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/custom_model_ema_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5452 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/dual_model_ema_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    17095 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/early_stopping_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5065 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/eval_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1358 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/force_train_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3967 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/fp16_sam_optimizer_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1367 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/ib_loss_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2649 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/logger_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5398 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/lr_updater_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4704 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/model_ema_v2_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2917 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/no_bias_decay_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3789 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/progress_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9733 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/recording_forward_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3708 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/sam_optimizer_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2514 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/semisl_cls_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2802 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/task_adapt_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3363 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/two_crop_transform_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2144 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/unbiased_teacher_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      875 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      859 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    44512 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3916 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnetv2.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12125 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/mobilenetv3.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9658 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/torchvision_backbones.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      862 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/builder.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      258 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      986 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/hooks.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1549 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7201 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/runners.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9695 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      105 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.330991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8618 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/augments.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      115 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4231 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14827 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5844 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/runner.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      695 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3782 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/exporter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      179 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/registry.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      226 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/version.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1619 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2267 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_builder_build_data_parallel.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2157 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_keys.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2386 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_pairs.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2167 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    23225 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/config_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      192 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12663 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/apis.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      478 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2181 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/mmdeploy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3868 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/onnx.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      313 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/operations_domain.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2117 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1070 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2927 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/compression.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4808 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2307 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/patches.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      524 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3525 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/utils/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      197 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2127 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/composed_dataloader.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      292 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4791 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/balanced_sampler.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5221 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/cls_incr_sampler.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      852 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/configs/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      887 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/configs/configuration_enums.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13764 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/configs/training_base.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      634 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12279 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/tasks/base_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12862 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/tasks/nncf_task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-04-07 06:23:14.000000 otx-1.2.0rc1/otx/algorithms/common/tools/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/common/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1331 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4852 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/common/utils/callback.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7337 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      528 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/distance_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      707 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/ext_loader.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/common/utils/ir.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4169 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/logger.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1803 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/common/utils/mask_to_bbox.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5905 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/mo_wrapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3821 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/task_adapt.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3662 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/common/utils/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      221 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/detection/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      612 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.334991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      518 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    30514 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/configurer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      845 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16150 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      703 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3413 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/load_pipelines.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5488 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/torchvision2mmdet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2792 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/task_adapt_dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    19083 2023-04-17 06:31:12.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/tiling.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/evaluation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      183 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/evaluation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10784 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/evaluation/mean_ap_seg.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/hooks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      235 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/hooks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5641 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/hooks/det_class_probability_map_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      298 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      231 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6164 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/imgclsmob.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      311 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3319 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_rpn_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5550 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_ssd_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2887 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_yolov3_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5468 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_atss_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5920 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11010 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_tile_optimized.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8525 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_single_stage_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3745 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_two_stage_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2928 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_vfnet_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6974 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_yolox_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      938 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/l2sp_detector_mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      466 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/sam_detector_mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8502 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/unbiased_teacher.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      743 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10539 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/cross_dataset_detector_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2436 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_anchor_generator.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9406 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_atss_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3021 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_retina_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8559 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_roi_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7055 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_ssd_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9589 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_vfnet_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_yolox_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      254 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3777 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/cross_focal_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3368 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/l2sp_loss.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      306 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3014 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_fpn.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7849 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_ssd_neck.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2465 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_yolov3_neck.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      196 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4090 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/mmov_bbox_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      196 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2228 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/mmov_mask_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.338991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      224 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2278 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9261 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5678 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4933 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    30035 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      522 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1530 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13603 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/config_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2340 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/exporter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      742 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7310 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    29587 2023-04-17 06:31:12.000000 otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      610 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/configs/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      704 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3190 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.342991 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      426 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_detection_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      904 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_detection_static.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      579 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      294 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_static.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.358991 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      626 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      764 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      786 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1215 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/single_stage_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      823 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/unbiased_teacher.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.358991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      114 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13095 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.382991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      670 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3121 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      272 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      288 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1600 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.382991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      646 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      670 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4205 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1695 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1526 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3407 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.382991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      637 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1744 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2577 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      285 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2701 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.382991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1744 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4204 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2799 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1526 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3103 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.398991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1862 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2523 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3023 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      644 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1850 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4082 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3121 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1521 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2914 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      638 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      888 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3015 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1145 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/template_experimental.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3037 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      633 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13851 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      669 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      889 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2629 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      367 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      592 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/deployment_tile_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4860 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1553 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3042 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      662 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      888 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2448 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      360 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      585 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/deployment_tile_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5285 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1532 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3040 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.402991 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      127 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12668 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      163 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      889 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2132 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      372 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4363 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1565 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3042 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/tile_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      888 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1951 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      365 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4788 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1544 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3040 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/tile_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    26259 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/algorithms/detection/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/detection/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      645 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13421 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/tools/detection_sample.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11060 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/tools/detection_semisl_sample.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15484 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/tools/instance_segmentation_sample.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/detection/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1073 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/detection/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    18620 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/utils/data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4355 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/detection/utils/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      224 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      616 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1660 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22383 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/configurer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1038 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9866 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      911 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4681 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/compose.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2023 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/loads.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12381 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/transforms.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1419 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      752 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    48294 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/litehrnet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      779 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      803 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      888 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/custom_fcn_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2264 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/detcon_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11757 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2673 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mmov_decode_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      773 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5488 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_pixel_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4014 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_weighted_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2329 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/cross_entropy_loss_with_ignore.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7636 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/detcon_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2652 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/otx_pixel_base.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.406991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      685 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3900 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/selfsl_mlp.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      856 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/base.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      691 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/constant.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1933 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/poly.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1734 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/step.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      886 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4177 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/class_incr_encoder_decoder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20672 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/detcon.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4764 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mean_teacher_segmentor.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7508 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2324 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/otx_encoder_decoder.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      844 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6642 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/aggregator.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1043 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/angular_pw_conv.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2919 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/asymmetric_position_attention.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      991 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/channel_shuffle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2106 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/local_attention.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2016 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/loss_equalizer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1248 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/normalize.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      879 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/psp_layer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      696 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6519 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      406 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4383 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21975 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1210 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2073 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11647 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/config_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8933 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/data_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2421 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/exporter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      307 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      706 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3965 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/blur.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16106 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      117 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      763 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6231 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/configuration.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      969 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/configuration_enums.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      629 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2269 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2311 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/selfsl/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      137 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2236 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/semisl/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.410991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/supcon/data_pipeline.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/deployments/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      131 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/deployments/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      347 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_dynamic.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      609 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_static.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      632 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/models/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11193 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/configuration.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      653 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1382 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      278 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1735 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2128 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/pot_optimization_config.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1944 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      661 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1959 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1374 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      658 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1407 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      283 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1795 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5948 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/pot_optimization_config.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1949 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2024 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      194 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2567 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1601 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.414991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1378 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      282 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      271 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2052 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4678 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/pot_optimization_config.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1887 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2233 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      194 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2821 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1636 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      657 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1382 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/compression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      716 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      331 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/deployment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      270 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/hpo_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1950 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11279 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/pot_optimization_config.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      665 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      471 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1893 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2183 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      664 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/data_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      194 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/hparam.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2725 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1617 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/template.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15760 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/algorithms/segmentation/task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15211 2023-04-07 06:23:13.000000 otx-1.2.0rc1/otx/algorithms/segmentation/tools/segmentation_sample.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/algorithms/segmentation/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      654 2023-04-07 06:23:12.000000 otx-1.2.0rc1/otx/algorithms/segmentation/utils/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/api/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      118 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/api/configuration/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1293 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1164 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/configurable_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3092 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/default_model_parameters.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/api/configuration/elements/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2259 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/configurable_enum.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2267 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/metadata_keys.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8015 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/parameter_group.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21228 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/primitive_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10385 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/elements/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.418991 otx-1.2.0rc1/otx/api/configuration/enums/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/enums/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1276 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/enums/auto_hpo_state.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2572 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/enums/config_element_type.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2320 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/enums/model_lifecycle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      608 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/enums/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.422991 otx-1.2.0rc1/otx/api/configuration/helper/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      737 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/configuration/helper/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2398 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/helper/config_element_mapping.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6091 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/helper/convert.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16176 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/configuration/helper/create.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8876 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/helper/substitute.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8418 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/configuration/helper/utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1081 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/helper/validate.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      397 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/model_lifecycle.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.422991 otx-1.2.0rc1/otx/api/configuration/ui_rules/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      290 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/ui_rules/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3897 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/ui_rules/rules.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1088 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/ui_rules/types.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      885 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/configuration/ui_rules/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.422991 otx-1.2.0rc1/otx/api/entities/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11281 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/annotation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4820 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/color.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1221 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/coordinate.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21565 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/dataset_item.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15287 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/datasets.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1109 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/explain_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4689 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/graph.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2218 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/id.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4156 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/image.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1519 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/inference_parameters.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.422991 otx-1.2.0rc1/otx/api/entities/interfaces/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       96 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/interfaces/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2195 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/interfaces/graph_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6910 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/label.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    29681 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/label_schema.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1659 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/media.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3656 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/metadata.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    24787 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/metrics.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15777 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    24344 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/model_template.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1482 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/optimization_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4793 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/entities/result_media.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6161 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/resultset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4032 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/scored_label.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.422991 otx-1.2.0rc1/otx/api/entities/shapes/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      219 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/shapes/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9894 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/shapes/ellipse.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8460 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/shapes/polygon.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11336 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/shapes/rectangle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6675 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/shapes/shape.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      569 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/subset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5151 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/task_environment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1462 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/tensor.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2350 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/train_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3857 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/entities/url.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/api/py.typed
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.426991 otx-1.2.0rc1/otx/api/serialization/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      140 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/serialization/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      897 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/serialization/datetime_mapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      521 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/serialization/id_mapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6329 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/serialization/label_mapper.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.426991 otx-1.2.0rc1/otx/api/usecases/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      210 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.426991 otx-1.2.0rc1/otx/api/usecases/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      138 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/adapters/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1812 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/adapters/model_adapter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.426991 otx-1.2.0rc1/otx/api/usecases/evaluation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      726 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13620 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/accuracy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4574 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/anomaly_metrics.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      304 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/averaging.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6011 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/basic_operations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8622 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/dice.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    37276 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/f_measure.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3667 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/metrics_helper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      505 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/evaluation/performance_provider_interface.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.426991 otx-1.2.0rc1/otx/api/usecases/exportable_code/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      118 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10254 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/LICENSE
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6117 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/README.md
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      105 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3473 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      451 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      317 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2904 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/asynchronous.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3763 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/sync_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1859 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/synchronous.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4918 2023-04-17 06:31:12.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/model_container.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1789 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-04-18 01:14:22.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/requirements.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      818 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/setup.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/inference/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      358 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/inference/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13270 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/inference/inference.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20321 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/prediction_to_annotation_converter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/streamer/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      513 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/streamer/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10603 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/streamer/streamer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      282 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2495 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/anomaly_visualizer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3013 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/visualizer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/reporting/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      430 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/reporting/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2556 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/reporting/callback.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6662 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/reporting/time_monitor_callback.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/exceptions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      601 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/image_computer_vision.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/image_deep_learning_task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.434991 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/deployment_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1146 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/evaluate_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/explain_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1125 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/export_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1810 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/inference_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1320 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/optimization_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2174 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/training_interface.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      848 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/unload_interface.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.438991 otx-1.2.0rc1/otx/api/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      114 2023-04-17 06:31:12.000000 otx-1.2.0rc1/otx/api/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3106 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/anomaly_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    18278 2023-04-07 06:48:43.000000 otx-1.2.0rc1/otx/api/utils/argument_checks.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1886 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/utils/async_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9844 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/dataset_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1580 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/detection_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      973 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/importing.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      625 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/labels_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2188 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/utils/nms.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10883 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/segmentation_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    25788 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/shape_drawer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7691 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/shape_factory.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10111 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/api/utils/tiler.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5895 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/time_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      874 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/api/utils/vis_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.438991 otx-1.2.0rc1/otx/cli/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      327 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.438991 otx-1.2.0rc1/otx/cli/builder/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      673 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/builder/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10855 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/builder/builder.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.462991 otx-1.2.0rc1/otx/cli/builder/supported_backbone/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      110 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7692 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmcls.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4855 2023-03-22 04:37:38.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmdet.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4712 2023-03-22 04:37:38.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmseg.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1714 2023-04-04 07:33:45.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/omz.mmcls.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      604 2023-04-04 07:33:45.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/otx.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13954 2023-03-22 04:37:38.000000 otx-1.2.0rc1/otx/cli/builder/supported_backbone/torchvision.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.462991 otx-1.2.0rc1/otx/cli/manager/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      192 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/manager/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    25280 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/cli/manager/config_manager.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/cli/registry/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/registry/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4852 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/registry/registry.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/cli/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      603 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4208 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/build.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2365 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/cli.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6363 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/cli/tools/demo.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3077 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/deploy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5824 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/eval.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8096 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/explain.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4425 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/export.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4749 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/find.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5988 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/optimize.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11391 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/tools/train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/cli/tools/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      607 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/utils/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/cli/tools/utils/demo/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      625 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/utils/demo/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6805 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/tools/utils/demo/images_capture.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8224 2023-04-17 02:04:16.000000 otx-1.2.0rc1/otx/cli/tools/utils/demo/visualization.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/cli/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3162 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      636 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/errors.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    32561 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/hpo.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4220 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/importing.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9196 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/io.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12332 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/multi_gpu.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1572 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/utils/nncf.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8855 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4673 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/cli/utils/report.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/cli/utils/telemetry.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/core/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      598 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/core/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      605 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/core/data/adapter/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4641 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/adapter/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10257 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/adapter/action_dataset_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10539 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/adapter/anomaly_dataset_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12203 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/adapter/base_dataset_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4329 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/adapter/classification_dataset_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2906 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/adapter/detection_dataset_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10542 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/adapter/segmentation_dataset_adapter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/core/data/caching/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      310 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/caching/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6345 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/caching/mem_cache_handler.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1110 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/caching/mem_cache_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.466991 otx-1.2.0rc1/otx/core/data/manager/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      611 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/manager/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4951 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/manager/dataset_manager.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/data/noisy_label_detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      352 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/noisy_label_detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1470 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/noisy_label_detection/base.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3387 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/noisy_label_detection/loss_dynamics_tracking_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/data/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-04-07 06:23:11.000000 otx-1.2.0rc1/otx/core/data/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3276 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/data/pipelines/load_image_from_otx_dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      312 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/file.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      180 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/graph/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    23734 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/graph.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/graph/parsers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      168 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/parsers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      207 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/parsers/builder.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/graph/parsers/cls/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      197 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/parsers/cls/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3134 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/parsers/cls/cls_base_parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      605 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/parsers/parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11467 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/graph/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      338 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/models/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2120 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/models/mmov_model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    18664 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/models/ov_model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2517 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/models/parser_mixin.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13957 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/omz_wrapper.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/ops/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7882 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/activations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3656 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/arithmetics.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2024 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3610 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/convolutions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      931 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/generation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4827 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/image_processings.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8388 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/infrastructures.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1332 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/matmuls.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.470991 otx-1.2.0rc1/otx/core/ov/ops/modules/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      185 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/modules/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3214 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/modules/op_module.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15619 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/movements.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6203 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/normalizations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6465 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/object_detections.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2909 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/op.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5286 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/poolings.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3241 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/reductions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4374 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/shape_manipulations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2985 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/sorting_maximization.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1855 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/type_conversions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1094 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/ops/utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1687 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/registry.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4004 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/ov/utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8065 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/core/patcher.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/hpo/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      777 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/hpo/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11587 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/hpo/hpo_base.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7636 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/hpo/hpo_runner.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    37688 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/hpo/hyperband.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8161 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/hpo/resource_manager.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    17281 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/hpo/search_space.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3194 2023-04-14 02:57:02.000000 otx-1.2.0rc1/otx/hpo/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      962 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      963 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_inst_seg.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      958 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_otx.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1333 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_ubt.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/custom_seg.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      115 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      788 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/data_seg.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1066 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_inst_seg_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1092 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_otx_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      984 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_resize_hflip_pad.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1391 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/incr_seg.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      947 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/twocrop_pipeline.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3091 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/ubt.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      453 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/seg_semisl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1633 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/selfsl_cls_data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1696 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/selfsl_seg_data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      489 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/data/twocrop_data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      142 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/default.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/dist/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/dist/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       57 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/dist/dist.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/logs/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/logs/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       19 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/logs/log.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      180 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/logs/tensorboard_logger.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      145 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/logs/text_logger.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/models/classifiers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/classifiers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      341 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/classifiers/classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      181 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/cls_semisl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      604 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/cls_supcon.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/models/detectors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/detectors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       92 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/detectors/detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      131 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      686 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/encoder_decoder.ote.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      745 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/seg_class_incr.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       95 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/segmentor.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.474991 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       67 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/adam.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/lars.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       86 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/optimizer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/optimizers/sgd.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      104 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/epoch_runner.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/epoch_runner_cancel.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      106 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/iter_runner.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       53 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/runners/runner.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      121 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/1cycle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/cos_anneal.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      258 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/plateau.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       57 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/_base_/schedules/schedule.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/classification/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      454 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/finetune.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      327 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/incremental.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/classification/multilabel/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      126 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/classification/multilabel/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      371 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/multilabel/incremental.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      305 2023-04-04 07:33:45.000000 otx-1.2.0rc1/otx/recipes/stages/classification/multilabel/semisl.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/multilabel/train.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      804 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/selfsl.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      352 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/semisl.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      354 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/supcon.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      313 2023-03-09 02:44:59.000000 otx-1.2.0rc1/otx/recipes/stages/classification/train.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      481 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/detection/finetune.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      850 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/detection/incremental.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      701 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/detection/semisl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      925 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/detection/train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      648 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/incremental.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      817 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.478991 otx-1.2.0rc1/otx/recipes/stages/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       68 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/finetune.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      914 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/incremental.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      864 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/selfsl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      926 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/semisl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      117 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/supcon.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      779 2023-04-07 06:23:10.000000 otx-1.2.0rc1/otx/recipes/stages/segmentation/train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.262991 otx-1.2.0rc1/otx.egg-info/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10258 2023-04-18 01:20:05.000000 otx-1.2.0rc1/otx.egg-info/PKG-INFO
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   120406 2023-04-18 01:20:06.000000 otx-1.2.0rc1/otx.egg-info/SOURCES.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)        1 2023-04-18 01:20:05.000000 otx-1.2.0rc1/otx.egg-info/dependency_links.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      308 2023-04-18 01:20:05.000000 otx-1.2.0rc1/otx.egg-info/entry_points.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2500 2023-04-18 01:20:05.000000 otx-1.2.0rc1/otx.egg-info/requires.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       10 2023-04-18 01:20:05.000000 otx-1.2.0rc1/otx.egg-info/top_level.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3589 2023-04-14 02:57:02.000000 otx-1.2.0rc1/pyproject.toml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.486991 otx-1.2.0rc1/requirements/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      170 2023-03-22 04:37:38.000000 otx-1.2.0rc1/requirements/action.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      170 2023-04-04 07:33:45.000000 otx-1.2.0rc1/requirements/anomaly.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      411 2023-04-14 02:57:02.000000 otx-1.2.0rc1/requirements/api.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      315 2023-04-04 07:33:45.000000 otx-1.2.0rc1/requirements/base.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      230 2023-04-14 02:57:02.000000 otx-1.2.0rc1/requirements/classification.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      252 2023-03-17 02:05:10.000000 otx-1.2.0rc1/requirements/detection.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      240 2023-03-09 02:44:59.000000 otx-1.2.0rc1/requirements/dev.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      146 2023-03-09 02:44:59.000000 otx-1.2.0rc1/requirements/docs.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      288 2023-03-09 02:44:59.000000 otx-1.2.0rc1/requirements/openvino.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      250 2023-04-14 02:57:02.000000 otx-1.2.0rc1/requirements/segmentation.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       38 2023-04-18 01:20:06.614991 otx-1.2.0rc1/setup.cfg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6460 2023-04-14 02:57:02.000000 otx-1.2.0rc1/setup.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.498991 otx-1.2.0rc1/tests/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.498991 otx-1.2.0rc1/tests/.pytest_cache/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       37 2023-03-24 14:35:28.000000 otx-1.2.0rc1/tests/.pytest_cache/.gitignore
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      191 2023-03-24 14:35:28.000000 otx-1.2.0rc1/tests/.pytest_cache/CACHEDIR.TAG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      302 2023-03-24 14:35:28.000000 otx-1.2.0rc1/tests/.pytest_cache/README.md
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/.pytest_cache/v/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.498991 otx-1.2.0rc1/tests/.pytest_cache/v/cache/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      915 2023-03-24 14:35:28.000000 otx-1.2.0rc1/tests/.pytest_cache/v/cache/nodeids
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)        2 2023-03-24 14:35:28.000000 otx-1.2.0rc1/tests/.pytest_cache/v/cache/stepwise
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      649 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      164 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_atr.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      186 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_atr.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       89 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       88 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_parts_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      164 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_atr.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       85 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_000_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_001_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1/instance_002_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2639 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_000_ADE_val_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_001_ADE_val_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_002_ADE_val_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2/instance_003_ADE_val_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3118 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       90 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_parts_2.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       74 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_000_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       83 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_001_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       81 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_002_ADE_train_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2639 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       93 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1_parts_1.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1_seg.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/anomaly/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/anomaly/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      950 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/classification/test.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1409 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/classification/train.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      864 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/classification/val.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.502991 otx-1.2.0rc1/tests/assets/anomaly/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1777 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/detection/test.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1410 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/detection/train.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2789 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/detection/val.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.506991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1787 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/00.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1787 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/01.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2282 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/02.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2258 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/03.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2317 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/04.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1923 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/05.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/06.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2010 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/07.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2274 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/08.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1982 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/09.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2166 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/10.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1967 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/11.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2174 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/12.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1830 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/13.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1471 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/14.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1969 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/15.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1437 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/ground_truth/colour/16.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.506991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   117825 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/00.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   117666 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/01.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   120006 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/02.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   118188 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/03.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   119597 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/04.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   118241 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/05.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   104506 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/06.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   120528 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/07.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115329 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/08.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   118280 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/09.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   120808 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/10.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   117311 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/11.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   120933 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/12.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115416 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/13.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116760 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/14.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   119611 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/15.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    98177 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/colour/16.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.506991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112334 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/04.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   113037 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/05.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112701 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/13.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114987 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/23.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   117138 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/25.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114837 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/test/good/28.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.510991 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   111251 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/00.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114872 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/01.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   109738 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/02.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112839 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/03.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112685 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/06.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116787 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/07.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114813 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/08.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116683 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/09.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115665 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/10.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116705 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/11.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   118571 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/12.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116126 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/14.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115989 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/15.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116855 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/16.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112902 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/17.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   117542 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/18.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116441 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/19.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115508 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/20.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   116200 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/21.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115219 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/22.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   111262 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/24.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115280 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/26.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115159 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/27.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115687 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/29.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115425 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/30.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   112056 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/31.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115326 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/32.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   115266 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/hazelnut/train/good/33.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.510991 otx-1.2.0rc1/tests/assets/anomaly/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    94407 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/segmentation/test.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1409 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/segmentation/train.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    79892 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/assets/anomaly/segmentation/val.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/car_tree_bug/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.510991 otx-1.2.0rc1/tests/assets/car_tree_bug/annotations/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7119 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/annotations/instances_train.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2247 2023-03-24 16:15:11.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/annotations/instances_val.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/car_tree_bug/images/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    26804 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide4.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    31177 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide5.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21277 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide6.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    32317 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide7.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22874 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide8.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    26796 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide9.PNG
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21103 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide3.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6123 2023-03-24 16:15:11.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide4.PNG
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10729 2023-03-24 16:15:11.000000 otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide5.PNG
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/defaultcity_000001_000031_gtFine_instanceIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/test/defaultcity/defaultcity_000001_000032_gtFine_instanceIds.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_instanceIds.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.218991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/gtFine/val/defaultcity/defaultcity_000001_000019_gtFine_instanceIds.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/defaultcity_000001_000031_leftImg8bit.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/test/defaultcity/defaultcity_000001_000032_leftImg8bit.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000002_000045_leftImg8bit.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/dataset/imgsFine/leftImg8bit/val/defaultcity/defaultcity_000001_000019_leftImg8bit.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000019_gtFine_instanceIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       69 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000019_gtFine_labelTrainIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000031_gtFine_instanceIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000031_gtFine_labelTrainIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000032_gtFine_instanceIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000001_000032_gtFine_labelTrainIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_instanceIds.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       71 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/gtFine/train/defaultcity/defaultcity_000002_000045_gtFine_labelTrainIds.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000019_leftImg8bit.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000031_leftImg8bit.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000001_000032_leftImg8bit.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       70 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cityscapes_dataset/train_dataset/imgsFine/leftImg8bit/train/defaultcity/defaultcity_000002_000045_leftImg8bit.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       75 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:48:03.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/detcon_mask/0003.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/images/0003.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      385 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      502 2023-03-24 15:11:40.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/detcon_mask/masks/0003.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       46 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-04-17 09:09:32.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-04-17 09:09:32.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      253 2023-04-17 09:09:32.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/0003.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       23 2023-04-17 09:09:32.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/detcon_mask/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/images/0003.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      492 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      531 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0002.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      487 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0003.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       46 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/dataset_meta.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/images/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      319 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/images/0002.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      420 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0001.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      652 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0002.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cvat_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.514991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00020.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00021.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00022.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00023.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00024.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00025.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00026.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00027.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00028.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00029.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00020.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00021.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00022.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00023.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00024.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00025.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00026.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00027.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00028.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00029.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1849 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00020.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00021.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00022.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00023.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00024.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00025.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00026.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00027.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00028.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00029.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2471 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000020.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000021.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000022.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000023.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000024.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000025.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000026.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000027.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000028.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000029.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.518991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2468 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.522991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000020.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000021.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000022.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000023.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000024.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000025.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000026.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000027.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000028.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000029.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.522991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2470 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/annotations.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000020.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000021.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000022.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000023.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000024.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000025.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000026.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000027.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000028.png
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000029.png
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)      307 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train.pkl
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/datumaro_h-label/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_h-label/annotations/
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)     4092 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_h-label/annotations/train.json
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)     3066 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_h-label/annotations/validation.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/train/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/train/a.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/train/b.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/validation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_h-label/images/validation/d.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/datumaro_multilabel/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_multilabel/annotations/
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)     1137 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_multilabel/annotations/train.json
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)      914 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_multilabel/annotations/validation.json
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/train/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/train/a.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/train/b.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/validation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/validation/d.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/imagenet_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_3.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_3.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.222991 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.526991 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_3.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_4.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_3.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_4.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_2.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_3.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_4.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/voc_dataset/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1195 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/2007_000001.xml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/test.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Action/train.txt
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/test.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Layout/train.txt
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/aeroplane_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/background_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bicycle_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bird_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/boat_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bottle_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/bus_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/car_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/cat_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/chair_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/cow_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/diningtable_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/dog_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/horse_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/ignored_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/motorbike_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/person_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/pottedplant_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/sheep_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/sofa_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/test.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/train_train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       15 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Main/tvmonitor_train.txt
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/test.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       12 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/ImageSets/Segmentation/val.txt
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000001.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000002.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationClass/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       97 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationClass/2007_000001.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationObject/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       94 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/SegmentationObject/2007_000001.png
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/Main/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       25 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/ImageSets/Main/train.txt
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      635 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/2007_000001.jpg
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/yolo_dataset/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       92 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/yolo_dataset/obj.data
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       80 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/yolo_dataset/obj.names
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/assets/yolo_dataset/obj_train_data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      631 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/yolo_dataset/obj_train_data/1.jpg
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       76 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/yolo_dataset/obj_train_data/1.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       34 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/assets/yolo_dataset/train.txt
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2640 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/conftest.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/e2e/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.530991 otx-1.2.0rc1/tests/e2e/cli/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/action/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3837 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/action/test_action_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3970 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/action/test_action_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      113 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/nncf_quantization.dot
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      113 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/nncf_quantization.dot
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/nncf_quantization.dot
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/nncf_quantization.dot
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      111 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    60633 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/nncf_quantization.dot
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      111 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)   114136 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/nncf_quantization.dot
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6194 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6180 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6188 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_segmentation.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/classification/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.226991 otx-1.2.0rc1/tests/e2e/cli/classification/reference/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficientNet-V2-S/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      356 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficientNet-V2-S/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficinetNet-B0/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      354 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficinetNet-B0/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_MobileNet-V3-large-1x/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      353 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/classification/reference/Custom_Image_Classification_MobileNet-V3-large-1x/compressed_model.yml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    36985 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/classification/test_classification.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/detection/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.246991 otx-1.2.0rc1/tests/e2e/cli/detection/reference/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_ATSS/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      214 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_ATSS/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.534991 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_SSD/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      211 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_SSD/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_YOLOX/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      211 2023-04-17 02:04:16.000000 otx-1.2.0rc1/tests/e2e/cli/detection/reference/Custom_Object_Detection_YOLOX/compressed_model.yml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16084 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/detection/test_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11723 2023-04-17 02:04:16.000000 otx-1.2.0rc1/tests/e2e/cli/detection/test_tiling_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.246991 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/reference/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      236 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      233 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/compressed_model.yml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12698 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/test_instance_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11588 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/test_tiling_instseg.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.246991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      108 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/compressed_model.yml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      109 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/compressed_model.yml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16151 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/test_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3541 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/e2e/cli/test_cli.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9915 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/e2e/test_api_xai_sanity.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/fuzzing/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/fuzzing/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.246991 otx-1.2.0rc1/tests/fuzzing/assets/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/fuzzing/assets/cli/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       74 2023-03-24 16:15:11.000000 otx-1.2.0rc1/tests/fuzzing/assets/cli/operations.dict
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1101 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/fuzzing/cli_fuzzing.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      374 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/fuzzing/helper.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/integration/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/integration/api/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.550991 otx-1.2.0rc1/tests/integration/api/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/action/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9632 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/api/action/test_api_action_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9677 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/api/action/test_api_action_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/api/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/classification/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12153 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/api/classification/test_api_classification.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/api/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11263 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/api/detection/test_api_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/api/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12882 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/api/segmentation/test_api_segmentation.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/api/xai/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/api/xai/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/integration/cli/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/cli/action/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2869 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/integration/cli/action/test_action_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2844 2023-04-07 06:23:08.000000 otx-1.2.0rc1/tests/integration/cli/action/test_action_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/anomaly/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/integration/cli/anomaly/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3216 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3202 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3210 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_segmentation.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/integration/cli/classification/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22421 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/classification/test_classification.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/integration/cli/detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9129 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/detection/test_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4852 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/detection/test_tiling_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/instance_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/instance_segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6335 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/instance_segmentation/test_instance_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6084 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/instance_segmentation/test_tiling_instseg.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/integration/cli/semantic_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/semantic_segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8656 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/semantic_segmentation/test_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13891 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/integration/cli/test_cli.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       82 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/pytest.ini
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/regression/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6676 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/action/test_action_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4038 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/action/test_action_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/anomaly/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10857 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_classificaiton.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10707 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10791 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_segmentation.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/regression/classification/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    39523 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/classification/test_classification.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/regression/detection/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14585 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/detection/test_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9536 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/detection/test_tiling_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/instance_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/regression/instance_segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11971 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/instance_segmentation/test_instnace_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9551 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/instance_segmentation/test_tiling_instnace_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11794 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/regression_command.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    57738 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/regression_config.json
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5299 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/regression/regression_test_helpers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.554991 otx-1.2.0rc1/tests/regression/semantic_segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/regression/semantic_segmentation/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    17981 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/regression/semantic_segmentation/test_segmentation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7731 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/regression/summarize_test_results.py
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)      614 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/run_code_checks.sh
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2172 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/run_model_templates_tests.py
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)      281 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/run_model_templates_tests.sh
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15505 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_helpers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/test_suite/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    72982 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/test_suite/ARCHITECTURE.md
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9626 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/test_suite/QUICK_HOWTO.md
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)        0 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3920 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/e2e_test_system.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16669 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/fixtures.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      764 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/logging.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4649 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/test_suite/pytest_insertions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    37586 2023-04-17 06:31:12.000000 otx-1.2.0rc1/tests/test_suite/run_test_command.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4460 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/training_test_case.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    31071 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/training_tests_actions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2298 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/training_tests_common.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14396 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/training_tests_helper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20104 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/test_suite/training_tests_stage.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)     2382 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/test_action_loading.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3185 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_cls_dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5115 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_det_dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6653 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_movinet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      675 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_register_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7524 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/test_action_fast_rcnn.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      934 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_movinet_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2550 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_roi_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2265 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/test_action_movinet_recognizer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13968 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/test_task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2464 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_det_eval_utils.py
+-rwxrwxr-x   0 songkich  (1000) songkich  (1000)     5867 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_export_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12257 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_action_dataloader.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7300 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_action_openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14577 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5001 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/test_helpers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/tools/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3695 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/tools/test_action_sample_classification.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3698 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/tools/test_action_sample_detection.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/action/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6019 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/action/utils/test_action_convert_public_data_to_cvat.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4768 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/action/utils/test_action_data.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1516 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_inference_callback.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2084 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_progress_callback.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1388 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/data/test_dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.558991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/config/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/config/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2713 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/config/test_model_config_load.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1447 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/conftest.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      103 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7374 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/dummy_dataset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1569 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/dummy_model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1534 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      101 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4135 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_inference.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2301 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_nncf.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3579 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_openvino.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2222 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      139 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5748 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_datasets.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3498 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_pipelines.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      158 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4991 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_byol.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7953 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_sam_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1065 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1169 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_mlc_classifier.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      934 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_supcon_classifier.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1894 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_contrastive_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1923 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3380 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_hierarchical_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2483 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_multilabel_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2853 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_multilabel_semisl.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4331 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_semisl_cls_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2565 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_asymmetric_multilabel.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1598 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_cross_entropy.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5577 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/test_selfsl_mlp.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2027 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      402 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      563 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_registers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      149 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2556 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/test_lars.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1314 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/test_cls_config_builder.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/openvino/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3081 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/openvino/test_openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1292 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/conftest.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3114 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/test_classification_nncf.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9796 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/test_classification_openvino_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7239 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/test_helper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2121 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/test_xai_classification_validity.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/classification/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3201 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/algorithms/classification/utils/test_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/common/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      116 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.562991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      125 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      130 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2764 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_adaptive_training_hooks.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1597 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_cancel_interface_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_checkpoint_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_composed_dataloader_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9000 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_early_stopping_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      792 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ema_v2_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6562 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_eval_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      580 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_fp16_sam_optimizer_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      519 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ib_loss_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_logger_replace_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4832 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_lr_updater_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3127 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_model_ema_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1758 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_no_bias_decay_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3766 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_recording_forward_hooks.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      551 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_save_initial_weight_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_semisl_cls_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      534 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_task_adapt_hook.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      573 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_unbiased_teacher_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10248 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_helpers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1692 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_hooks.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      643 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_runners.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5411 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      140 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      151 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3704 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augments.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5256 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augmix.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1871 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_otx_transforms.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2987 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_random_augment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1433 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_twocrop_transform.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2537 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_exporter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1135 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_helpers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      260 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_version.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7305 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/test_hooks.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       72 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7832 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_deploy_apis.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2197 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_helpers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1092 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_mmdeploy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1996 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_onnx.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      382 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_operations_domain.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2872 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2967 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_compression.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4178 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1118 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2543 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.246991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      143 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1288 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_balanced_sampler.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1098 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_cls_incr_sampler.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/common/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/common/utils/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.566991 otx-1.2.0rc1/tests/unit/algorithms/detection/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6257 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/test_torchvision2mmdet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4772 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/test_detection_dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3958 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_class_probability_map_hook.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1332 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/test_ov_mmdet_mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2053 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_rpn_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2598 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_ssd_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3606 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_yolov3_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4333 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_atss_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6229 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_single_stage_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9029 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_two_stage_detector.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3940 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_vfnet_detector.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1667 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_cross_focal_loss.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3193 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_l2sp_loss.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1465 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/test_ov_mmdet_mmov_ssd_neck.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      699 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/test_ov_mmdet_single_level_roi_extractor.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2972 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      391 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3812 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    12001 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/test_configurer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13686 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/test_task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      937 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8798 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_config_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1912 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_exporter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6027 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/test_detection_openvino_models.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11198 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/test_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/conftest.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4870 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/test_helpers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2478 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/test_xai_detection_validity.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10444 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/test_tiling_detection.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8723 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/test_tiling_tile_classifier.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/detection/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2952 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/utils/test_detection_data.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      707 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/utils/test_detection_mask_to_bbox.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      927 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/detection/utils/test_detection_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.570991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      137 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      146 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      156 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6161 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_compose.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1929 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_loads.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10665 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_transforms.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4049 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3051 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_litehrnet.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1652 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_mmseg_mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      150 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1984 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_detcon_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2010 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_mmseg_mmov_decode_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      151 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2265 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/test_detcon_loss.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      150 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5527 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/test_selfsl_mlp.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      154 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4125 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/test_schedulers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      155 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10196 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/test_detcon.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      829 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/test_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1962 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      397 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_patches.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2466 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11507 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/test_mmseg_configurer.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      144 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3677 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3077 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1444 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_exporter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2011 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/test_blur.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8386 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/test_openvino_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2439 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/test_otx_segmentation_task.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      593 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/conftest.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3837 2023-04-07 06:23:10.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/test_helpers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4065 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/algorithms/segmentation/test_task.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.574991 otx-1.2.0rc1/tests/unit/api/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.590991 otx-1.2.0rc1/tests/unit/api/configuration/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)        0 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      666 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/unit/api/configuration/dummy_broken_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6162 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/dummy_config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3431 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/unit/api/configuration/dummy_config.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.590991 otx-1.2.0rc1/tests/unit/api/configuration/elements/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    18494 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/elements/test_elements_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4489 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/elements/test_metadata_keys.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    26713 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/elements/test_primitive_parameters.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.590991 otx-1.2.0rc1/tests/unit/api/configuration/enums/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4832 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/enums/test_config_element_type.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1139 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/enums/test_enum_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1402 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/enums/test_model_lifecycle.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.590991 otx-1.2.0rc1/tests/unit/api/configuration/helper/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5113 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/helper/test_config_element_mapping.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    29023 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/helper/test_create.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15725 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/helper/test_helper_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8893 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/test_configurable_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    21587 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/test_configuration_helper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1203 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/configuration/test_model_configuration.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.590991 otx-1.2.0rc1/tests/unit/api/constants/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/constants/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      386 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/constants/components.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      208 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/constants/requirements.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.594991 otx-1.2.0rc1/tests/unit/api/entities/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3546 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/unit/api/entities/dummy_config.yaml
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      627 2023-03-09 02:44:59.000000 otx-1.2.0rc1/tests/unit/api/entities/dummy_template.yaml
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.594991 otx-1.2.0rc1/tests/unit/api/entities/interfaces/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1818 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/interfaces/test_graph_interface.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.594991 otx-1.2.0rc1/tests/unit/api/entities/shapes/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10810 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/shapes/test_ellipse.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9962 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/shapes/test_polygon.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    25972 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/api/entities/shapes/test_rectangle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13460 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/shapes/test_shape.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    20545 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_annotation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2730 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_color.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3189 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_coordinate.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    49384 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/api/entities/test_dataset_item.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    28328 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_datasets.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    41363 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_graph.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2294 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_id.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5673 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_image.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3391 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_inference_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5604 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_label.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    89448 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_label_schema.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2364 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_media.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8347 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/api/entities/test_metadata.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    49221 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_metrics.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14661 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_model.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    56549 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_model_template.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3500 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_optimization_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1183 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_pickle.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    11302 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_result_media.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4290 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_resultset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2954 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_scored_label.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3642 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_subset.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    15594 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_task_environment.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5513 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_tensor.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2265 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_train_parameters.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10153 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/entities/test_url.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.594991 otx-1.2.0rc1/tests/unit/api/fixtures/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       84 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/fixtures/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      325 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/fixtures/general.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.606991 otx-1.2.0rc1/tests/unit/api/parameters_validation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3058 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/parameters_validation/validation_helper.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.606991 otx-1.2.0rc1/tests/unit/api/serialization/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1130 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/serialization/test_datetime_mapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1256 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/serialization/test_id_mapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13738 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/serialization/test_label_mapper.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.250991 otx-1.2.0rc1/tests/unit/api/usecases/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.606991 otx-1.2.0rc1/tests/unit/api/usecases/adapters/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8590 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/adapters/test_model_adapter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.606991 otx-1.2.0rc1/tests/unit/api/usecases/evaluation/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    29069 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_accuracy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10528 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_basic_operations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    23497 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_dice.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    77705 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_f_measure.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.606991 otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    45324 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_prediction_to_annotation_converter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10950 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_streamer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6863 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_visualization.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/api/usecases/reporting/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3278 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/reporting/test_callback.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22380 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/reporting/test_time_monitor_callback.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.250991 otx-1.2.0rc1/tests/unit/api/usecases/tasks/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/api/usecases/tasks/interfaces/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    10061 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/usecases/tasks/interfaces/test_interfaces.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/api/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22733 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/utils/test_segmentation_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    54212 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/utils/test_shape_drawer.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5985 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/api/utils/test_shape_factory.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/builder/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    13345 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/builder/test_cli_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      152 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/conftest.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/manager/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22499 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/manager/test_config_manager.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/registry/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4581 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/registry/test_cli_registry.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/tools/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3601 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_build.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1261 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_cli.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3086 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_deploy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3949 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_eval.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2465 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_export.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2416 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_find.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4153 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_optimize.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4671 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/tools/test_train.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/cli/utils/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3314 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_config.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    28094 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_hpo.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1688 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_importing.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     8495 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_io.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    16566 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_multi_gpu.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1481 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_nncf.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7191 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2220 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_report.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4434 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/cli/utils/test_telemetry.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/data/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/data/adapter/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3444 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_action_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4917 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_anomaly_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5374 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_classification_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4553 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_detection_adapter.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2454 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_init.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6246 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/adapter/test_segmentation_adapter.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/data/manager/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4030 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/data/manager/test_dataset_manager.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4644 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/data/test_caching.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5016 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/data/test_helpers.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/graph/
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/graph/parsers/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      915 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_cls_parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      847 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_parser.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6358 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/graph/test_ov_graph_grapy.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1466 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/graph/test_ov_graph_utils.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/models/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      581 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/backbones/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1366 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/backbones/test_ov_mmcls_mmov_backbone.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      873 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_cls_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1163 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_conv_head.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1283 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_mmcv_cls_head.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.610991 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/necks/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      572 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/necks/test_ov_mmcls_mmov_neck.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1117 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/test_helpers.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1703 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/models/test_ov_models_ov_model.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.614991 otx-1.2.0rc1/tests/unit/core/ov/ops/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     7249 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_activations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5307 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_arithmetics.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1678 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_builder.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3657 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_convolutions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      873 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_generation.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2953 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_image_processings.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3851 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_infrastructures.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2096 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_matmuls.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1705 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_module.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     9440 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_movements.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5022 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_normalizations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3270 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_object_detections.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      796 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_op.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     3991 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_poolings.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     4015 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_reductions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2998 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_shape_manipulations.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1438 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_sorting_maximization.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2280 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_type_conversions.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1162 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     1350 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/test_ov_omz_wrapper.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)      823 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/test_ov_registry.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2611 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/core/ov/test_ov_utils.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    14233 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/core/test_core_patcher.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.614991 otx-1.2.0rc1/tests/unit/hpo/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     5551 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/hpo/test_hpo_base.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    45592 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/hpo/test_hyperband.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     6268 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/hpo/test_resource_manager.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)    22348 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/hpo/test_search_space.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.614991 otx-1.2.0rc1/tests/unit/mpa/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       79 2023-04-07 06:23:09.000000 otx-1.2.0rc1/tests/unit/mpa/__init__.py
+drwxrwxr-x   0 songkich  (1000) songkich  (1000)        0 2023-04-18 01:20:06.614991 otx-1.2.0rc1/tests/unit/mpa/deploy/
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)       72 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/mpa/deploy/__init__.py
+-rw-rw-r--   0 songkich  (1000) songkich  (1000)     2437 2023-04-14 02:57:02.000000 otx-1.2.0rc1/tests/unit/mpa/test_augments.py
```

### Comparing `otx-1.1.2rc1/LICENSE` & `otx-1.2.0rc1/LICENSE`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/PKG-INFO` & `otx-1.2.0rc1/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -1,44 +1,28 @@
-Metadata-Version: 2.1
-Name: otx
-Version: 1.1.2rc1
-Summary: OpenVINO Training Extensions: Train, Evaluate, Optimize, Deploy Computer Vision Models via OpenVINO
-Home-page: https://github.com/openvinotoolkit/training_extensions
-Author: OpenVINO Training Extensions Contributors
-License: Apache License 2.0
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Cython
-Description-Content-Type: text/markdown
-Provides-Extra: action
-Provides-Extra: anomaly
-Provides-Extra: classification
-Provides-Extra: detection
-Provides-Extra: segmentation
-Provides-Extra: full
-License-File: LICENSE
-
 <div align="center">
 
 # OpenVINO Training Extensions
 
 ---
 
 [Key Features](#key-features) 
-[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/index.html) 
-[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/index.html) 
+[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/index.html) 
+[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/index.html) 
 [License](#license)
 
 [![PyPI](https://img.shields.io/pypi/v/otx)](https://pypi.org/project/otx)
+
+<!-- markdownlint-disable MD042 -->
+
 [![python](https://img.shields.io/badge/python-3.8%2B-green)]()
 [![pytorch](https://img.shields.io/badge/pytorch-1.13.1%2B-orange)]()
 [![openvino](https://img.shields.io/badge/openvino-2022.3.0-purple)]()
+
+<!-- markdownlint-enable  MD042 -->
+
 [![Codacy Badge](https://app.codacy.com/project/badge/Grade/f9ba89f9ea2a47eeb9d52c2acc311e6c)](https://www.codacy.com/gh/openvinotoolkit/training_extensions/dashboard?utm_source=github.com&utm_medium=referral&utm_content=openvinotoolkit/training_extensions&utm_campaign=Badge_Grade)
 [![Codecov](https://codecov.io/gh/openvinotoolkit/training_extensions/branch/develop/graph/badge.svg?token=9HVFNMPFGD)](https://codecov.io/gh/openvinotoolkit/training_extensions)
 [![Pre-Merge Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml)
 [![Nightly Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml)
 [![Build Docs](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml)
 [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
 [![Downloads](https://static.pepy.tech/personalized-badge/otx?period=total&units=international_system&left_color=grey&right_color=green&left_text=PyPI%20Downloads)](https://pepy.tech/project/otx)
@@ -67,69 +51,60 @@
 - **Classification**, including multi-class, multi-label and hierarchical image classification tasks.
 - **Object detection** including rotated bounding box support
 - **Semantic segmentation**
 - **Instance segmentation** including tiling algorithm support
 - **Action recognition** including action classification and detection
 - **Anomaly recognition** tasks including anomaly classification, detection and segmentation
 
-OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/algorithms/index.html):
+OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/algorithms/index.html):
 
 - **Supervised**, incremental training, which includes class incremental scenario and contrastive learning for classification and semantic segmentation tasks
 - **Semi-supervised learning**
 - **Self-supervised learning**
 
 OpenVINO Training Extensions will provide the following features in coming releases:
 
 - **Distributed training** to accelerate the training process when you have multiple GPUs
 - **Half-precision training** to save GPUs memory and use larger batch sizes
-- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
+- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
 - OpenVINO Training Extensions uses [Datumaro](https://openvinotoolkit.github.io/datumaro/docs/) as the backend to hadle datasets. Thanks to that, OpenVINO Training Extensions supports the most common academic field dataset formats for each task. We constantly working to extend supported formats to give more freedom of datasets format choice.
-- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
+- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
 
 ---
 
 ## Getting Started
 
 ### Installation
 
-Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/installation.html).
+Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/installation.html).
 
 ### OpenVINO Training Extensions CLI Commands
 
 - `otx find` helps you quickly find the best pre-configured models templates as well as a list of supported backbones
 - `otx build` creates the workspace folder with all necessary components to start training. It can help you configure your own model with any supported backbone and even prepare a custom split for your dataset
 - `otx train` actually starts training on your dataset
 - `otx eval` runs evaluation of your trained model in PyTorch or OpenVINO IR format
 - `otx optimize` runs an optimization algorithm to quantize and prune your deep learning model with help of [NNCF](https://github.com/openvinotoolkit/nncf) and [POT](https://docs.openvino.ai/latest/pot_introduction.html) tools.
 - `otx export` starts exporting your model to the OpenVINO IR format
 - `otx deploy` outputs the exported model together with the self-contained python package, a demo application to port and infer it outside of this repository.
 - `otx demo` allows one to apply a trained model on the custom data or the online footage from a web camera and see how it will work in a real-life scenario.
 - `otx explain` runs explain algorithm on the provided data and outputs images with the saliency maps to show how your model makes predictions.
 
-You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/cli_commands.html).
+You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/cli_commands.html).
 
 ---
 
 ## Updates
 
-### v1.1.0 (1Q23)
-
-- Add FP16 IR export support (<https://github.com/openvinotoolkit/training_extensions/pull/1683>)
-- Add in-memory caching in dataloader (<https://github.com/openvinotoolkit/training_extensions/pull/1694>)
-- Add MoViNet template for action classification (<https://github.com/openvinotoolkit/training_extensions/pull/1742>)
-- Add Semi-SL multilabel classification algorithm (<https://github.com/openvinotoolkit/training_extensions/pull/1805>)
-- Integrate multi-gpu training for semi-supervised learning and self-supervised learning (<https://github.com/openvinotoolkit/training_extensions/pull/1534>)
-- Add train-type parameter to otx train (<https://github.com/openvinotoolkit/training_extensions/pull/1874>)
-- Add embedding of inference configuration to IR for classification (<https://github.com/openvinotoolkit/training_extensions/pull/1842>)
-- Enable VOC dataset in OTX (<https://github.com/openvinotoolkit/training_extensions/pull/1862>)
-- Add mmcls.VisionTransformer backbone support (<https://github.com/openvinotoolkit/training_extensions/pull/1908>)
-
-### v1.2+ (2Q23)
+### v1.2.0 (2Q23)
 
-- In planning
+- Add generating feature cli_report.log in output for otx training (<https://github.com/openvinotoolkit/training_extensions/pull/1959>)
+- Support multiple python versions up to 3.10 (<https://github.com/openvinotoolkit/training_extensions/pull/1978>)
+- Support export of onnx models (<https://github.com/openvinotoolkit/training_extensions/pull/1976>)
+- Add option to save images after inference in OTX CLI demo together with demo in exportable code (<https://github.com/openvinotoolkit/training_extensions/pull/2005>)
 
 ### Release History
 
 Please refer to the [CHANGELOG.md](CHANGELOG.md)
 
 ---
```

### Comparing `otx-1.1.2rc1/README.md` & `otx-1.2.0rc1/PKG-INFO`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,51 @@
+Metadata-Version: 2.1
+Name: otx
+Version: 1.2.0rc1
+Summary: OpenVINO Training Extensions: Train, Evaluate, Optimize, Deploy Computer Vision Models via OpenVINO
+Home-page: https://github.com/openvinotoolkit/training_extensions
+Author: OpenVINO Training Extensions Contributors
+License: Apache License 2.0
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Cython
+Description-Content-Type: text/markdown
+Provides-Extra: action
+Provides-Extra: anomaly
+Provides-Extra: classification
+Provides-Extra: detection
+Provides-Extra: segmentation
+Provides-Extra: full
+License-File: LICENSE
+
 <div align="center">
 
 # OpenVINO Training Extensions
 
 ---
 
 [Key Features](#key-features) 
-[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/index.html) 
-[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/index.html) 
+[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/index.html) 
+[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/index.html) 
 [License](#license)
 
 [![PyPI](https://img.shields.io/pypi/v/otx)](https://pypi.org/project/otx)
+
+<!-- markdownlint-disable MD042 -->
+
 [![python](https://img.shields.io/badge/python-3.8%2B-green)]()
 [![pytorch](https://img.shields.io/badge/pytorch-1.13.1%2B-orange)]()
 [![openvino](https://img.shields.io/badge/openvino-2022.3.0-purple)]()
+
+<!-- markdownlint-enable  MD042 -->
+
 [![Codacy Badge](https://app.codacy.com/project/badge/Grade/f9ba89f9ea2a47eeb9d52c2acc311e6c)](https://www.codacy.com/gh/openvinotoolkit/training_extensions/dashboard?utm_source=github.com&utm_medium=referral&utm_content=openvinotoolkit/training_extensions&utm_campaign=Badge_Grade)
 [![Codecov](https://codecov.io/gh/openvinotoolkit/training_extensions/branch/develop/graph/badge.svg?token=9HVFNMPFGD)](https://codecov.io/gh/openvinotoolkit/training_extensions)
 [![Pre-Merge Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml)
 [![Nightly Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml)
 [![Build Docs](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml)
 [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
 [![Downloads](https://static.pepy.tech/personalized-badge/otx?period=total&units=international_system&left_color=grey&right_color=green&left_text=PyPI%20Downloads)](https://pepy.tech/project/otx)
@@ -45,69 +74,60 @@
 - **Classification**, including multi-class, multi-label and hierarchical image classification tasks.
 - **Object detection** including rotated bounding box support
 - **Semantic segmentation**
 - **Instance segmentation** including tiling algorithm support
 - **Action recognition** including action classification and detection
 - **Anomaly recognition** tasks including anomaly classification, detection and segmentation
 
-OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/algorithms/index.html):
+OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/algorithms/index.html):
 
 - **Supervised**, incremental training, which includes class incremental scenario and contrastive learning for classification and semantic segmentation tasks
 - **Semi-supervised learning**
 - **Self-supervised learning**
 
 OpenVINO Training Extensions will provide the following features in coming releases:
 
 - **Distributed training** to accelerate the training process when you have multiple GPUs
 - **Half-precision training** to save GPUs memory and use larger batch sizes
-- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
+- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
 - OpenVINO Training Extensions uses [Datumaro](https://openvinotoolkit.github.io/datumaro/docs/) as the backend to hadle datasets. Thanks to that, OpenVINO Training Extensions supports the most common academic field dataset formats for each task. We constantly working to extend supported formats to give more freedom of datasets format choice.
-- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
+- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
 
 ---
 
 ## Getting Started
 
 ### Installation
 
-Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/installation.html).
+Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/installation.html).
 
 ### OpenVINO Training Extensions CLI Commands
 
 - `otx find` helps you quickly find the best pre-configured models templates as well as a list of supported backbones
 - `otx build` creates the workspace folder with all necessary components to start training. It can help you configure your own model with any supported backbone and even prepare a custom split for your dataset
 - `otx train` actually starts training on your dataset
 - `otx eval` runs evaluation of your trained model in PyTorch or OpenVINO IR format
 - `otx optimize` runs an optimization algorithm to quantize and prune your deep learning model with help of [NNCF](https://github.com/openvinotoolkit/nncf) and [POT](https://docs.openvino.ai/latest/pot_introduction.html) tools.
 - `otx export` starts exporting your model to the OpenVINO IR format
 - `otx deploy` outputs the exported model together with the self-contained python package, a demo application to port and infer it outside of this repository.
 - `otx demo` allows one to apply a trained model on the custom data or the online footage from a web camera and see how it will work in a real-life scenario.
 - `otx explain` runs explain algorithm on the provided data and outputs images with the saliency maps to show how your model makes predictions.
 
-You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/cli_commands.html).
+You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/cli_commands.html).
 
 ---
 
 ## Updates
 
-### v1.1.0 (1Q23)
-
-- Add FP16 IR export support (<https://github.com/openvinotoolkit/training_extensions/pull/1683>)
-- Add in-memory caching in dataloader (<https://github.com/openvinotoolkit/training_extensions/pull/1694>)
-- Add MoViNet template for action classification (<https://github.com/openvinotoolkit/training_extensions/pull/1742>)
-- Add Semi-SL multilabel classification algorithm (<https://github.com/openvinotoolkit/training_extensions/pull/1805>)
-- Integrate multi-gpu training for semi-supervised learning and self-supervised learning (<https://github.com/openvinotoolkit/training_extensions/pull/1534>)
-- Add train-type parameter to otx train (<https://github.com/openvinotoolkit/training_extensions/pull/1874>)
-- Add embedding of inference configuration to IR for classification (<https://github.com/openvinotoolkit/training_extensions/pull/1842>)
-- Enable VOC dataset in OTX (<https://github.com/openvinotoolkit/training_extensions/pull/1862>)
-- Add mmcls.VisionTransformer backbone support (<https://github.com/openvinotoolkit/training_extensions/pull/1908>)
-
-### v1.2+ (2Q23)
+### v1.2.0 (2Q23)
 
-- In planning
+- Add generating feature cli_report.log in output for otx training (<https://github.com/openvinotoolkit/training_extensions/pull/1959>)
+- Support multiple python versions up to 3.10 (<https://github.com/openvinotoolkit/training_extensions/pull/1978>)
+- Support export of onnx models (<https://github.com/openvinotoolkit/training_extensions/pull/1976>)
+- Add option to save images after inference in OTX CLI demo together with demo in exportable code (<https://github.com/openvinotoolkit/training_extensions/pull/2005>)
 
 ### Release History
 
 Please refer to the [CHANGELOG.md](CHANGELOG.md)
 
 ---
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/cls_dataset.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/cls_dataset.py`

 * *Files 5% similar despite different names*

```diff
@@ -21,18 +21,14 @@
 from mmaction.datasets.builder import DATASETS
 from mmaction.datasets.pipelines import Compose
 from mmaction.datasets.rawframe_dataset import RawframeDataset
 
 from otx.algorithms.action.adapters.mmaction.data.pipelines import RawFrameDecode
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import LabelEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 
 
 # pylint: disable=too-many-instance-attributes
 @DATASETS.register_module()
 class OTXActionClsDataset(RawframeDataset):
     """Wrapper that allows using a OTX dataset to train mmaction models.
 
@@ -92,52 +88,50 @@
 
             Action classification needs video for training, therefore this function generate item from video_info
             """
 
             item = self.video_info[list(self.video_info.keys())[index]]
             return item
 
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     # pylint: disable=too-many-arguments, invalid-name, super-init-not-called
     # TODO Check need for additional params such as multi_class, with_offset
     def __init__(
         self,
         otx_dataset: DatasetEntity,
         labels: List[LabelEntity],
         pipeline: Sequence[dict],
         test_mode: bool = False,
         modality: str = "RGB",  # [RGB, FLOW(Optical flow)]
     ):
         self.otx_dataset = otx_dataset
         self.labels = labels
+        self.CLASSES = [label.name for label in labels]
         self.test_mode = test_mode
         self.modality = modality
 
         self.video_infos = OTXActionClsDataset._DataInfoProxy(otx_dataset, labels, modality)
 
         self.pipeline = Compose(pipeline)
         for transform in self.pipeline.transforms:
             if isinstance(transform, RawFrameDecode):
                 transform.otx_dataset = self.otx_dataset
 
     def __len__(self) -> int:
         """Return length of dataset."""
         return len(self.video_infos)
 
-    @check_input_parameters_type()
     def prepare_train_frames(self, idx: int) -> Dict[str, Any]:
         """Get training data and annotations after pipeline.
 
         Args:
             idx (int): Index of data
         """
         item = copy(self.video_infos[idx])  # Copying dict(), not contents
         return self.pipeline(item)
 
-    @check_input_parameters_type()
     def prepare_test_frames(self, idx: int) -> Dict[str, Any]:
         """Get testing data after pipeline.
 
         Args:
             idx (int): Index of data
         """
         item = copy(self.video_infos[idx])  # Copying dict(), not contents
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/det_dataset.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/det_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,18 +31,14 @@
 
 from otx.algorithms.action.adapters.mmaction.data.pipelines import RawFrameDecode
 from otx.algorithms.action.adapters.mmaction.utils import det_eval
 from otx.api.entities.annotation import Annotation
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import LabelEntity
 from otx.api.entities.metadata import VideoMetadata
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 from otx.api.utils.shape_factory import ShapeFactory
 
 root_logger = get_root_logger()
 
 
 # pylint: disable=too-many-instance-attributes, too-many-arguments, too-many-locals, super-init-not-called
 @DATASETS.register_module()
@@ -205,29 +201,29 @@
                 thr = min(self.person_det_score_thr, max(proposals[:, 4]))
                 positive_inds = proposals[:, 4] >= thr
                 proposals = proposals[positive_inds]
                 proposals = proposals[: self.num_max_proposals]
                 metadata.update("proposals", proposals[:, :4])
                 metadata.update("scores", proposals[:, 4])
 
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     # TODO Remove duplicated codes with mmaction's AVADataset
     def __init__(
         self,
         otx_dataset: DatasetEntity,
         labels: List[LabelEntity],
         pipeline: Sequence[dict],
         test_mode: bool = False,
         person_det_score_thr: float = 0.9,
         num_max_proposals: int = 1000,
         modality: str = "RGB",
         fps: int = 30,
     ):
         self.otx_dataset = otx_dataset
         self.labels = labels
+        self.CLASSES = [label.name for label in labels]
         self.test_mode = test_mode
         self.modality = modality
         self._FPS = fps
         self.person_det_score_thr = person_det_score_thr
         self.num_max_proposals = num_max_proposals
 
         # OTX does not support custom_classes
@@ -241,25 +237,23 @@
         for transform in self.pipeline.transforms:
             if isinstance(transform, RawFrameDecode):
                 transform.otx_dataset = self.otx_dataset
 
         # TODO. Handle exclude file for AVA dataset
         self.exclude_file = None
 
-    @check_input_parameters_type()
     def prepare_train_frames(self, idx: int) -> Dict[str, Any]:
         """Get training data and annotations after pipeline.
 
         Args:
             idx (int): Index of data
         """
         item = copy(self.video_infos[idx])  # Copying dict(), not contents
         return self.pipeline(item)
 
-    @check_input_parameters_type()
     def prepare_test_frames(self, idx: int) -> Dict[str, Any]:
         """Get testing data after pipeline.
 
         Args:
             idx (int): Index of data
         """
         item = copy(self.video_infos[idx])  # Copying dict(), not contents
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/loading.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/data/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/backbones/movinet.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/backbones/movinet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/detectors/fast_rcnn.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/detectors/fast_rcnn.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/movinet_head.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/movinet_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/heads/roi_head.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/heads/roi_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/movinet_recognizer.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/models/recognizers/movinet_recognizer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/config_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/tools/test_action_sample_classification.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,109 +1,120 @@
-"""Collection of utils for task implementation in Action Task."""
+"""Unit Test for otx.algorithms.action.tools.sample_classification."""
 
-# Copyright (C) 2021 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
 #
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions
-# and limitations under the License.
-
-from collections import defaultdict
-from typing import List, Union
-
-from mmcv.utils import Config, ConfigDict
-
-from otx.algorithms.common.adapters.mmcv.utils import (
-    get_data_cfg,
-    patch_data_pipeline,
-    prepare_work_dir,
+
+from mmcv.utils import Config
+
+from otx.algorithms.action.tools.sample_classification import (
+    load_test_dataset,
+    main,
+    parse_args,
 )
+from otx.algorithms.common.configs.training_base import TrainType
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.label import LabelEntity
+from otx.api.entities.label import Domain
+from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.model_template import TaskType
-from otx.api.usecases.reporting.time_monitor_callback import TimeMonitorCallback
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
+from tests.test_suite.e2e_test_system import e2e_pytest_unit
+from tests.unit.algorithms.action.test_helpers import (
+    generate_action_cls_otx_dataset,
+    generate_labels,
 )
 
 
-@check_input_parameters_type()
-def patch_config(config: Config, data_pipeline_path: str, work_dir: str, task_type: TaskType):
-    """Patch recipe config suitable to mmaction."""
-    # FIXME omnisource is hard coded
-    config.omnisource = None
-    config.work_dir = work_dir
-    patch_data_pipeline(config, data_pipeline_path)
-    if task_type == TaskType.ACTION_CLASSIFICATION:
-        _patch_cls_datasets(config)
-    elif task_type == TaskType.ACTION_DETECTION:
-        _patch_det_dataset(config)
-    else:
-        raise NotImplementedError(f"{task_type} is not supported in action task")
-
-
-@check_input_parameters_type()
-def _patch_cls_datasets(config: Config):
-    """Patch cls dataset config suitable to mmaction."""
-
-    assert "data" in config
-    for subset in ("train", "val", "test", "unlabeled"):
-        cfg = config.data.get(subset, None)
-        if not cfg:
-            continue
-        cfg.type = "OTXActionClsDataset"
-        cfg.otx_dataset = None
-        cfg.labels = None
-
-
-@check_input_parameters_type()
-def _patch_det_dataset(config: Config):
-    """Patch det dataset config suitable to mmaction."""
-    assert "data" in config
-    for subset in ("train", "val", "test", "unlabeled"):
-        cfg = config.data.get(subset, None)
-        if not cfg:
-            continue
-        cfg.type = "OTXActionDetDataset"
-
-
-@check_input_parameters_type()
-def set_data_classes(config: Config, labels: List[LabelEntity], task_type: TaskType):
-    """Setter data classes into config."""
-    for subset in ("train", "val", "test"):
-        cfg = get_data_cfg(config, subset)
-        cfg.labels = labels
-
-    # FIXME classification head name is hard-coded
-    if task_type == TaskType.ACTION_CLASSIFICATION:
-        config.model["cls_head"].num_classes = len(labels)
-    elif task_type == TaskType.ACTION_DETECTION:
-        config.model["roi_head"]["bbox_head"].num_classes = len(labels) + 1
-        if len(labels) < 5:
-            config.model["roi_head"]["bbox_head"]["topk"] = len(labels) - 1
-
-
-@check_input_parameters_type({"train_dataset": DatasetParamTypeCheck, "val_dataset": DatasetParamTypeCheck})
-def prepare_for_training(
-    config: Union[Config, ConfigDict],
-    train_dataset: DatasetEntity,
-    val_dataset: DatasetEntity,
-    time_monitor: TimeMonitorCallback,
-    learning_curves: defaultdict,
-) -> Config:
-    """Prepare configs for training phase."""
-    prepare_work_dir(config)
-    data_train = get_data_cfg(config)
-    data_train.otx_dataset = train_dataset
-    config.data.val.otx_dataset = val_dataset
-    config.custom_hooks.append({"type": "OTXProgressHook", "time_monitor": time_monitor, "verbose": True})
-    config.log_config.hooks.append({"type": "OTXLoggerHook", "curves": learning_curves})
+@e2e_pytest_unit
+def test_parse_args(mocker) -> None:
+    """Test parse_args function."""
+
+    class MockArgParser:
+        def __init__(self, description):
+            self.description = description
+
+        def add_argument(self, name, *args, **kwargs):
+            setattr(self, name.split("--")[-1], True)
+
+        def parse_args(self):
+            return self
+
+    mocker.patch("otx.algorithms.action.tools.sample_classification.argparse.ArgumentParser", side_effect=MockArgParser)
+    parser = parse_args()
+    assert parser.template_file_path is not None
+    assert parser.export is not None
+
+
+@e2e_pytest_unit
+def test_load_test_dataset() -> None:
+    """Test laod_test_dataset function."""
+
+    class MockTemplate:
+        task_type = TaskType.ACTION_CLASSIFICATION
+        hyper_parameters = Config(
+            {"parameter_overrides": {"algo_backend": {"train_type": {"default_value": TrainType.Incremental.value}}}}
+        )
+
+    dataset, label_schema = load_test_dataset(MockTemplate())
+    isinstance(dataset, DatasetEntity)
+    isinstance(label_schema, LabelSchemaEntity)
+
+
+@e2e_pytest_unit
+def test_main(mocker) -> None:
+    """Test main function."""
+
+    class MockArgs:
+        template_file_path = "dummy_path"
+        export = False
+
+    class MockTaskEnvironment:
+        def __init__(self, *args, **kwargs):
+            self.model = None
+
+        def get_model_configuration(self):
+            return True
+
+    class MockTestCls:
+        def __init__(self, task_environment):
+            pass
+
+        def train(self, dataset, output_model):
+            pass
+
+        def infer(self, dataset, params):
+            return dataset
+
+        def evaluate(self, resultset):
+            resultset.performance = 1.0
+
+        def export(self, export_type, model):
+            return model
+
+        def optimize(self, optimization_type, dataset, modle, params):
+            pass
+
+    mocker.patch(
+        "otx.algorithms.action.tools.sample_classification.parse_model_template",
+        return_value=Config(
+            {
+                "hyper_parameters": {"data": "dummy_data"},
+                "entrypoints": {"base": "dummy_base", "openvino": "dummy_base"},
+            }
+        ),
+    )
+    mocker.patch(
+        "otx.algorithms.action.tools.sample_classification.load_test_dataset",
+        return_value=(
+            generate_action_cls_otx_dataset(3, 3, generate_labels(3, Domain.ACTION_CLASSIFICATION)),
+            "dummy_label_schema",
+        ),
+    )
+    mocker.patch(
+        "otx.algorithms.action.tools.sample_classification.create",
+        return_value=Config({"learning_parameters": {"num_iters": 4}}),
+    )
+    mocker.patch("otx.algorithms.action.tools.sample_classification.TaskEnvironment", side_effect=MockTaskEnvironment)
+    mocker.patch("otx.algorithms.action.tools.sample_classification.get_task_class", return_value=MockTestCls)
+    main(MockArgs())
 
-    return config
+    MockArgs.export = True
+    main(MockArgs())
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/det_eval_utils.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/det_eval_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/mmaction/utils/export_utils.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/utils/export_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/dataloader.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/dataloader.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/model_wrappers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/model_wrappers/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/adapters/openvino/model_wrappers/openvino_models.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/model_wrappers/openvino_models.py`

 * *Files 7% similar despite different names*

```diff
@@ -17,15 +17,14 @@
 # pylint: disable=invalid-name
 
 from typing import Any, Dict, List
 
 import numpy as np
 
 from otx.api.entities.datasets import DatasetItemEntity
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 try:
     from openvino.model_zoo.model_api.adapters import OpenvinoAdapter
     from openvino.model_zoo.model_api.models.model import Model
     from openvino.model_zoo.model_api.models.utils import (
         RESIZE_TYPES,
         Detection,
@@ -33,23 +32,21 @@
     )
 except ImportError as e:
     import warnings
 
     warnings.warn(f"{e}, ModelAPI was not found.")
 
 
-@check_input_parameters_type()
 def softmax_numpy(x: np.ndarray):
     """Softmax numpy."""
     x = np.exp(x - np.max(x))
     x /= np.sum(x)
     return x
 
 
-@check_input_parameters_type()
 def get_multiclass_predictions(logits: np.ndarray, activate: bool = True):
     """Get multiclass predictions."""
     index = np.argmax(logits)
     if activate:
         logits = softmax_numpy(logits)
     return [(index, logits[index])]
 
@@ -89,37 +86,34 @@
     def _get_outputs(self):
         layer_name = "logits"
         for name, meta in self.outputs.items():
             if "logits" in meta.names:
                 layer_name = name
         return layer_name
 
-    @check_input_parameters_type()
     def preprocess(self, inputs: List[DatasetItemEntity]):
         """Pre-process."""
         meta = {"original_shape": inputs[0].media.numpy.shape}
         frames = []
         for item in inputs:
             frame = item.media.numpy
             frame = self.resize(frame, (self.w, self.h))
             frames.append(frame)
         np_frames = self._reshape(frames)
         dict_inputs = {self.image_blob_name: np_frames}
         meta.update({"resized_shape": np_frames[0].shape})
         return dict_inputs, meta
 
     @staticmethod
-    @check_input_parameters_type()
     def _reshape(inputs: List[np.ndarray]) -> np.ndarray:
         """Reshape(expand, transpose, permute) the input np.ndarray."""
         np_inputs = np.expand_dims(inputs, axis=(0, 1))  # [1, 1, T, H, W, C]
         np_inputs = np_inputs.transpose(0, 1, -1, 2, 3, 4)  # [1, 1, C, T, H, W]
         return np_inputs
 
-    @check_input_parameters_type()
     # pylint: disable=unused-argument
     def postprocess(self, outputs: Dict[str, np.ndarray], meta: Dict[str, Any]):
         """Post-process."""
         logits = outputs[self.out_layer_name].squeeze()
         return get_multiclass_predictions(logits)
 
 
@@ -158,37 +152,34 @@
         for name in self.outputs:
             if "bboxes" in name:
                 out_names["bboxes"] = name
             elif "labels" in name:
                 out_names["labels"] = name
         return out_names
 
-    @check_input_parameters_type()
     def preprocess(self, inputs: List[DatasetItemEntity]):
         """Pre-process."""
         meta = {"original_shape": inputs[0].media.numpy.shape}
         frames = []
         for item in inputs:
             frame = item.media.numpy
             frame = self.resize(frame, (self.w, self.h))
             frames.append(frame)
         np_frames = self.reshape(frames)
         dict_inputs = {self.image_blob_name: np_frames}
         meta.update({"resized_shape": np_frames.shape})
         return dict_inputs, meta
 
     @staticmethod
-    @check_input_parameters_type()
     def reshape(inputs: List[np.ndarray]) -> np.ndarray:
         """Reshape(expand, transpose, permute) the input np.ndarray."""
         np_inputs = np.expand_dims(inputs, axis=0)  # [1, T, H, W, C]
         np_inputs = np_inputs.transpose(0, -1, 1, 2, 3)  # [1, C, T, H, W]
         return np_inputs
 
-    @check_input_parameters_type()
     def postprocess(self, outputs: Dict[str, np.ndarray], meta: Dict[str, Any]):
         """Post-process."""
         # TODO Support multi label classification
         H, W, _ = meta["original_shape"]
         bboxes = outputs[self.out_layer_names["bboxes"]]
         labels = outputs[self.out_layer_names["labels"]]
         scores = labels[:, 1:].max(axis=1)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/base/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/base/configuration.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/base/configuration.py`

 * *Files 4% similar despite different names*

```diff
@@ -50,14 +50,19 @@
             "Finally, for training on large datasets for at least 20 "
             "epochs, cyclic annealing could result in the best model.",
             editable=True,
             visible_in_ui=True,
         )
 
     @attrs
+    class __Postprocessing(BaseConfig.BasePostprocessing):
+        header = string_attribute("Postprocessing")
+        description = header
+
+    @attrs
     class __NNCFOptimization(BaseConfig.BaseNNCFOptimization):
         header = string_attribute("Optimization by NNCF")
         description = header
         visible_in_ui = boolean_attribute(False)
 
     @attrs
     class __POTParameter(BaseConfig.BasePOTParameter):
@@ -67,10 +72,11 @@
 
     @attrs
     class __AlgoBackend(BaseConfig.BaseAlgoBackendParameters):
         header = string_attribute("Parameters for the MPA algo-backend")
         description = header
 
     learning_parameters = add_parameter_group(__LearningParameters)
+    postprocessing = add_parameter_group(__Postprocessing)
     nncf_optimization = add_parameter_group(__NNCFOptimization)
     pot_parameters = add_parameter_group(__POTParameter)
     algo_backend = add_parameter_group(__AlgoBackend)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/data_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,14 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 # dataset settings
-seed = 2
 dataset_type = "RawframeDataset"
 
 img_norm_cfg = dict(mean=[0.0, 0.0, 0.0], std=[255.0, 255.0, 255.0], to_bgr=False)
 
 clip_len = 8
 frame_interval = 4
 train_pipeline = [
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/movinet/template.yaml` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/movinet/template.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 application: ~
 
 # Algo backend.
 framework: OTXAction v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.action.tasks.ActionTrainTask
-  openvino: otx.algorithms.action.tasks.ActionOpenVINOTask
+  base: otx.algorithms.action.adapters.mmaction.task.MMActionTask
+  openvino: otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/classification/x3d/template.yaml` & `otx-1.2.0rc1/otx/algorithms/action/configs/classification/x3d/template.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 application: ~
 
 # Algo backend.
 framework: OTXAction v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.action.tasks.ActionTrainTask
-  openvino: otx.algorithms.action.tasks.ActionOpenVINOTask
+  base: otx.algorithms.action.adapters.mmaction.task.MMActionTask
+  openvino: otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/ava_data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/ava_data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/base_detection_static.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/base_detection_static.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/base/faster_rcnn_config.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/base/faster_rcnn_config.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/__init__.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/model.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of Fast RCNN with X3D for Action Detection Task."""
+"""Model configuration of ATSS model for Detection Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -12,62 +12,80 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
-# model setting
+_base_ = [
+    "../../../../../recipes/stages/detection/incremental.py",
+    "../../../../common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml",
+    "../../base/models/detector.py",
+]
+
 model = dict(
-    type="AVAFastRCNN",
-    backbone=dict(type="X3D", gamma_w=1, gamma_b=2.25, gamma_d=2.2),
-    roi_head=dict(
-        type="AVARoIHead",
-        bbox_roi_extractor=dict(
-            type="SingleRoIExtractor3D", roi_layer_type="RoIAlign", output_size=8, with_temporal_pool=True
+    type="CustomATSS",
+    neck=dict(
+        type="FPN",
+        in_channels=[24, 32, 96, 320],
+        out_channels=64,
+        start_level=1,
+        add_extra_convs="on_output",
+        num_outs=5,
+        relu_before_extra_convs=True,
+    ),
+    bbox_head=dict(
+        type="CustomATSSHead",
+        num_classes=2,
+        in_channels=64,
+        stacked_convs=4,
+        feat_channels=64,
+        anchor_generator=dict(
+            type="AnchorGenerator",
+            ratios=[1.0],
+            octave_base_scale=8,
+            scales_per_octave=1,
+            strides=[8, 16, 32, 64, 128],
+        ),
+        bbox_coder=dict(
+            type="DeltaXYWHBBoxCoder",
+            target_means=[0.0, 0.0, 0.0, 0.0],
+            target_stds=[0.1, 0.1, 0.2, 0.2],
+        ),
+        loss_cls=dict(type="FocalLoss", use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=1.0),
+        loss_bbox=dict(type="GIoULoss", loss_weight=2.0),
+        loss_centerness=dict(type="CrossEntropyLoss", use_sigmoid=True, loss_weight=1.0),
+        use_qfl=False,
+        qfl_cfg=dict(
+            type="QualityFocalLoss",
+            use_sigmoid=True,
+            beta=2.0,
+            loss_weight=1.0,
         ),
-        bbox_head=dict(type="BBoxHeadAVA", in_channels=432, num_classes=81, multilabel=False, dropout_ratio=0.5),
     ),
     train_cfg=dict(
-        rcnn=dict(
-            assigner=dict(type="MaxIoUAssignerAVA", pos_iou_thr=0.9, neg_iou_thr=0.9, min_pos_iou=0.9),
-            sampler=dict(type="RandomSampler", num=32, pos_fraction=1, neg_pos_ub=-1, add_gt_as_proposals=True),
-            pos_weight=1.0,
-            debug=False,
+        assigner=dict(type="ATSSAssigner", topk=9),
+        allowed_border=-1,
+        pos_weight=-1,
+        debug=False,
+    ),
+    test_cfg=dict(
+        nms_pre=1000,
+        min_bbox_size=0,
+        score_thr=0.05,
+        nms=dict(type="nms", iou_threshold=0.6),
+        max_per_img=100,
+    ),
+    backbone=dict(
+        out_indices=(
+            2,
+            3,
+            4,
+            5,
         )
     ),
-    test_cfg=dict(rcnn=dict(action_thr=0.002)),
 )
 
-optimizer = dict(type="SGD", lr=0.1, momentum=0.9, weight_decay=1e-5)
-optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))
+load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
+/models/object_detection/v2/mobilenet_v2-atss.pth"
 
-lr_config = dict(
-    policy="CosineAnnealing",
-    by_epoch=False,
-    min_lr=0,
-    warmup="linear",
-    warmup_by_epoch=True,
-    warmup_iters=2,
-    warmup_ratio=0.1,
-)
-checkpoint_config = dict(interval=1)
-workflow = [("train", 1)]
-evaluation = dict(interval=1, save_best="mAP@0.5IOU", final_metric="mAP@0.5IOU")
-log_config = dict(
-    interval=10,
-    hooks=[
-        dict(type="TextLoggerHook"),
-    ],
-)
-dist_params = dict(backend="nccl")
-log_level = "INFO"
-work_dir = "logs/x3d_kinetics_pretrained_ava_rgb/cosine/"
-load_from = (
-    "https://download.openmmlab.com/mmaction/recognition/x3d/facebook/"
-    "x3d_m_facebook_16x5x1_kinetics400_rgb_20201027-3f42382a.pth"
-)
-resume_from = None
-find_unused_parameters = False
-# Temporary solution, gpu_ids is not used in otx
-gpu_ids = [0]
-seed = 2
+fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/template.yaml` & `otx-1.2.0rc1/otx/algorithms/action/configs/detection/x3d_fast_rcnn/template.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 application: ~
 
 # Algo backend.
 framework: OTXAction v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.action.tasks.ActionTrainTask
-  openvino: otx.algorithms.action.tasks.ActionOpenVINOTask
+  base: otx.algorithms.action.adapters.mmaction.task.MMActionTask
+  openvino: otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tasks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Task Initialization of OTX Action Task."""
+"""Adapters of classification - openvino."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -10,16 +10,10 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-from .inference import ActionInferenceTask
-from .openvino import ActionOpenVINOTask
-from .train import ActionTrainTask
+from .task import ClassificationOpenVINOTask
 
-__all__ = [
-    "ActionInferenceTask",
-    "ActionOpenVINOTask",
-    "ActionTrainTask",
-]
+__all__ = ["ClassificationOpenVINOTask"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tasks/inference.py` & `otx-1.2.0rc1/otx/algorithms/action/task.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,409 +1,331 @@
-"""Inference Task of OTX Action Task."""
+"""Task of OTX Video Recognition."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-import copy
 import io
 import os
-import warnings
-from typing import Dict, Iterable, Optional, Tuple
+from abc import ABC, abstractmethod
+from typing import Any, Dict, Iterable, List, Optional, Union
 
 import numpy as np
 import torch
-from mmaction.datasets import build_dataloader, build_dataset
-from mmaction.models import build_model
-from mmaction.utils import get_root_logger
-from mmcv.parallel import MMDataParallel
-from mmcv.runner import load_checkpoint, load_state_dict
-from mmcv.utils import Config
-
-from otx.algorithms.action.adapters.mmaction import (
-    Exporter,
-    patch_config,
-    set_data_classes,
-)
+from mmcv.utils import ConfigDict
+
 from otx.algorithms.action.configs.base import ActionConfig
-from otx.algorithms.common.adapters.mmcv.utils import prepare_for_testing
-from otx.algorithms.common.tasks.training_base import BaseTask
-from otx.algorithms.common.utils.callback import InferenceProgressCallback
+from otx.algorithms.common.tasks.base_task import TRAIN_TYPE_DIR_PATH, OTXTask
+from otx.algorithms.common.utils.callback import (
+    InferenceProgressCallback,
+    TrainingProgressCallback,
+)
+from otx.algorithms.common.utils.logger import get_logger
+from otx.api.configuration import cfg_helper
+from otx.api.configuration.helper.utils import config_to_bytes, ids_to_strings
 from otx.api.entities.annotation import Annotation
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.metrics import (
+    BarChartInfo,
+    BarMetricsGroup,
+    CurveMetric,
+    LineChartInfo,
+    LineMetricsGroup,
+    MetricsGroup,
+    ScoreMetric,
+    VisualizationType,
+)
 from otx.api.entities.model import (
     ModelEntity,
     ModelFormat,
     ModelOptimizationType,
     ModelPrecision,
 )
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.result_media import ResultMediaEntity
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.rectangle import Rectangle
+from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.entities.tensor import TensorEntity
-from otx.api.entities.train_parameters import default_progress_callback
+from otx.api.entities.train_parameters import TrainParameters, default_progress_callback
 from otx.api.serialization.label_mapper import label_schema_to_bytes
+from otx.api.usecases.evaluation.accuracy import Accuracy
+from otx.api.usecases.evaluation.f_measure import FMeasure
 from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
-from otx.api.usecases.tasks.interfaces.export_interface import ExportType, IExportTask
-from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
-from otx.api.usecases.tasks.interfaces.unload_interface import IUnload
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from otx.api.utils.vis_utils import get_actmap
 
-logger = get_root_logger()
-
+logger = get_logger()
 
-# pylint: disable=too-many-locals, unused-argument
-class ActionInferenceTask(BaseTask, IInferenceTask, IExportTask, IEvaluationTask, IUnload):
-    """Inference Task Implementation of OTX Action Task."""
 
-    @check_input_parameters_type()
-    def __init__(self, task_environment: TaskEnvironment, **kwargs):
-        super().__init__(ActionConfig, task_environment, **kwargs)
-        self.deploy_cfg = None
+class OTXActionTask(OTXTask, ABC):
+    """Task class for OTX action."""
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
-    def infer(
-        self,
-        dataset: DatasetEntity,
-        inference_parameters: Optional[InferenceParameters] = None,
-    ) -> DatasetEntity:
-        """Main infer function of OTX Action Task."""
-        logger.info("infer()")
+    # pylint: disable=too-many-instance-attributes, too-many-locals
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__(task_environment, output_path)
+        self._task_config = ActionConfig
+        self._hyperparams: ConfigDict = task_environment.get_hyper_parameters(self._task_config)
+        self._train_type = self._hyperparams.algo_backend.train_type
+        self._model_dir = os.path.join(
+            os.path.abspath(os.path.dirname(self._task_environment.model_template.model_template_path)),
+            TRAIN_TYPE_DIR_PATH[self._train_type.name],
+        )
 
-        if inference_parameters:
-            update_progress_callback = inference_parameters.update_progress
+        if hasattr(self._hyperparams, "postprocessing") and hasattr(
+            self._hyperparams.postprocessing, "confidence_threshold"
+        ):
+            self.confidence_threshold = self._hyperparams.postprocessing.confidence_threshold
         else:
-            update_progress_callback = default_progress_callback
+            self.confidence_threshold = 0.0
 
-        self._time_monitor = InferenceProgressCallback(len(dataset), update_progress_callback)
+        if task_environment.model is not None:
+            self._load_model()
 
-        def pre_hook(module, inp):
-            self._time_monitor.on_test_batch_begin(None, None)
+        self.data_pipeline_path = os.path.join(self._model_dir, "data_pipeline.py")
 
-        def hook(module, inp, out):
-            self._time_monitor.on_test_batch_end(None, None)
+    def train(
+        self, dataset: DatasetEntity, output_model: ModelEntity, train_parameters: Optional[TrainParameters] = None
+    ):
+        """Train function for OTX action task.
+
+        Actual training is processed by _train_model fucntion
+        """
+        logger.info("train()")
+        # Check for stop signal when training has stopped.
+        # If should_stop is true, training was cancelled and no new
+        if self._should_stop:
+            logger.info("Training cancelled.")
+            self._should_stop = False
+            self._is_training = False
+            return
 
-        if self._recipe_cfg is None:
-            self._init_task()
-        if self._model:
-            with self._model.register_forward_pre_hook(pre_hook), self._model.register_forward_hook(hook):
-                prediction_results, _ = self._infer_model(dataset, inference_parameters)
-            # TODO Load _add_predictions_to_dataset function from self._task_type
-            if self._task_type == TaskType.ACTION_CLASSIFICATION:
-                self._add_predictions_to_dataset(prediction_results, dataset)
-            elif self._task_type == TaskType.ACTION_DETECTION:
-                self._add_det_predictions_to_dataset(prediction_results, dataset)
-            logger.info("Inference completed")
+        # Set OTX LoggerHook & Time Monitor
+        if train_parameters:
+            update_progress_callback = train_parameters.update_progress
         else:
-            raise Exception("Model initialization is failed")
-        return dataset
+            update_progress_callback = default_progress_callback
+        self._time_monitor = TrainingProgressCallback(update_progress_callback)
 
-    def _initialize_post_hook(self, options=None):
-        """Procedure after inialization."""
+        results = self._train_model(dataset)
 
-        if options is None:
+        # Check for stop signal when training has stopped. If should_stop is true, training was cancelled and no new
+        if self._should_stop:
+            logger.info("Training cancelled.")
+            self._should_stop = False
+            self._is_training = False
             return
 
-        if "deploy_cfg" in options:
-            self.deploy_cfg = options["deploy_cfg"]
-
-    def _infer_model(
-        self, dataset: DatasetEntity, inference_parameters: Optional[InferenceParameters] = None
-    ) -> Tuple[Iterable, Optional[float]]:
-        """Inference wrapper.
-
-        This method triggers the inference and returns `prediction_results` zipped with prediction results,
-        feature vectors, and saliency maps. `metric` is returned as a float value if InferenceParameters.is_evaluation
-        is set to true, otherwise, `None` is returned.
-
-        Args:
-            dataset (DatasetEntity): the validation or test dataset to be inferred with
-            inference_parameters (Optional[InferenceParameters], optional): Option to run evaluation or not.
-                If `InferenceParameters.is_evaluation=True` then metric is returned, otherwise, both metric and
-                saliency maps are empty. Defaults to None.
-
-        Returns:
-            Tuple[Iterable, float]: Iterable prediction results for each sample and metric for on the given dataset
-        """
-        if self._recipe_cfg is None:
-            raise Exception("Recipe config is not initialized properly")
+        # get output model
+        model_ckpt = results.get("final_ckpt")
+        if model_ckpt is None:
+            logger.error("cannot find final checkpoint from the results.")
+            return
+        # update checkpoint to the newly trained model
+        self._model_ckpt = model_ckpt
 
-        dump_features = False
-        dump_saliency_map = False
+        # get prediction on validation set
+        self._is_training = False
+        val_dataset = dataset.get_subset(Subset.VALIDATION)
+        val_preds, val_performance = self._infer_model(val_dataset, InferenceParameters(is_evaluation=True))
 
-        test_config = prepare_for_testing(self._recipe_cfg, dataset)
-        mm_test_dataset = build_dataset(test_config.data.test)
-        # TODO Get batch size and num_gpus autometically
-        batch_size = 1
-        mm_test_dataloader = build_dataloader(
-            mm_test_dataset,
-            videos_per_gpu=batch_size,
-            workers_per_gpu=test_config.data.workers_per_gpu,
-            num_gpus=1,
-            dist=False,
-            shuffle=False,
+        preds_val_dataset = val_dataset.with_empty_annotations()
+        if self._task_type == TaskType.ACTION_CLASSIFICATION:
+            self._add_cls_predictions_to_dataset(val_preds, preds_val_dataset)
+        elif self._task_type == TaskType.ACTION_DETECTION:
+            self._add_det_predictions_to_dataset(val_preds, preds_val_dataset, 0.0)
+
+        result_set = ResultSetEntity(
+            model=output_model,
+            ground_truth_dataset=val_dataset,
+            prediction_dataset=preds_val_dataset,
         )
 
-        self._model.eval()
-        if torch.cuda.is_available():
-            eval_model = MMDataParallel(self._model.cuda(test_config.gpu_ids[0]), device_ids=test_config.gpu_ids)
-        else:
-            eval_model = MMDataParallel(self._model)
-
-        eval_predictions = []
-        feature_vectors = []
-        saliency_maps = []
-
-        def dump_features_hook():
-            raise NotImplementedError("get_feature_vector function for mmaction is not implemented")
-
-        # pylint: disable=unused-argument
-        def dummy_dump_features_hook(model, inp, out):
-            feature_vectors.append(None)
-
-        def dump_saliency_hook():
-            raise NotImplementedError("get_saliency_map for mmaction is not implemented")
-
-        # pylint: disable=unused-argument
-        def dummy_dump_saliency_hook(model, inp, out):
-            saliency_maps.append(None)
-
-        feature_vector_hook = dump_features_hook if dump_features else dummy_dump_features_hook
-        saliency_map_hook = dump_saliency_hook if dump_saliency_map else dummy_dump_saliency_hook
-
-        # Use a single gpu for testing. Set in both mm_test_dataloader and eval_model
-        with eval_model.module.backbone.register_forward_hook(feature_vector_hook):
-            with eval_model.module.backbone.register_forward_hook(saliency_map_hook):
-                for data in mm_test_dataloader:
-                    with torch.no_grad():
-                        result = eval_model(return_loss=False, **data)
-                    eval_predictions.extend(result)
-
-        # hard-code way to remove EvalHook args
-        for key in ["interval", "tmpdir", "start", "gpu_collect", "save_best", "rule", "dynamic_intervals"]:
-            self._recipe_cfg.evaluation.pop(key, None)
-
-        metric = None
-        metric_name = self._recipe_cfg.evaluation.final_metric
-        if inference_parameters:
-            if inference_parameters.is_evaluation:
-                metric = mm_test_dataset.evaluate(eval_predictions, **self._recipe_cfg.evaluation)[metric_name]
-
-        assert len(eval_predictions) == len(feature_vectors), f"{len(eval_predictions)} != {len(feature_vectors)}"
-        assert len(eval_predictions) == len(saliency_maps), f"{len(eval_predictions)} != {len(saliency_maps)}"
-        predictions = zip(eval_predictions, feature_vectors, saliency_maps)
-
-        return predictions, metric
-
-    # pylint: disable=attribute-defined-outside-init
-    def _init_task(self, **kwargs):
-        # FIXME: Temporary remedy for CVS-88098
-        self._initialize(kwargs)
-        logger.info(f"running task... kwargs = {kwargs}")
-        if self._recipe_cfg is None:
-            raise RuntimeError("'config' is not initialized yet. call prepare() method before calling this method")
-
-        self._model = self._load_model(self._task_environment.model)
-
-    def _load_model(self, model: ModelEntity):
-        if self._recipe_cfg is None:
-            raise Exception("Recipe config is not initialized properly")
-        if model is not None:
-            # If a model has been trained and saved for the task already, create empty model and load weights here
-            buffer = io.BytesIO(model.get_data("weights.pth"))
-            model_data = torch.load(buffer, map_location=torch.device("cpu"))
-
-            self.confidence_threshold: float = model_data.get("confidence_threshold", self.confidence_threshold)
-            model = self._create_model(self._recipe_cfg, from_scratch=True)
-
-            try:
-                load_state_dict(model, model_data["model"])
-
-                # It prevent model from being overwritten
-                if "load_from" in self._recipe_cfg:
-                    self._recipe_cfg.load_from = None
-
-                logger.info("Loaded model weights from Task Environment")
-                logger.info(f"Model architecture: {self._model_name}")
-                for name, weights in model.named_parameters():
-                    if not torch.isfinite(weights).all():
-                        logger.info(f"Invalid weights in: {name}. Recreate model from pre-trained weights")
-                        model = self._create_model(self._recipe_cfg, from_scratch=False)
-                        return model
+        metric: Union[Accuracy, FMeasure]
 
-            except BaseException as ex:
-                raise ValueError("Could not load the saved model. The model file structure is invalid.") from ex
-        else:
-            # If there is no trained model yet, create model with pretrained weights as defined in the model config
-            # file.
-            model = self._create_model(self._recipe_cfg, from_scratch=False)
-            logger.info(
-                f"No trained model in project yet. Created new model with '{self._model_name}' "
-                f"architecture and general-purpose pretrained weights."
-            )
-        return model
+        if self._task_type == TaskType.ACTION_CLASSIFICATION:
+            metric = MetricsHelper.compute_accuracy(result_set)
+        if self._task_type == TaskType.ACTION_DETECTION:
+            if self._hyperparams.postprocessing.result_based_confidence_threshold:
+                best_confidence_threshold = None
+                logger.info("Adjusting the confidence threshold")
+                metric = MetricsHelper.compute_f_measure(result_set, vary_confidence_threshold=True)
+                if metric.best_confidence_threshold:
+                    best_confidence_threshold = metric.best_confidence_threshold.value
+                if best_confidence_threshold is None:
+                    raise ValueError("Cannot compute metrics: Invalid confidence threshold!")
+                logger.info(f"Setting confidence threshold to {best_confidence_threshold} based on results")
+                self.confidence_threshold = best_confidence_threshold
+            else:
+                metric = MetricsHelper.compute_f_measure(result_set, vary_confidence_threshold=False)
 
-    @staticmethod
-    def _create_model(config: Config, from_scratch: bool = False):
-        """Creates a model, based on the configuration in config.
+        # compose performance statistics
+        performance = metric.get_performance()
+        performance.dashboard_metrics.extend(self._generate_training_metrics(self._learning_curves, val_performance))
+        logger.info(f"Final model performance: {performance}")
+        # save resulting model
+        self.save_model(output_model)
+        output_model.performance = performance
+        logger.info("train done.")
+
+    @abstractmethod
+    def _train_model(self, dataset: DatasetEntity):
+        """Train model and return the results."""
+        raise NotImplementedError
 
-        :param config: mmaction configuration from which the model has to be built
-        :param from_scratch: bool, if True does not load any weights
+    def infer(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ) -> DatasetEntity:
+        """Main infer function."""
+        logger.info("infer()")
 
-        :return model: ModelEntity in training mode
-        """
-        model_cfg = copy.deepcopy(config.model)
+        update_progress_callback = default_progress_callback
+        if inference_parameters is not None:
+            update_progress_callback = inference_parameters.update_progress  # type: ignore
 
-        init_from = None if from_scratch else config.get("load_from", None)
-        logger.warning(init_from)
-        if init_from is not None:
-            # No need to initialize backbone separately, if all weights are provided.
-            # model_cfg.pretrained = None
-            logger.warning("build model")
-            model = build_model(model_cfg)
-            # Load all weights.
-            logger.warning("load checkpoint")
-            load_checkpoint(model, init_from, map_location="cpu")
-        else:
-            logger.warning("build model")
-            model = build_model(model_cfg)
-        return model
+        self._time_monitor = InferenceProgressCallback(len(dataset), update_progress_callback)
+        # If confidence threshold is adaptive then up-to-date value should be stored in the model
+        # and should not be changed during inference. Otherwise user-specified value should be taken.
+        if not self._hyperparams.postprocessing.result_based_confidence_threshold:
+            self.confidence_threshold = self._hyperparams.postprocessing.confidence_threshold
+        logger.info(f"Confidence threshold {self.confidence_threshold}")
 
-    @check_input_parameters_type()
-    def evaluate(
-        self,
-        output_resultset: ResultSetEntity,
-    ):
-        """Evaluate function of OTX Action Task."""
-        logger.info("called evaluate()")
-        self._remove_empty_frames(output_resultset.ground_truth_dataset)
-        metric = self._get_metric(output_resultset)
-        performance = metric.get_performance()
-        logger.info(f"Final model performance: {str(performance)}")
-        output_resultset.performance = metric.get_performance()
-        logger.info("Evaluation completed")
+        prediction_results, _ = self._infer_model(dataset, inference_parameters)
 
-    def _get_metric(self, output_resultset: ResultSetEntity):
         if self._task_type == TaskType.ACTION_CLASSIFICATION:
-            return MetricsHelper.compute_accuracy(output_resultset)
-        if self._task_type == TaskType.ACTION_DETECTION:
-            return MetricsHelper.compute_f_measure(output_resultset)
-        raise NotImplementedError(f"{self._task_type} is not supported in action task")
-
-    def _remove_empty_frames(self, dataset: DatasetEntity):
-        """Remove empty frame for action detection dataset."""
-        remove_indices = []
-        for idx, item in enumerate(dataset):
-            if item.get_metadata()[0].data.is_empty_frame:
-                remove_indices.append(idx)
-        dataset.remove_at_indices(remove_indices)
+            self._add_cls_predictions_to_dataset(prediction_results, dataset)
+        elif self._task_type == TaskType.ACTION_DETECTION:
+            self._add_det_predictions_to_dataset(prediction_results, dataset, self.confidence_threshold)
+        logger.info("Inference completed")
+        return dataset
 
-    def unload(self):
-        """Unload the task."""
-        if self._work_dir_is_temp:
-            self._delete_scratch_space()
+    @abstractmethod
+    def _infer_model(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ):
+        """Get inference results from dataset."""
+        raise NotImplementedError
 
-    @check_input_parameters_type()
     def export(
         self,
         export_type: ExportType,
         output_model: ModelEntity,
         precision: ModelPrecision = ModelPrecision.FP32,
-        dump_features: bool = False,
+        dump_features: bool = True,
     ):
-        """Export function of OTX Action Task."""
+        """Export function of OTX Task."""
         if dump_features:
             raise NotImplementedError(
-                "Feature dumping is not implemented for the anomaly task."
+                "Feature dumping is not implemented for the action task."
                 "The saliency maps and representation vector outputs will not be dumped in the exported model."
             )
 
         # copied from OTX inference_task.py
         logger.info("Exporting the model")
         if export_type != ExportType.OPENVINO:
             raise RuntimeError(f"not supported export type {export_type}")
         output_model.model_format = ModelFormat.OPENVINO
         output_model.optimization_type = ModelOptimizationType.MO
-        self._init_task(export=True, dump_features=dump_features)
+        output_model.has_xai = dump_features
 
-        self._precision[0] = precision
-        half_precision = precision == ModelPrecision.FP16
+        results = self._export_model(precision, dump_features)
 
-        try:
-            from torch.jit._trace import TracerWarning
+        outputs = results.get("outputs")
+        logger.debug(f"results of run_task = {outputs}")
+        if outputs is None:
+            raise RuntimeError(results.get("msg"))
+
+        bin_file = outputs.get("bin")
+        xml_file = outputs.get("xml")
+        onnx_file = outputs.get("onnx")
+
+        if xml_file is None or bin_file is None or onnx_file is None:
+            raise RuntimeError("invalid status of exporting. bin and xml should not be None")
+        with open(bin_file, "rb") as f:
+            output_model.set_data("openvino.bin", f.read())
+        with open(xml_file, "rb") as f:
+            output_model.set_data("openvino.xml", f.read())
+        with open(onnx_file, "rb") as f:
+            output_model.set_data("model.onnx", f.read())
+        output_model.set_data(
+            "confidence_threshold",
+            np.array([self.confidence_threshold], dtype=np.float32).tobytes(),
+        )
+        output_model.set_data("config.json", config_to_bytes(self._hyperparams))
+        output_model.precision = self._precision
+        output_model.optimization_methods = self._optimization_methods
+        output_model.has_xai = dump_features
+        output_model.set_data(
+            "label_schema.json",
+            label_schema_to_bytes(self._task_environment.label_schema),
+        )
+        logger.info("Exporting completed")
 
-            warnings.filterwarnings("ignore", category=TracerWarning)
-            exporter = Exporter(
-                self._recipe_cfg,
-                self._model.state_dict(),
-                self.deploy_cfg,
-                f"{self._output_path}/openvino",
-                half_precision,
-            )
-            exporter.export()
-            bin_file = [f for f in os.listdir(self._output_path) if f.endswith(".bin")][0]
-            xml_file = [f for f in os.listdir(self._output_path) if f.endswith(".xml")][0]
-            with open(os.path.join(self._output_path, bin_file), "rb") as f:
-                output_model.set_data("openvino.bin", f.read())
-            with open(os.path.join(self._output_path, xml_file), "rb") as f:
-                output_model.set_data("openvino.xml", f.read())
-            output_model.set_data(
-                "confidence_threshold", np.array([self.confidence_threshold], dtype=np.float32).tobytes()
+    @abstractmethod
+    def _export_model(self, precision: ModelPrecision, dump_features: bool = True):
+        raise NotImplementedError
+
+    def explain(
+        self,
+        dataset: DatasetEntity,
+        explain_parameters: Optional[ExplainParameters] = None,
+    ) -> DatasetEntity:
+        """Main explain function of OTX Task."""
+        raise NotImplementedError("Video recognition task don't support otx explain yet.")
+
+    def evaluate(
+        self,
+        output_resultset: ResultSetEntity,
+        evaluation_metric: Optional[str] = None,
+    ):
+        """Evaluate function of OTX Action Task."""
+        logger.info("called evaluate()")
+        if evaluation_metric is not None:
+            logger.warning(
+                f"Requested to use {evaluation_metric} metric, " "but parameter is ignored. Use F-measure instead."
             )
-            output_model.precision = self._precision
-            output_model.optimization_methods = self._optimization_methods
-        except Exception as ex:
-            raise RuntimeError("Optimization was unsuccessful.") from ex
-        output_model.set_data("label_schema.json", label_schema_to_bytes(self._task_environment.label_schema))
-        logger.info("Exporting completed")
+        self._remove_empty_frames(output_resultset.ground_truth_dataset)
+
+        metric: Union[Accuracy, FMeasure]
+        if self._task_type == TaskType.ACTION_CLASSIFICATION:
+            metric = MetricsHelper.compute_accuracy(output_resultset)
+        if self._task_type == TaskType.ACTION_DETECTION:
+            metric = MetricsHelper.compute_f_measure(output_resultset)
+        performance = metric.get_performance()
+        logger.info(f"Final model performance: {str(performance)}")
+        output_resultset.performance = metric.get_performance()
+        logger.info("Evaluation completed")
 
-    def _init_recipe_hparam(self) -> dict:
-        configs = super()._init_recipe_hparam()
-        configs.data.videos_per_gpu = configs.data.pop("samples_per_gpu", None)  # type: ignore[attr-defined]
-        self._recipe_cfg.total_epochs = configs.runner.max_epochs  # type: ignore[attr-defined]
-        # FIXME lr_config variables are hard-coded
-        if hasattr(configs, "lr_config") and hasattr(configs["lr_config"], "warmup_iters"):
-            self._recipe_cfg.lr_config.warmup = "linear"  # type: ignore[attr-defined]
-            self._recipe_cfg.lr_config.warmup_by_epoch = True  # type: ignore[attr-defined]
-        configs["use_adaptive_interval"] = self._hyperparams.learning_parameters.use_adaptive_interval
-        return configs
-
-    def _init_recipe(self):
-        logger.info("called _init_recipe()")
-        recipe_root = os.path.abspath(os.path.dirname(self.template_file_path))
-        recipe = os.path.join(recipe_root, "model.py")
-        self._recipe_cfg = Config.fromfile(recipe)
-        patch_config(self._recipe_cfg, self.data_pipeline_path, self._output_path, self._task_type)
-        set_data_classes(self._recipe_cfg, self._labels, self._task_type)
-        logger.info(f"initialized recipe = {recipe}")
-
-    def _init_model_cfg(self):
-        model_cfg = Config.fromfile(os.path.join(self._model_dir, "model.py"))
-        return model_cfg
+    def _remove_empty_frames(self, dataset: DatasetEntity):
+        """Remove empty frame for action detection dataset."""
+        remove_indices = []
+        for idx, item in enumerate(dataset):
+            if item.get_metadata()[0].data.is_empty_frame:
+                remove_indices.append(idx)
+        dataset.remove_at_indices(remove_indices)
 
-    def _add_predictions_to_dataset(self, prediction_results: Iterable, dataset: DatasetEntity):
+    def _add_cls_predictions_to_dataset(self, prediction_results: Iterable, dataset: DatasetEntity):
         """Loop over dataset again to assign predictions. Convert from MM format to OTX format."""
         prediction_results = list(prediction_results)
         video_info: Dict[str, int] = {}
         for dataset_item in dataset:
             video_id = dataset_item.get_metadata()[0].data.video_id
             if video_id not in video_info:
                 video_info[video_id] = len(video_info)
@@ -426,16 +348,17 @@
                     type="saliency_map",
                     annotation_scene=dataset_item.annotation_scene,
                     numpy=saliency_map,
                     roi=dataset_item.roi,
                 )
                 dataset_item.append_metadata_item(saliency_map_media, model=self._task_environment.model)
 
-    def _add_det_predictions_to_dataset(self, prediction_results: Iterable, dataset: DatasetEntity):
-        confidence_threshold = 0.05
+    def _add_det_predictions_to_dataset(
+        self, prediction_results: Iterable, dataset: DatasetEntity, confidence_threshold: float = 0.05
+    ):
         self._remove_empty_frames(dataset)
         for dataset_item, (all_results, feature_vector, saliency_map) in zip(dataset, prediction_results):
             shapes = []
             for label_idx, detections in enumerate(all_results):
                 for i in range(detections.shape[0]):
                     probability = float(detections[i, 4])
                     coords = detections[i, :4]
@@ -464,7 +387,66 @@
                     name="Saliency Map",
                     type="saliency_map",
                     annotation_scene=dataset_item.annotation_scene,
                     numpy=saliency_map,
                     roi=dataset_item.roi,
                 )
                 dataset_item.append_metadata_item(saliency_map_media, model=self._task_environment.model)
+
+    @staticmethod
+    # TODO Implement proper function for action classification
+    def _generate_training_metrics(learning_curves, scores, metric_name="mAP") -> Iterable[MetricsGroup[Any, Any]]:
+        """Get Training metrics (epochs & scores).
+
+        Parses the mmaction logs to get metrics from the latest training run
+        :return output List[MetricsGroup]
+        """
+        output: List[MetricsGroup] = []
+
+        # Learning curves.
+        for key, curve in learning_curves.items():
+            len_x, len_y = len(curve.x), len(curve.y)
+            if len_x != len_y:
+                logger.warning(f"Learning curve {key} has inconsistent number of coordinates ({len_x} vs {len_y}.")
+                len_x = min(len_x, len_y)
+                curve.x = curve.x[:len_x]
+                curve.y = curve.y[:len_x]
+            metric_curve = CurveMetric(
+                xs=np.nan_to_num(curve.x).tolist(),
+                ys=np.nan_to_num(curve.y).tolist(),
+                name=key,
+            )
+            visualization_info = LineChartInfo(name=key, x_axis_label="Epoch", y_axis_label=key)
+            output.append(LineMetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
+
+        # Final mAP value on the validation set.
+        output.append(
+            BarMetricsGroup(
+                metrics=[ScoreMetric(value=scores, name=f"{metric_name}")],
+                visualization_info=BarChartInfo("Validation score", visualization_type=VisualizationType.RADIAL_BAR),
+            )
+        )
+
+        return output
+
+    def save_model(self, output_model: ModelEntity):
+        """Save best model weights in ActionTrainTask."""
+        logger.info("called save_model")
+        buffer = io.BytesIO()
+        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
+        labels = {label.name: label.color.rgb_tuple for label in self._labels}
+        model_ckpt = torch.load(self._model_ckpt)
+        modelinfo = {
+            "model": model_ckpt["state_dict"],
+            "config": hyperparams_str,
+            "labels": labels,
+            "confidence_threshold": self.confidence_threshold,
+            "VERSION": 1,
+        }
+
+        torch.save(modelinfo, buffer)
+        output_model.set_data("weights.pth", buffer.getvalue())
+        output_model.set_data(
+            "label_schema.json",
+            label_schema_to_bytes(self._task_environment.label_schema),
+        )
+        output_model.precision = self._precision
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tasks/openvino.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/openvino/task.py`

 * *Files 7% similar despite different names*

```diff
@@ -25,14 +25,15 @@
 import numpy as np
 from addict import Dict as ADDict
 from compression.api import DataLoader
 from compression.engines.ie_engine import IEEngine
 from compression.graph import load_model, save_model
 from compression.graph.model_utils import compress_model_weights, get_nodes_by_type
 from compression.pipeline.initializer import create_pipeline
+from mmcv.utils import ProgressBar
 
 from otx.algorithms.action.adapters.openvino import (
     ActionOVClsDataLoader,
     get_ovdataloader,
     model_wrappers,
 )
 from otx.algorithms.action.configs.base import ActionConfig
@@ -65,18 +66,14 @@
 from otx.api.usecases.tasks.interfaces.deployment_interface import IDeploymentTask
 from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
 from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
 from otx.api.usecases.tasks.interfaces.optimization_interface import (
     IOptimizationTask,
     OptimizationType,
 )
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 
 try:
     from openvino.model_zoo.model_api.adapters import OpenvinoAdapter, create_core
     from openvino.model_zoo.model_api.models import Model
 except ImportError:
     import warnings
 
@@ -85,15 +82,14 @@
 logger = logging.getLogger(__name__)
 
 
 # TODO: refactoring to Sphinx style.
 class ActionOpenVINOInferencer(BaseInferencer):
     """ActionOpenVINOInferencer class in OpenVINO task for action recognition."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         task_type: str,
         hparams: ActionConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
@@ -122,53 +118,47 @@
         self.model = Model.create_model(self.task_type, model_adapter, self.configuration, preload=True)
         self.converter: IPredictionToAnnotationConverter
         if self.task_type == "ACTION_CLASSIFICATION":
             self.converter = ClassificationToAnnotationConverter(self.label_schema)
         else:
             self.converter = DetectionBoxToAnnotationConverter(self.label_schema)
 
-    @check_input_parameters_type()
     def pre_process(self, image: List[DatasetItemEntity]) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
         """Pre-process function of OpenVINO Inferencer for Action Recognition."""
         return self.model.preprocess(image)
 
-    @check_input_parameters_type()
     def post_process(
         self, prediction: Dict[str, np.ndarray], metadata: Dict[str, Any]
     ) -> Optional[AnnotationSceneEntity]:
         """Post-process function of OpenVINO Inferencer for Action Recognition."""
 
         prediction = self.model.postprocess(prediction, metadata)
         return self.converter.convert_to_annotation(prediction, metadata)
 
-    @check_input_parameters_type()
     def predict(self, image: List[DatasetItemEntity]) -> AnnotationSceneEntity:
         """Predict function of OpenVINO Action Inferencer for Action Recognition."""
         data, metadata = self.pre_process(image)
         raw_predictions = self.forward(data)
         predictions = self.post_process(raw_predictions, metadata)
         return predictions
 
-    # @check_input_parameters_type()
     def forward(self, image: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
         """Forward function of OpenVINO Action Inferencer for Action Recognition."""
 
         return self.model.infer_sync(image)
 
 
 class DataLoaderWrapper(DataLoader):
     """DataLoader implementation for ActionOpenVINOTask."""
 
-    @check_input_parameters_type()
     def __init__(self, dataloader: DataLoader, inferencer: BaseInferencer):
         super().__init__(config=None)
         self.dataloader = dataloader
         self.inferencer = inferencer
 
-    @check_input_parameters_type()
     def __getitem__(self, index: int):
         """Get item from dataset."""
         item = self.dataloader[index]
         annotation = item[len(item) // 2].annotation_scene
         inputs, metadata = self.inferencer.pre_process(item)
         return (index, annotation), inputs, metadata
 
@@ -176,15 +166,14 @@
         """Get length of dataset."""
         return len(self.dataloader)
 
 
 class ActionOpenVINOTask(IDeploymentTask, IInferenceTask, IEvaluationTask, IOptimizationTask):
     """Task implementation for OTX Action Recognition using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(self, task_environment: TaskEnvironment):
         self.task_environment = task_environment
         self.hparams = self.task_environment.get_hyper_parameters(ActionConfig)
         self.model = self.task_environment.model
         self.task_type = self.task_environment.model_template.task_type.name
         self.inferencer = self.load_inferencer()
 
@@ -199,46 +188,46 @@
             self.hparams,
             self.task_environment.label_schema,
             self.model.get_data("openvino.xml"),
             self.model.get_data("openvino.bin"),
         )
 
     # pylint: disable=no-value-for-parameter
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def infer(
         self, dataset: DatasetEntity, inference_parameters: Optional[InferenceParameters] = None
     ) -> DatasetEntity:
         """Infer function of OpenVINOTask for Action Recognition."""
         update_progress_callback = default_progress_callback
         clip_len = self.inferencer.model.t
         width = self.inferencer.model.w
         height = self.inferencer.model.h
         dataloader = get_ovdataloader(dataset, self.task_type, clip_len, width, height)
         dataset_size = len(dataloader)
+        prog_bar = ProgressBar(len(dataloader))
         for i, data in enumerate(dataloader):
             prediction = self.inferencer.predict(data)
             if isinstance(dataloader, ActionOVClsDataLoader):
                 dataloader.add_prediction(dataset, data, prediction)
             else:
                 dataloader.add_prediction(data, prediction)
             update_progress_callback(int(i / dataset_size * 100))
+            prog_bar.update()
+        print("")
         return dataset
 
-    @check_input_parameters_type()
     def evaluate(self, output_resultset: ResultSetEntity, evaluation_metric: Optional[str] = None):
         """Evaluate function of OpenVINOTask."""
 
         if evaluation_metric is not None:
             logger.warning(f"Requested to use {evaluation_metric} metric," "but parameter is ignored.")
         if self.task_type == "ACTION_CLASSIFICATION":
             output_resultset.performance = MetricsHelper.compute_accuracy(output_resultset).get_performance()
         elif self.task_type == "ACTION_DETECTION":
             output_resultset.performance = MetricsHelper.compute_f_measure(output_resultset).get_performance()
 
-    @check_input_parameters_type()
     def deploy(self, output_model: ModelEntity) -> None:
         """Deploy function of OpenVINOTask."""
 
         logger.info("Deploying the model")
 
         work_dir = os.path.dirname(demo.__file__)
         parameters = {}  # type: Dict[Any, Any]
@@ -267,15 +256,14 @@
             arch.write(os.path.join(work_dir, "requirements.txt"), os.path.join("python", "requirements.txt"))
             arch.write(os.path.join(work_dir, "LICENSE"), os.path.join("python", "LICENSE"))
             arch.write(os.path.join(work_dir, "README.md"), os.path.join("python", "README.md"))
             arch.write(os.path.join(work_dir, "demo.py"), os.path.join("python", "demo.py"))
         output_model.exportable_code = zip_buffer.getvalue()
         logger.info("Deploying completed")
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def optimize(
         self,
         optimization_type: OptimizationType,
         dataset: DatasetEntity,
         output_model: ModelEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):  # pylint: disable=too-many-locals
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tasks/train.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/task.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-"""Train Task of OTX Action Task."""
+"""Task of OTX Segmentation."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,233 +12,371 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 import io
 import os
-from glob import glob
-from typing import Any, Iterable, List, Optional
+from abc import ABC, abstractmethod
+from typing import List, Optional
 
 import numpy as np
 import torch
-from mmaction.apis import train_model
-from mmaction.datasets import build_dataset
-from mmaction.utils import get_root_logger
+from mmcv.utils import ConfigDict
 
-from otx.algorithms.action.adapters.mmaction.utils import prepare_for_training
-from otx.algorithms.common.utils import TrainingProgressCallback
+from otx.algorithms.common.configs.training_base import TrainType
+from otx.algorithms.common.tasks.base_task import TRAIN_TYPE_DIR_PATH, OTXTask
+from otx.algorithms.common.utils.callback import (
+    InferenceProgressCallback,
+    TrainingProgressCallback,
+)
+from otx.algorithms.common.utils.logger import get_logger
+from otx.algorithms.segmentation.adapters.openvino.model_wrappers.blur import (
+    get_activation_map,
+)
+from otx.algorithms.segmentation.configs.base import SegmentationConfig
 from otx.api.configuration import cfg_helper
 from otx.api.configuration.helper.utils import ids_to_strings
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.inference_parameters import (
+    default_progress_callback as default_infer_progress_callback,
+)
 from otx.api.entities.metrics import (
-    BarChartInfo,
-    BarMetricsGroup,
     CurveMetric,
+    InfoMetric,
     LineChartInfo,
-    LineMetricsGroup,
     MetricsGroup,
+    Performance,
     ScoreMetric,
+    VisualizationInfo,
     VisualizationType,
 )
-from otx.api.entities.model import ModelEntity
-from otx.api.entities.model_template import TaskType
+from otx.api.entities.model import (
+    ModelEntity,
+    ModelFormat,
+    ModelOptimizationType,
+    ModelPrecision,
+)
+from otx.api.entities.result_media import ResultMediaEntity
 from otx.api.entities.resultset import ResultSetEntity
-from otx.api.entities.subset import Subset
+from otx.api.entities.task_environment import TaskEnvironment
+from otx.api.entities.tensor import TensorEntity
 from otx.api.entities.train_parameters import TrainParameters, default_progress_callback
 from otx.api.serialization.label_mapper import label_schema_to_bytes
-from otx.api.usecases.tasks.interfaces.training_interface import ITrainingTask
+from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType
+from otx.api.utils.segmentation_utils import (
+    create_annotation_from_segmentation_map,
+    create_hard_prediction_from_soft_prediction,
+)
+from otx.cli.utils.multi_gpu import is_multigpu_child_process
 
-from .inference import ActionInferenceTask
+logger = get_logger()
+RECIPE_TRAIN_TYPE = {
+    TrainType.Semisupervised: "semisl.py",
+    TrainType.Incremental: "incremental.py",
+    TrainType.Selfsupervised: "selfsl.py",
+}
+
+
+class OTXSegmentationTask(OTXTask, ABC):
+    """Task class for OTX segmentation."""
+
+    # pylint: disable=too-many-instance-attributes, too-many-locals
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__(task_environment, output_path)
+        self._task_config = SegmentationConfig
+        self._hyperparams: ConfigDict = task_environment.get_hyper_parameters(self._task_config)
+        self._model_name = task_environment.model_template.name
+        self._train_type = self._hyperparams.algo_backend.train_type
+        self.metric = "mDice"
+        self._label_dictionary = dict(enumerate(sorted(self._labels), 1))
+
+        self._model_dir = os.path.join(
+            os.path.abspath(os.path.dirname(self._task_environment.model_template.model_template_path)),
+            TRAIN_TYPE_DIR_PATH[self._train_type.name],
+        )
+        if (
+            self._train_type in RECIPE_TRAIN_TYPE
+            and self._train_type == TrainType.Incremental
+            and self._hyperparams.learning_parameters.enable_supcon
+            and not self._model_dir.endswith("supcon")
+        ):
+            self._model_dir = os.path.join(self._model_dir, "supcon")
+
+        if task_environment.model is not None:
+            self._load_model()
+
+        self.data_pipeline_path = os.path.join(self._model_dir, "data_pipeline.py")
+
+    def _load_model_ckpt(self, model: Optional[ModelEntity]):
+        if model and "weights.pth" in model.model_adapters:
+            # If a model has been trained and saved for the task already, create empty model and load weights here
+            buffer = io.BytesIO(model.get_data("weights.pth"))
+            model_data = torch.load(buffer, map_location=torch.device("cpu"))
+            return model_data
+        return None
 
-logger = get_root_logger()
+    def infer(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ) -> DatasetEntity:
+        """Main infer function."""
+        logger.info("infer()")
+
+        if inference_parameters is not None:
+            update_progress_callback = inference_parameters.update_progress
+            is_evaluation = inference_parameters.is_evaluation
+        else:
+            update_progress_callback = default_infer_progress_callback
+            is_evaluation = False
 
+        update_progress_callback = default_progress_callback
+        if inference_parameters is not None:
+            update_progress_callback = inference_parameters.update_progress  # type: ignore
 
-# pylint: disable=too-many-locals, too-many-instance-attributes
-class ActionTrainTask(ActionInferenceTask, ITrainingTask):
-    """Train Task Implementation of OTX Action Task."""
+        self._time_monitor = InferenceProgressCallback(len(dataset), update_progress_callback)
 
-    def save_model(self, output_model: ModelEntity):
-        """Save best model weights in ActionTrainTask."""
-        logger.info("called save_model")
-        buffer = io.BytesIO()
-        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
-        labels = {label.name: label.color.rgb_tuple for label in self._labels}
-        model_ckpt = torch.load(self._model_ckpt)
-        modelinfo = {
-            "model": model_ckpt["state_dict"],
-            "config": hyperparams_str,
-            "labels": labels,
-            "confidence_threshold": self.confidence_threshold,
-            "VERSION": 1,
-        }
+        predictions = self._infer_model(dataset, InferenceParameters(is_evaluation=True))
+        prediction_results = zip(predictions["eval_predictions"], predictions["feature_vectors"])
+        self._add_predictions_to_dataset(prediction_results, dataset, dump_soft_prediction=not is_evaluation)
 
-        torch.save(modelinfo, buffer)
-        output_model.set_data("weights.pth", buffer.getvalue())
-        output_model.set_data(
-            "label_schema.json",
-            label_schema_to_bytes(self._task_environment.label_schema),
-        )
-        output_model.precision = self._precision
-
-    def cancel_training(self):
-        """Cancel training function in ActionTrainTask.
-
-        Sends a cancel training signal to gracefully stop the optimizer. The signal consists of creating a
-        '.stop_training' file in the current work_dir. The runner checks for this file periodically.
-        The stopping mechanism allows stopping after each iteration, but validation will still be carried out. Stopping
-        will therefore take some time.
-        """
-        logger.info("Cancel training requested.")
-        self._should_stop = True
-        if self.cancel_interface is not None:
-            self.cancel_interface.cancel()
-        else:
-            logger.info("but training was not started yet. reserved it to cancel")
-            self.reserved_cancel = True
+        logger.info("Inference completed")
+        return dataset
 
     def train(
-        self,
-        dataset: DatasetEntity,
-        output_model: ModelEntity,
-        train_parameters: Optional[TrainParameters] = None,
+        self, dataset: DatasetEntity, output_model: ModelEntity, train_parameters: Optional[TrainParameters] = None
     ):
-        """Train function in ActionTrainTask."""
+        """Train function for OTX segmentation task.
+
+        Actual training is processed by _train_model fucntion
+        """
         logger.info("train()")
         # Check for stop signal when training has stopped.
         # If should_stop is true, training was cancelled and no new
-        if self._should_stop:
+        if self._should_stop:  # type: ignore
             logger.info("Training cancelled.")
             self._should_stop = False
             self._is_training = False
             return
 
-        # Set OTE LoggerHook & Time Monitor
+        # Set OTX LoggerHook & Time Monitor
         if train_parameters:
             update_progress_callback = train_parameters.update_progress
         else:
             update_progress_callback = default_progress_callback
         self._time_monitor = TrainingProgressCallback(update_progress_callback)
 
-        self._is_training = True
-        self._init_task()
-
-        if self._recipe_cfg is None:
-            raise Exception("Recipe config is not initialized properly")
-
         results = self._train_model(dataset)
 
         # Check for stop signal when training has stopped. If should_stop is true, training was cancelled and no new
         if self._should_stop:
             logger.info("Training cancelled.")
             self._should_stop = False
             self._is_training = False
             return
 
-        self._get_output_model(results)
-        performance = self._get_final_eval_results(dataset, output_model)
+        # get output model
+        model_ckpt = results.get("final_ckpt")
+        if model_ckpt is None:
+            logger.error("cannot find final checkpoint from the results.")
+            # output_model.model_status = ModelStatus.FAILED
+            return
+        # update checkpoint to the newly trained model
+        self._model_ckpt = model_ckpt
+
+        # get prediction on validation set
+        self._is_training = False
 
+        # Get training metrics group from learning curves
+        training_metrics, best_score = self._generate_training_metrics(self._learning_curves)
+        performance = Performance(
+            score=ScoreMetric(value=best_score, name=self.metric),
+            dashboard_metrics=training_metrics,
+        )
+
+        logger.info(f"Final model performance: {str(performance)}")
         # save resulting model
         self.save_model(output_model)
         output_model.performance = performance
         self._is_training = False
         logger.info("train done.")
 
-    def _train_model(self, dataset: DatasetEntity):
-        if self._recipe_cfg is None:
-            raise Exception("Recipe config does not initialize properly!")
-        train_dataset = dataset.get_subset(Subset.TRAINING)
-        val_dataset = dataset.get_subset(Subset.VALIDATION)
-        training_config = prepare_for_training(
-            self._recipe_cfg, train_dataset, val_dataset, self._time_monitor, self._learning_curves
-        )
-        mm_train_dataset = build_dataset(training_config.data.train)
-        logger.info("Start training")
-        self._model.train()
-        # FIXME runner is built inside of train_model funciton, it is hard to change runner's type
-        train_model(model=self._model, dataset=mm_train_dataset, cfg=training_config, validate=True)
-        checkpoint_file_path = glob(os.path.join(self._recipe_cfg.work_dir, "best*pth"))
-        if len(checkpoint_file_path) == 0:
-            checkpoint_file_path = os.path.join(self._recipe_cfg.work_dir, "latest.pth")
-        elif len(checkpoint_file_path) > 1:
-            logger.warning(f"Multiple candidates for the best checkpoint found: {checkpoint_file_path}")
-            checkpoint_file_path = checkpoint_file_path[0]
-        else:
-            checkpoint_file_path = checkpoint_file_path[0]
-        logger.info(f"Use {checkpoint_file_path} for final model weights")
+    def export(
+        self,
+        export_type: ExportType,
+        output_model: ModelEntity,
+        precision: ModelPrecision = ModelPrecision.FP32,
+        dump_features: bool = True,
+    ):
+        """Export function of OTX Task."""
+        logger.info("Exporting the model")
+        if export_type != ExportType.OPENVINO:
+            raise RuntimeError(f"not supported export type {export_type}")
+        output_model.model_format = ModelFormat.OPENVINO
+        output_model.optimization_type = ModelOptimizationType.MO
+
+        results = self._export_model(precision, dump_features)
+        outputs = results.get("outputs")
+        logger.debug(f"results of run_task = {outputs}")
+        if outputs is None:
+            raise RuntimeError(results.get("msg"))
+
+        bin_file = outputs.get("bin")
+        xml_file = outputs.get("xml")
+        onnx_file = outputs.get("onnx")
+
+        if xml_file is None or bin_file is None or onnx_file is None:
+            raise RuntimeError("invalid status of exporting. bin and xml or onnx should not be None")
+        with open(bin_file, "rb") as f:
+            output_model.set_data("openvino.bin", f.read())
+        with open(xml_file, "rb") as f:
+            output_model.set_data("openvino.xml", f.read())
+        with open(onnx_file, "rb") as f:
+            output_model.set_data("model.onnx", f.read())
+        output_model.precision = self._precision
+        output_model.optimization_methods = self._optimization_methods
+        output_model.has_xai = dump_features
+        output_model.set_data("label_schema.json", label_schema_to_bytes(self._task_environment.label_schema))
+        logger.info("Exporting completed")
 
-        return {"final_ckpt": checkpoint_file_path}
+    def explain(
+        self,
+        dataset: DatasetEntity,
+        explain_parameters: Optional[ExplainParameters] = None,
+    ) -> DatasetEntity:
+        """Main explain function of OTX Task."""
+        raise NotImplementedError
 
-    def _get_output_model(self, results):
-        model_ckpt = results.get("final_ckpt")
-        if model_ckpt is None:
-            logger.error("cannot find final checkpoint from the results.")
-            return
-        # update checkpoint to the newly trained model
-        self._model_ckpt = model_ckpt
-        self._model.load_state_dict(torch.load(self._model_ckpt)["state_dict"])
+    def evaluate(
+        self,
+        output_resultset: ResultSetEntity,
+        evaluation_metric: Optional[str] = None,
+    ):
+        """Evaluate function of OTX Segmentation Task."""
+        logger.info("called evaluate()")
+        if evaluation_metric is not None:
+            logger.warning(
+                f"Requested to use {evaluation_metric} metric, " "but parameter is ignored. Use mDice instead."
+            )
+        metric = MetricsHelper.compute_dice_averaged_over_pixels(output_resultset)
+        logger.info(f"mDice after evaluation: {metric.overall_dice.value}")
+        output_resultset.performance = metric.get_performance()
+        logger.info("Evaluation completed")
+
+    def _add_predictions_to_dataset(self, prediction_results, dataset, dump_soft_prediction):
+        """Loop over dataset again to assign predictions. Convert from MMSegmentation format to OTX format."""
+
+        for dataset_item, (prediction, feature_vector) in zip(dataset, prediction_results):
+            soft_prediction = np.transpose(prediction[0], axes=(1, 2, 0))
+            hard_prediction = create_hard_prediction_from_soft_prediction(
+                soft_prediction=soft_prediction,
+                soft_threshold=self._hyperparams.postprocessing.soft_threshold,
+                blur_strength=self._hyperparams.postprocessing.blur_strength,
+            )
+            annotations = create_annotation_from_segmentation_map(
+                hard_prediction=hard_prediction,
+                soft_prediction=soft_prediction,
+                label_map=self._label_dictionary,
+            )
+            dataset_item.append_annotations(annotations=annotations)
 
-    def _get_final_eval_results(self, dataset, output_model):
-        logger.info("Final Evaluation")
-        val_dataset = dataset.get_subset(Subset.VALIDATION)
-        val_preds, val_map = self._infer_model(val_dataset, InferenceParameters(is_evaluation=True))
-
-        preds_val_dataset = val_dataset.with_empty_annotations()
-        # TODO Load _add_predictions_to_dataset function from self._task_type
-        if self._task_type == TaskType.ACTION_CLASSIFICATION:
-            self._add_predictions_to_dataset(val_preds, preds_val_dataset)
-        elif self._task_type == TaskType.ACTION_DETECTION:
-            self._add_det_predictions_to_dataset(val_preds, preds_val_dataset)
-
-        result_set = ResultSetEntity(
-            model=output_model,
-            ground_truth_dataset=val_dataset,
-            prediction_dataset=preds_val_dataset,
-        )
+            if feature_vector is not None:
+                active_score = TensorEntity(name="representation_vector", numpy=feature_vector.reshape(-1))
+                dataset_item.append_metadata_item(active_score, model=self._task_environment.model)
+
+            if dump_soft_prediction:
+                for label_index, label in self._label_dictionary.items():
+                    if label_index == 0:
+                        continue
+                    current_label_soft_prediction = soft_prediction[:, :, label_index]
+                    class_act_map = get_activation_map(current_label_soft_prediction)
+                    result_media = ResultMediaEntity(
+                        name=label.name,
+                        type="soft_prediction",
+                        label=label,
+                        annotation_scene=dataset_item.annotation_scene,
+                        roi=dataset_item.roi,
+                        numpy=class_act_map,
+                    )
+                    dataset_item.append_metadata_item(result_media, model=self._task_environment.model)
 
-        metric = self._get_metric(result_set)
+    def save_model(self, output_model: ModelEntity):
+        """Save best model weights in SegmentationTrainTask."""
 
-        # compose performance statistics
-        performance = metric.get_performance()
-        metric_name = self._recipe_cfg.evaluation.final_metric
-        performance.dashboard_metrics.extend(
-            ActionTrainTask._generate_training_metrics(self._learning_curves, val_map, metric_name)
+        if is_multigpu_child_process():
+            return
+        logger.info("called save_model")
+        buffer = io.BytesIO()
+        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
+        labels = {label.name: label.color.rgb_tuple for label in self._labels}
+        model_ckpt = torch.load(self._model_ckpt)
+        modelinfo = {
+            "model": model_ckpt,
+            "config": hyperparams_str,
+            "labels": labels,
+            "VERSION": 1,
+        }
+
+        torch.save(modelinfo, buffer)
+        output_model.set_data("weights.pth", buffer.getvalue())
+        output_model.set_data(
+            "label_schema.json",
+            label_schema_to_bytes(self._task_environment.label_schema),
         )
-        logger.info(f"Final model performance: {str(performance)}")
-        return performance
+        output_model.precision = self._precision
 
-    @staticmethod
-    # TODO Implement proper function for action classification
-    def _generate_training_metrics(learning_curves, scores, metric_name) -> Iterable[MetricsGroup[Any, Any]]:
+    def _generate_training_metrics(self, learning_curves):
         """Get Training metrics (epochs & scores).
 
-        Parses the mmaction logs to get metrics from the latest training run
+        Parses the mmsegmentation logs to get metrics from the latest training run
         :return output List[MetricsGroup]
         """
         output: List[MetricsGroup] = []
-
-        # Learning curves.
-        for key, curve in learning_curves.items():
-            len_x, len_y = len(curve.x), len(curve.y)
-            if len_x != len_y:
-                logger.warning(f"Learning curve {key} has inconsistent number of coordinates ({len_x} vs {len_y}.")
-                len_x = min(len_x, len_y)
-                curve.x = curve.x[:len_x]
-                curve.y = curve.y[:len_x]
-            metric_curve = CurveMetric(
-                xs=np.nan_to_num(curve.x).tolist(),
-                ys=np.nan_to_num(curve.y).tolist(),
-                name=key,
-            )
-            visualization_info = LineChartInfo(name=key, x_axis_label="Epoch", y_axis_label=key)
-            output.append(LineMetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
-
-        # Final mAP value on the validation set.
+        # Model architecture
+        architecture = InfoMetric(name="Model architecture", value=self._model_name)
+        visualization_info_architecture = VisualizationInfo(
+            name="Model architecture", visualisation_type=VisualizationType.TEXT
+        )
         output.append(
-            BarMetricsGroup(
-                metrics=[ScoreMetric(value=scores, name=f"{metric_name}")],
-                visualization_info=BarChartInfo("Validation score", visualization_type=VisualizationType.RADIAL_BAR),
+            MetricsGroup(
+                metrics=[architecture],
+                visualization_info=visualization_info_architecture,
             )
         )
+        # Learning curves
+        best_score = -1
+        for key, curve in learning_curves.items():
+            metric_curve = CurveMetric(xs=curve.x, ys=curve.y, name=key)
+            if key == f"val/{self.metric}":
+                best_score = max(curve.y)
+            visualization_info = LineChartInfo(name=key, x_axis_label="Epoch", y_axis_label=key)
+            output.append(MetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
+
+        return output, best_score
+
+    @abstractmethod
+    def _train_model(self, dataset: DatasetEntity):
+        """Train model and return the results."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def _infer_model(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ):
+        """Get inference results from dataset."""
+        raise NotImplementedError
 
-        return output
+    @abstractmethod
+    def _export_model(self, precision, dump_features):
+        """Export model and return the results."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def _explain_model(self, dataset: DatasetEntity, explain_parameters: Optional[ExplainParameters]):
+        """Explain model and return the results."""
+        raise NotImplementedError
```

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tools/sample_classification.py` & `otx-1.2.0rc1/otx/algorithms/action/tools/sample_classification.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/tools/sample_detection.py` & `otx-1.2.0rc1/otx/algorithms/action/tools/sample_detection.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/utils/convert_public_data_to_cvat.py` & `otx-1.2.0rc1/otx/algorithms/action/utils/convert_public_data_to_cvat.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/action/utils/data.py` & `otx-1.2.0rc1/otx/algorithms/action/utils/data.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,18 +28,16 @@
 )
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.id import ID
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.rectangle import Rectangle
 from otx.api.entities.subset import Subset
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 
-@check_input_parameters_type()
 def find_label_by_name(labels: List[LabelEntity], name: str, domain: Domain):
     """Return label from name."""
     matching_labels = [label for label in labels if label.name == name]
     if len(matching_labels) == 1:
         return matching_labels[0]
     if len(matching_labels) == 0:
         label = LabelEntity(name=name, domain=domain, id=ID(int(name)))
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/inference.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/inference.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/progress.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/callbacks/progress.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/config/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/config/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/config/anomalib_config.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/config/anomalib_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,14 +27,15 @@
 def get_anomalib_config(task_name: str, otx_config: ConfigurableParameters) -> Union[DictConfig, ListConfig]:
     """Get anomalib configuration.
 
     Create an anomalib config object that matches the values specified in the
     OTX config.
 
     Args:
+        task_name: Task name to load configuration from the Anomalib
         otx_config: ConfigurableParameters: OTX config object parsed from
             configuration.yaml file
 
     Returns:
         Anomalib config object for the specified model type with overwritten
         default values.
     """
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/create_mvtec_ad_json_annotations.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/create_mvtec_ad_json_annotations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/data.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/data.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/dataset.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/dataset.py`

 * *Files 6% similar despite different names*

```diff
@@ -108,26 +108,26 @@
 
 class AnomalyClassificationDataset(BaseAnomalyDataset):
     """Dataloader for Anomaly Classification Task.
 
     Example:
     >>> train_subset = {
             "ann_file": "tests/assets/anomaly/classification/train.json",
-            "data_root": "tests/assets/anomaly/shapes",
+            "data_root": "tests/assets/anomaly/hazelnut",
         }
     >>> val_subset = {
             "ann_file": "tests/assets/anomaly/classification/val.json",
-            "data_root": "tests/assets/anomaly/shapes"
+            "data_root": "tests/assets/anomaly/hazelnut"
         }
     >>> training_dataset = AnomalyClassificationDataset(
             train_subset=train_subset, val_subset=val_subset
         )
     >>> test_subset = {
             "ann_file": "tests/assets/anomaly/classification/test.json",
-            "data_root": "tests/assets/anomaly/shapes"
+            "data_root": "tests/assets/anomaly/hazelnut"
         }
     >>> testing_dataset = AnomalyClassificationDataset(test_subset=test_subset)
     """
 
     def get_dataset_items(self, ann_file_path: Path, data_root_dir: Path, subset: Subset) -> List[DatasetItemEntity]:
         """Loads dataset based on the image path in annotation file.
 
@@ -165,26 +165,26 @@
 
 class AnomalySegmentationDataset(BaseAnomalyDataset):
     """Dataloader for Anomaly Segmentation Task.
 
     Example:
         >>> train_subset = {
                 "ann_file": "tests/assets/anomaly/segmentation/train.json",
-                "data_root": "tests/assets/anomaly/shapes",
+                "data_root": "tests/assets/anomaly/hazelnut",
             }
         >>> val_subset = {
                 "ann_file": "tests/assets/anomaly/segmentation/val.json",
-                "data_root": "tests/assets/anomaly/shapes"
+                "data_root": "tests/assets/anomaly/hazelnut"
             }
         >>> training_dataset = AnomalySegmentationDataset(
                 train_subset=train_subset, val_subset=val_subset
             )
         >>> test_subset = {
                 "ann_file": "tests/assets/anomaly/segmentation/test.json",
-                "data_root": "tests/assets/anomaly/shapes"
+                "data_root": "tests/assets/anomaly/hazelnut"
             }
         >>> testing_dataset = AnomalySegmentationDataset(test_subset=test_subset)
 
     """
 
     def get_dataset_items(self, ann_file_path: Path, data_root_dir: Path, subset: Subset) -> List[DatasetItemEntity]:
         """Loads dataset based on the image path in annotation file.
@@ -245,26 +245,26 @@
 
 class AnomalyDetectionDataset(BaseAnomalyDataset):
     """Dataloader for Anomaly Segmentation Task.
 
     Example:
         >>> train_subset = {
                 "ann_file": "tests/assets/anomaly/detection/train.json",
-                "data_root": "tests/assets/anomaly/shapes",
+                "data_root": "tests/assets/anomaly/hazelnut",
             }
         >>> val_subset = {
                 "ann_file": "tests/assets/anomaly/detection/val.json",
-                "data_root": "tests/assets/anomaly/shapes"
+                "data_root": "tests/assets/anomaly/hazelnut"
             }
         >>> training_dataset = AnomalyDetectionDataset(
                 train_subset=train_subset, val_subset=val_subset
             )
         >>> test_subset = {
                 "ann_file": "tests/assets/anomaly/detection/test.json",
-                "data_root": "tests/assets/anomaly/shapes"
+                "data_root": "tests/assets/anomaly/hazelnut"
             }
         >>> testing_dataset = AnomalyDetectionDataset(test_subset=test_subset)
 
     """
 
     def get_dataset_items(self, ann_file_path: Path, data_root_dir: Path, subset: Subset) -> List[DatasetItemEntity]:
         """Loads dataset based on the image path in annotation file.
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/data/mvtec.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/data/mvtec.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_classification.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_classification.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_detection.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_detection.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_segmentation.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/anomaly_segmentation.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/base.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/exportable_code/base.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/logger/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/logger/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/adapters/anomalib/logger/logger.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/adapters/anomalib/logger/logger.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/configuration_enums.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/configuration_enums.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/draem/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/draem/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/padim/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/padim/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/padim/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/padim/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/stfpm/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/stfpm/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/base/stfpm/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/base/stfpm/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/template_experimental.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/template_experimental.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Most accurate model across datasets, but longer training time.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/draem/transform_config.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/draem/transform_config.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/padim/template.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/padim/template.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
 summary: This model is faster and in many cases more accurate, but it requires a fixed position of the objects within the image.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/classification/stfpm/template.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/classification/stfpm/template.yaml`

 * *Files 12% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Use this model when the position of the objects in the image frame might differ between images.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/template_experimental.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/template_experimental.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Most accurate model across datasets, but longer training time.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/draem/transform_config.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/draem/transform_config.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Most accurate model across datasets, but longer training time.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: tasks.TrainingTask
   openvino: tasks.OpenVINOTask
   nncf: tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/padim/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/padim/template.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/template.yaml`

 * *Files 12% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # Description.
-model_template_id: ote_anomaly_detection_padim
+model_template_id: ote_anomaly_segmentation_padim
 name: PADIM
-task_type: ANOMALY_DETECTION
+task_type: ANOMALY_SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: This model is faster and in many cases more accurate, but it requires a fixed position of the objects within the image.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
+framework: OTXAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/detection/stfpm/template.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/detection/stfpm/template.yaml`

 * *Files 14% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Use this model when the position of the objects in the image frame might differ between images.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
+framework: OTXAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/template_experimental.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/template_experimental.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Most accurate model across datasets, but longer training time.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0
+framework: OTXAnomalyClassification v0.1.0
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/draem/transform_config.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/draem/transform_config.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/padim/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/compression_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/template.yaml` & `otx-1.2.0rc1/otx/algorithms/anomaly/configs/segmentation/stfpm/template.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 task_type: ANOMALY_SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Use this model when the position of the objects in the image frame might differ between images.
 application: ~
 
 # Algo backend.
-framework: OTEAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
+framework: OTXAnomalyClassification v0.1.0 # TODO: update after the name has been changed on the platform side
 
 # Task implementations.
 entrypoints:
   base: otx.algorithms.anomaly.tasks.TrainingTask
   openvino: otx.algorithms.anomaly.tasks.OpenVINOTask
   nncf: otx.algorithms.anomaly.tasks.NNCFTask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tasks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tasks/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tasks/inference.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tasks/inference.py`

 * *Files 1% similar despite different names*

```diff
@@ -269,19 +269,18 @@
             logger.warning(
                 "Feature dumping is not implemented for the anomaly task."
                 "The saliency maps and representation vector outputs will not be dumped in the exported model."
             )
 
         self.precision[0] = precision
         assert export_type == ExportType.OPENVINO, f"Incorrect export_type={export_type}"
-        output_model.model_format = ModelFormat.OPENVINO
-        output_model.optimization_type = ModelOptimizationType.MO
 
         output_model.model_format = ModelFormat.OPENVINO
         output_model.optimization_type = self.optimization_type
+        output_model.has_xai = dump_features
 
         # pylint: disable=no-member; need to refactor this
         logger.info("Exporting the OpenVINO model.")
         onnx_path = os.path.join(self.config.project.path, "onnx_model.onnx")
         self._export_to_onnx(onnx_path)
         optimize_command = ["mo", "--input_model", onnx_path, "--output_dir", self.config.project.path]
         if precision == ModelPrecision.FP16:
@@ -289,14 +288,16 @@
         subprocess.run(optimize_command, check=True)
         bin_file = glob(os.path.join(self.config.project.path, "*.bin"))[0]
         xml_file = glob(os.path.join(self.config.project.path, "*.xml"))[0]
         with open(bin_file, "rb") as file:
             output_model.set_data("openvino.bin", file.read())
         with open(xml_file, "rb") as file:
             output_model.set_data("openvino.xml", file.read())
+        with open(onnx_path, "rb") as file:
+            output_model.set_data("model.onnx", file.read())
 
         output_model.precision = self.precision
         output_model.optimization_methods = self.optimization_methods
 
         output_model.set_data("label_schema.json", label_schema_to_bytes(self.task_environment.label_schema))
         self._set_metadata(output_model)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tasks/nncf.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tasks/nncf.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,14 +63,15 @@
     """Base Anomaly Task."""
 
     def __init__(self, task_environment: TaskEnvironment, **kwargs) -> None:
         """Task for compressing models using NNCF.
 
         Args:
             task_environment (TaskEnvironment): OTX Task environment.
+            **kwargs: Addition keyword arguments.
         """
         self.compression_ctrl = None
         self.nncf_preset = "nncf_quantization"
         super().__init__(task_environment, **kwargs)
         self.optimization_type = ModelOptimizationType.NNCF
 
     def _set_attributes_by_hyperparams(self):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tasks/openvino.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tasks/openvino.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tasks/train.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tasks/train.py`

 * *Files 1% similar despite different names*

```diff
@@ -91,22 +91,22 @@
         self.trainer.fit(model=self.model, datamodule=datamodule)
 
         self.save_model(output_model)
 
         logger.info("Training completed.")
 
     def load_model(self, otx_model: Optional[ModelEntity]) -> AnomalyModule:
-        """Create and Load Anomalib Module from OTE Model.
+        """Create and Load Anomalib Module from OTX Model.
 
-        This method checks if the task environment has a saved OTE Model,
-        and creates one. If the OTE model already exists, it returns the
+        This method checks if the task environment has a saved OTX Model,
+        and creates one. If the OTX model already exists, it returns the
         the model with the saved weights.
 
         Args:
-            otx_model (Optional[ModelEntity]): OTE Model from the
+            otx_model (Optional[ModelEntity]): OTX Model from the
                 task environment.
 
         Returns:
             AnomalyModule: Anomalib
                 classification or segmentation model with/without weights.
         """
         model = get_model(config=self.config)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tools/README.md` & `otx-1.2.0rc1/otx/algorithms/anomaly/tools/README.md`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tools/__init__.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/anomaly/tools/sample.py` & `otx-1.2.0rc1/otx/algorithms/anomaly/tools/sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""OTX Algorithms - Classification."""
+"""Adapters for Detection."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,38 +1,21 @@
-"""Adapters of classification - mmcls."""
+"""OTX Algorithms - Segmentation pipelines."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
+from .compose import MaskCompose, ProbCompose
+from .loads import LoadAnnotationFromOTXDataset, LoadImageFromOTXDataset
+from .transforms import TwoCropTransform
 
-from .datasets import OTXClsDataset, SelfSLDataset
-from .models import BYOL, ConstrastiveHead, SelfSLMLP
-from .optimizer import LARS
-
-# fmt: off
-# isort: off
-# FIXME: openvino pot library adds stream handlers to root logger
-# which makes annoying duplicated logging
-from mmcls.utils import get_root_logger  # pylint: disable=wrong-import-order
-get_root_logger().propagate = False
-# isort:on
-# fmt: on
-
-__all__ = [
-    "OTXClsDataset",
-    "SelfSLDataset",
-    "BYOL",
-    "SelfSLMLP",
-    "ConstrastiveHead",
-    "LARS",
-]
+__all__ = ["MaskCompose", "ProbCompose", "LoadImageFromOTXDataset", "LoadAnnotationFromOTXDataset", "TwoCropTransform"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/otx_datasets.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/otx_datasets.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,50 +2,47 @@
 
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 # pylint: disable=invalid-name, too-many-locals, no-member
 
-from typing import Any, Dict, List
+from typing import Any, Dict, List, Union
 
 import numpy as np
 from mmcls.core import average_performance, mAP
 from mmcls.datasets.base_dataset import BaseDataset
 from mmcls.datasets.builder import DATASETS, PIPELINES
 from mmcls.datasets.pipelines import Compose
 from mmcv.utils.registry import build_from_cfg
 from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix
 from torch.utils.data import Dataset
 
 from otx.algorithms.common.utils import get_cls_img_indices, get_old_new_img_indices
 from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.id import ID
 from otx.api.entities.label import LabelEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 
 logger = get_logger()
 
 
 # pylint: disable=too-many-instance-attributes
 @DATASETS.register_module()
 class OTXClsDataset(BaseDataset):
     """Multi-class classification dataset class."""
 
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     def __init__(
         self, otx_dataset: DatasetEntity, labels: List[LabelEntity], empty_label=None, **kwargs
     ):  # pylint: disable=super-init-not-called
         self.otx_dataset = otx_dataset
         self.labels = labels
         self.label_names = [label.name for label in self.labels]
         self.label_idx = {label.id: i for i, label in enumerate(labels)}
+        self.idx_to_label_id = {v: k for k, v in self.label_idx.items()}
         self.empty_label = empty_label
         self.class_acc = False
 
         self.CLASSES = list(label.name for label in labels)
         self.gt_labels = []  # type: List
         pipeline = kwargs.get("pipeline", [])
         self.num_classes = len(self.CLASSES)
@@ -77,36 +74,41 @@
                     else:
                         class_indices.append(-1)
             else:  # this supposed to happen only on inference stage
                 class_indices.append(-1)
             self.gt_labels.append(class_indices)
         self.gt_labels = np.array(self.gt_labels)
 
-    @check_input_parameters_type()
     def __getitem__(self, index: int):
         """Get item from dataset."""
         dataset = self.otx_dataset
         item = dataset[index]
         ignored_labels = np.array([self.label_idx[lbs.id] for lbs in item.ignored_labels])
 
         height, width = item.height, item.width
 
+        gt_label = self.gt_labels[index]
         data_info = dict(
             dataset_item=item,
             width=width,
             height=height,
             index=index,
-            gt_label=self.gt_labels[index],
+            gt_label=gt_label,
             ignored_labels=ignored_labels,
+            entity_id=getattr(item, "id_", None),
+            label_id=self._get_label_id(gt_label),
         )
 
         if self.pipeline is None:
             return data_info
         return self.pipeline(data_info)
 
+    def _get_label_id(self, gt_label: np.ndarray) -> Union[ID, List[ID]]:
+        return self.idx_to_label_id.get(gt_label.item(), ID())
+
     def get_gt_labels(self):
         """Get all ground-truth labels (categories).
 
         Returns:
             list[int]: categories for all images.
         """
 
@@ -214,14 +216,15 @@
         Args:
             results (list): Testing results of the dataset.
             metric (str | list[str]): Metrics to be evaluated.
                 Default value is 'mAP'. Options are 'mAP', 'CP', 'CR', 'CF1',
                 'OP', 'OR' and 'OF1'.
             metric_options (dict, optional): Options for calculating metrics.
                 Allowed keys are 'k' and 'thr'. Defaults to None
+            indices (list, optional):  Indices to filter the gt label. Defaults to None.
             logger (logging.Logger | str, optional): Logger used for printing
                 related information during evaluation. Defaults to None.
 
         Returns:
             dict: evaluation results
         """
         if metric_options is None or metric_options == {}:
@@ -280,14 +283,17 @@
             performance_values = average_performance(results, gt_labels, **metric_options)
             for k, v in zip(performance_keys, performance_values):
                 if k in metrics:
                     eval_results[k] = v
 
         return eval_results
 
+    def _get_label_id(self, gt_label: np.ndarray) -> Union[ID, List[ID]]:
+        return [self.idx_to_label_id.get(idx, ID()) for idx, v in enumerate(gt_label) if v == 1]
+
 
 @DATASETS.register_module()
 class OTXHierarchicalClsDataset(OTXMultilabelClsDataset):
     """Hierarchical classification dataset class."""
 
     def __init__(self, **kwargs):
         self.hierarchical_info = kwargs.pop("hierarchical_info", None)
@@ -351,14 +357,16 @@
         Args:
             results (list): Testing results of the dataset.
             metric (str | list[str]): Metrics to be evaluated.
                 Default value is 'mAP'. Options are 'mAP', 'CP', 'CR', 'CF1',
                 'OP', 'OR' and 'OF1'.
             metric_options (dict, optional): Options for calculating metrics.
                 Allowed keys are 'k' and 'thr'. Defaults to None
+            indices (list, optional):  Indices to filter the gt label.
+                Defaults to None.
             logger (logging.Logger | str, optional): Logger used for printing
                 related information during evaluation. Defaults to None.
 
         Returns:
             dict: evaluation results
         """
         if metric_options is None or metric_options == {}:
@@ -417,15 +425,14 @@
 
 @DATASETS.register_module()
 class SelfSLDataset(Dataset):
     """SelfSL dataset that training with two pipelines and no label."""
 
     CLASSES = None
 
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     def __init__(
         self, otx_dataset: DatasetEntity, pipeline: Dict[str, Any], **kwargs
     ):  # pylint: disable=unused-argument
         super().__init__()
         self.otx_dataset = otx_dataset
 
         self.load_pipeline = build_from_cfg(dict(type="LoadImageFromOTXDataset"), PIPELINES)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/otx_pipelines.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/otx_pipelines.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,14 @@
 from mmcls.datasets import PIPELINES
 from mmcls.datasets.pipelines import Compose
 from mmcv.utils.registry import build_from_cfg
 from PIL import Image, ImageFilter
 from torchvision import transforms as T
 
 import otx.core.data.pipelines.load_image_from_otx_dataset as load_image_base
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 # TODO: refactoring to common modules
 # TODO: refactoring to Sphinx style.
 
 
 @PIPELINES.register_module()
 class LoadImageFromOTXDataset(load_image_base.LoadImageFromOTXDataset):
@@ -32,15 +31,14 @@
     :param p: Probability, defaults to 0.5
     """
 
     def __init__(self, transforms: List, p: float = 0.5):
         t = [build_from_cfg(t, PIPELINES) for t in transforms]  # pylint: disable=invalid-name
         self.trans = T.RandomApply(t, p=p)
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of RandomAppliedTrans.
 
         :param results: Inputs to be transformed.
         """
         return self.trans(results)
 
@@ -70,20 +68,18 @@
 class GaussianBlur:
     """Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709.
 
     :param sigma_min: Minimum value of sigma of gaussian filter.
     :param sigma_max: Maximum value of sigma of gaussian filter.
     """
 
-    @check_input_parameters_type()
     def __init__(self, sigma_min: float, sigma_max: float):
         self.sigma_min = sigma_min
         self.sigma_max = sigma_max
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of GaussianBlur.
 
         :param results: Inputs to be transformed.
         """
         for key in results.get("img_fields", ["img"]):
             img = Image.fromarray(results[key])
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/augmix.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/augmix.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/otx_transforms.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/otx_transforms.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/random_augment.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/random_augment.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/twocrop_transform.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/twocrop_transform.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/mmov_backbone.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/backbones/mmov_backbone.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/byol.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/byol.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,25 +21,28 @@
 from otx.algorithms.common.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @CLASSIFIERS.register_module()
 class BYOL(nn.Module):
-    """Implementation of 'Bootstrap Your Own Latent: A New Approach to \
-    Self-Supervised Learning (https://arxiv.org/abs/2006.07733)'.
+    """BYOL Implementation.
+
+    Implementation of 'Bootstrap Your Own Latent: A New Approach to Self-Supervised
+    Learning (https://arxiv.org/abs/2006.07733)'.
 
     Args:
         backbone (dict): Config dict for module of backbone ConvNet.
         neck (dict): Config dict for module of deep features to compact feature vectors.
             Default: None.
         head (dict): Config dict for module of loss functions. Default: None.
         pretrained (str, optional): Path to pre-trained weights. Default: None.
         base_momentum (float): The base momentum coefficient for the target network.
             Default: 0.996.
+        **kwargs: Addition keyword arguments.
     """
 
     def __init__(
         self,
         backbone: Dict[str, Any],
         neck: Optional[Dict[str, Any]] = None,
         head: Optional[Dict[str, Any]] = None,
@@ -118,14 +121,15 @@
         """Forward computation during training.
 
         Args:
             img1 (Tensor): Input of two concatenated images of shape (N, C, H, W).
                 Typically these should be mean centered and std scaled.
             img2 (Tensor): Input of two concatenated images of shape (N, C, H, W).
                 Typically these should be mean centered and std scaled.
+            **kwargs: Addition keyword arguments.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
         proj_1 = self.online_projector(self.online_backbone(img1))
         proj_2 = self.online_projector(self.online_backbone(img2))
         with torch.no_grad():
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,21 +7,21 @@
 from mmcls.models.builder import CLASSIFIERS
 from mmcls.models.classifiers.image import ImageClassifier
 
 from otx.algorithms.common.adapters.mmdeploy.utils import is_mmdeploy_enabled
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.common.utils.task_adapt import map_class_names
 
-from .sam_classifier_mixin import SAMClassifierMixin
+from .mixin import ClsLossDynamicsTrackingMixin, SAMClassifierMixin
 
 logger = get_logger()
 
 
 @CLASSIFIERS.register_module()
-class SAMImageClassifier(SAMClassifierMixin, ImageClassifier):
+class SAMImageClassifier(SAMClassifierMixin, ClsLossDynamicsTrackingMixin, ImageClassifier):
     """SAM-enabled ImageClassifier."""
 
     def __init__(self, task_adapt=None, **kwargs):
         if "multilabel" in kwargs:
             self.multilabel = kwargs.pop("multilabel")
         if "hierarchical" in kwargs:
             self.hierarchical = kwargs.pop("hierarchical")
@@ -48,14 +48,16 @@
                 Typically these should be mean centered and std scaled.
 
             gt_label (Tensor): It should be of shape (N, 1) encoding the
                 ground-truth label of input images for single label task. It
                 shoulf be of shape (N, C) encoding the ground-truth label
                 of input images for multi-labels task.
 
+            **kwargs (Any): Addition keyword arguments.
+
         Returns:
             dict[str, Tensor]: a dictionary of loss components
         """
         if self.augments is not None:
             img, gt_label = self.augments(img, gt_label)
 
         x = self.extract_feat(img)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_classifier.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_multilabel_classifier.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_multilabel_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/supcon_classifier.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/classifiers/supcon_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/contrastive_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/contrastive_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/conv_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/conv_head.py`

 * *Files 8% similar despite different names*

```diff
@@ -35,15 +35,15 @@
 
     def pre_logits(self, x):
         """Preprocess logits."""
         if isinstance(x, tuple):
             x = x[-1]
         return x
 
-    def simple_test(self, cls_score, softmax=True, post_process=True):
+    def simple_test(self, x, softmax=True, post_process=True):
         """Inference without augmentation.
 
         Args:
             x (tuple[Tensor]): The input features.
                 Multi-stage inputs are acceptable but only the last stage will
                 be used to classify. The shape of every item should be
                 ``(num_samples, in_channels)``.
@@ -55,15 +55,15 @@
             Tensor | list: The inference results.
 
                 - If no post processing, the output is a tensor with shape
                   ``(num_samples, num_classes)``.
                 - If post processing, the output is a multi-dimentional list of
                   float and the dimensions are ``(num_samples, num_classes)``.
         """
-        x = self.pre_logits(cls_score)
+        x = self.pre_logits(x)
         cls_score = self.conv(x).squeeze()
 
         if softmax:
             pred = F.softmax(cls_score, dim=1) if cls_score is not None else None
         else:
             pred = cls_score
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_linear_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_linear_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_non_linear_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_hierarchical_non_linear_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_linear_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_linear_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_non_linear_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/custom_multi_label_non_linear_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/mmov_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/mmov_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/non_linear_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/non_linear_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_cls_head.py`

 * *Files 0% similar despite different names*

```diff
@@ -32,15 +32,15 @@
         if torch.cuda.is_available():
             self.classwise_acc = self.classwise_acc.cuda()
 
     def loss(self, logits, gt_label, pseudo_label=None, mask=None):
         """Loss function in which unlabeled data is considered.
 
         Args:
-            logit (set): (labeled data logit, unlabeled data logit)
+            logits (set): (labeled data logit, unlabeled data logit)
             gt_label (Tensor): target features for labeled data
             pseudo_label (Tensor): target feature for unlabeled data
             mask (Tensor): Mask that shows pseudo-label that passes threshold
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_multilabel_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/semisl_multilabel_cls_head.py`

 * *Files 5% similar despite different names*

```diff
@@ -36,92 +36,77 @@
 class EMAMeter:
     """Exponential Moving Average Meter class."""
 
     def __init__(self, alpha=0.9):
         """Initialize the Exponential Moving Average Meter.
 
         Args:
-        - alpha (float): Smoothing factor for the exponential moving average. Defaults to 0.9.
-
-        Returns:
-        - None
+            alpha (float): Smoothing factor for the exponential moving average. Defaults to 0.9.
         """
         self.alpha = alpha
         self.val = 0
 
     def reset(self):
-        """Reset the Exponential Moving Average Meter.
-
-        Args:
-        - None
-
-        Returns:
-        - None
-        """
+        """Reset the Exponential Moving Average Meter."""
         self.val = 0
 
     def update(self, val):
         """Update the Exponential Moving Average Meter with new value.
 
         Args:
-        - val (float): New value to update the meter.
-
-        Returns:
-        - None
+            val (float): New value to update the meter.
         """
         self.val = self.alpha * self.val + (1 - self.alpha) * val
 
 
 class LossBalancer:
     """Loss Balancer class."""
 
     def __init__(self, num_losses, weights=None, ema_weight=0.7) -> None:
         """Initialize the Loss Balancer.
 
         Args:
-        - num_losses (int): Number of losses to balance.
-        - weights (list): List of weights to be applied to each loss. If None, equal weights are applied.
-        - ema_weight (float): Smoothing factor for the exponential moving average meter. Defaults to 0.7.
-
-        Returns:
-        - None
+            num_losses (int): Number of losses to balance.
+            weights (list): List of weights to be applied to each loss. If None, equal weights are applied.
+            ema_weight (float): Smoothing factor for the exponential moving average meter. Defaults to 0.7.
         """
         self.epsilon = 1e-9
         self.avg_estimators = [EMAMeter(ema_weight) for _ in range(num_losses)]
 
         if weights is not None:
             assert len(weights) == num_losses
             self.final_weights = weights
         else:
             self.final_weights = [1.0] * num_losses
 
     def balance_losses(self, losses):
         """Balance the given losses using the weights and exponential moving average.
 
         Args:
-        - losses (list): List of losses to be balanced.
+            losses (list): List of losses to be balanced.
 
         Returns:
-        - total_loss (float): Balanced loss value.
+            total_loss (float): Balanced loss value.
         """
         total_loss = 0.0
         for i, loss in enumerate(losses):
             self.avg_estimators[i].update(float(loss))
             total_loss += (
                 self.final_weights[i] * loss / (self.avg_estimators[i].val + self.epsilon) * self.avg_estimators[0].val
             )
         return total_loss
 
 
 class SemiMultilabelClsHead:
     """Multilabel Classification head for Semi-SL.
 
     Args:
-        unlabeled_coef (float): unlabeled loss coefficient, default is 1.0
-        use_dynamic_loss_weighting (boolean): whether to use dynamic unlabeled loss weighting, default is True
+        unlabeled_coef (float): unlabeled loss coefficient, default is 1.0.
+        use_dynamic_loss_weighting (boolean): whether to use dynamic unlabeled loss weighting, default is True.
+        aux_loss (dict, optional): auxiliary loss function, default is None.
     """
 
     def __init__(
         self,
         unlabeled_coef=0.1,
         use_dynamic_loss_weighting=True,
         aux_loss=None,
@@ -138,15 +123,15 @@
             self.loss_balancer = None
         self.num_pseudo_label = 0
 
     def loss(self, logits, gt_label, features):
         """Loss function in which unlabeled data is considered.
 
         Args:
-            logit (Tensor): Labeled data logits
+            logits (Tensor): Labeled data logits
             gt_label (Tensor): target features for labeled data
             features (set): (weak data features, strong data features)
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
         num_samples = gt_label.shape[0]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/heads/supcon_cls_head.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/heads/supcon_cls_head.py`

 * *Files 1% similar despite different names*

```diff
@@ -64,14 +64,15 @@
         return self.simple_test(x)
 
     def forward_train(self, x, gt_label):
         """Forward train head using the Supervised Contrastive Loss.
 
         Args:
             x (Tensor): features from the backbone.
+            gt_label (Tensor): ground truth.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
 
         losses = dict(loss=0.0)
         cls_score = self.fc(x)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_angular_loss_with_ignore.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_angular_loss_with_ignore.py`

 * *Files 7% similar despite different names*

```diff
@@ -23,14 +23,16 @@
 ):  # pylint: disable=too-many-arguments, too-many-locals
     """Asymmetric angular loss.
 
     Args:
         pred (torch.Tensor): The prediction with shape (N, *).
         target (torch.Tensor): The ground truth label of the prediction with
             shape (N, *).
+        valid_label_mask (torch.Tensor, optional): Label mask for consideration
+            of ignored label.
         weight (torch.Tensor, optional): Sample-wise loss weight with shape
             (N, ). Dafaults to None.
         gamma_pos (float): positive focusing parameter. Defaults to 0.0.
         gamma_neg (float): Negative focusing parameter. We usually set
             gamma_neg > gamma_pos. Defaults to 1.0.
         k (float): positive balance parameter. Defaults to 0.8.
         clip (float, optional): Probability margin. Defaults to 0.05.
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_loss_with_ignore.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/asymmetric_loss_with_ignore.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 ):  # pylint: disable=too-many-arguments
     """Asymmetric loss, please refer to the `paper <https://arxiv.org/abs/2009.14119>`_ for details.
 
     Args:
         pred (torch.Tensor): The prediction with shape (N, *).
         target (torch.Tensor): The ground truth label of the prediction with
             shape (N, *).
+        valid_label_mask (torch.Tensor, optional): Label mask for consideration of ignored label.
         weight (torch.Tensor, optional): Sample-wise loss weight with shape
             (N, ). Dafaults to None.
         gamma_pos (float): positive focusing parameter. Defaults to 0.0.
         gamma_neg (float): Negative focusing parameter. We usually set
             gamma_neg > gamma_pos. Defaults to 4.0.
         clip (float, optional): Probability margin. Defaults to 0.05.
         reduction (str): The method used to reduce the loss.
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/barlowtwins_loss.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/barlowtwins_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/cross_entropy_loss.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/cross_entropy_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/losses/ib_loss.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/losses/ib_loss.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,31 +10,34 @@
 from mmcls.models.losses import CrossEntropyLoss
 
 
 @LOSSES.register_module()
 class IBLoss(CrossEntropyLoss):
     """IB Loss, Influence-Balanced Loss for Imbalanced Visual Classification, https://arxiv.org/abs/2110.02444."""
 
-    def __init__(self, num_classes, start=5, alpha=1000.0):
+    def __init__(self, num_classes, start=5, alpha=1000.0, reduction: str = "mean"):
         """Init fuction of IBLoss.
 
         Args:
             num_classes (int): Number of classes in dataset
             start (int): Epoch to start finetuning with IB loss
             alpha (float): Hyper-parameter for an adjustment for IB loss re-weighting
+            reduction (str): How to reduce the output. Available options are "none" or "mean". Defaults to 'mean'.
         """
-        super().__init__(loss_weight=1.0)
+        super().__init__(loss_weight=1.0, reduction=reduction)
         if alpha < 0:
             raise ValueError("Alpha for IB loss should be bigger than 0")
         self.alpha = alpha
         self.epsilon = 0.001
         self.num_classes = num_classes
-        self.weight = None
+        self.register_buffer("weight", torch.ones(size=(self.num_classes,)))
         self._start_epoch = start
         self._cur_epoch = 0
+        if reduction not in {"mean", "none"}:
+            raise ValueError(f"reduction={reduction} is not allowed.")
 
     @property
     def cur_epoch(self):
         """Return current epoch."""
         return self._cur_epoch
 
     @cur_epoch.setter
@@ -44,20 +47,20 @@
     def update_weight(self, cls_num_list):
         """Update loss weight per class."""
         if len(cls_num_list) == 0:
             raise ValueError("Cannot compute the IB loss weight with empty cls_num_list.")
         per_cls_weights = 1.0 / np.array(cls_num_list)
         per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)
         per_cls_weights = torch.FloatTensor(per_cls_weights)
-        self.weight = per_cls_weights
+        self.weight.data = per_cls_weights.to(device=self.weight.device)
 
     def forward(self, x, target, feature):
         """Forward fuction of IBLoss."""
         if self._cur_epoch < self._start_epoch:
             return super().forward(x, target)
         grads = torch.sum(torch.abs(F.softmax(x, dim=1) - F.one_hot(target, self.num_classes)), 1)
         feature = torch.sum(torch.abs(feature), 1).reshape(-1, 1)
         scaler = grads * feature.reshape(-1)
         scaler = self.alpha / (scaler + self.epsilon)
-        ce_loss = F.cross_entropy(x, target, weight=self.weight.to(x.get_device()), reduction="none")
+        ce_loss = F.cross_entropy(x, target, weight=self.weight, reduction="none")
         loss = ce_loss * scaler
-        return loss.mean()
+        return loss.mean() if self.reduction == "mean" else loss
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/mmov_neck.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/mmov_neck.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/models/necks/selfsl_mlp.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/models/necks/selfsl_mlp.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/builder.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/nncf/registers.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/registers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/optimizer/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/optimizer/lars.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/optimizer/lars.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/tasks/exporter.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/exporter.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,64 +1,60 @@
-"""Base exporter for OTX Classification with MMCLS."""
-# Copyright (C) 2023 Intel Corporation
+"""Export task for OTX Segmentation with MMSEG."""
+# Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import numpy as np
 from mmcv.runner import wrap_fp16_model
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
-from otx.algorithms.common.adapters.mmcv.tasks.registry import STAGES
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
 from otx.algorithms.common.adapters.mmdeploy.utils import sync_batchnorm_2_batchnorm
 from otx.algorithms.common.utils.logger import get_logger
-
-from .stage import ClsStage
+from otx.algorithms.segmentation.adapters.mmseg.utils.builder import build_segmentor
 
 logger = get_logger()
 
 
-@STAGES.register_module()
-class ClsExporter(ExporterMixin, ClsStage):
-    """Base exporter class."""
+class SegmentationExporter(Exporter):
+    """Exporter for OTX Segmentation using mmsegmentation training backend."""
 
-    def run(self, model_cfg, model_ckpt, data_cfg, **kwargs):  # noqa: C901
+    def run(self, cfg, **kwargs):  # noqa: C901
         """Run exporter stage."""
 
         precision = kwargs.get("precision", "FP32")
-        model_builder = kwargs.get("model_builder", self.MODEL_BUILDER)
+        model_builder = kwargs.get("model_builder", build_segmentor)
 
         def model_builder_helper(*args, **kwargs):
             model = model_builder(*args, **kwargs)
             # TODO: handle various input size
             model = sync_batchnorm_2_batchnorm(model, 2)
 
-            if hasattr(model, "is_export"):
-                model.is_export = True
-
             if precision == "FP16":
                 wrap_fp16_model(model)
             elif precision == "INT8":
                 from nncf.torch.nncf_network import NNCFNetwork
 
                 assert isinstance(model, NNCFNetwork)
 
             return model
 
         kwargs["model_builder"] = model_builder_helper
-        return super().run(model_cfg, model_ckpt, data_cfg, **kwargs)
+
+        return super().run(cfg, **kwargs)
 
     @staticmethod
     def naive_export(output_dir, model_builder, precision, cfg, model_name="model"):
-        """Export procedure with pytorch backend."""
-        from mmcls.datasets.pipelines import Compose
+        """Export using pytorch backend."""
+        from mmseg.apis.inference import LoadImage
+        from mmseg.datasets.pipelines import Compose
 
         from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
 
         def get_fake_data(cfg, orig_img_shape=(128, 128, 3)):
-            pipeline = cfg.data.test.pipeline
+            pipeline = [LoadImage()] + cfg.data.test.pipeline[1:]
             pipeline = Compose(pipeline)
             data = dict(img=np.zeros(orig_img_shape, dtype=np.uint8))
             data = pipeline(data)
             return data
 
         fake_data = get_fake_data(cfg)
         opset_version = 11
@@ -66,11 +62,11 @@
         NaiveExporter.export2openvino(
             output_dir,
             model_builder,
             cfg,
             fake_data,
             precision=precision,
             model_name=model_name,
-            input_names=["data"],
-            output_names=["logits"],
+            input_names=["input"],
+            output_names=["output"],
             opset_version=opset_version,
         )
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/builder.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/mmcls/utils/config_utils.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/config_utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -22,20 +22,18 @@
     get_configs_by_pairs,
     get_dataset_configs,
     get_meta_keys,
     patch_color_conversion,
 )
 from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.label import Domain
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 
-@check_input_parameters_type()
 def patch_datasets(
     config: Config,
     domain: Domain = Domain.CLASSIFICATION,
     subsets: Optional[List[str]] = None,
     **kwargs,
 ):
     """Update dataset configs."""
@@ -44,15 +42,15 @@
 
     if subsets is None:
         subsets = ["train", "val", "test", "unlabeled"]
 
     def update_pipeline(cfg):
         if subset == "train":
             for collect_cfg in get_configs_by_pairs(cfg, dict(type="Collect")):
-                get_meta_keys(collect_cfg)
+                get_meta_keys(collect_cfg, ["entity_id", "label_id"])
 
     for subset in subsets:
         if subset not in config.data:
             continue
         config.data[f"{subset}_dataloader"] = config.data.get(f"{subset}_dataloader", ConfigDict())
 
         # For stable hierarchical information indexing
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-"""Adapters of classification - openvino."""
-
+"""Base data configurations pipeline folder."""
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/openvino_models.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/model_wrappers/openvino_models.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,16 +16,14 @@
 
 # pylint: disable=invalid-name
 
 from typing import Any, Dict
 
 import numpy as np
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 try:
     from openvino.model_zoo.model_api.models.classification import Classification
     from openvino.model_zoo.model_api.models.types import BooleanValue, DictValue
 except ImportError:
     import warnings
 
     warnings.warn("ModelAPI was not found.")
@@ -82,27 +80,25 @@
             if layer_shape[1] != len(self.labels):
                 raise RuntimeError(
                     "Model's number of classes and parsed "
                     f"labels must match ({layer_shape[1]} != {len(self.labels)})"
                 )
         return layer_name
 
-    @check_input_parameters_type()
     def postprocess(self, outputs: Dict[str, np.ndarray], meta: Dict[str, Any]):  # pylint: disable=unused-argument
         """Post-process."""
         logits = outputs[self.out_layer_name].squeeze()
         if self.multilabel:
             return get_multilabel_predictions(logits)
         if self.hierarchical:
             return get_hierarchical_predictions(logits, self.multihead_class_info)
 
         return get_multiclass_predictions(logits)
 
     # pylint: disable=unused-argument
-    @check_input_parameters_type()
     def postprocess_aux_outputs(self, outputs: Dict[str, np.ndarray], metadata: Dict[str, Any]):
         """Post-process for auxiliary outputs."""
         logits = outputs[self.out_layer_name].squeeze()
         if self.multilabel:
             probs = sigmoid_numpy(logits)
         elif self.hierarchical:
             probs = activate_multihead_output(logits, self.multihead_class_info)
@@ -115,42 +111,38 @@
             repr_vector = outputs["feature_vector"].reshape(-1)
         else:
             saliency_map, repr_vector = None, None
 
         return probs, saliency_map, repr_vector, act_score
 
 
-@check_input_parameters_type()
 def sigmoid_numpy(x: np.ndarray):
     """Sigmoid numpy."""
     return 1.0 / (1.0 + np.exp(-1.0 * x))
 
 
-@check_input_parameters_type()
 def softmax_numpy(x: np.ndarray, eps: float = 1e-9):
     """Softmax numpy."""
     x = np.exp(x - np.max(x))
     return x / (np.sum(x) + eps)
 
 
-@check_input_parameters_type()
 def activate_multihead_output(logits: np.ndarray, multihead_class_info: dict):
     """Activate multi-head output."""
     for i in range(multihead_class_info["num_multiclass_heads"]):
         logits_begin, logits_end = multihead_class_info["head_idx_to_logits_range"][str(i)]
         logits[logits_begin:logits_end] = softmax_numpy(logits[logits_begin:logits_end])
 
     if multihead_class_info["num_multilabel_classes"]:
         logits_begin = multihead_class_info["num_single_label_classes"]
         logits[logits_begin:] = sigmoid_numpy(logits[logits_begin:])
 
     return logits
 
 
-@check_input_parameters_type()
 def get_hierarchical_predictions(
     logits: np.ndarray, multihead_class_info: dict, pos_thr: float = 0.5, activate: bool = True
 ):
     """Get hierarchical predictions."""
     predicted_labels = []
     for i in range(multihead_class_info["num_multiclass_heads"]):
         logits_begin, logits_end = multihead_class_info["head_idx_to_logits_range"][str(i)]
@@ -171,24 +163,22 @@
             if head_logits[i] > pos_thr:
                 label_str = multihead_class_info["all_groups"][multihead_class_info["num_multiclass_heads"] + i][0]
                 predicted_labels.append((multihead_class_info["label_to_idx"][label_str], head_logits[i]))
 
     return predicted_labels
 
 
-@check_input_parameters_type()
 def get_multiclass_predictions(logits: np.ndarray, activate: bool = True):
     """Get multiclass predictions."""
     index = np.argmax(logits)
     if activate:
         logits = softmax_numpy(logits)
     return [(index, logits[index])]
 
 
-@check_input_parameters_type()
 def get_multilabel_predictions(logits: np.ndarray, pos_thr: float = 0.5, activate: bool = True):
     """Get multilabel predictions."""
     if activate:
         logits = sigmoid_numpy(logits)
     scores = []
     indices = []
     for i in range(logits.shape[0]):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/configuration.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/configuration.py`

 * *Files 8% similar despite different names*

```diff
@@ -49,14 +49,23 @@
     @attrs
     class __AlgoBackend(BaseConfig.BaseAlgoBackendParameters):
         """Algorithm backend configurations."""
 
         header = string_attribute("Parameters for the MPA algo-backend")
         description = header
 
+        enable_noisy_label_detection = configurable_boolean(
+            default_value=False,
+            header="Enable loss dynamics tracking for noisy label detection",
+            description="Set to True to enable loss dynamics tracking for each sample to detect noisy labeled samples.",
+            editable=False,
+            visible_in_ui=False,
+            affects_outcome_of=ModelLifecycle.TRAINING,
+        )
+
     @attrs
     class __POTParameter(BaseConfig.BasePOTParameter):
         """POT-related parameter configurations."""
 
         header = string_attribute("POT Parameters")
         description = header
         visible_in_ui = boolean_attribute(False)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Base data configurations pipeline folder."""
+"""Base data pipeline configurations folder."""
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/data/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/data/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/deployments/base_classification_static.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/deployments/base_classification_static.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/base/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/base/models/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/configuration.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -366,9 +366,24 @@
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     visible_in_ui: false
     warning: null
+  enable_noisy_label_detection:
+    affects_outcome_of: TRAINING
+    default_value: false
+    description: Set to True to enable loss dynamics tracking for each sample to detect noisy labeled samples.
+    editable: true
+    header: Enable loss dynamics tracking for noisy label detection
+    type: BOOLEAN
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: true
+    visible_in_ui: false
+    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -1,13 +1,13 @@
 {
     "base": {
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
-            "log_dir": "."
+            "log_dir": "/tmp"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_hierarchical.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_hierarchical.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/selfsl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/semisl/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/supcon/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_b0_cls_incr/template.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Image Classification for EfficientNet-B0
 application: ~
 
 # Algo backend.
-framework: OTEClassification v1.2.3
+framework: OTXClassification v1.2.3
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.classification.tasks.ClassificationTrainTask
-  openvino: otx.algorithms.classification.tasks.ClassificationOpenVINOTask
-  nncf: otx.algorithms.classification.tasks.nncf.ClassificationNNCFTask
+  base: otx.algorithms.classification.adapters.mmcls.task.MMClassificationTask
+  openvino: otx.algorithms.classification.adapters.openvino.task.ClassificationOpenVINOTask
+  nncf: otx.algorithms.classification.adapters.mmcls.nncf.task.ClassificationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/compression_config.json`

 * *Files 20% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.6796875%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}",*

 * * "'order_of_parts'": '{delete: [1]}',*

 * * 'delete': "['nncf_quantization_pruning']"}*

```diff
@@ -1,13 +1,13 @@
 {
     "base": {
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
-            "log_dir": "."
+            "log_dir": "/tmp"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
@@ -27,42 +27,11 @@
                         }
                     },
                     "preset": "mixed"
                 }
             ]
         }
     },
-    "nncf_quantization_pruning": {
-        "nncf": {
-            "coeff_decrease_lr_for_nncf": 1.0
-        },
-        "nncf_config": {
-            "accuracy_aware_training": {
-                "mode": "adaptive_compression_level",
-                "params": {
-                    "initial_training_phase_epochs": 100,
-                    "maximal_absolute_accuracy_degradation": 0.01,
-                    "maximal_total_epochs": 200,
-                    "patience_epochs": 100
-                }
-            },
-            "compression": [
-                {
-                    "algorithm": "quantization",
-                    "initializer": {
-                        "batchnorm_adaptation": {
-                            "num_bn_adaptation_samples": 8192
-                        },
-                        "range": {
-                            "num_init_samples": 8192
-                        }
-                    },
-                    "preset": "mixed"
-                }
-            ]
-        }
-    },
     "order_of_parts": [
-        "nncf_quantization",
-        "nncf_quantization_pruning"
+        "nncf_quantization"
     ]
 }
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/selfsl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/semisl/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/supcon/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/template.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/template.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -1,59 +1,59 @@
 # Description.
-model_template_id: Custom_Image_Classification_EfficientNet-V2-S
-name: EfficientNet-V2-S
+model_template_id: Custom_Image_Classification_MobileNet-V3-large-1x
+name: MobileNet-V3-large-1x
 task_type: CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Image Classification for EfficientNet-V2-S
+summary: Class-Incremental Image Classification for MobileNet-V3-large-1x
 application: ~
 
 # Algo backend.
-framework: OTEClassification v1.2.3
+framework: OTXClassification v1.2.3
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.classification.tasks.ClassificationTrainTask
-  openvino: otx.algorithms.classification.tasks.ClassificationOpenVINOTask
-  nncf: otx.algorithms.classification.tasks.nncf.ClassificationNNCFTask
+  base: otx.algorithms.classification.adapters.mmcls.task.MMClassificationTask
+  openvino: otx.algorithms.classification.adapters.openvino.task.ClassificationOpenVINOTask
+  nncf: otx.algorithms.classification.adapters.mmcls.nncf.task.ClassificationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
         default_value: 64
         auto_hpo_state: POSSIBLE
       learning_rate:
-        default_value: 0.0071
+        default_value: 0.0058
         auto_hpo_state: POSSIBLE
       learning_rate_warmup_iters:
-        default_value: 0
+        default_value: 10
       num_iters:
         default_value: 90
     nncf_optimization:
       enable_quantization:
         default_value: true
       enable_pruning:
         default_value: false
       pruning_supported:
-        default_value: false
+        default_value: true
       maximal_accuracy_degradation:
         default_value: 1.0
     algo_backend:
       train_type:
         default_value: Incremental
 
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 5.76
-size: 20.23
+gigaflops: 0.44
+size: 4.29
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -1,13 +1,13 @@
 {
     "base": {
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
-            "log_dir": "."
+            "log_dir": "/tmp"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_hierarchical.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_hierarchical.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/selfsl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/supcon/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/template_experiment.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_075_cls_incr/template_experiment.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Image Classification for MobileNet-V3-learge-0.75x
 application: ~
 
 # Algo backend.
-framework: OTEClassification v1.2.3
+framework: OTXClassification v1.2.3
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.classification.tasks.ClassificationTrainTask
-  openvino: otx.algorithms.classification.tasks.ClassificationOpenVINOTask
-  nncf: otx.algorithms.classification.tasks.nncf.ClassificationNNCFTask
+  base: otx.algorithms.classification.adapters.mmcls.task.MMClassificationTask
+  openvino: otx.algorithms.classification.adapters.openvino.task.ClassificationOpenVINOTask
+  nncf: otx.algorithms.classification.adapters.mmcls.nncf.task.ClassificationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -1,13 +1,13 @@
 {
     "base": {
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
-            "log_dir": "."
+            "log_dir": "/tmp"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_hierarchical.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_hierarchical.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/selfsl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/semisl/model_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/supcon/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_large_1_cls_incr/template.yaml` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/template.yaml`

 * *Files 25% similar despite different names*

```diff
@@ -1,59 +1,61 @@
 # Description.
-model_template_id: Custom_Image_Classification_MobileNet-V3-large-1x
-name: MobileNet-V3-large-1x
-task_type: CLASSIFICATION
+model_template_id: Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR
+name: Lite-HRNet-x-mod3
+task_type: SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Image Classification for MobileNet-V3-large-1x
+summary: Class-Incremental Semantic Segmentation with heavy-size architecture which based on the Lite-HRNet backbone for the accurate predictions but long training.
 application: ~
 
 # Algo backend.
-framework: OTEClassification v1.2.3
+framework: OTXSegmentation v0.14.0
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.classification.tasks.ClassificationTrainTask
-  openvino: otx.algorithms.classification.tasks.ClassificationOpenVINOTask
-  nncf: otx.algorithms.classification.tasks.nncf.ClassificationNNCFTask
+  base: otx.algorithms.segmentation.adapters.mmseg.task.MMSegmentationTask
+  openvino: otx.algorithms.segmentation.adapters.openvino.task.OpenVINOSegmentationTask
+  nncf: otx.algorithms.segmentation.adapters.mmseg.nncf.task.SegmentationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
-        default_value: 64
+        default_value: 8
         auto_hpo_state: POSSIBLE
       learning_rate:
-        default_value: 0.0058
+        default_value: 0.001
         auto_hpo_state: POSSIBLE
+      learning_rate_fixed_iters:
+        default_value: 0
       learning_rate_warmup_iters:
-        default_value: 10
+        default_value: 100
       num_iters:
-        default_value: 90
+        default_value: 300
     nncf_optimization:
       enable_quantization:
         default_value: true
       enable_pruning:
         default_value: false
       pruning_supported:
-        default_value: true
+        default_value: false
       maximal_accuracy_degradation:
         default_value: 1.0
     algo_backend:
       train_type:
         default_value: Incremental
 
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 0.44
-size: 4.29
+gigaflops: 13.97
+size: 6.4
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -1,13 +1,13 @@
 {
     "base": {
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
-            "log_dir": "."
+            "log_dir": "/tmp"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/hparam.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/hparam.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/template_experiment.yaml` & `otx-1.2.0rc1/otx/algorithms/classification/configs/efficientnet_v2_s_cls_incr/template.yaml`

 * *Files 18% similar despite different names*

```diff
@@ -1,50 +1,59 @@
 # Description.
-model_template_id: Custom_Image_Classification_MobileNet-V3-small
-name: MobileNet-V3-small
+model_template_id: Custom_Image_Classification_EfficientNet-V2-S
+name: EfficientNet-V2-S
 task_type: CLASSIFICATION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Image Classification for MobileNet-V3-small
+summary: Class-Incremental Image Classification for EfficientNet-V2-S
 application: ~
 
 # Algo backend.
-framework: OTEClassification v1.2.3
+framework: OTXClassification v1.2.3
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.classification.tasks.ClassificationTrainTask
-  openvino: otx.algorithms.classification.tasks.ClassificationOpenVINOTask
-  nncf: otx.algorithms.classification.tasks.nncf.ClassificationNNCFTask
+  base: otx.algorithms.classification.adapters.mmcls.task.MMClassificationTask
+  openvino: otx.algorithms.classification.adapters.openvino.task.ClassificationOpenVINOTask
+  nncf: otx.algorithms.classification.adapters.mmcls.nncf.task.ClassificationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
-        default_value: 32
+        default_value: 64
         auto_hpo_state: POSSIBLE
       learning_rate:
-        default_value: 0.016
+        default_value: 0.0071
         auto_hpo_state: POSSIBLE
       learning_rate_warmup_iters:
-        default_value: 100
+        default_value: 0
       num_iters:
-        default_value: 20
+        default_value: 90
+    nncf_optimization:
+      enable_quantization:
+        default_value: true
+      enable_pruning:
+        default_value: false
+      pruning_supported:
+        default_value: false
+      maximal_accuracy_degradation:
+        default_value: 1.0
     algo_backend:
       train_type:
         default_value: Incremental
 
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 0.12
-size: 1.56
+gigaflops: 5.76
+size: 20.23
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tasks/inference.py` & `otx-1.2.0rc1/otx/algorithms/classification/task.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,321 +1,331 @@
-"""Inference Task of OTX Classification."""
+"""Task of OTX Classification."""
 
-# Copyright (C) 2022 Intel Corporation
-# SPDX-License-Identifier: Apache-2.0
+# Copyright (C) 2023 Intel Corporation
 #
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions
+# and limitations under the License.
 
+import io
 import json
 import os
-from typing import Optional
+from abc import ABC, abstractmethod
+from typing import List, Optional
 
 import numpy as np
-from mmcv.utils import ConfigDict
+import torch
 
-from otx.algorithms.classification.adapters.mmcls.utils.builder import build_classifier
-from otx.algorithms.classification.adapters.mmcls.utils.config_utils import (
-    patch_datasets,
-    patch_evaluation,
-)
-from otx.algorithms.classification.configs import ClassificationConfig
+from otx.algorithms.classification.configs.base import ClassificationConfig
 from otx.algorithms.classification.utils import (
     get_cls_deploy_config,
     get_cls_inferencer_configuration,
     get_cls_model_api_configuration,
 )
 from otx.algorithms.classification.utils import (
     get_multihead_class_info as get_hierarchical_info,
 )
-from otx.algorithms.common.adapters.mmcv.utils import (
-    patch_data_pipeline,
-    patch_default_config,
-    patch_runner,
-)
-from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
 from otx.algorithms.common.configs import TrainType
-from otx.algorithms.common.tasks import BaseTask
+from otx.algorithms.common.tasks.base_task import TRAIN_TYPE_DIR_PATH, OTXTask
 from otx.algorithms.common.utils import embed_ir_model_data
+from otx.algorithms.common.utils.callback import TrainingProgressCallback
 from otx.algorithms.common.utils.logger import get_logger
+from otx.api.configuration import cfg_helper
+from otx.api.configuration.helper.utils import ids_to_strings
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import (
     InferenceParameters,
-    default_progress_callback,
+)
+from otx.api.entities.inference_parameters import (
+    default_progress_callback as default_infer_progress_callback,
 )
 from otx.api.entities.metadata import FloatMetadata, FloatType
+from otx.api.entities.metrics import (
+    CurveMetric,
+    LineChartInfo,
+    LineMetricsGroup,
+    MetricsGroup,
+    Performance,
+    ScoreMetric,
+)
 from otx.api.entities.model import (  # ModelStatus
     ModelEntity,
     ModelFormat,
     ModelOptimizationType,
     ModelPrecision,
 )
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.entities.tensor import TensorEntity
+from otx.api.entities.train_parameters import (
+    TrainParameters,
+)
+from otx.api.entities.train_parameters import (
+    default_progress_callback as default_train_progress_callback,
+)
 from otx.api.serialization.label_mapper import label_schema_to_bytes
 from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
-from otx.api.usecases.tasks.interfaces.explain_interface import IExplainTask
-from otx.api.usecases.tasks.interfaces.export_interface import ExportType, IExportTask
-from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
-from otx.api.usecases.tasks.interfaces.unload_interface import IUnload
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from otx.api.utils.dataset_utils import add_saliency_maps_to_dataset_item
 from otx.api.utils.labels_utils import get_empty_label
-
-# pylint: disable=invalid-name
+from otx.cli.utils.multi_gpu import is_multigpu_child_process
 
 logger = get_logger()
-
-TASK_CONFIG = ClassificationConfig
 RECIPE_TRAIN_TYPE = {
     TrainType.Semisupervised: "semisl.yaml",
     TrainType.Incremental: "incremental.yaml",
     TrainType.Selfsupervised: "selfsl.yaml",
 }
 
 
-# pylint: disable=too-many-instance-attributes
-class ClassificationInferenceTask(BaseTask, IInferenceTask, IExportTask, IEvaluationTask, IExplainTask, IUnload):
-    """Inference Task Implementation of OTX Classification."""
-
-    @check_input_parameters_type()
-    def __init__(self, task_environment: TaskEnvironment, **kwargs):
-        self._should_stop = False
-        super().__init__(TASK_CONFIG, task_environment, **kwargs)
-
-        self._task_environment = task_environment
-        if len(task_environment.get_labels(False)) == 1:
-            self._labels = task_environment.get_labels(include_empty=True)
+class OTXClassificationTask(OTXTask, ABC):
+    """Task class for OTX classification."""
+
+    # pylint: disable=too-many-instance-attributes, too-many-locals, too-many-boolean-expressions
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__(task_environment, output_path)
+        self._task_config = ClassificationConfig
+        self._hyperparams = self._task_environment.get_hyper_parameters(self._task_config)
+        if len(self._task_environment.get_labels(False)) == 1:
+            self._labels = self._task_environment.get_labels(include_empty=True)
         else:
-            self._labels = task_environment.get_labels(include_empty=False)
-        self._empty_label = get_empty_label(task_environment.label_schema)
+            self._labels = self._task_environment.get_labels(include_empty=False)
+        self._empty_label = get_empty_label(self._task_environment.label_schema)
 
         self._multilabel = False
         self._hierarchical = False
+        self._hierarchical_info = None
         self._selfsl = False
+        self._set_train_mode()
 
-        self._multilabel = len(task_environment.label_schema.get_groups(False)) > 1 and len(
-            task_environment.label_schema.get_groups(False)
+        self._train_type = self._hyperparams.algo_backend.train_type
+        self._model_dir = os.path.join(
+            os.path.abspath(os.path.dirname(self._task_environment.model_template.model_template_path)),
+            TRAIN_TYPE_DIR_PATH[self._train_type.name],
+        )
+        if (
+            self._train_type in RECIPE_TRAIN_TYPE
+            and self._train_type == TrainType.Incremental
+            and not self._multilabel
+            and not self._hierarchical
+            and self._hyperparams.learning_parameters.enable_supcon
+            and not self._model_dir.endswith("supcon")
+        ):
+            self._model_dir = os.path.join(self._model_dir, "supcon")
+
+        self.data_pipeline_path = os.path.join(self._model_dir, "data_pipeline.py")
+
+        if self._task_environment.model is not None:
+            self._load_model()
+
+    def _set_train_mode(self):
+        self._multilabel = len(self._task_environment.label_schema.get_groups(False)) > 1 and len(
+            self._task_environment.label_schema.get_groups(False)
         ) == len(
-            task_environment.get_labels(include_empty=False)
+            self._task_environment.get_labels(include_empty=False)
         )  # noqa:E127
         if self._multilabel:
             logger.info("Classification mode: multilabel")
 
-        self._hierarchical_info = None
-        if not self._multilabel and len(task_environment.label_schema.get_groups(False)) > 1:
+        if not self._multilabel and len(self._task_environment.label_schema.get_groups(False)) > 1:
             logger.info("Classification mode: hierarchical")
             self._hierarchical = True
-            self._hierarchical_info = get_hierarchical_info(task_environment.label_schema)
+            self._hierarchical_info = get_hierarchical_info(self._task_environment.label_schema)
         if not self._multilabel and not self._hierarchical:
             logger.info("Classification mode: multiclass")
 
         if self._hyperparams.algo_backend.train_type == TrainType.Selfsupervised:
             self._selfsl = True
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def infer(
         self,
         dataset: DatasetEntity,
         inference_parameters: Optional[InferenceParameters] = None,
     ) -> DatasetEntity:
         """Main infer function of OTX Classification."""
 
-        logger.info("called infer()")
-        stage_module = "ClsInferrer"
-        self._data_cfg = self._init_test_data_cfg(dataset)
-
-        dump_features = True
-        dump_saliency_map = not inference_parameters.is_evaluation if inference_parameters else True
-
-        results = self._run_task(
-            stage_module,
-            mode="eval",
-            dataset=dataset,
-            dump_features=dump_features,
-            dump_saliency_map=dump_saliency_map,
-        )
-        logger.debug(f"result of run_task {stage_module} module = {results}")
-        predictions = results["outputs"]
+        logger.info("infer()")
+
+        results = self._infer_model(dataset, inference_parameters)
         prediction_results = zip(
-            predictions["eval_predictions"],
-            predictions["feature_vectors"],
-            predictions["saliency_maps"],
+            results["eval_predictions"],
+            results["feature_vectors"],
+            results["saliency_maps"],
         )
 
-        update_progress_callback = default_progress_callback
+        update_progress_callback = default_infer_progress_callback
         process_saliency_maps = False
         explain_predicted_classes = True
         if inference_parameters is not None:
             update_progress_callback = inference_parameters.update_progress  # type: ignore
             process_saliency_maps = inference_parameters.process_saliency_maps
             explain_predicted_classes = inference_parameters.explain_predicted_classes
 
         self._add_predictions_to_dataset(
             prediction_results, dataset, update_progress_callback, process_saliency_maps, explain_predicted_classes
         )
         return dataset
 
-    def explain(
-        self,
-        dataset: DatasetEntity,
-        explain_parameters: Optional[InferenceParameters] = None,
-    ) -> DatasetEntity:
-        """Main explain function of OTX Classification Task."""
-        logger.info("called explain()")
-        stage_module = "ClsExplainer"
-        self._data_cfg = self._init_test_data_cfg(dataset)
-
-        results = self._run_task(
-            stage_module,
-            mode="train",
-            dataset=dataset,
-            explainer=explain_parameters.explainer if explain_parameters else None,
-        )
-        logger.debug(f"result of run_task {stage_module} module = {results}")
-        predictions = results["outputs"]["eval_predictions"]
-        saliency_maps = results["outputs"]["saliency_maps"]
-
-        update_progress_callback = default_progress_callback
-        process_saliency_maps = False
-        explain_predicted_classes = True
-        if explain_parameters is not None:
-            update_progress_callback = explain_parameters.update_progress  # type: ignore
-            process_saliency_maps = explain_parameters.process_saliency_maps
-            explain_predicted_classes = explain_parameters.explain_predicted_classes
-
-        self._add_explanations_to_dataset(
-            predictions,
-            saliency_maps,
-            dataset,
-            update_progress_callback,
-            process_saliency_maps,
-            explain_predicted_classes,
-        )
-        logger.info("Explain completed")
-        return dataset
-
-    @check_input_parameters_type()
-    def evaluate(
-        self,
-        output_resultset: ResultSetEntity,
-        evaluation_metric: Optional[str] = None,
+    def train(
+        self, dataset: DatasetEntity, output_model: ModelEntity, train_parameters: Optional[TrainParameters] = None
     ):
-        """Evaluate function of OTX Classification Task."""
+        """Train function for OTX classification task.
 
-        logger.info("called evaluate()")
-        metric = MetricsHelper.compute_accuracy(output_resultset)
-        logger.info(f"Accuracy after evaluation: {metric.accuracy.value}")
-        output_resultset.performance = metric.get_performance()
-        logger.info("Evaluation completed")
+        Actual training is processed by _train_model fucntion
+        """
+        logger.info("train()")
+        # Check for stop signal when training has stopped.
+        # If should_stop is true, training was cancelled and no new
+        if self._should_stop:
+            logger.info("Training cancelled.")
+            self._should_stop = False
+            self._is_training = False
+            return
+
+        # Set OTX LoggerHook & Time Monitor
+        if train_parameters:
+            update_progress_callback = train_parameters.update_progress
+        else:
+            update_progress_callback = default_train_progress_callback
+        self._time_monitor = TrainingProgressCallback(update_progress_callback)
 
-    def unload(self):
-        """Unload function of OTX Classification Task."""
-        logger.info("called unload()")
-        self.cleanup()
+        results = self._train_model(dataset)
+
+        # Check for stop signal when training has stopped. If should_stop is true, training was cancelled and no new
+        if self._should_stop:
+            logger.info("Training cancelled.")
+            self._should_stop = False
+            self._is_training = False
+            return
+
+        # get output model
+        model_ckpt = results.get("final_ckpt")
+        if model_ckpt is None:
+            logger.error("cannot find final checkpoint from the results.")
+            return
+        # update checkpoint to the newly trained model
+        self._model_ckpt = model_ckpt
+
+        # compose performance statistics
+        training_metrics, final_acc = self._generate_training_metrics(self._learning_curves)
+        # save resulting model
+        self.save_model(output_model)
+        performance = Performance(
+            score=ScoreMetric(value=final_acc, name="accuracy"),
+            dashboard_metrics=training_metrics,
+        )
+        logger.info(f"Final model performance: {str(performance)}")
+        output_model.performance = performance
+        self._is_training = False
+        logger.info("train done.")
 
-    @check_input_parameters_type()
     def export(
         self,
         export_type: ExportType,
         output_model: ModelEntity,
         precision: ModelPrecision = ModelPrecision.FP32,
-        dump_features: bool = False,
+        dump_features: bool = True,
     ):
         """Export function of OTX Classification Task."""
 
         logger.info("Exporting the model")
         if export_type != ExportType.OPENVINO:
             raise RuntimeError(f"not supported export type {export_type}")
         output_model.model_format = ModelFormat.OPENVINO
         output_model.optimization_type = ModelOptimizationType.MO
 
-        stage_module = "ClsExporter"
-        results = self._run_task(
-            stage_module,
-            mode="train",
-            export=True,
-            enable_fp16=(precision == ModelPrecision.FP16),
-            dump_features=dump_features,
-        )
+        results = self._export_model(precision, dump_features)
         outputs = results.get("outputs")
         logger.debug(f"results of run_task = {outputs}")
         if outputs is None:
             raise RuntimeError(results.get("msg"))
 
         bin_file = outputs.get("bin")
         xml_file = outputs.get("xml")
+        onnx_file = outputs.get("onnx")
 
         inference_config = get_cls_inferencer_configuration(self._task_environment.label_schema)
         deploy_cfg = get_cls_deploy_config(self._task_environment.label_schema, inference_config)
         ir_extra_data = get_cls_model_api_configuration(self._task_environment.label_schema, inference_config)
         ir_extra_data[("otx_config",)] = json.dumps(deploy_cfg, ensure_ascii=False)
         embed_ir_model_data(xml_file, ir_extra_data)
 
-        if xml_file is None or bin_file is None:
-            raise RuntimeError("invalid status of exporting. bin and xml should not be None")
+        if xml_file is None or bin_file is None or onnx_file is None:
+            raise RuntimeError("invalid status of exporting. bin and xml or onnx should not be None")
         with open(bin_file, "rb") as f:
             output_model.set_data("openvino.bin", f.read())
         with open(xml_file, "rb") as f:
             output_model.set_data("openvino.xml", f.read())
+        with open(onnx_file, "rb") as f:
+            output_model.set_data("model.onnx", f.read())
         output_model.precision = self._precision
+        output_model.has_xai = dump_features
         output_model.set_data(
             "label_schema.json",
             label_schema_to_bytes(self._task_environment.label_schema),
         )
         logger.info("Exporting completed")
 
-    # pylint: disable=too-many-locals
-    def _get_item_labels(self, prediction_item, pos_thr):
-        item_labels = []
+    def explain(
+        self,
+        dataset: DatasetEntity,
+        explain_parameters: Optional[ExplainParameters] = None,
+    ) -> DatasetEntity:
+        """Main explain function of OTX Classification Task."""
 
-        if self._multilabel:
-            if max(prediction_item) < pos_thr:
-                logger.info("Confidence is smaller than pos_thr, empty_label will be appended to item_labels.")
-                item_labels.append(ScoredLabel(self._empty_label, probability=1.0))
-            else:
-                for cls_idx, pred_item in enumerate(prediction_item):
-                    if pred_item > pos_thr:
-                        cls_label = ScoredLabel(self.labels[cls_idx], probability=float(pred_item))
-                        item_labels.append(cls_label)
+        predictions, saliency_maps = self._explain_model(
+            dataset,
+            explain_parameters=explain_parameters,
+        )
 
-        elif self._hierarchical:
-            for head_idx in range(self._hierarchical_info["num_multiclass_heads"]):
-                logits_begin, logits_end = self._hierarchical_info["head_idx_to_logits_range"][str(head_idx)]
-                head_logits = prediction_item[logits_begin:logits_end]
-                head_pred = np.argmax(head_logits)  # Assume logits already passed softmax
-                label_str = self._hierarchical_info["all_groups"][head_idx][head_pred]
-                otx_label = next(x for x in self._labels if x.name == label_str)
-                item_labels.append(ScoredLabel(label=otx_label, probability=float(head_logits[head_pred])))
+        update_progress_callback = default_infer_progress_callback
+        process_saliency_maps = False
+        explain_predicted_classes = True
+        if explain_parameters is not None:
+            update_progress_callback = explain_parameters.update_progress  # type: ignore
+            process_saliency_maps = explain_parameters.process_saliency_maps
+            explain_predicted_classes = explain_parameters.explain_predicted_classes
 
-            if self._hierarchical_info["num_multilabel_classes"]:
-                head_logits = prediction_item[self._hierarchical_info["num_single_label_classes"] :]
-                for logit_idx, logit in enumerate(head_logits):
-                    if logit > pos_thr:  # Assume logits already passed sigmoid
-                        label_str_idx = self._hierarchical_info["num_multiclass_heads"] + logit_idx
-                        label_str = self._hierarchical_info["all_groups"][label_str_idx][0]
-                        otx_label = next(x for x in self._labels if x.name == label_str)
-                        item_labels.append(ScoredLabel(label=otx_label, probability=float(logit)))
-            item_labels = self._task_environment.label_schema.resolve_labels_probabilistic(item_labels)
-            if not item_labels:
-                logger.info("item_labels is empty.")
-                item_labels.append(ScoredLabel(self._empty_label, probability=1.0))
+        self._add_explanations_to_dataset(
+            predictions,
+            saliency_maps,
+            dataset,
+            update_progress_callback,
+            process_saliency_maps,
+            explain_predicted_classes,
+        )
+        logger.info("Explain completed")
+        return dataset
 
-        else:
-            label_idx = prediction_item.argmax()
-            cls_label = ScoredLabel(
-                self._labels[label_idx],
-                probability=float(prediction_item[label_idx]),
+    def evaluate(
+        self,
+        output_resultset: ResultSetEntity,
+        evaluation_metric: Optional[str] = None,
+    ):
+        """Evaluate function of OTX Classification Task."""
+
+        logger.info("called evaluate()")
+        if evaluation_metric is not None:
+            logger.warning(
+                f"Requested to use {evaluation_metric} metric, " "but parameter is ignored. Use accuracy instead."
             )
-            item_labels.append(cls_label)
-        return item_labels
+        metric = MetricsHelper.compute_accuracy(output_resultset)
+        logger.info(f"Accuracy after evaluation: {metric.accuracy.value}")
+        output_resultset.performance = metric.get_performance()
+        logger.info("Evaluation completed")
 
     # pylint: disable=too-many-branches, too-many-locals
     def _add_predictions_to_dataset(
         self,
         prediction_results,
         dataset,
         update_progress_callback,
@@ -357,14 +367,59 @@
                     labels=self._labels,
                     predicted_scored_labels=item_labels,
                     explain_predicted_classes=explain_predicted_classes,
                     process_saliency_maps=process_saliency_maps,
                 )
             update_progress_callback(int(i / dataset_size * 100))
 
+    # pylint: disable=too-many-locals
+    def _get_item_labels(self, prediction_item, pos_thr):
+        item_labels = []
+
+        if self._multilabel:
+            if max(prediction_item) < pos_thr:
+                logger.info("Confidence is smaller than pos_thr, empty_label will be appended to item_labels.")
+                item_labels.append(ScoredLabel(self._empty_label, probability=1.0))
+            else:
+                for cls_idx, pred_item in enumerate(prediction_item):
+                    if pred_item > pos_thr:
+                        cls_label = ScoredLabel(self._labels[cls_idx], probability=float(pred_item))
+                        item_labels.append(cls_label)
+
+        elif self._hierarchical:
+            for head_idx in range(self._hierarchical_info["num_multiclass_heads"]):
+                logits_begin, logits_end = self._hierarchical_info["head_idx_to_logits_range"][str(head_idx)]
+                head_logits = prediction_item[logits_begin:logits_end]
+                head_pred = np.argmax(head_logits)  # Assume logits already passed softmax
+                label_str = self._hierarchical_info["all_groups"][head_idx][head_pred]
+                otx_label = next(x for x in self._labels if x.name == label_str)
+                item_labels.append(ScoredLabel(label=otx_label, probability=float(head_logits[head_pred])))
+
+            if self._hierarchical_info["num_multilabel_classes"]:
+                head_logits = prediction_item[self._hierarchical_info["num_single_label_classes"] :]
+                for logit_idx, logit in enumerate(head_logits):
+                    if logit > pos_thr:  # Assume logits already passed sigmoid
+                        label_str_idx = self._hierarchical_info["num_multiclass_heads"] + logit_idx
+                        label_str = self._hierarchical_info["all_groups"][label_str_idx][0]
+                        otx_label = next(x for x in self._labels if x.name == label_str)
+                        item_labels.append(ScoredLabel(label=otx_label, probability=float(logit)))
+            item_labels = self._task_environment.label_schema.resolve_labels_probabilistic(item_labels)
+            if not item_labels:
+                logger.info("item_labels is empty.")
+                item_labels.append(ScoredLabel(self._empty_label, probability=1.0))
+
+        else:
+            label_idx = prediction_item.argmax()
+            cls_label = ScoredLabel(
+                self._labels[label_idx],
+                probability=float(prediction_item[label_idx]),
+            )
+            item_labels.append(cls_label)
+        return item_labels
+
     def _add_explanations_to_dataset(
         self,
         predictions,
         saliency_maps,
         dataset,
         update_progress_callback,
         process_saliency_maps,
@@ -381,140 +436,83 @@
                 labels=self._labels,
                 predicted_scored_labels=item_labels,
                 explain_predicted_classes=explain_predicted_classes,
                 process_saliency_maps=process_saliency_maps,
             )
             update_progress_callback(int(i / dataset_size * 100))
 
-    def _init_recipe_hparam(self) -> dict:
-        params = self._hyperparams.learning_parameters
-        warmup_iters = int(params.learning_rate_warmup_iters)
-        if self._multilabel:
-            # hack to use 1cycle policy
-            lr_config = ConfigDict(max_lr=params.learning_rate, warmup=None)
-        else:
-            lr_config = (
-                ConfigDict(warmup_iters=warmup_iters) if warmup_iters > 0 else ConfigDict(warmup_iters=0, warmup=None)
-            )
-
-        early_stop = False
-        if self._recipe_cfg is not None:
-            if params.enable_early_stopping and self._recipe_cfg.get("evaluation", None):
-                early_stop = ConfigDict(
-                    start=int(params.early_stop_start),
-                    patience=int(params.early_stop_patience),
-                    iteration_patience=int(params.early_stop_iteration_patience),
-                )
+    def save_model(self, output_model: ModelEntity):
+        """Save best model weights in ClassificationTrainTask."""
+        if is_multigpu_child_process():
+            return
+
+        logger.info("called save_model")
+        buffer = io.BytesIO()
+        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
+        labels = {label.name: label.color.rgb_tuple for label in self._labels}
+        model_ckpt = torch.load(self._model_ckpt)
+        modelinfo = {
+            "model": model_ckpt,
+            "config": hyperparams_str,
+            "labels": labels,
+            "VERSION": 1,
+        }
 
-        if self._recipe_cfg.runner.get("type").startswith("IterBasedRunner"):  # type: ignore
-            runner = ConfigDict(max_iters=int(params.num_iters))
-        else:
-            runner = ConfigDict(max_epochs=int(params.num_iters))
-
-        config = ConfigDict(
-            optimizer=ConfigDict(lr=params.learning_rate),
-            lr_config=lr_config,
-            early_stop=early_stop,
-            data=ConfigDict(
-                samples_per_gpu=int(params.batch_size),
-                workers_per_gpu=int(params.num_workers),
-            ),
-            runner=runner,
+        torch.save(modelinfo, buffer)
+        output_model.set_data("weights.pth", buffer.getvalue())
+        output_model.set_data(
+            "label_schema.json",
+            label_schema_to_bytes(self._task_environment.label_schema),
         )
+        output_model.precision = self._precision
 
-        if self._train_type.value == "Semisupervised":
-            unlabeled_config = ConfigDict(
-                data=ConfigDict(
-                    unlabeled_dataloader=ConfigDict(
-                        samples_per_gpu=int(params.unlabeled_batch_size),
-                        workers_per_gpu=int(params.num_workers),
-                    )
-                )
-            )
-            config.update(unlabeled_config)
-        return config
-
-    def _init_recipe(self):
-        logger.info("called _init_recipe()")
-
-        logger.info(f"train type = {self._train_type}")
-        # TODO: Need to remove the hard coding for supcon only.
-        # pylint: disable=too-many-boolean-expressions
-        if (
-            self._train_type in RECIPE_TRAIN_TYPE
-            and self._train_type == TrainType.Incremental
-            and not self._multilabel
-            and not self._hierarchical
-            and self._hyperparams.learning_parameters.enable_supcon
-            and not self._model_dir.endswith("supcon")
-        ):
-            self._model_dir = os.path.join(self._model_dir, "supcon")
-
-        self._recipe_cfg = self._init_model_cfg()
+    def _generate_training_metrics(self, learning_curves):  # pylint: disable=arguments-renamed
+        """Parses the classification logs to get metrics from the latest training run.
 
-        # FIXME[Soobee] : if train type is not in cfg, it raises an error in default Incremental mode.
-        # During semi-implementation, this line should be fixed to -> self._recipe_cfg.train_type = train_type
-        self._recipe_cfg.train_type = self._train_type.name
+        :return output List[MetricsGroup]
+        """
+        output: List[MetricsGroup] = []
 
-        options_for_patch_datasets = {"type": "OTXClsDataset", "empty_label": self._empty_label}
-        options_for_patch_evaluation = {"task": "normal"}
         if self._multilabel:
-            options_for_patch_datasets["type"] = "OTXMultilabelClsDataset"
-            options_for_patch_evaluation["task"] = "multilabel"
+            metric_key = "val/accuracy-mlc"
         elif self._hierarchical:
-            options_for_patch_datasets["type"] = "OTXHierarchicalClsDataset"
-            options_for_patch_datasets["hierarchical_info"] = self._hierarchical_info
-            options_for_patch_evaluation["task"] = "hierarchical"
-        elif self._selfsl:
-            options_for_patch_datasets["type"] = "SelfSLDataset"
-        patch_default_config(self._recipe_cfg)
-        patch_runner(self._recipe_cfg)
-        patch_data_pipeline(self._recipe_cfg, self.data_pipeline_path)
-        patch_datasets(
-            self._recipe_cfg,
-            self._task_type.domain,
-            **options_for_patch_datasets,
-        )  # for OTX compatibility
-        patch_evaluation(self._recipe_cfg, **options_for_patch_evaluation)  # for OTX compatibility
-
-    # TODO: make cfg_path loaded from custom model cfg file corresponding to train_type
-    # model.py contains heads/classifier only for Incremental setting
-    # error log : ValueError: Unexpected type of 'data_loader' parameter
-    def _init_model_cfg(self):
-        if self._multilabel:
-            cfg_path = os.path.join(self._model_dir, "model_multilabel.py")
-        elif self._hierarchical:
-            cfg_path = os.path.join(self._model_dir, "model_hierarchical.py")
+            metric_key = "val/MHAcc"
         else:
-            cfg_path = os.path.join(self._model_dir, "model.py")
-        cfg = MPAConfig.fromfile(cfg_path)
+            metric_key = "val/accuracy_top-1"
 
-        cfg.model.multilabel = self._multilabel
-        cfg.model.hierarchical = self._hierarchical
-        if self._hierarchical:
-            cfg.model.head.hierarchical_info = self._hierarchical_info
-        return cfg
-
-    def _init_test_data_cfg(self, dataset: DatasetEntity):
-        data_cfg = ConfigDict(
-            data=ConfigDict(
-                train=ConfigDict(
-                    otx_dataset=dataset,
-                    labels=self._labels,
-                ),
-                test=ConfigDict(
-                    otx_dataset=dataset,
-                    labels=self._labels,
-                ),
-            )
-        )
-        return data_cfg
+        # Learning curves
+        best_acc = -1
+        if learning_curves is None:
+            return output
+
+        for key, curve in learning_curves.items():
+            metric_curve = CurveMetric(xs=curve.x, ys=curve.y, name=key)
+            if key == metric_key:
+                best_acc = max(curve.y)
+            visualization_info = LineChartInfo(name=key, x_axis_label="Timestamp", y_axis_label=key)
+            output.append(LineMetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
+
+        return output, best_acc
+
+    @abstractmethod
+    def _train_model(self, dataset: DatasetEntity):
+        """Train model and return the results."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def _export_model(self, precision, dump_features):
+        """Export model and return the results."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def _explain_model(self, dataset: DatasetEntity, explain_parameters: Optional[ExplainParameters]):
+        """Explain model and return the results."""
+        raise NotImplementedError
 
-    def _update_stage_module(self, stage_module):
-        module_prefix = {TrainType.Incremental: "Incr", TrainType.Semisupervised: "SemiSL"}
-        if self._train_type in module_prefix and stage_module in ["ClsTrainer", "ClsInferrer"]:
-            stage_module = module_prefix[self._train_type] + stage_module
-        return stage_module
-
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
-        options["model_builder"] = build_classifier
+    @abstractmethod
+    def _infer_model(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ):
+        """Get inference results from dataset."""
+        raise NotImplementedError
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tasks/nncf.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/nncf/task.py`

 * *Files 17% similar despite different names*

```diff
@@ -18,58 +18,70 @@
 from typing import List, Optional
 
 import otx.algorithms.classification.adapters.mmcls.nncf.patches  # noqa: F401  # pylint: disable=unused-import
 import otx.algorithms.classification.adapters.mmcls.nncf.registers  # noqa: F401  # pylint: disable=unused-import
 from otx.algorithms.classification.adapters.mmcls.nncf.builder import (
     build_nncf_classifier,
 )
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
+from otx.algorithms.classification.adapters.mmcls.task import MMClassificationTask
+from otx.algorithms.classification.adapters.mmcls.utils import patch_evaluation
+from otx.algorithms.common.tasks.nncf_task import NNCFBaseTask
 from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.metrics import (
     CurveMetric,
     LineChartInfo,
     LineMetricsGroup,
     MetricsGroup,
     Performance,
     ScoreMetric,
 )
 from otx.api.entities.model import ModelEntity  # ModelStatus
 from otx.api.entities.optimization_parameters import OptimizationParameters
-
-from .inference import ClassificationInferenceTask
+from otx.api.entities.task_environment import TaskEnvironment
 
 logger = get_logger()
 
 
-class ClassificationNNCFTask(NNCFBaseTask, ClassificationInferenceTask):  # pylint: disable=too-many-ancestors
+class ClassificationNNCFTask(NNCFBaseTask, MMClassificationTask):  # pylint: disable=too-many-ancestors
     """ClassificationNNCFTask."""
 
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__()
+        super(NNCFBaseTask, self).__init__(task_environment, output_path)
+        self._set_attributes_by_hyperparams()
+
+    def _init_task(self, export: bool = False):  # noqa
+        super(NNCFBaseTask, self)._init_task(export)
+        # Patch Evaluation Metric for nncf_config
+        options_for_patch_evaluation = {"task": "normal"}
+        if self._multilabel:
+            options_for_patch_evaluation["task"] = "multilabel"
+        elif self._hierarchical:
+            options_for_patch_evaluation["task"] = "hierarchical"
+        patch_evaluation(self._recipe_cfg, **options_for_patch_evaluation)
+        self._prepare_optimize(export)
+
+    def _prepare_optimize(self, export=False):
+        super()._prepare_optimize()
 
-        export = options.get("export", False)
-        options["model_builder"] = partial(
+        self.model_builder = partial(
             self.model_builder,
             nncf_model_builder=build_nncf_classifier,
             return_compression_ctrl=False,
             is_export=export,
         )
 
     def _optimize(
         self,
         dataset: DatasetEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
-        results = self._run_task(
-            "ClsTrainer",
-            mode="train",
-            dataset=dataset,
-            parameters=optimization_parameters,
-        )
+        results = self._train_model(dataset)
+
         return results
 
     def _optimize_post_hook(
         self,
         dataset: DatasetEntity,
         output_model: ModelEntity,
     ):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tasks/openvino.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/openvino/task.py`

 * *Files 13% similar despite different names*

```diff
@@ -35,14 +35,15 @@
 from otx.algorithms.classification.configs import ClassificationConfig
 from otx.algorithms.classification.utils import (
     get_cls_deploy_config,
     get_cls_inferencer_configuration,
 )
 from otx.api.entities.annotation import AnnotationSceneEntity
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import (
     InferenceParameters,
     default_progress_callback,
 )
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.metadata import FloatMetadata, FloatType
 from otx.api.entities.model import (
@@ -68,18 +69,14 @@
 from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
 from otx.api.usecases.tasks.interfaces.explain_interface import IExplainTask
 from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
 from otx.api.usecases.tasks.interfaces.optimization_interface import (
     IOptimizationTask,
     OptimizationType,
 )
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 from otx.api.utils.dataset_utils import add_saliency_maps_to_dataset_item
 
 try:
     from openvino.model_zoo.model_api.adapters import OpenvinoAdapter, create_core
     from openvino.model_zoo.model_api.models import Model
 except ImportError:
     warnings.warn("ModelAPI was not found.")
@@ -87,25 +84,24 @@
 logger = logging.getLogger(__name__)
 
 
 # TODO: refactoring to Sphinx style.
 class ClassificationOpenVINOInferencer(BaseInferencer):
     """ClassificationOpenVINOInferencer class in OpenVINO task."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         hparams: ClassificationConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
         device: str = "CPU",
         num_requests: int = 1,
     ):  # pylint: disable=unused-argument
-        """Inferencer implementation for OTXDetection using OpenVINO backend.
+        """Inferencer implementation for OTXClassification using OpenVINO backend.
 
         :param model: Path to model to load, `.xml`, `.bin` or `.onnx` file.
         :param hparams: Hyper parameters that the model should use.
         :param num_requests: Maximum number of requests that the inferencer can make.
             Good value is the number of available cores. Defaults to 1.
         :param device: Device to run inference on, such as CPU, GPU or MYRIAD. Defaults to "CPU".
         """
@@ -115,57 +111,51 @@
             create_core(), model_file, weight_file, device=device, max_num_requests=num_requests
         )
         self.configuration = get_cls_inferencer_configuration(self.label_schema)
         self.model = Model.create_model("otx_classification", model_adapter, self.configuration, preload=True)
 
         self.converter = ClassificationToAnnotationConverter(self.label_schema)
 
-    @check_input_parameters_type()
     def pre_process(self, image: np.ndarray) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
         """Pre-process function of OpenVINO Classification Inferencer."""
 
         return self.model.preprocess(image)
 
-    @check_input_parameters_type()
     def post_process(
         self, prediction: Dict[str, np.ndarray], metadata: Dict[str, Any]
     ) -> Optional[AnnotationSceneEntity]:
         """Post-process function of OpenVINO Classification Inferencer."""
 
         classification = self.model.postprocess(prediction, metadata)
         return self.converter.convert_to_annotation(classification, metadata)
 
-    @check_input_parameters_type()
     def predict(self, image: np.ndarray) -> Tuple[AnnotationSceneEntity, np.ndarray, np.ndarray, np.ndarray, Any]:
         """Predict function of OpenVINO Classification Inferencer."""
 
         image, metadata = self.pre_process(image)
         raw_predictions = self.forward(image)
         predictions = self.post_process(raw_predictions, metadata)
         probs, actmap, repr_vectors, act_score = self.model.postprocess_aux_outputs(raw_predictions, metadata)
 
         return predictions, probs, actmap, repr_vectors, act_score
 
-    @check_input_parameters_type()
     def forward(self, image: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
         """Forward function of OpenVINO Classification Inferencer."""
 
         return self.model.infer_sync(image)
 
 
 class OTXOpenVinoDataLoader(DataLoader):
     """DataLoader implementation for ClassificationOpenVINOTask."""
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def __init__(self, dataset: DatasetEntity, inferencer: BaseInferencer):
         super().__init__(config=None)
         self.dataset = dataset
         self.inferencer = inferencer
 
-    @check_input_parameters_type()
     def __getitem__(self, index: int):
         """Get item from dataset."""
 
         image = self.dataset[index].numpy
         annotation = self.dataset[index].annotation_scene
         inputs, metadata = self.inferencer.pre_process(image)
 
@@ -176,15 +166,14 @@
 
         return len(self.dataset)
 
 
 class ClassificationOpenVINOTask(IDeploymentTask, IInferenceTask, IEvaluationTask, IExplainTask, IOptimizationTask):
     """Task implementation for OTXClassification using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(self, task_environment: TaskEnvironment):
         self.task_environment = task_environment
         self.hparams = self.task_environment.get_hyper_parameters(ClassificationConfig)
         self.model = self.task_environment.model
         self.inferencer = self.load_inferencer()
 
     def load_inferencer(self) -> ClassificationOpenVINOInferencer:
@@ -197,15 +186,14 @@
             self.hparams,
             self.task_environment.label_schema,
             self.model.get_data("openvino.xml"),
             self.model.get_data("openvino.bin"),
         )
 
     # pylint: disable-msg=too-many-locals
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def infer(
         self, dataset: DatasetEntity, inference_parameters: Optional[InferenceParameters] = None
     ) -> DatasetEntity:
         """Infer function of ClassificationOpenVINOTask."""
 
         update_progress_callback = default_progress_callback
         dump_features = False
@@ -246,58 +234,61 @@
                     warnings.warn(
                         "Could not find Feature Vector and Saliency Map in OpenVINO output. "
                         "Please rerun OpenVINO export or retrain the model."
                     )
             update_progress_callback(int(i / dataset_size * 100))
         return dataset
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def explain(
         self,
         dataset: DatasetEntity,
-        explain_parameters: Optional[InferenceParameters] = None,
+        explain_parameters: Optional[ExplainParameters] = None,
     ) -> DatasetEntity:
         """Explain function of ClassificationOpenVINOTask."""
 
         update_progress_callback = default_progress_callback
         process_saliency_maps = False
         explain_predicted_classes = True
         if explain_parameters is not None:
             update_progress_callback = explain_parameters.update_progress  # type: ignore
             process_saliency_maps = explain_parameters.process_saliency_maps
             explain_predicted_classes = explain_parameters.explain_predicted_classes
 
         dataset_size = len(dataset)
         for i, dataset_item in enumerate(dataset, 1):
             predicted_scene, _, saliency_map, _, _ = self.inferencer.predict(dataset_item.numpy)
+            if saliency_map is None:
+                raise RuntimeError(
+                    "There is no Saliency Map in OpenVINO IR model output. "
+                    "Please export model to OpenVINO IR with dump_features"
+                )
+
             item_labels = predicted_scene.annotations[0].get_labels()
             dataset_item.append_labels(item_labels)
             add_saliency_maps_to_dataset_item(
                 dataset_item=dataset_item,
                 saliency_map=saliency_map,
                 model=self.model,
                 labels=self.task_environment.get_labels(),
                 predicted_scored_labels=item_labels,
                 explain_predicted_classes=explain_predicted_classes,
                 process_saliency_maps=process_saliency_maps,
             )
             update_progress_callback(int(i / dataset_size * 100))
         return dataset
 
-    @check_input_parameters_type()
     def evaluate(self, output_resultset: ResultSetEntity, evaluation_metric: Optional[str] = None):
         """Evaluate function of ClassificationOpenVINOTask."""
 
         if evaluation_metric is not None:
             logger.warning(
                 f"Requested to use {evaluation_metric} metric," "but parameter is ignored. Use accuracy instead."
             )
         output_resultset.performance = MetricsHelper.compute_accuracy(output_resultset).get_performance()
 
-    @check_input_parameters_type()
     def deploy(self, output_model: ModelEntity) -> None:
         """Deploy function of ClassificationOpenVINOTask."""
 
         logger.info("Deploying the model")
 
         work_dir = os.path.dirname(demo.__file__)
         parameters = get_cls_deploy_config(self.task_environment.label_schema, self.inferencer.configuration)
@@ -322,15 +313,14 @@
             arch.write(os.path.join(work_dir, "requirements.txt"), os.path.join("python", "requirements.txt"))
             arch.write(os.path.join(work_dir, "LICENSE"), os.path.join("python", "LICENSE"))
             arch.write(os.path.join(work_dir, "README.md"), os.path.join("python", "README.md"))
             arch.write(os.path.join(work_dir, "demo.py"), os.path.join("python", "demo.py"))
         output_model.exportable_code = zip_buffer.getvalue()
         logger.info("Deploying completed")
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def optimize(
         self,
         optimization_type: OptimizationType,
         dataset: DatasetEntity,
         output_model: ModelEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):  # pylint: disable=too-many-locals
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tasks/train.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_ssd_neck.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,193 +1,212 @@
-"""Train Task of OTX Classification."""
-
+"""MMOVSSDNeck class for OMZ models."""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
-# pylint: disable=invalid-name
-
-import io
-from typing import List, Optional
+from typing import Dict, List, Optional, Union
 
+import openvino.runtime as ov
 import torch
-from mmcv.utils import ConfigDict
-
-from otx.algorithms.classification.configs import ClassificationConfig
-from otx.algorithms.common.utils.callback import TrainingProgressCallback
-from otx.algorithms.common.utils.data import get_dataset
-from otx.algorithms.common.utils.logger import get_logger
-from otx.api.configuration import cfg_helper
-from otx.api.configuration.helper.utils import ids_to_strings
-from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.metrics import (
-    CurveMetric,
-    LineChartInfo,
-    LineMetricsGroup,
-    MetricsGroup,
-    Performance,
-    ScoreMetric,
-)
-from otx.api.entities.model import ModelEntity  # ModelStatus
-from otx.api.entities.subset import Subset
-from otx.api.entities.train_parameters import TrainParameters
-from otx.api.entities.train_parameters import (
-    default_progress_callback as train_default_progress_callback,
-)
-from otx.api.serialization.label_mapper import label_schema_to_bytes
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
-
-from .inference import ClassificationInferenceTask
-
-logger = get_logger()
-
-TASK_CONFIG = ClassificationConfig
-
-
-# pylint: disable= too-many-ancestors
-class ClassificationTrainTask(ClassificationInferenceTask):
-    """Train Task Implementation of OTX Classification."""
-
-    @check_input_parameters_type()
-    def save_model(self, output_model: ModelEntity):
-        """Save best model weights in ClassificationTrainTask."""
-        logger.info("called save_model")
-        buffer = io.BytesIO()
-        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
-        labels = {label.name: label.color.rgb_tuple for label in self._labels}
-        model_ckpt = torch.load(self._model_ckpt)
-        modelinfo = {
-            "model": model_ckpt,
-            "config": hyperparams_str,
-            "labels": labels,
-            "VERSION": 1,
-        }
-
-        torch.save(modelinfo, buffer)
-        output_model.set_data("weights.pth", buffer.getvalue())
-        output_model.set_data(
-            "label_schema.json",
-            label_schema_to_bytes(self._task_environment.label_schema),
-        )
-        output_model.precision = self._precision
+from mmcv.cnn import ConvModule, DepthwiseSeparableConvModule
+from mmcv.runner import BaseModule
+from mmdet.models.builder import NECKS
+from torch import nn
+
+from otx.core.ov.models.mmov_model import MMOVModel
+
+# pylint: disable=too-many-arguments, too-many-locals
+
+
+# FIXME: get rid of defined SSDNeck as this is a workaround for forked/deprecated mmdet
+class SSDNeck(BaseModule):
+    """Extra layers of SSD backbone to generate multi-scale feature maps.
+
+    Args:
+        in_channels (Sequence[int]): Number of input channels per scale.
+        out_channels (Sequence[int]): Number of output channels per scale.
+        level_strides (Sequence[int]): Stride of 3x3 conv per level.
+        level_paddings (Sequence[int]): Padding size of 3x3 conv per level.
+        l2_norm_scale (float|None): L2 normalization layer init scale.
+            If None, not use L2 normalization on the first input feature.
+        last_kernel_size (int): Kernel size of the last conv layer.
+            Default: 3.
+        use_depthwise (bool): Whether to use DepthwiseSeparableConv.
+            Default: False.
+        conv_cfg (dict): Config dict for convolution layer. Default: None.
+        norm_cfg (dict): Dictionary to construct and config norm layer.
+            Default: None.
+        act_cfg (dict): Config dict for activation layer.
+            Default: dict(type='ReLU').
+        init_cfg (dict or list[dict], optional): Initialization config dict.
+    """
 
-    def cancel_training(self):
-        """Cancel training function in ClassificationTrainTask.
-
-        Sends a cancel training signal to gracefully stop the optimizer.
-        The signal consists of creating a '.stop_training' file in the current work_dir.
-        The runner checks for this file periodically.
-        The stopping mechanism allows stopping after each iteration, but validation will still be carried out.
-        Stopping will therefore take some time.
+    def __init__(
+        self,
+        in_channels,
+        out_channels,
+        level_strides,
+        level_paddings,
+        l2_norm_scale=20.0,
+        last_kernel_size=3,
+        use_depthwise=False,
+        conv_cfg=None,
+        norm_cfg=None,
+        act_cfg=None,
+        init_cfg=None,
+    ):
+        if init_cfg is None:
+            init_cfg = [
+                dict(type="Xavier", distribution="uniform", layer="Conv2d"),
+                dict(type="Constant", val=1, layer="BatchNorm2d"),
+            ]
+        super().__init__(init_cfg)
+        assert len(out_channels) > len(in_channels)
+        assert len(out_channels) - len(in_channels) == len(level_strides)
+        assert len(level_strides) == len(level_paddings)
+        assert in_channels == out_channels[: len(in_channels)]
+
+        act_cfg = dict(type="ReLU") if act_cfg is None else act_cfg
+
+        if l2_norm_scale:
+            self.l2_norm = L2Norm(in_channels[0], l2_norm_scale)
+            self.init_cfg += [dict(type="Constant", val=self.l2_norm.scale, override=dict(name="l2_norm"))]
+
+        self.extra_layers = nn.ModuleList()
+        extra_layer_channels = out_channels[len(in_channels) :]
+        second_conv = DepthwiseSeparableConvModule if use_depthwise else ConvModule
+
+        for i, (out_channel, stride, padding) in enumerate(zip(extra_layer_channels, level_strides, level_paddings)):
+            kernel_size = last_kernel_size if i == len(extra_layer_channels) - 1 else 3
+            per_lvl_convs = nn.Sequential(
+                ConvModule(
+                    out_channels[len(in_channels) - 1 + i],
+                    out_channel // 2,
+                    1,
+                    conv_cfg=conv_cfg,
+                    norm_cfg=norm_cfg,
+                    act_cfg=act_cfg,
+                ),
+                second_conv(
+                    out_channel // 2,
+                    out_channel,
+                    kernel_size,
+                    stride=stride,
+                    padding=padding,
+                    conv_cfg=conv_cfg,
+                    norm_cfg=norm_cfg,
+                    act_cfg=act_cfg,
+                ),
+            )
+            self.extra_layers.append(per_lvl_convs)
+
+    def forward(self, inputs):
+        """Forward function."""
+        outs = list(inputs)
+        if hasattr(self, "l2_norm"):
+            outs[0] = self.l2_norm(outs[0])
+
+        feat = outs[-1]
+        for layer in self.extra_layers:
+            feat = layer(feat)
+            outs.append(feat)
+        return tuple(outs)
+
+
+class L2Norm(nn.Module):
+    """L2 normalization class."""
+
+    def __init__(self, n_dims, scale=20.0, eps=1e-10):
+        """L2 normalization layer.
+
+        Args:
+            n_dims (int): Number of dimensions to be normalized
+            scale (float, optional): Defaults to 20..
+            eps (float, optional): Used to avoid division by zero.
+                Defaults to 1e-10.
         """
-        self._should_stop = True
-        logger.info("Cancel training requested.")
-        if self.cancel_interface is not None:
-            self.cancel_interface.cancel()
-        else:
-            logger.info("but training was not started yet. reserved it to cancel")
-            self.reserved_cancel = True
+        super().__init__()
+        self.n_dims = n_dims
+        self.weight = nn.Parameter(torch.Tensor(self.n_dims))
+        self.eps = eps
+        self.scale = scale
+
+    def forward(self, x):
+        """Forward function."""
+        # normalization layer convert to FP32 in FP16 training
+        x_float = x.float()
+        norm = x_float.pow(2).sum(1, keepdim=True).sqrt() + self.eps
+        return (self.weight[None, :, None, None].float().expand_as(x_float) * x_float / norm).type_as(x)
+
+
+@NECKS.register_module()
+class MMOVSSDNeck(SSDNeck):
+    """MMOVSSDNeck class for OMZ models."""
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
-    def train(
+    def __init__(
         self,
-        dataset: DatasetEntity,
-        output_model: ModelEntity,
-        train_parameters: Optional[TrainParameters] = None,
+        model_path_or_model: Union[str, ov.Model],
+        weight_path: Optional[str] = None,
+        inputs: Optional[Union[Dict[str, Union[str, List[str]]], List[str], str]] = None,
+        outputs: Optional[Union[Dict[str, Union[str, List[str]]], List[str], str]] = None,
+        init_weight: bool = False,
+        verify_shape: bool = True,
     ):
-        """Train function in ClassificationTrainTask."""
-        logger.info("train()")
-        # Check for stop signal between pre-eval and training.
-        # If training is cancelled at this point,
-        if self._should_stop:
-            logger.info("Training cancelled.")
-            self._should_stop = False
-            self._is_training = False
-            return
-
-        # Set OTX LoggerHook & Time Monitor
-        update_progress_callback = train_default_progress_callback
-        if train_parameters is not None:
-            update_progress_callback = train_parameters.update_progress  # type: ignore
-        self._time_monitor = TrainingProgressCallback(update_progress_callback)
-
-        stage_module = "ClsTrainer"
-        self._data_cfg = self._init_train_data_cfg(dataset)
-        self._is_training = True
-        results = self._run_task(stage_module, mode="train", dataset=dataset, parameters=train_parameters)
-
-        # Check for stop signal between pre-eval and training.
-        # If training is cancelled at this point,
-        if self._should_stop:
-            logger.info("Training cancelled.")
-            self._should_stop = False
-            self._is_training = False
-            return
-
-        # get output model
-        model_ckpt = results.get("final_ckpt")
-        if model_ckpt is None:
-            logger.error("cannot find final checkpoint from the results.")
-            return
-        # update checkpoint to the newly trained model
-        self._model_ckpt = model_ckpt
-
-        # compose performance statistics
-        training_metrics, final_acc = self._generate_training_metrics_group(self._learning_curves)
-        # save resulting model
-        self.save_model(output_model)
-        performance = Performance(
-            score=ScoreMetric(value=final_acc, name="accuracy"),
-            dashboard_metrics=training_metrics,
+        # dummy
+        in_channels = (512, 1024)
+        out_channels = (512, 1024, 512, 256, 256, 256)
+        level_strides = (2, 2, 1, 1)
+        level_paddings = (1, 1, 0, 0)
+        l2_norm_scale = None
+        super().__init__(
+            in_channels=in_channels,
+            out_channels=out_channels,
+            level_strides=level_strides,
+            level_paddings=level_paddings,
+            l2_norm_scale=l2_norm_scale,
         )
-        logger.info(f"Final model performance: {str(performance)}")
-        output_model.performance = performance
-        self._is_training = False
-        logger.info("train done.")
-
-    def _init_train_data_cfg(self, dataset: DatasetEntity):
-        logger.info("init data cfg.")
-        data_cfg = ConfigDict(data=ConfigDict())
-
-        for cfg_key, subset in zip(
-            ["train", "val", "unlabeled"],
-            [Subset.TRAINING, Subset.VALIDATION, Subset.UNLABELED],
-        ):
-            subset = get_dataset(dataset, subset)
-            if subset:
-                data_cfg.data[cfg_key] = ConfigDict(
-                    otx_dataset=subset,
-                    labels=self._labels,
-                )
-
-        return data_cfg
-
-    def _generate_training_metrics_group(self, learning_curves):
-        """Parses the classification logs to get metrics from the latest training run.
 
-        :return output List[MetricsGroup]
-        """
-        output: List[MetricsGroup] = []
+        self._model_path_or_model = model_path_or_model
+        self._weight_path = weight_path
+        self._init_weight = init_weight
+
+        self.extra_layers = torch.nn.ModuleList()
+
+        # TODO: Need to fix what exactly the types of inputs and outputs are.
+        if not isinstance(inputs, dict) or not isinstance(outputs, dict):
+            raise ValueError("The type of inputs & outputs is invalid.")
+        for input_e, output_e in zip(inputs["extra_layers"], outputs["extra_layers"]):
+            if input_e and output_e:
+                self.extra_layers.append(
+                    MMOVModel(
+                        model_path_or_model,
+                        weight_path,
+                        inputs=input_e,
+                        outputs=output_e,
+                        remove_normalize=False,
+                        merge_bn=False,
+                        paired_bn=False,
+                        init_weight=init_weight,
+                        verify_shape=verify_shape,
+                    )
+                )
+            else:
+                self.extra_layers.append(torch.nn.Identity())
 
-        if self._multilabel:
-            metric_key = "val/accuracy-mlc"
-        elif self._hierarchical:
-            metric_key = "val/MHAcc"
-        else:
-            metric_key = "val/accuracy_top-1"
-
-        # Learning curves
-        best_acc = -1
-        if learning_curves is None:
-            return output
-
-        for key, curve in learning_curves.items():
-            metric_curve = CurveMetric(xs=curve.x, ys=curve.y, name=key)
-            if key == metric_key:
-                best_acc = max(curve.y)
-            visualization_info = LineChartInfo(name=key, x_axis_label="Timestamp", y_axis_label=key)
-            output.append(LineMetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
+        if "l2_norm" in inputs and "l2_norm" in outputs:
+            for input_l2, output_l2 in zip(inputs["l2_norm"], outputs["l2_norm"]):
+                self.l2_norm = MMOVModel(
+                    model_path_or_model,
+                    weight_path,
+                    inputs=input_l2,
+                    outputs=output_l2,
+                    remove_normalize=False,
+                    merge_bn=False,
+                    paired_bn=False,
+                    init_weight=init_weight,
+                    verify_shape=verify_shape,
+                )
 
-        return output, best_acc
+    def init_weights(self, pretrained=None):  # pylint: disable=unused-argument
+        """Initial weights of MMOVSSDNeck."""
+        # TODO
+        return
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tools/__init__.py` & `otx-1.2.0rc1/otx/algorithms/classification/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/tools/classification_sample.py` & `otx-1.2.0rc1/otx/algorithms/classification/tools/classification_sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/utils/cls_utils.py` & `otx-1.2.0rc1/otx/algorithms/classification/utils/cls_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,18 +17,16 @@
 # pylint: disable=too-many-nested-blocks, invalid-name
 
 from operator import itemgetter
 from typing import Any, Dict
 
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.serialization.label_mapper import LabelSchemaMapper
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 
-@check_input_parameters_type()
 def get_multihead_class_info(label_schema: LabelSchemaEntity):  # pylint: disable=too-many-locals
     """Get multihead info by label schema."""
     all_groups = label_schema.get_groups(include_empty=False)
     all_groups_str = []
     for g in all_groups:
         group_labels_str = [lbl.name for lbl in g.labels]
         all_groups_str.append(group_labels_str)
@@ -93,15 +91,15 @@
     parameters["model_parameters"]["labels"] = LabelSchemaMapper.forward(label_schema)
     return parameters
 
 
 def get_cls_model_api_configuration(label_schema: LabelSchemaEntity, inference_config: Dict[str, Any]):
     """Get ModelAPI config."""
     mapi_config = {}
-    mapi_config[("model_info", "model_type")] = "classification"
+    mapi_config[("model_info", "model_type")] = "Classification"
     mapi_config[("model_info", "confidence_threshold")] = str(inference_config["confidence_threshold"])
     mapi_config[("model_info", "multilabel")] = str(inference_config["multilabel"])
 
     all_labels = ""
     for lbl in label_schema.get_labels(include_empty=False):
         all_labels += lbl.name.replace(" ", "_") + " "
     all_labels = all_labels.strip()
```

### Comparing `otx-1.1.2rc1/otx/algorithms/classification/utils/convert_coco_to_multilabel.py` & `otx-1.2.0rc1/otx/algorithms/classification/utils/convert_coco_to_multilabel.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,43 +1,43 @@
 """Convert dataset: Public dataset (COCO) --> Multi-label dataset (Datumaro format).
 
 this script contains a lot of hard-coding to create .json file that Datumaro can consume.
 """
 
-import argparse
-import json
-
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
+
+import argparse
+import json
 from typing import Any, Dict, List
 
 from otx.algorithms.detection.utils.data import CocoDataset
 
-multilabel_ann_format = {
+multilabel_ann_format: Dict[str, Any] = {
     "info": {},
     "categories": {
         "label": {
             "label_groups": [],
             "labels": [],
             "attributes": [],
         }
     },
     "items": [],
-}  # type: Dict[str, Any]
+}
 
 
 def coco_to_datumaro_multilabel(ann_file_path: str, data_root_dir: str, output: str, test_mode: bool = False):
     """Convert coco dataset to datumaro multi-label format.
 
     Args:
         ann_file_path (str): The path of annotation file (COCO)
@@ -54,15 +54,15 @@
         test_mode=test_mode,
         with_mask=False,
     )
 
     # Fill the categories part
     # For the multi-label classification,
     # Datumaro will make label_groups and labels
-    overall_classes = coco_dataset.get_classes()  # type: List
+    overall_classes: List = coco_dataset.get_classes()
     for class_name in overall_classes:
         multilabel_ann_format["categories"]["label"]["label_groups"].append(
             {"name": str(class_name), "group_type": "exclusive", "labels": [str(class_name)]}
         )
 
         multilabel_ann_format["categories"]["label"]["labels"].append(
             {"name": class_name, "parent": "", "attributes": []}
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_18.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_18.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_s.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_s.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_x.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/configs/backbones/lite_hrnet_x.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -31,34 +31,35 @@
     StopLossNanTrainingHook,
 )
 from .eval_hook import CustomEvalHook, DistCustomEvalHook
 from .force_train_hook import ForceTrainModeHook
 from .fp16_sam_optimizer_hook import Fp16SAMOptimizerHook
 from .ib_loss_hook import IBLossHook
 from .logger_hook import LoggerReplaceHook, OTXLoggerHook
+from .lr_updater_hook import CustomstepLrUpdaterHook
 from .model_ema_v2_hook import ModelEmaV2Hook
 from .no_bias_decay_hook import NoBiasDecayHook
 from .progress_hook import OTXProgressHook
 from .recording_forward_hook import (
     ActivationMapHook,
     BaseRecordingForwardHook,
     EigenCamHook,
     FeatureVectorHook,
 )
 from .sam_optimizer_hook import SAMOptimizerHook
 from .semisl_cls_hook import SemiSLClsHook
 from .task_adapt_hook import TaskAdaptHook
 from .two_crop_transform_hook import TwoCropTransformHook
 from .unbiased_teacher_hook import UnbiasedTeacherHook
-from .workflow_hook import WorkflowHook
 
 __all__ = [
     "AdaptiveTrainSchedulingHook",
     "CancelInterfaceHook",
     "CancelTrainingHook",
+    "CustomstepLrUpdaterHook",
     "CheckpointHookWithValResults",
     "EnsureCorrectBestCheckpointHook",
     "ComposedDataLoadersHook",
     "CustomEvalHook",
     "DistCustomEvalHook",
     "EarlyStoppingHook",
     "LazyEarlyStoppingHook",
@@ -81,9 +82,8 @@
     "FeatureVectorHook",
     "SAMOptimizerHook",
     "SaveInitialWeightHook",
     "SemiSLClsHook",
     "TaskAdaptHook",
     "TwoCropTransformHook",
     "UnbiasedTeacherHook",
-    "WorkflowHook",
 ]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/adaptive_training_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/adaptive_training_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -92,17 +92,18 @@
                     logger.info(f"Update EvalHook interval: {hook.interval} -> {adaptive_interval}")
                     hook.interval = adaptive_interval
                 elif isinstance(hook, LrUpdaterHook):
                     patience = max(
                         math.ceil((self.base_lr_patience / adaptive_interval)),
                         self.min_lr_patience,
                     )
-                    logger.info(f"Update LrUpdaterHook patience: {hook.patience} -> {patience}")
-                    hook.interval = adaptive_interval
-                    hook.patience = patience
+                    if hasattr(hook, "interval") and hasattr(hook, "patience"):
+                        hook.interval = adaptive_interval
+                        hook.patience = patience
+                        logger.info(f"Update LrUpdaterHook patience: {hook.patience} -> {patience}")
                 elif isinstance(hook, EarlyStoppingHook):
                     patience = max(
                         math.ceil((self.base_es_patience / adaptive_interval)),
                         self.min_es_patience,
                     )
                     logger.info(f"Update EarlyStoppingHook patience: {hook.patience} -> {patience}")
                     hook.start = adaptive_interval
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/cancel_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/cancel_hook.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,25 +7,23 @@
 import os
 from typing import Callable
 
 from mmcv.runner import BaseRunner, EpochBasedRunner
 from mmcv.runner.hooks import HOOKS, Hook
 
 from otx.algorithms.common.utils.logger import get_logger
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 
 # pylint: disable=too-many-instance-attributes, protected-access, too-many-arguments, unused-argument
 @HOOKS.register_module()
 class CancelTrainingHook(Hook):
     """CancelTrainingHook for Training Stopping."""
 
-    @check_input_parameters_type()
     def __init__(self, interval: int = 5):
         """Periodically check whether whether a stop signal is sent to the runner during model training.
 
         Every 'check_interval' iterations, the work_dir for the runner is checked to see if a file '.stop_training'
         is present. If it is, training is stopped.
 
         :param interval: Period for checking for stop signal, given in iterations.
@@ -41,15 +39,14 @@
         if os.path.exists(stop_filepath):
             if isinstance(runner, EpochBasedRunner):
                 epoch = runner.epoch
                 runner._max_epochs = epoch  # Force runner to stop by pretending it has reached it's max_epoch
             runner.should_stop = True  # Set this flag to true to stop the current training epoch
             os.remove(stop_filepath)
 
-    @check_input_parameters_type()
     def after_train_iter(self, runner: BaseRunner):
         """Log after_train_iter for CancelTrainingHook."""
         if not self.every_n_iters(runner, self.interval):
             return
         self._check_for_stop_signal(runner)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/checkpoint_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/checkpoint_hook.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,16 +7,14 @@
 from pathlib import Path
 from typing import Optional
 
 from mmcv.runner import BaseRunner
 from mmcv.runner.dist_utils import allreduce_params, master_only
 from mmcv.runner.hooks.hook import HOOKS, Hook
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 
 @HOOKS.register_module()
 class CheckpointHookWithValResults(Hook):  # pylint: disable=too-many-instance-attributes
     """Save checkpoints periodically.
 
     Args:
         interval (int): The saving period. If ``by_epoch=True``, interval
@@ -149,15 +147,14 @@
 class EnsureCorrectBestCheckpointHook(Hook):
     """EnsureCorrectBestCheckpointHook.
 
     This hook makes sure that the 'best_mAP' checkpoint points properly to the best model, even if the best model is
     created in the last epoch.
     """
 
-    @check_input_parameters_type()
     def after_run(self, runner: BaseRunner):
         """Called after train epoch hooks."""
         runner.call_hook("after_train_epoch")
 
 
 @HOOKS.register_module()
 class SaveInitialWeightHook(Hook):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/composed_dataloaders_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/composed_dataloaders_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     Especially used for semi-supervised learning to aggregate a unlabeled dataloader and a labeled dataloader.
     """
 
     def __init__(
         self,
         data_loaders: Union[Sequence[DataLoader], DataLoader],
     ):
-        self.data_loaders = []  # type: List[DataLoader]
+        self.data_loaders: List[DataLoader] = []
         self.composed_loader = None
 
         self.add_dataloaders(data_loaders)
 
     def add_dataloaders(self, data_loaders: Union[Sequence[DataLoader], DataLoader]):
         """Create data_loaders to be added into composed dataloader."""
         if isinstance(data_loaders, DataLoader):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/custom_model_ema_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/custom_model_ema_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/dual_model_ema_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/dual_model_ema_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/early_stopping_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/early_stopping_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,14 @@
 from typing import List, Optional
 
 from mmcv.runner import BaseRunner, LrUpdaterHook
 from mmcv.runner.hooks import HOOKS, Hook
 from mmcv.utils import print_log
 
 from otx.algorithms.common.utils.logger import get_logger
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 # pylint: disable=too-many-arguments, too-many-instance-attributes
 
 
 @HOOKS.register_module()
@@ -46,15 +45,14 @@
     """
 
     rule_map = {"greater": lambda x, y: x > y, "less": lambda x, y: x < y}
     init_value_map = {"greater": -inf, "less": inf}
     greater_keys = ["acc", "top", "AR@", "auc", "precision", "mAP", "mDice", "mIoU", "mAcc", "aAcc", "MHAcc"]
     less_keys = ["loss"]
 
-    @check_input_parameters_type()
     def __init__(
         self,
         interval: int,
         metric: str = "bbox_mAP",
         rule: Optional[str] = None,
         patience: int = 5,
         iteration_patience: int = 500,
@@ -105,33 +103,30 @@
                 raise ValueError(
                     f"Cannot infer the rule for key " f"{key_indicator}, thus a specific rule " f"must be specified."
                 )
         self.rule = rule
         self.key_indicator = key_indicator
         self.compare_func = self.rule_map[self.rule]
 
-    @check_input_parameters_type()
     def before_run(self, runner: BaseRunner):
         """Called before_run in EarlyStoppingHook."""
         if runner.max_epochs is None:
             self.by_epoch = False
         for hook in runner.hooks:
             if isinstance(hook, LrUpdaterHook):
                 self.warmup_iters = hook.warmup_iters
                 break
         if getattr(self, "warmup_iters", None) is None:
             raise ValueError("LrUpdaterHook must be registered to runner.")
 
-    @check_input_parameters_type()
     def after_train_iter(self, runner: BaseRunner):
         """Called after every training iter to evaluate the results."""
         if not self.by_epoch:
             self._do_check_stopping(runner)
 
-    @check_input_parameters_type()
     def after_train_epoch(self, runner: BaseRunner):
         """Called after every training epoch to evaluate the results."""
         if self.by_epoch:
             self._do_check_stopping(runner)
 
     def _do_check_stopping(self, runner):
         """Called _do_check_stopping in EarlyStoppingHook."""
@@ -205,17 +200,16 @@
 
         if self.start is None:
             if not check_time(runner, self.interval):
                 # No evaluation during the interval.
                 return False
         elif (current + 1) < self.start:
             return False
-        else:
-            if (current + 1 - self.start) % self.interval:
-                return False
+        elif (current + 1 - self.start) % self.interval:
+            return False
         return True
 
 
 @HOOKS.register_module(force=True)
 class ReduceLROnPlateauLrUpdaterHook(LrUpdaterHook):
     """Reduce learning rate when a metric has stopped improving.
 
@@ -245,15 +239,14 @@
     """
 
     rule_map = {"greater": lambda x, y: x > y, "less": lambda x, y: x < y}
     init_value_map = {"greater": -inf, "less": inf}
     greater_keys = ["acc", "top", "AR@", "auc", "precision", "mAP", "mDice", "mIoU", "mAcc", "aAcc", "MHAcc"]
     less_keys = ["loss"]
 
-    @check_input_parameters_type()
     def __init__(
         self,
         min_lr: float,
         interval: int,
         metric: str = "bbox_mAP",
         rule: Optional[str] = None,
         factor: float = 0.1,
@@ -267,15 +260,15 @@
         self.factor = factor
         self.patience = patience
         self.iteration_patience = iteration_patience
         self.metric = metric
         self.bad_count = 0
         self.last_iter = 0
         self.current_lr = -1.0
-        self.base_lr = []  # type: List
+        self.base_lr: List[float] = []
         self._init_rule(rule, metric)
         self.best_score = self.init_value_map[self.rule]
 
     def _init_rule(self, rule, key_indicator):
         """Initialize rule, key_indicator, comparison_func, and best score.
 
         Here is the rule to determine which rule is used for key indicator
@@ -319,15 +312,14 @@
         """Check whether current epoch is a next epoch after multiples of interval."""
         return runner.epoch % interval == 0 if interval > 0 and runner.epoch != 0 else False
 
     def after_each_n_iters(self, runner: BaseRunner, interval: int) -> bool:
         """Check whether current iter is a next iter after multiples of interval."""
         return runner.iter % interval == 0 if interval > 0 and runner.iter != 0 else False
 
-    @check_input_parameters_type()
     def get_lr(self, runner: BaseRunner, base_lr: float):
         """Called get_lr in ReduceLROnPlateauLrUpdaterHook."""
         if self.current_lr < 0:
             self.current_lr = base_lr
 
         if not self._is_check_timing(runner):
             return self.current_lr
@@ -365,15 +357,14 @@
             print_log(
                 f"\nDrop LR from: {self.current_lr}, to: " f"{max(self.current_lr * self.factor, self.min_lr)}",
                 logger=runner.logger,
             )
             self.current_lr = max(self.current_lr * self.factor, self.min_lr)
         return self.current_lr
 
-    @check_input_parameters_type()
     def before_run(self, runner: BaseRunner):
         """Called before_run in ReduceLROnPlateauLrUpdaterHook."""
         # TODO: remove overloaded method after fixing the issue
         #  https://github.com/open-mmlab/mmdetection/issues/6572
         for group in runner.optimizer.param_groups:
             group.setdefault("initial_lr", group["lr"])
         self.base_lr = [group["initial_lr"] for group in runner.optimizer.param_groups]
@@ -383,13 +374,12 @@
         self.best_score = self.init_value_map[self.rule]
 
 
 @HOOKS.register_module(force=True)
 class StopLossNanTrainingHook(Hook):
     """StopLossNanTrainingHook."""
 
-    @check_input_parameters_type()
     def after_train_iter(self, runner: BaseRunner):
         """Called after_train_iter in StopLossNanTrainingHook."""
         if isnan(runner.outputs["loss"].item()):
             logger.warning("Early Stopping since loss is NaN")
             runner.should_stop = True
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/eval_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/eval_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/force_train_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/force_train_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/fp16_sam_optimizer_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/fp16_sam_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/ib_loss_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/ib_loss_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/logger_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/logger_hook.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 from typing import Any, Dict, Optional
 
 from mmcv.runner import BaseRunner
 from mmcv.runner.dist_utils import master_only
 from mmcv.runner.hooks import HOOKS, Hook, LoggerHook
 
 from otx.algorithms.common.utils.logger import get_logger
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 
 @HOOKS.register_module()
 class OTXLoggerHook(LoggerHook):
     """OTXLoggerHook for Logging."""
@@ -26,28 +25,26 @@
         def __repr__(self):
             """Repr function."""
             points = []
             for x, y in zip(self.x, self.y):
                 points.append(f"({x},{y})")
             return "curve[" + ",".join(points) + "]"
 
-    @check_input_parameters_type()
     def __init__(
         self,
         curves: Optional[Dict[Any, Curve]] = None,
         interval: int = 10,
         ignore_last: bool = True,
         reset_flag: bool = True,
         by_epoch: bool = True,
     ):
         super().__init__(interval, ignore_last, reset_flag, by_epoch)
         self.curves = curves if curves is not None else defaultdict(self.Curve)
 
     @master_only
-    @check_input_parameters_type()
     def log(self, runner: BaseRunner):
         """Log function for OTXLoggerHook."""
         tags = self.get_loggable_tags(runner, allow_text=False, tags_to_skip=())
         if runner.max_epochs is not None:
             normalized_iter = self.get_iter(runner) / runner.max_iters * runner.max_epochs
         else:
             normalized_iter = self.get_iter(runner)
@@ -56,15 +53,14 @@
             # Remove duplicates.
             if len(curve.x) > 0 and curve.x[-1] == normalized_iter:
                 curve.x.pop()
                 curve.y.pop()
             curve.x.append(normalized_iter)
             curve.y.append(value)
 
-    @check_input_parameters_type()
     def after_train_epoch(self, runner: BaseRunner):
         """Called after_train_epoch in OTXLoggerHook."""
         # Iteration counter is increased right after the last iteration in the epoch,
         # temporarily decrease it back.
         runner._iter -= 1
         super().after_train_epoch(runner)
         runner._iter += 1
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/model_ema_v2_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/model_ema_v2_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/no_bias_decay_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/no_bias_decay_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/progress_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/progress_hook.py`

 * *Files 16% similar despite different names*

```diff
@@ -17,82 +17,72 @@
 import math
 
 from mmcv.runner import BaseRunner
 from mmcv.runner.hooks import HOOKS, Hook
 
 from otx.algorithms.common.utils.logger import get_logger
 from otx.api.usecases.reporting.time_monitor_callback import TimeMonitorCallback
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 
 @HOOKS.register_module()
 class OTXProgressHook(Hook):
     """OTXProgressHook for getting progress."""
 
-    @check_input_parameters_type()
     def __init__(self, time_monitor: TimeMonitorCallback, verbose: bool = False):
         super().__init__()
         self.time_monitor = time_monitor
         self.verbose = verbose
         self.print_threshold = 1
 
-    @check_input_parameters_type()
     def before_run(self, runner: BaseRunner):
         """Called before_run in OTXProgressHook."""
         total_epochs = runner.max_epochs if runner.max_epochs is not None else 1
         self.time_monitor.total_epochs = total_epochs
         self.time_monitor.train_steps = runner.max_iters // total_epochs if total_epochs else 1
         self.time_monitor.steps_per_epoch = self.time_monitor.train_steps + self.time_monitor.val_steps
         self.time_monitor.total_steps = max(math.ceil(self.time_monitor.steps_per_epoch * total_epochs), 1)
         self.time_monitor.current_step = 0
         self.time_monitor.current_epoch = 0
         self.time_monitor.on_train_begin()
 
-    @check_input_parameters_type()
     def before_epoch(self, runner: BaseRunner):
         """Called before_epoch in OTXProgressHook."""
         self.time_monitor.on_epoch_begin(runner.epoch)
 
-    @check_input_parameters_type()
     def after_epoch(self, runner: BaseRunner):
         """Called after_epoch in OTXProgressHook."""
         # put some runner's training status to use on the other hooks
         runner.log_buffer.output["current_iters"] = runner.iter
         self.time_monitor.on_epoch_end(runner.epoch, runner.log_buffer.output)
 
-    @check_input_parameters_type()
     def before_iter(self, runner: BaseRunner):
         """Called before_iter in OTXProgressHook."""
         self.time_monitor.on_train_batch_begin(1)
 
-    @check_input_parameters_type()
     def after_iter(self, runner: BaseRunner):
         """Called after_iter in OTXProgressHook."""
         # put some runner's training status to use on the other hooks
         runner.log_buffer.output["current_iters"] = runner.iter
         self.time_monitor.on_train_batch_end(1)
         if self.verbose:
             progress = self.progress
             if progress >= self.print_threshold:
                 logger.warning(f"training progress {progress:.0f}%")
                 self.print_threshold = (progress + 10) // 10 * 10
 
-    @check_input_parameters_type()
     def before_val_iter(self, runner: BaseRunner):
         """Called before_val_iter in OTXProgressHook."""
         self.time_monitor.on_test_batch_begin(1, logger)
 
-    @check_input_parameters_type()
     def after_val_iter(self, runner: BaseRunner):
         """Called after_val_iter in OTXProgressHook."""
         self.time_monitor.on_test_batch_end(1, logger)
 
-    @check_input_parameters_type()
     def after_run(self, runner: BaseRunner):
         """Called after_run in OTXProgressHook."""
         self.time_monitor.on_train_end(1)
         if self.time_monitor.update_progress_callback:
             self.time_monitor.update_progress_callback(int(self.time_monitor.get_progress()))
 
     @property
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/recording_forward_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/recording_forward_hook.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,20 +11,20 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 from __future__ import annotations
 
-from abc import ABC, abstractmethod
+from abc import ABC
 from typing import List, Sequence, Union
 
 import torch
 
-from otx import MMCLS_AVAILABLE
+from otx.algorithms.classification import MMCLS_AVAILABLE
 
 if MMCLS_AVAILABLE:
     from mmcls.models.necks.gap import GlobalAveragePooling
 
 
 class BaseRecordingForwardHook(ABC):
     """While registered with the designated PyTorch module, this class caches feature vector during forward pass.
@@ -40,28 +40,27 @@
         fpn_idx (int, optional): The layer index to be processed if the model is a FPN.
                                   Defaults to 0 which uses the largest feature map from FPN.
     """
 
     def __init__(self, module: torch.nn.Module, fpn_idx: int = -1) -> None:
         self._module = module
         self._handle = None
-        self._records = []  # type: List[torch.Tensor]
+        self._records: List[torch.Tensor] = []
         self._fpn_idx = fpn_idx
 
     @property
     def records(self):
         """Return records."""
         return self._records
 
-    @abstractmethod
     def func(self, feature_map: torch.Tensor, fpn_idx: int = -1) -> torch.Tensor:
         """This method get the feature vector or saliency map from the output of the module.
 
         Args:
-            x (torch.Tensor): Feature map from the backbone module
+            feature_map (torch.Tensor): Feature map from the backbone module
             fpn_idx (int, optional): The layer index to be processed if the model is a FPN.
                                     Defaults to 0 which uses the largest feature map from FPN.
 
         Returns:
             torch.Tensor (torch.Tensor): Saliency map for feature vector
         """
         raise NotImplementedError
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/sam_optimizer_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/sam_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/semisl_cls_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/semisl_cls_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/task_adapt_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/task_adapt_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/two_crop_transform_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/two_crop_transform_hook.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 """Two crop transform hook."""
 from typing import List
 
 from mmcv.runner import BaseRunner
 from mmcv.runner.hooks import HOOKS, Hook
 
 from otx.algorithms.common.utils.logger import get_logger
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 logger = get_logger()
 
 
 @HOOKS.register_module()
 class TwoCropTransformHook(Hook):
     """TwoCropTransformHook with every specific interval.
@@ -20,58 +19,53 @@
     Args:
         interval (int): If `interval` == 1, both pipelines is used.
             If `interval` > 1, the first pipeline is used and then
             both pipelines are used every `interval`. Defaults to 1.
         by_epoch (bool): (TODO) Use `interval` by epoch. Defaults to False.
     """
 
-    @check_input_parameters_type()
     def __init__(self, interval: int = 1, by_epoch: bool = False):
         assert interval > 0, f"interval (={interval}) must be positive value."
         if by_epoch:
             raise NotImplementedError("by_epoch is not implemented.")
 
         self.interval = interval
         self.cnt = 0
 
-    @check_input_parameters_type()
     def _get_dataset(self, runner: BaseRunner):
         """Get dataset to handle `is_both`."""
         if hasattr(runner.data_loader.dataset, "dataset"):
             # for RepeatDataset
             dataset = runner.data_loader.dataset.dataset
         else:
             dataset = runner.data_loader.dataset
 
         return dataset
 
     # pylint: disable=inconsistent-return-statements
-    @check_input_parameters_type()
     def _find_two_crop_transform(self, transforms: List[object]):
         """Find TwoCropTransform among transforms."""
         for transform in transforms:
             if transform.__class__.__name__ == "TwoCropTransform":
                 return transform
 
-    @check_input_parameters_type()
     def before_train_epoch(self, runner: BaseRunner):
         """Called before_train_epoch in TwoCropTransformHook."""
         # Always keep `TwoCropTransform` enabled.
         if self.interval == 1:
             return
 
         dataset = self._get_dataset(runner)
         two_crop_transform = self._find_two_crop_transform(dataset.pipeline.transforms)
         if self.cnt == self.interval - 1:
             # start using both pipelines
             two_crop_transform.is_both = True
         else:
             two_crop_transform.is_both = False
 
-    @check_input_parameters_type()
     def after_train_iter(self, runner: BaseRunner):
         """Called after_train_iter in TwoCropTransformHook."""
         # Always keep `TwoCropTransform` enabled.
         if self.interval == 1:
             return
 
         if self.cnt < self.interval - 1:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/hooks/unbiased_teacher_hook.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/unbiased_teacher_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnet.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnet.py`

 * *Files 5% similar despite different names*

```diff
@@ -570,14 +570,15 @@
         version : str. Version of EfficientNet ('b0'...'b8').
         in_size : tuple of two ints. Spatial size of the expected input image.
         tf_mode : bool, default False. Whether to use TF-like mode.
         bn_eps : float, default 1e-5. Small float added to variance in Batch norm.
         model_name : str or None, default None. Model name for loading pretrained model.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     if version == "b0":
         assert in_size == (224, 224)
         depth_factor = 1.0
         width_factor = 1.0
         dropout_rate = 0.2
     elif version == "b1":
@@ -685,113 +686,123 @@
 def efficientnet_b0(in_size=(224, 224), **kwargs):
     """EfficientNet-B0.
 
     Args:
         in_size : tuple of two ints, default (224, 224). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b0", in_size=in_size, model_name="efficientnet_b0", **kwargs)
 
 
 def efficientnet_b1(in_size=(240, 240), **kwargs):
     """EfficientNet-B1.
 
     Args:
         in_size : tuple of two ints, default (240, 240). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b1", in_size=in_size, model_name="efficientnet_b1", **kwargs)
 
 
 def efficientnet_b2(in_size=(260, 260), **kwargs):
     """EfficientNet-B2.
 
     Args:
         in_size : tuple of two ints, default (260, 260). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b2", in_size=in_size, model_name="efficientnet_b2", **kwargs)
 
 
 def efficientnet_b3(in_size=(300, 300), **kwargs):
     """EfficientNet-B3.
 
     Args:
         in_size : tuple of two ints, default (300, 300). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b3", in_size=in_size, model_name="efficientnet_b3", **kwargs)
 
 
 def efficientnet_b4(in_size=(380, 380), **kwargs):
     """EfficientNet-B4.
 
     Args:
         in_size : tuple of two ints, default (380, 380). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b4", in_size=in_size, model_name="efficientnet_b4", **kwargs)
 
 
 def efficientnet_b5(in_size=(456, 456), **kwargs):
     """EfficientNet-B5.
 
     Args:
         in_size : tuple of two ints, default (456, 456). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b5", in_size=in_size, model_name="efficientnet_b5", **kwargs)
 
 
 def efficientnet_b6(in_size=(528, 528), **kwargs):
     """EfficientNet-B6 model.
 
     Args:
         in_size : tuple of two ints, default (528, 528). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b6", in_size=in_size, model_name="efficientnet_b6", **kwargs)
 
 
 def efficientnet_b7(in_size=(600, 600), **kwargs):
     """EfficientNet-B7 model.
 
     Args:
         in_size : tuple of two ints, default (600, 600). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b7", in_size=in_size, model_name="efficientnet_b7", **kwargs)
 
 
 def efficientnet_b8(in_size=(672, 672), **kwargs):
     """EfficientNet-B8.
 
     Args:
         in_size : tuple of two ints, default (672, 672). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(version="b8", in_size=in_size, model_name="efficientnet_b8", **kwargs)
 
 
 def efficientnet_b0b(in_size=(224, 224), **kwargs):
     """EfficientNet-B0-b.
 
     Args:
         in_size : tuple of two ints, default (224, 224). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b0",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b0b",
@@ -802,14 +813,15 @@
 def efficientnet_b1b(in_size=(240, 240), **kwargs):
     """EfficientNet-B1-b.
 
     Args:
         in_size : tuple of two ints, default (240, 240). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b1",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b1b",
@@ -820,14 +832,15 @@
 def efficientnet_b2b(in_size=(260, 260), **kwargs):
     """EfficientNet-B2-b.
 
     Args:
         in_size : tuple of two ints, default (260, 260). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b2",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b2b",
@@ -838,14 +851,15 @@
 def efficientnet_b3b(in_size=(300, 300), **kwargs):
     """EfficientNet-B3-b.
 
     Args:
         in_size : tuple of two ints, default (300, 300). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b3",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b3b",
@@ -856,14 +870,15 @@
 def efficientnet_b4b(in_size=(380, 380), **kwargs):
     """EfficientNet-B4-b.
 
     Args:
         in_size : tuple of two ints, default (380, 380). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b4",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b4b",
@@ -874,14 +889,15 @@
 def efficientnet_b5b(in_size=(456, 456), **kwargs):
     """EfficientNet-B5-b.
 
     Args:
         in_size : tuple of two ints, default (456, 456). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b5",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b5b",
@@ -892,14 +908,15 @@
 def efficientnet_b6b(in_size=(528, 528), **kwargs):
     """EfficientNet-B6-b.
 
     Args:
         in_size : tuple of two ints, default (528, 528). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b6",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b6b",
@@ -910,14 +927,15 @@
 def efficientnet_b7b(in_size=(600, 600), **kwargs):
     """EfficientNet-B7-b.
 
     Args:
         in_size : tuple of two ints, default (600, 600). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b7",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b7b",
@@ -928,14 +946,15 @@
 def efficientnet_b0c(in_size=(224, 224), **kwargs):
     """EfficientNet-B0-c.
 
     Args:
         in_size : tuple of two ints, default (224, 224). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b0",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b0c",
@@ -946,14 +965,15 @@
 def efficientnet_b1c(in_size=(240, 240), **kwargs):
     """EfficientNet-B1-c.
 
     Args:
         in_size : tuple of two ints, default (240, 240). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b1",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b1c",
@@ -964,14 +984,15 @@
 def efficientnet_b2c(in_size=(260, 260), **kwargs):
     """EfficientNet-B2-c.
 
     Args:
         in_size : tuple of two ints, default (260, 260). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b2",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b2c",
@@ -982,14 +1003,15 @@
 def efficientnet_b3c(in_size=(300, 300), **kwargs):
     """EfficientNet-B3-c.
 
     Args:
         in_size : tuple of two ints, default (300, 300). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b3",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b3c",
@@ -1000,14 +1022,15 @@
 def efficientnet_b4c(in_size=(380, 380), **kwargs):
     """EfficientNet-B4-c.
 
     Args:
         in_size : tuple of two ints, default (380, 380). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b4",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b4c",
@@ -1018,14 +1041,15 @@
 def efficientnet_b5c(in_size=(456, 456), **kwargs):
     """EfficientNet-B5-c.
 
     Args:
         in_size : tuple of two ints, default (456, 456). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b5",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b5c",
@@ -1036,14 +1060,15 @@
 def efficientnet_b6c(in_size=(528, 528), **kwargs):
     """EfficientNet-B6-c.
 
     Args:
         in_size : tuple of two ints, default (528, 528). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b6",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b6c",
@@ -1054,14 +1079,15 @@
 def efficientnet_b7c(in_size=(600, 600), **kwargs):
     """EfficientNet-B7-c.
 
     Args:
         in_size : tuple of two ints, default (600, 600). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
     return get_efficientnet(
         version="b7",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
         model_name="efficientnet_b7c",
@@ -1072,14 +1098,15 @@
 def efficientnet_b8c(in_size=(672, 672), **kwargs):
     """EfficientNet-B8-c.
 
     Args:
         in_size : tuple of two ints, default (672, 672). Spatial size of the expected input image.
         pretrained : bool, default False. Whether to load the pretrained weights for model.
         root : str, default '~/.torch/models'. Location for keeping the model parameters.
+        **kwargs: Addition keyword arguments.
     """
 
     return get_efficientnet(
         version="b8",
         in_size=in_size,
         tf_mode=True,
         bn_eps=1e-3,
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnetv2.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/efficientnetv2.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/mobilenetv3.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/mobilenetv3.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/backbones/torchvision_backbones.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/backbones/torchvision_backbones.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/models/builder.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/models/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/hooks.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/hooks.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/patches.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/patches.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/runners.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/runners.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/nncf/utils.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/nncf/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/augments.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/augments.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/runner.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/runner.py`

 * *Files 4% similar despite different names*

```diff
@@ -30,16 +30,14 @@
     IterBasedRunner,
     IterLoader,
     get_dist_info,
 )
 from mmcv.runner.utils import get_host_info
 from torch.utils.data.dataloader import DataLoader
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 
 # pylint: disable=too-many-instance-attributes, attribute-defined-outside-init
 @RUNNERS.register_module()
 class EpochRunnerWithCancel(EpochBasedRunner):
     """Simple modification to EpochBasedRunner to allow cancelling the training during an epoch.
 
     A stopping hook should set the runner.should_stop flag to True if stopping is required.
@@ -64,15 +62,14 @@
 
         if self.distributed:
             dist.broadcast_object_list(broadcast_obj, src=0)
         if broadcast_obj[0]:
             self._max_epochs = self.epoch
         return broadcast_obj[0]
 
-    @check_input_parameters_type()
     def train(self, data_loader: DataLoader, **kwargs):
         """Train call hook."""
         self.model.train()
         self.mode = "train"
         self.data_loader = data_loader
         self._max_iters = self._max_epochs * len(self.data_loader)
         self.call_hook("before_train_epoch")
@@ -102,15 +99,14 @@
     # TODO: Implement cancelling of training via keyboard interrupt signal, instead of should_stop
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.should_stop = False
 
-    @check_input_parameters_type()
     def main_loop(self, workflow: List[tuple], iter_loaders: Sequence[IterLoader], **kwargs):
         """Main loop function in IterBasedRunnerWithCancel."""
         while self.iter < self._max_iters:
             for i, flow in enumerate(workflow):
                 self._inner_iter = 0
                 mode, iters = flow
                 if not isinstance(mode, str) or not hasattr(self, mode):
@@ -119,15 +115,14 @@
                 for _ in range(iters):
                     if mode == "train" and self.iter >= self._max_iters:
                         break
                     iter_runner(iter_loaders[i], **kwargs)
                     if self.should_stop:
                         return
 
-    @check_input_parameters_type()
     def run(self, data_loaders: Sequence[DataLoader], workflow: List[tuple], max_iters: Optional[int] = None, **kwargs):
         """Function of main run."""
         assert isinstance(data_loaders, list)
         assert mmcv.is_list_of(workflow, tuple)
         assert len(data_loaders) == len(workflow)
         if max_iters is not None:
             warnings.warn(
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/exporter_mixin.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/tasks/exporter.py`

 * *Files 19% similar despite different names*

```diff
@@ -7,32 +7,21 @@
 import traceback
 
 from otx.algorithms.common.utils.logger import get_logger
 
 logger = get_logger()
 
 
-class ExporterMixin:
-    """Exporter Mixin class for OTX export."""
+class Exporter:
+    """Exporter class for OTX export."""
 
-    def run(self, model_cfg, model_ckpt, data_cfg, **kwargs):  # noqa: C901
+    def run(self, cfg, **kwargs):  # noqa: C901
         """Run export procedure."""
-        self._init_logger()
-        logger.info("exporting the model")
-        mode = kwargs.get("mode", "train")
-        if mode not in self.mode:
-            logger.warning(f"Supported modes are {self.mode} but '{mode}' is given.")
-            return {}
-
-        cfg = self.configure(model_cfg, model_ckpt, data_cfg, training=False, **kwargs)
         logger.info("export!")
 
-        #  from torch.jit._trace import TracerWarning
-        #  import warnings
-        #  warnings.filterwarnings("ignore", category=TracerWarning)
         precision = kwargs.pop("precision", "FP32")
         if precision not in ("FP32", "FP16", "INT8"):
             raise NotImplementedError
         logger.info(f"Model will be exported with precision {precision}")
         model_name = cfg.get("model_name", "model")
 
         # TODO: handle complicated pipeline
@@ -68,18 +57,21 @@
                 "msg": f"exception {type(ex)}: {ex}\n\n{traceback.format_exc()}",
             }
 
         return {
             "outputs": {
                 "bin": os.path.join(cfg.work_dir, f"{model_name}.bin"),
                 "xml": os.path.join(cfg.work_dir, f"{model_name}.xml"),
+                "onnx": os.path.join(cfg.work_dir, f"{model_name}.onnx"),
                 "partitioned": [
                     {
-                        "bin": os.path.join(cfg.work_dir, name.replace(".xml", ".bin")),
-                        "xml": os.path.join(cfg.work_dir, name),
+                        f"{os.path.splitext(name)[0]}": {
+                            "bin": os.path.join(cfg.work_dir, name.replace(".xml", ".bin")),
+                            "xml": os.path.join(cfg.work_dir, name),
+                        }
                     }
                     for name in os.listdir(cfg.work_dir)
                     if name.endswith(".xml")
                     and name != f"{model_name}.xml"
                     and name.replace(".xml", ".bin") in os.listdir(cfg.work_dir)
                 ],
             },
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/tasks/stage.py` & `otx-1.2.0rc1/otx/algorithms/action/adapters/mmaction/task.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,553 +1,526 @@
-"""Base stage for OTX tasks."""
-# Copyright (C) 2022 Intel Corporation
-# SPDX-License-Identifier: Apache-2.0
+"""Task of OTX Video Recognition using mmaction training backend."""
+
+# Copyright (C) 2023 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
 #
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions
+# and limitations under the License.
 
-import importlib
-import json
+import glob
 import os
-import os.path as osp
-import random
 import time
-from typing import Any, Callable, Dict, List, Optional
+from copy import deepcopy
+from typing import Optional, Union
 
-import mmcv
-import numpy as np
 import torch
-from mmcv import Config, ConfigDict
-from mmcv.runner import CheckpointLoader, wrap_fp16_model
-from torch import distributed as dist
+from mmaction import __version__
+from mmaction.apis import train_model
+from mmaction.datasets import build_dataloader, build_dataset
+from mmaction.models import build_model as build_videomodel
+from mmaction.utils import collect_env
+from mmcv.runner import CheckpointLoader, load_state_dict, wrap_fp16_model
+from mmcv.utils import Config, ConfigDict, ProgressBar, get_git_hash
 
+from otx.algorithms.action.adapters.mmaction import (
+    Exporter,
+)
+from otx.algorithms.action.task import OTXActionTask
 from otx.algorithms.common.adapters.mmcv.utils import (
-    build_dataloader,
-    build_dataset,
-    get_data_cfg,
+    build_data_parallel,
+    get_configs_by_pairs,
+    patch_adaptive_interval_training,
+    patch_data_pipeline,
+    patch_early_stopping,
+    patch_from_hyperparams,
+    patch_persistent_workers,
 )
 from otx.algorithms.common.adapters.mmcv.utils.config_utils import (
     MPAConfig,
     update_or_add_custom_hook,
 )
-from otx.algorithms.common.utils.logger import config_logger, get_logger
-
-from .registry import STAGES
+from otx.algorithms.common.utils import set_random_seed
+from otx.algorithms.common.utils.data import get_dataset
+from otx.algorithms.common.utils.logger import get_logger
+from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.model import ModelPrecision
+from otx.api.entities.model_template import TaskType
+from otx.api.entities.subset import Subset
+from otx.api.entities.task_environment import TaskEnvironment
+from otx.core.data import caching
 
 logger = get_logger()
 
+# TODO Remove unnecessary pylint disable
+# pylint: disable=too-many-lines
 
-def _set_random_seed(seed, deterministic=False):
-    """Set random seed.
 
-    Args:
-        seed (int): Seed to be used.
-        deterministic (bool): Whether to set the deterministic option for
-            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`
-            to True and `torch.backends.cudnn.benchmark` to False.
-            Default: False.
-    """
-    random.seed(seed)
-    np.random.seed(seed)
-    torch.manual_seed(seed)
-    torch.cuda.manual_seed_all(seed)
-    os.environ["PYTHONHASHSEED"] = str(seed)
-    logger.info(f"Training seed was set to {seed} w/ deterministic={deterministic}.")
-    if deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-
-def get_available_types():
-    """Return available type of stage."""
-    types = []
-    for key in STAGES.module_dict:
-        types.append(key)
-    return types
-
-
-MODEL_TASK = {"classification": "mmcls", "detection": "mmdet", "segmentation": "mmseg"}
-
-
-# @STAGES.register_module()
-# pylint: disable=too-many-instance-attributes
-class Stage:
-    """Class for base stage of OTX tasks."""
+class MMActionTask(OTXActionTask):
+    """Task class for OTX action using mmaction training backend."""
 
-    MODEL_BUILDER: Optional[Callable] = None
+    # pylint: disable=too-many-instance-attributes
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__(task_environment, output_path)
+        self._data_cfg: Optional[Config] = None
+        self._recipe_cfg: Optional[Config] = None
+
+    # pylint: disable=too-many-locals, too-many-branches, too-many-statements
+    def _init_task(self, export: bool = False):  # noqa
+        """Initialize task."""
+
+        self._recipe_cfg = MPAConfig.fromfile(os.path.join(self._model_dir, "model.py"))
+        self._recipe_cfg.domain = self._task_type.domain
+        self._config = self._recipe_cfg
+
+        set_random_seed(self._recipe_cfg.get("seed", 5), logger, self._recipe_cfg.get("deterministic", False))
+
+        # Belows may go to the configure function
+        patch_data_pipeline(self._recipe_cfg, self.data_pipeline_path)
+
+        if not export:
+            patch_from_hyperparams(self._recipe_cfg, self._hyperparams)
+            self._recipe_cfg.total_epochs = self._recipe_cfg.runner.max_epochs
+
+        if "custom_hooks" in self.override_configs:
+            override_custom_hooks = self.override_configs.pop("custom_hooks")
+            for override_custom_hook in override_custom_hooks:
+                update_or_add_custom_hook(self._recipe_cfg, ConfigDict(override_custom_hook))
+        if len(self.override_configs) > 0:
+            logger.info(f"before override configs merging = {self._recipe_cfg}")
+            self._recipe_cfg.merge_from_dict(self.override_configs)
+            logger.info(f"after override configs merging = {self._recipe_cfg}")
+
+        # add Cancel training hook
+        update_or_add_custom_hook(
+            self._recipe_cfg,
+            ConfigDict(type="CancelInterfaceHook", init_callback=self.on_hook_initialized),
+        )
+        if self._time_monitor is not None:
+            update_or_add_custom_hook(
+                self._recipe_cfg,
+                ConfigDict(
+                    type="OTXProgressHook",
+                    time_monitor=self._time_monitor,
+                    verbose=True,
+                    priority=71,
+                ),
+            )
+        self._recipe_cfg.log_config.hooks.append({"type": "OTXLoggerHook", "curves": self._learning_curves})
 
-    # pylint: disable=too-many-branches, too-many-statements
-    def __init__(self, name, mode, config, common_cfg=None, index=0, **kwargs):
-        logger.debug(f"init stage with: {name}, {mode}, {config}, {common_cfg}, {index}, {kwargs}")
-        # the name of 'config' cannot be changed to such as 'config_file'
-        # because it is defined as 'config' in recipe file.....
-        self.name = name
-        self.mode = mode
-        self.index = index
-        self.input = kwargs.pop("input", {})  # input_map?? input_dict? just input?
-        self.output_keys = kwargs.pop("output", [])
-        self._distributed = False
-        self.task_adapt_type = None
-        self.task_adapt_op = "REPLACE"
-        self.org_model_classes: List[str] = []
-        self.model_classes: List[str] = []
-        self.data_classes: List[str] = []
-
-        if common_cfg is None:
-            common_cfg = dict(output_path="logs")
-
-        if not isinstance(common_cfg, dict):
-            raise TypeError(f"common_cfg should be the type of dict but {type(common_cfg)}")
-        if common_cfg.get("output_path") is None:
-            logger.info("output_path is not set in common_cfg. set it to 'logs' as default")
-            common_cfg["output_path"] = "logs"
-
-        self.output_prefix = common_cfg["output_path"]
-        self.output_suffix = f"stage{self.index:02d}_{self.name}"
-
-        # # Work directory
-        # work_dir = os.path.join(self.output_prefix, self.output_suffix)
-        # mmcv.mkdir_or_exist(os.path.abspath(work_dir))
-
-        if isinstance(config, Config):
-            cfg = config
-        elif isinstance(config, dict):
-            cfg = Config(cfg_dict=config)
-        elif isinstance(config, str):
-            if os.path.exists(config):
-                cfg = MPAConfig.fromfile(config)
-            else:
-                err_msg = f"cannot find configuration file {config}"
-                logger.error(err_msg)
-                raise ValueError(err_msg)
-        else:
-            err_msg = "'config' argument could be one of the \
-                       [dictionary, Config object, or string of the cfg file path]"
-            logger.error(err_msg)
-            raise ValueError(err_msg)
-
-        cfg.merge_from_dict(common_cfg)
-
-        if len(kwargs) > 0:
-            addtional_dict = {}
-            logger.info("found override configurations for the stage")
-            for key, value in kwargs.items():
-                addtional_dict[key] = value
-                logger.info(f"\t{key}: {value}")
-            cfg.merge_from_dict(addtional_dict)
-
-        max_epochs = -1
-        if hasattr(cfg, "total_epochs"):
-            max_epochs = cfg.pop("total_epochs")
-        if hasattr(cfg, "runner"):
-            if hasattr(cfg.runner, "max_epochs"):
-                if max_epochs != -1:
-                    max_epochs = min(max_epochs, cfg.runner.max_epochs)
-                else:
-                    max_epochs = cfg.runner.max_epochs
-        if max_epochs > 0:
-            if cfg.runner.max_epochs != max_epochs:
-                cfg.runner.max_epochs = max_epochs
-                logger.info(f"The maximum number of epochs is adjusted to {max_epochs}.")
-            if hasattr(cfg, "checkpoint_config"):
-                if hasattr(cfg.checkpoint_config, "interval"):
-                    if cfg.checkpoint_config.interval > max_epochs:
-                        logger.warning(
-                            f"adjusted checkpoint interval from {cfg.checkpoint_config.interval} to {max_epochs} \
-                            since max_epoch is shorter than ckpt interval configuration"
-                        )
-                        cfg.checkpoint_config.interval = max_epochs
+        # Update recipe with caching modules
+        self._update_caching_modules(self._recipe_cfg.data)
 
-        if cfg.get("seed", None) is not None:
-            _set_random_seed(cfg.seed, deterministic=cfg.get("deterministic", False))
-        else:
-            cfg.seed = None
+        logger.info("initialized.")
 
-        # Work directory
-        work_dir = cfg.get("work_dir", "")
-        work_dir = os.path.join(self.output_prefix, work_dir if work_dir else "", self.output_suffix)
-        cfg.work_dir = os.path.abspath(work_dir)
-        logger.info(f"work dir = {cfg.work_dir}")
-        mmcv.mkdir_or_exist(os.path.abspath(work_dir))
-
-        # config logger replace hook
-        hook_cfg = ConfigDict(type="LoggerReplaceHook")
-        update_or_add_custom_hook(cfg, hook_cfg)
-
-        self.cfg = cfg
-
-        self.__init_device()
-
-    def __init_device(self):
-        if torch.distributed.is_initialized():
-            self._distributed = True
-            self.cfg.gpu_ids = [int(os.environ["LOCAL_RANK"])]
-        elif "gpu_ids" not in self.cfg:
-            gpu_ids = os.environ.get("CUDA_VISIBLE_DEVICES")
-            logger.info(f"CUDA_VISIBLE_DEVICES = {gpu_ids}")
-            if gpu_ids is not None:
-                self.cfg.gpu_ids = range(len(gpu_ids.split(",")))
-            else:
-                self.cfg.gpu_ids = range(1)
-
-        # consider "cuda" and "cpu" device only
-        if not torch.cuda.is_available():
-            self.cfg.device = "cpu"
-            self.cfg.gpu_ids = range(-1, 0)
+    def build_model(
+        self,
+        cfg: Config,
+        fp16: bool = False,
+        **kwargs,
+    ) -> torch.nn.Module:
+        """Build model from model_builder."""
+        model_builder = getattr(self, "model_builder", build_videomodel)
+        model = model_builder(cfg.model, **kwargs)
+        ckpt = CheckpointLoader.load_checkpoint(cfg.load_from, map_location="cpu")
+        if "model" in ckpt:
+            ckpt = ckpt["model"]
+        if "state_dict" in ckpt:
+            ckpt = ckpt["state_dict"]
+        load_state_dict(model, ckpt)
+        if fp16:
+            wrap_fp16_model(model)
+        return model
+
+    # pylint: disable=too-many-arguments
+    def configure(
+        self,
+        training=True,
+        subset="train",
+        ir_options=None,
+    ):
+        """Patch mmcv configs for OTX action settings."""
+
+        # deepcopy all configs to make sure
+        # changes under MPA and below does not take an effect to OTX for clear distinction
+        recipe_cfg = deepcopy(self._recipe_cfg)
+        data_cfg = deepcopy(self._data_cfg)
+        assert recipe_cfg is not None, "'recipe_cfg' is not initialized."
+
+        recipe_cfg.work_dir = self._output_path
+        recipe_cfg.resume = self._resume
+        recipe_cfg.distributed = False
+        recipe_cfg.omnisource = False
+
+        if data_cfg is not None:
+            recipe_cfg.merge_from_dict(data_cfg)
+
+        if self._task_type == TaskType.ACTION_CLASSIFICATION:
+            _dataset_type = "OTXActionClsDataset"
         else:
-            self.cfg.device = "cuda"
+            _dataset_type = "OTXActionDetDataset"
+        for subset in ("train", "val", "test", "unlabeled"):
+            _cfg = recipe_cfg.data.get(subset, None)
+            if not _cfg:
+                continue
+            _cfg.type = _dataset_type
+            while "dataset" in _cfg:
+                _cfg = _cfg.dataset
+            _cfg.labels = self._labels
+
+        if self._task_type == TaskType.ACTION_CLASSIFICATION:
+            recipe_cfg.model["cls_head"].num_classes = len(self._labels)
+        elif self._task_type == TaskType.ACTION_DETECTION:
+            recipe_cfg.model["roi_head"]["bbox_head"].num_classes = len(self._labels) + 1
+            if len(self._labels) < 5:
+                recipe_cfg.model["roi_head"]["bbox_head"]["topk"] = len(self._labels) - 1
+
+        recipe_cfg.data.videos_per_gpu = recipe_cfg.data.pop("samples_per_gpu", None)
+
+        patch_adaptive_interval_training(recipe_cfg)
+        patch_early_stopping(recipe_cfg)
+        patch_persistent_workers(recipe_cfg)
 
-    @property
-    def distributed(self):
-        """Return whether this is distributed running."""
-        return self._distributed
+        if self._model_ckpt is not None:
+            recipe_cfg.load_from = self._model_ckpt
 
-    def _init_logger(self):
-        timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
-        config_logger(os.path.join(self.cfg.work_dir, f"{timestamp}.log"), level=self.cfg.log_level)
-        logger.info(f"configured logger at {self.cfg.work_dir} with named {timestamp}.log")
-        return logger
-
-    def configure_data(self, cfg, training):
-        """Update data configuration using image options."""
-        logger.info("configure_data()")
-        logger.debug(f"[args] {cfg.data}")
-        pipeline_options = cfg.data.pop("pipeline_options", None)
-        if pipeline_options is not None and isinstance(pipeline_options, dict):
-            self._configure_split(cfg, pipeline_options, "train")
-            self._configure_split(cfg, pipeline_options, "val")
-            if not training:
-                self._configure_split(cfg, pipeline_options, "test")
-            self._configure_split(cfg, pipeline_options, "unlabeled")
-
-    @staticmethod
-    def _configure_split(cfg, pipeline_options, target):
-        def update_transform(opt, pipeline, idx, transform):
-            if isinstance(opt, dict):
-                if "_delete_" in opt.keys() and opt.get("_delete_", False):
-                    # if option include _delete_=True, remove this transform from pipeline
-                    logger.info(f"configure_data: {transform['type']} is deleted")
-                    del pipeline[idx]
-                    return
-                logger.info(f"configure_data: {transform['type']} is updated with {opt}")
-                transform.update(**opt)
-
-        # pylint: disable=too-many-nested-blocks
-        def update_config(src, pipeline_options):
-            logger.info(f"update_config() {pipeline_options}")
-            if src.get("pipeline") is not None or (
-                src.get("dataset") is not None and src.get("dataset").get("pipeline") is not None
-            ):
-                if src.get("pipeline") is not None:
-                    pipeline = src.get("pipeline", None)
-                else:
-                    pipeline = src.get("dataset").get("pipeline")
-                if isinstance(pipeline, list):
-                    for idx, transform in enumerate(pipeline):
-                        for opt_key, opt in pipeline_options.items():
-                            if transform["type"] == opt_key:
-                                update_transform(opt, pipeline, idx, transform)
-                elif isinstance(pipeline, dict):
-                    for _, pipe in pipeline.items():
-                        for idx, transform in enumerate(pipe):
-                            for opt_key, opt in pipeline_options.items():
-                                if transform["type"] == opt_key:
-                                    update_transform(opt, pipe, idx, transform)
-                else:
-                    raise NotImplementedError(f"pipeline type of {type(pipeline)} is not supported")
-            else:
-                logger.info("no pipeline in the data split")
-
-        split = cfg.data.get(target)
-        if split is not None:
-            if isinstance(split, list):
-                for sub_item in split:
-                    update_config(sub_item, pipeline_options)
-            elif isinstance(split, dict):
-                update_config(split, pipeline_options)
-            else:
-                logger.warning(f"type of split '{target}'' should be list or dict but {type(split)}")
-
-    def configure_ckpt(self, cfg, model_ckpt, pretrained=None):
-        """Patch checkpoint path for pretrained weight.
-
-        Replace cfg.load_from to model_ckpt
-        Replace cfg.load_from to pretrained
-        Replace cfg.resume_from to cfg.load_from
-        """
-        if model_ckpt:
-            cfg.load_from = self.get_model_ckpt(model_ckpt)
-        if pretrained and isinstance(pretrained, str):
-            logger.info(f"Overriding cfg.load_from -> {pretrained}")
-            cfg.load_from = pretrained  # Overriding by stage input
-        if cfg.get("resume", False):
-            cfg.resume_from = cfg.load_from
-
-    @staticmethod
-    def configure_hook(cfg):
-        """Update cfg.custom_hooks based on cfg.custom_hook_options."""
-
-        def update_hook(opt, custom_hooks, idx, hook):
-            """Delete of update a custom hook."""
-            if isinstance(opt, dict):
-                if opt.get("_delete_", False):
-                    # if option include _delete_=True, remove this hook from custom_hooks
-                    logger.info(f"configure_hook: {hook['type']} is deleted")
-                    del custom_hooks[idx]
-                else:
-                    logger.info(f"configure_hook: {hook['type']} is updated with {opt}")
-                    hook.update(**opt)
-
-        custom_hook_options = cfg.pop("custom_hook_options", {})
-        # logger.info(f"configure_hook() {cfg.get('custom_hooks', [])} <- {custom_hook_options}")
-        custom_hooks = cfg.get("custom_hooks", [])
-        for idx, hook in enumerate(custom_hooks):
-            for opt_key, opt in custom_hook_options.items():
-                if hook["type"] == opt_key:
-                    update_hook(opt, custom_hooks, idx, hook)
+        self._config = recipe_cfg
+        return recipe_cfg
 
-    @staticmethod
-    def configure_samples_per_gpu(
-        cfg: Config,
-        subset: str,
-        distributed: bool = False,
+    # pylint: disable=too-many-branches, too-many-statements
+    def _train_model(
+        self,
+        dataset: DatasetEntity,
     ):
-        """Patch samples_per_gpu settings."""
+        """Train function in MMActionTask."""
+        logger.info("init data cfg.")
+        self._data_cfg = ConfigDict(data=ConfigDict())
+
+        for cfg_key, subset in zip(
+            ["train", "val", "unlabeled"],
+            [Subset.TRAINING, Subset.VALIDATION, Subset.UNLABELED],
+        ):
+            subset = get_dataset(dataset, subset)
+            if subset and self._data_cfg is not None:
+                self._data_cfg.data[cfg_key] = ConfigDict(
+                    otx_dataset=subset,
+                    labels=self._labels,
+                )
 
-        dataloader_cfg = cfg.data.get(f"{subset}_dataloader", ConfigDict())
-        samples_per_gpu = dataloader_cfg.get("samples_per_gpu", cfg.data.get("samples_per_gpu", 1))
+        self._is_training = True
 
-        data_cfg = get_data_cfg(cfg, subset)
-        dataset_len = len(data_cfg.otx_dataset)
+        self._init_task()
 
-        if distributed:
-            dataset_len = dataset_len // dist.get_world_size()
+        cfg = self.configure(True, "train", None)
+        logger.info("train!")
 
-        # set batch size as a total dataset
-        # if it is smaller than total dataset
-        if dataset_len < samples_per_gpu:
-            dataloader_cfg.samples_per_gpu = dataset_len
+        timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
 
-        # drop the last batch if the last batch size is 1
-        # batch size of 1 is a runtime error for training batch normalization layer
-        if subset in ("train", "unlabeled") and dataset_len % samples_per_gpu == 1:
-            dataloader_cfg.drop_last = True
+        # Environment
+        logger.info(f"cfg.gpu_ids = {cfg.gpu_ids}, distributed = {cfg.distributed}")
+        env_info_dict = collect_env()
+        env_info = "\n".join([(f"{k}: {v}") for k, v in env_info_dict.items()])
+        dash_line = "-" * 60 + "\n"
+        logger.info(f"Environment info:\n{dash_line}{env_info}\n{dash_line}")
+
+        # Data
+        datasets = [build_dataset(cfg.data.train)]
+
+        # FIXME: Currently action do not support multi batch evaluation. This will be fixed
+        if "val" in cfg.data:
+            cfg.data.val_dataloader["videos_per_gpu"] = 1
+
+        # Target classes
+        if "task_adapt" in cfg:
+            target_classes = cfg.task_adapt.get("final", [])
+        else:
+            target_classes = datasets[0].CLASSES
 
-        cfg.data[f"{subset}_dataloader"] = dataloader_cfg
+        # Metadata
+        meta = dict()
+        meta["env_info"] = env_info
+        meta["seed"] = cfg.seed
+        meta["exp_name"] = cfg.work_dir
+        if cfg.checkpoint_config is not None:
+            cfg.checkpoint_config.meta = dict(
+                mmaction2_version=__version__ + get_git_hash()[:7],
+                CLASSES=target_classes,
+            )
 
-    @staticmethod
-    def configure_compat_cfg(
-        cfg: Config,
+        # Model
+        model = self.build_model(cfg, fp16=cfg.get("fp16", False))
+        model.train()
+        model.CLASSES = target_classes
+
+        if cfg.distributed:
+            torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
+
+        validate = bool(cfg.data.get("val", None))
+        train_model(
+            model,
+            datasets,
+            cfg,
+            distributed=cfg.distributed,
+            validate=validate,
+            timestamp=timestamp,
+            meta=meta,
+        )
+
+        # Save outputs
+        output_ckpt_path = os.path.join(cfg.work_dir, "latest.pth")
+        best_ckpt_path = glob.glob(os.path.join(cfg.work_dir, "best_*.pth"))
+        if best_ckpt_path:
+            output_ckpt_path = best_ckpt_path[0]
+        return dict(
+            final_ckpt=output_ckpt_path,
+        )
+
+    def _infer_model(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
     ):
-        """Modify config to keep the compatibility."""
-
-        def _configure_dataloader(cfg):
-            """Consume all the global dataloader config and convert them to specific dataloader config."""
-            global_dataloader_cfg = {}
-            global_dataloader_cfg.update(
-                {
-                    k: cfg.data.pop(k)
-                    for k in list(cfg.data.keys())
-                    if k
-                    not in [
-                        "train",
-                        "val",
-                        "test",
-                        "unlabeled",
-                        "train_dataloader",
-                        "val_dataloader",
-                        "test_dataloader",
-                        "unlabeled_dataloader",
-                    ]
-                }
+        """Main infer function."""
+        self._data_cfg = ConfigDict(
+            data=ConfigDict(
+                train=ConfigDict(
+                    otx_dataset=None,
+                    labels=self._labels,
+                ),
+                test=ConfigDict(
+                    otx_dataset=dataset,
+                    labels=self._labels,
+                ),
             )
+        )
 
-            for subset in ["train", "val", "test", "unlabeled"]:
-                if subset not in cfg.data:
-                    continue
-                dataloader_cfg = cfg.data.get(f"{subset}_dataloader", None)
-                if dataloader_cfg is None:
-                    raise AttributeError(f"{subset}_dataloader is not found in config.")
-                dataloader_cfg = {**global_dataloader_cfg, **dataloader_cfg}
-                cfg.data[f"{subset}_dataloader"] = dataloader_cfg
-
-        _configure_dataloader(cfg)
-
-    @staticmethod
-    def configure_fp16_optimizer(cfg: Config, distributed: bool = False):
-        """Configure Fp16OptimizerHook and Fp16SAMOptimizerHook."""
-
-        fp16_config = cfg.pop("fp16", None)
-        if fp16_config is not None:
-            optim_type = cfg.optimizer_config.get("type", "OptimizerHook")
-            opts: Dict[str, Any] = dict(
-                distributed=distributed,
-                **fp16_config,
-            )
-            if optim_type == "SAMOptimizerHook":
-                opts["type"] = "Fp16SAMOptimizerHook"
-            elif optim_type == "OptimizerHook":
-                opts["type"] = "Fp16OptimizerHook"
-            else:
-                # does not support optimizerhook type
-                # let mm library handle it
-                cfg.fp16 = fp16_config
-                opts = dict()
-            cfg.optimizer_config.update(opts)
-
-    @staticmethod
-    def configure_unlabeled_dataloader(cfg: Config, distributed: bool = False):
-        """Patch for loading unlabeled dataloader."""
-        if "unlabeled" in cfg.data:
-            task_lib_module = importlib.import_module(f"{MODEL_TASK[cfg.model_task]}.datasets")
-            dataset_builder = getattr(task_lib_module, "build_dataset")
-            dataloader_builder = getattr(task_lib_module, "build_dataloader")
-
-            dataset = build_dataset(cfg, "unlabeled", dataset_builder, consume=True)
-            unlabeled_dataloader = build_dataloader(
-                dataset,
-                cfg,
-                "unlabeled",
-                dataloader_builder,
-                distributed=distributed,
-                consume=True,
-            )
+        dump_features = False
+        dump_saliency_map = False
 
-            custom_hooks = cfg.get("custom_hooks", [])
-            updated = False
-            for custom_hook in custom_hooks:
-                if custom_hook["type"] == "ComposedDataLoadersHook":
-                    custom_hook["data_loaders"] = [*custom_hook["data_loaders"], unlabeled_dataloader]
-                    updated = True
-            if not updated:
-                custom_hooks.append(
-                    ConfigDict(
-                        type="ComposedDataLoadersHook",
-                        data_loaders=unlabeled_dataloader,
-                    )
-                )
-            cfg.custom_hooks = custom_hooks
+        self._init_task()
 
-    @staticmethod
-    def get_model_meta(cfg):
-        """Return model_meta."""
-        ckpt_path = cfg.get("load_from", None)
-        meta = {}
-        if ckpt_path:
-            ckpt = CheckpointLoader.load_checkpoint(ckpt_path, map_location="cpu")
-            meta = ckpt.get("meta", {})
-        return meta
-
-    @staticmethod
-    def get_data_cfg(cfg, subset):
-        """Return data_cfg from cfg's subset."""
-        assert subset in ["train", "val", "test"], f"Unknown subset:{subset}"
-        if "dataset" in cfg.data[subset]:  # Concat|RepeatDataset
-            dataset = cfg.data[subset].dataset
-            while hasattr(dataset, "dataset"):
-                dataset = dataset.dataset
-            return dataset
-        return cfg.data[subset]
-
-    @staticmethod
-    def get_data_classes(cfg):
-        """Return data_classes from cfg."""
-        data_classes = []
-        train_cfg = Stage.get_data_cfg(cfg, "train")
-        if "data_classes" in train_cfg:
-            data_classes = list(train_cfg.pop("data_classes", []))
-        elif "classes" in train_cfg:
-            data_classes = list(train_cfg.classes)
-        return data_classes
-
-    @staticmethod
-    def get_model_classes(cfg):
-        """Extract trained classes info from checkpoint file.
-
-        MMCV-based models would save class info in ckpt['meta']['CLASSES']
-        For other cases, try to get the info from cfg.model.classes (with pop())
-        - Which means that model classes should be specified in model-cfg for
-          non-MMCV models (e.g. OMZ models)
-        """
-        classes = []
-        meta = Stage.get_model_meta(cfg)
-        # for MPA classification legacy compatibility
-        classes = meta.get("CLASSES", [])
-        classes = meta.get("classes", classes)
-        if classes is None:
-            classes = []
-
-        if len(classes) == 0:
-            ckpt_path = cfg.get("load_from", None)
-            if ckpt_path:
-                classes = Stage.read_label_schema(ckpt_path)
-        if len(classes) == 0:
-            classes = cfg.model.pop("classes", cfg.pop("model_classes", []))
-        return classes
-
-    @staticmethod
-    def get_model_ckpt(ckpt_path, new_path=None):
-        """Return model ckpt from ckpt_path."""
-        ckpt = CheckpointLoader.load_checkpoint(ckpt_path, map_location="cpu")
-        if "model" in ckpt:
-            ckpt = ckpt["model"]
-            if not new_path:
-                new_path = ckpt_path[:-3] + "converted.pth"
-            torch.save(ckpt, new_path)
-            return new_path
-        return ckpt_path
-
-    @staticmethod
-    def read_label_schema(ckpt_path, name_only=True, file_name="label_schema.json"):
-        """Read label_schema and return all classes."""
-        serialized_label_schema = []
-        if any(ckpt_path.endswith(extension) for extension in (".xml", ".bin", ".pth")):
-            label_schema_path = osp.join(osp.dirname(ckpt_path), file_name)
-            if osp.exists(label_schema_path):
-                with open(label_schema_path, encoding="UTF-8") as read_file:
-                    serialized_label_schema = json.load(read_file)
-        if serialized_label_schema:
-            if name_only:
-                all_classes = [labels["name"] for labels in serialized_label_schema["all_labels"].values()]
-            else:
-                all_classes = serialized_label_schema
+        cfg = self.configure(False, "test", None)
+        logger.info("infer!")
+
+        videos_per_gpu = cfg.data.test_dataloader.get("videos_per_gpu", 1)
+
+        # Data loader
+        mm_dataset = build_dataset(cfg.data.test)
+        dataloader = build_dataloader(
+            mm_dataset,
+            videos_per_gpu=videos_per_gpu,
+            workers_per_gpu=cfg.data.test_dataloader.get("workers_per_gpu", 0),
+            num_gpus=len(cfg.gpu_ids),
+            dist=cfg.distributed,
+            seed=cfg.get("seed", None),
+            shuffle=False,
+        )
+
+        # Target classes
+        if "task_adapt" in cfg:
+            target_classes = cfg.task_adapt.final
+            if len(target_classes) < 1:
+                raise KeyError(
+                    f"target_classes={target_classes} is empty check the metadata from model ckpt or recipe "
+                    "configuration"
+                )
         else:
-            all_classes = []
-        return all_classes
+            target_classes = mm_dataset.CLASSES
+
+        # Model
+        model = self.build_model(cfg, fp16=cfg.get("fp16", False))
+        model.CLASSES = target_classes
+        model.eval()
+        model = build_data_parallel(model, cfg, distributed=False)
 
-    # pylint: disable=unused-argument
-    @staticmethod
-    def set_inference_progress_callback(model, cfg):
-        """Inferenceprogresscallback (Time Monitor enable into Infer task)."""
+        # InferenceProgressCallback (Time Monitor enable into Infer task)
         time_monitor = None
         if cfg.get("custom_hooks", None):
             time_monitor = [hook.time_monitor for hook in cfg.custom_hooks if hook.type == "OTXProgressHook"]
             time_monitor = time_monitor[0] if time_monitor else None
         if time_monitor is not None:
 
-            def pre_hook(*args, **kwargs):
+            # pylint: disable=unused-argument
+            def pre_hook(module, inp):
                 time_monitor.on_test_batch_begin(None, None)
 
-            def hook(*args, **kwargs):
+            def hook(module, inp, outp):
                 time_monitor.on_test_batch_end(None, None)
 
             model.register_forward_pre_hook(pre_hook)
             model.register_forward_hook(hook)
 
-    @classmethod
-    def build_model(
-        cls,
-        cfg: Config,
-        model_builder: Optional[Callable] = None,
-        *,
-        fp16: bool = False,
-        **kwargs,
-    ) -> torch.nn.Module:
-        """Build model from model_builder."""
-        if model_builder is None:
-            model_builder = cls.MODEL_BUILDER
-        assert model_builder is not None
-        model = model_builder(cfg, **kwargs)
-        if bool(fp16):
-            wrap_fp16_model(model)
-        return model
+        eval_predictions = []
+        feature_vectors = []
+        saliency_maps = []
+
+        def dump_features_hook():
+            raise NotImplementedError("get_feature_vector function for mmaction is not implemented")
+
+        # pylint: disable=unused-argument
+        def dummy_dump_features_hook(model, inp, out):
+            feature_vectors.append(None)
+
+        def dump_saliency_hook():
+            raise NotImplementedError("get_saliency_map for mmaction is not implemented")
+
+        # pylint: disable=unused-argument
+        def dummy_dump_saliency_hook(model, inp, out):
+            saliency_maps.append(None)
+
+        feature_vector_hook = dump_features_hook if dump_features else dummy_dump_features_hook
+        saliency_map_hook = dump_saliency_hook if dump_saliency_map else dummy_dump_saliency_hook
+
+        prog_bar = ProgressBar(len(dataloader))
+        with model.module.backbone.register_forward_hook(feature_vector_hook):
+            with model.module.backbone.register_forward_hook(saliency_map_hook):
+                for data in dataloader:
+                    with torch.no_grad():
+                        result = model(return_loss=False, **data)
+                    eval_predictions.extend(result)
+                    for _ in range(len(data)):
+                        prog_bar.update()
+        prog_bar.file.write("\n")
+
+        for key in ["interval", "tmpdir", "start", "gpu_collect", "save_best", "rule", "dynamic_intervals"]:
+            cfg.evaluation.pop(key, None)
+
+        metric = None
+        metric_name = self._recipe_cfg.evaluation.final_metric
+        if inference_parameters:
+            if inference_parameters.is_evaluation:
+                metric = mm_dataset.evaluate(eval_predictions, **self._recipe_cfg.evaluation)[metric_name]
+
+        assert len(eval_predictions) == len(feature_vectors), f"{len(eval_predictions)} != {len(feature_vectors)}"
+        assert len(eval_predictions) == len(saliency_maps), f"{len(eval_predictions)} != {len(saliency_maps)}"
+        predictions = zip(eval_predictions, feature_vectors, saliency_maps)
+
+        return predictions, metric
+
+    def _export_model(self, precision: ModelPrecision, dump_features: bool = True):
+        """Main export function."""
+        self._init_task(export=True)
+
+        cfg = self.configure(False, "test", None)
+        deploy_cfg = self._init_deploy_cfg(cfg)
+
+        state_dict = torch.load(self._model_ckpt)
+        if "model" in state_dict.keys():
+            state_dict = state_dict["model"]
+
+        self._precision[0] = precision
+        half_precision = precision == ModelPrecision.FP16
+
+        exporter = Exporter(cfg, state_dict, deploy_cfg, f"{self._output_path}/openvino", half_precision)
+        exporter.export()
+        bin_file = [f for f in os.listdir(self._output_path) if f.endswith(".bin")][0]
+        xml_file = [f for f in os.listdir(self._output_path) if f.endswith(".xml")][0]
+        onnx_file = [f for f in os.listdir(self._output_path) if f.endswith(".onnx")][0]
+        results = {
+            "outputs": {
+                "bin": os.path.join(self._output_path, bin_file),
+                "xml": os.path.join(self._output_path, xml_file),
+                "onnx": os.path.join(self._output_path, onnx_file),
+            }
+        }
+        return results
+
+    # This should be removed
+    def update_override_configurations(self, config):
+        """Update override_configs."""
+        logger.info(f"update override config with: {config}")
+        config = ConfigDict(**config)
+        self.override_configs.update(config)
+
+    # This should moved somewhere
+    def _init_deploy_cfg(self, cfg: Config) -> Union[Config, None]:
+        base_dir = os.path.abspath(os.path.dirname(self._task_environment.model_template.model_template_path))
+        deploy_cfg_path = os.path.join(base_dir, "deployment.py")
+        deploy_cfg = None
+        if os.path.exists(deploy_cfg_path):
+            deploy_cfg = MPAConfig.fromfile(deploy_cfg_path)
+
+            def patch_input_preprocessing(deploy_cfg):
+                normalize_cfg = get_configs_by_pairs(
+                    cfg.data.test.pipeline,
+                    dict(type="Normalize"),
+                )
+                assert len(normalize_cfg) == 1
+                normalize_cfg = normalize_cfg[0]
 
-    def _get_feature_module(self, model):
-        return model
+                options = dict(flags=[], args={})
+                # NOTE: OTX loads image in RGB format
+                # so that `to_rgb=True` means a format change to BGR instead.
+                # Conventionally, OpenVINO IR expects a image in BGR format
+                # but OpenVINO IR under OTX assumes a image in RGB format.
+                #
+                # `to_rgb=True` -> a model was trained with images in BGR format
+                #                  and a OpenVINO IR needs to reverse input format from RGB to BGR
+                # `to_rgb=False` -> a model was trained with images in RGB format
+                #                   and a OpenVINO IR does not need to do a reverse
+                if normalize_cfg.get("to_rgb", False):
+                    options["flags"] += ["--reverse_input_channels"]
+                # value must be a list not a tuple
+                if normalize_cfg.get("mean", None) is not None:
+                    options["args"]["--mean_values"] = list(normalize_cfg.get("mean"))
+                if normalize_cfg.get("std", None) is not None:
+                    options["args"]["--scale_values"] = list(normalize_cfg.get("std"))
+
+                # fill default
+                backend_config = deploy_cfg.backend_config
+                if backend_config.get("mo_options") is None:
+                    backend_config.mo_options = ConfigDict()
+                mo_options = backend_config.mo_options
+                if mo_options.get("args") is None:
+                    mo_options.args = ConfigDict()
+                if mo_options.get("flags") is None:
+                    mo_options.flags = []
+
+                # already defiend options have higher priority
+                options["args"].update(mo_options.args)
+                mo_options.args = ConfigDict(options["args"])
+                # make sure no duplicates
+                mo_options.flags.extend(options["flags"])
+                mo_options.flags = list(set(mo_options.flags))
+
+            patch_input_preprocessing(deploy_cfg)
+            if not deploy_cfg.backend_config.get("model_inputs", []):
+                raise NotImplementedError("Video recognition task must specify model input info in deployment.py")
+
+        return deploy_cfg
+
+    # These need to be moved somewhere
+    def _update_caching_modules(self, data_cfg: Config) -> None:
+        def _find_max_num_workers(cfg: dict):
+            num_workers = [0]
+            for key, value in cfg.items():
+                if key == "workers_per_gpu" and isinstance(value, int):
+                    num_workers += [value]
+                elif isinstance(value, dict):
+                    num_workers += [_find_max_num_workers(value)]
+
+            return max(num_workers)
+
+        def _get_mem_cache_size():
+            if not hasattr(self._hyperparams.algo_backend, "mem_cache_size"):
+                return 0
+
+            return self._hyperparams.algo_backend.mem_cache_size
+
+        max_num_workers = _find_max_num_workers(data_cfg)
+        mem_cache_size = _get_mem_cache_size()
+
+        mode = "multiprocessing" if max_num_workers > 0 else "singleprocessing"
+        caching.MemCacheHandlerSingleton.create(mode, mem_cache_size)
+
+        update_or_add_custom_hook(
+            self._recipe_cfg,
+            ConfigDict(type="MemCacheHook", priority="VERY_LOW"),
+        )
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -11,17 +11,22 @@
     MPAConfig,
     align_data_config_with_recipe,
     config_from_string,
     get_data_cfg,
     get_dataset_configs,
     get_meta_keys,
     is_epoch_based_runner,
+    patch_adaptive_interval_training,
     patch_color_conversion,
     patch_data_pipeline,
     patch_default_config,
+    patch_early_stopping,
+    patch_fp16,
+    patch_from_hyperparams,
+    patch_persistent_workers,
     patch_runner,
     prepare_for_testing,
     prepare_work_dir,
     remove_from_config,
     remove_from_configs_by_type,
     update_config,
 )
@@ -35,17 +40,22 @@
     "get_configs_by_pairs",
     "get_configs_by_keys",
     "update_config",
     "get_dataset_configs",
     "prepare_for_testing",
     "is_epoch_based_runner",
     "config_from_string",
+    "patch_adaptive_interval_training",
     "patch_default_config",
     "patch_data_pipeline",
     "patch_color_conversion",
+    "patch_early_stopping",
+    "patch_from_hyperparams",
+    "patch_fp16",
+    "patch_persistent_workers",
     "patch_runner",
     "align_data_config_with_recipe",
     "get_meta_keys",
     "prepare_work_dir",
     "get_data_cfg",
     "MPAConfig",
 ]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_builder_build_data_parallel.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_builder_build_data_parallel.py`

 * *Files 16% similar despite different names*

```diff
@@ -8,16 +8,14 @@
 import os
 from typing import Literal, Union, overload
 
 import torch
 from mmcv import Config
 from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 
 @overload
 def build_data_parallel(
     model: torch.nn.Module,
     config: Config,
     *,
     distributed: Literal[True],
@@ -41,15 +39,14 @@
     config: Config,
     *,
     distributed: bool,
 ) -> Union[MMDataParallel, MMDistributedDataParallel]:
     ...
 
 
-@check_input_parameters_type()
 def build_data_parallel(
     model: torch.nn.Module,
     config: Config,
     *,
     distributed: bool = False,
 ) -> Union[MMDataParallel, MMDistributedDataParallel]:
     """Prepare model for execution.
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_keys.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_keys.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_pairs.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_pairs.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/builder.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/builder.py`

 * *Files 11% similar despite different names*

```diff
@@ -4,21 +4,18 @@
 #
 
 from typing import Callable
 
 from mmcv import Config
 from torch.utils.data import DataLoader, Dataset
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 # pylint: disable-next=unused-import
 from ._builder_build_data_parallel import build_data_parallel  # noqa: F401
 
 
-@check_input_parameters_type()
 def build_dataset(
     config: Config,
     subset: str,
     dataset_builder: Callable,
     *,
     consume: bool = False,
 ) -> Dataset:
@@ -30,15 +27,14 @@
         default_args = dict(test_mode=False)
 
     dataset_cfg = config.data.pop(subset) if consume else config.data.get(subset)
     dataset = dataset_builder(dataset_cfg, default_args)
     return dataset
 
 
-@check_input_parameters_type()
 def build_dataloader(
     dataset,
     config: Config,
     subset: str,
     dataloader_builder: Callable,
     *,
     distributed: bool = False,
@@ -74,14 +70,14 @@
             ]
         }
     )
 
     specific_loader_cfg = (
         config.data.pop(f"{subset}_dataloader", {}) if consume else config.data.get(f"{subset}_dataloader", {})
     )
-    loader_cfg = {**loader_cfg, **specific_loader_cfg, **kwargs}
+    loader_cfg = Config(cfg_dict={**loader_cfg, **specific_loader_cfg, **kwargs})
 
     dataloader = dataloader_builder(
         dataset,
         **loader_cfg,
     )
     return dataloader
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmcv/utils/config_utils.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/utils/config_utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -23,25 +23,22 @@
 import sys
 import tempfile
 import warnings
 from collections.abc import Mapping
 from importlib import import_module
 from typing import Any, Callable, Dict, List, Tuple, Union
 
+import torch
 from mmcv import Config, ConfigDict
 from mmcv.utils.config import BASE_KEY, DEPRECATION_KEY
 from mmcv.utils.misc import import_modules_from_strings
 from mmcv.utils.path import check_file_exist
 
 from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 
 from ._config_utils_get_configs_by_keys import get_configs_by_keys
 from ._config_utils_get_configs_by_pairs import get_configs_by_pairs
 
 logger = get_logger()
 
 
@@ -245,27 +242,25 @@
             found = True
             break
     if not found:
         custom_hooks.append(hook_cfg)
         cfg["custom_hooks"] = custom_hooks
 
 
-@check_input_parameters_type()
 def remove_from_config(config: Union[Config, ConfigDict], key: str):
     """Update & Remove configs."""
     if key in config:
         if isinstance(config, Config):
             del config._cfg_dict[key]  # pylint: disable=protected-access
         elif isinstance(config, ConfigDict):
             del config[key]
         else:
             raise ValueError(f"Unknown config type {type(config)}")
 
 
-@check_input_parameters_type()
 def remove_from_configs_by_type(configs: List[ConfigDict], type_name: str):
     """Update & remove by type."""
     indices = []
     for i, config in enumerate(configs):
         type_name_ = config.get("type", None)
         if type_name_ == type_name:
             indices.append(i)
@@ -291,15 +286,14 @@
                 assert isinstance(key, int), f"{key} of {path} must be int for ({type(ptr)}: {ptr})"
                 assert len(ptr) < key, f"{key} of {path} exceeds {len(ptr)}"
             if len(path_) == 0:
                 ptr[key] = value
             ptr = ptr[key]
 
 
-@check_input_parameters_type()
 def get_dataset_configs(config: Union[Config, ConfigDict], subset: str) -> List[ConfigDict]:
     """A function that retrieves 'datasets' configurations from the input `Config` object or `ConfigDict` object.
 
     :param config: Union[Config, ConfigDict], an instance of `Config` class or `ConfigDict` class containing the
                    configurations.
     :param subset: str, a string representing the subset for which the 'datasets' configuration is required.
     :return: List[ConfigDict], a list of 'datasets' configuration dictionaries.
@@ -307,78 +301,71 @@
     if config.data.get(subset, None) is None:
         return []
     data_cfg = config.data[subset]
     data_cfgs = get_configs_by_keys(data_cfg, ["dataset", "datasets"])
     return data_cfgs if data_cfgs else [data_cfg]
 
 
-@check_input_parameters_type({"dataset": DatasetParamTypeCheck})
 def prepare_for_testing(config: Union[Config, ConfigDict], dataset: DatasetEntity) -> Config:
     """Prepare configs for testing phase."""
     config = copy.deepcopy(config)
     # FIXME. Should working directories be modified here?
     config.data.test.otx_dataset = dataset
     return config
 
 
-@check_input_parameters_type()
 def is_epoch_based_runner(runner_config: ConfigDict):
     """Check Epoch based or Iter based runner."""
     return "Epoch" in runner_config.type
 
 
-@check_input_parameters_type()
 def config_from_string(config_string: str) -> Config:
     """Generate an mmcv config dict object from a string.
 
     :param config_string: string to parse
     :return config: configuration object
     """
     with tempfile.NamedTemporaryFile("w", suffix=".py") as temp_file:
         temp_file.write(config_string)
         temp_file.flush()
         return Config.fromfile(temp_file.name)
 
 
-@check_input_parameters_type()
 def patch_default_config(config: Config):
     """Patch default config."""
     if "runner" not in config:
         config.runner = ConfigDict({"type": "EpochBasedRunner"})
     if "log_config" not in config:
         config.log_config = ConfigDict()
     if "evaluation" not in config:
         config.evaluation = ConfigDict()
     if "checkpoint_config" not in config:
         config.checkpoint_config = ConfigDict({"type": "CheckpointHook", "interval": 1})
 
 
-@check_input_parameters_type()
 def patch_data_pipeline(config: Config, data_pipeline: str = ""):
     """Replace data pipeline to data_pipeline.py if it exist."""
     if os.path.isfile(data_pipeline):
         data_pipeline_cfg = Config.fromfile(data_pipeline)
         config.merge_from_dict(data_pipeline_cfg)
     else:
         raise FileNotFoundError(f"data_pipeline: {data_pipeline} not founded")
 
 
-@check_input_parameters_type()
 def patch_color_conversion(config: Config):
     """Patch color conversion."""
     assert "data" in config
 
     for cfg in get_configs_by_pairs(config.data, dict(type="Normalize")):
         to_rgb = False
         if "to_rgb" in cfg:
             to_rgb = cfg.to_rgb
         cfg.to_rgb = not bool(to_rgb)
 
 
-@check_input_parameters_type()
 def patch_runner(config: Config):
     """Patch runner."""
     assert "runner" in config
 
     # Check that there is no conflict in specification of number of training epochs.
     # Move global definition of epochs inside runner config.
     if "total_epochs" in config:
@@ -387,23 +374,151 @@
                 logger.warning("Conflicting declaration of training epochs number.")
             config.runner.max_epochs = config.total_epochs
         else:
             logger.warning(f"Total number of epochs set for an iteration based runner {config.runner.type}.")
         remove_from_config(config, "total_epochs")
 
     # Change runner's type.
-    if is_epoch_based_runner(config.runner) and config.runner.type != "EpochRunnerWithCancel":
-        logger.info(f"Replacing runner from {config.runner.type} to EpochRunnerWithCancel.")
-        config.runner.type = "EpochRunnerWithCancel"
-    elif not is_epoch_based_runner(config.runner) and config.runner.type != "IterBasedRunnerWithCancel":
-        logger.info(f"Replacing runner from {config.runner.type} to IterBasedRunnerWithCancel.")
-        config.runner.type = "IterBasedRunnerWithCancel"
+    if config.runner.type != "AccuracyAwareRunner":
+        if is_epoch_based_runner(config.runner) and config.runner.type != "EpochRunnerWithCancel":
+            logger.info(f"Replacing runner from {config.runner.type} to EpochRunnerWithCancel.")
+            config.runner.type = "EpochRunnerWithCancel"
+        elif not is_epoch_based_runner(config.runner) and config.runner.type != "IterBasedRunnerWithCancel":
+            logger.info(f"Replacing runner from {config.runner.type} to IterBasedRunnerWithCancel.")
+            config.runner.type = "IterBasedRunnerWithCancel"
+
+
+def patch_fp16(config: Config):
+    """Remove FP16 config if running on CPU device and revert to FP32.
+
+    Please refer https://github.com/pytorch/pytorch/issues/23377
+    """
+    if not torch.cuda.is_available() and "fp16" in config:
+        logger.info("Revert FP16 to FP32 on CPU device")
+        if isinstance(config, Config):
+            del config._cfg_dict["fp16"]  # pylint: disable=protected-access
+        elif isinstance(config, ConfigDict):
+            del config["fp16"]
+
+
+def patch_adaptive_interval_training(config: Config):
+    """Update adaptive interval settings for OTX training.
+
+    This function can be removed by adding custom hook cfg into recipe.py directly.
+    """
+    # default adaptive hook for evaluating before and after training
+    add_custom_hook_if_not_exists(
+        config,
+        ConfigDict(
+            type="AdaptiveTrainSchedulingHook",
+            enable_adaptive_interval_hook=False,
+            enable_eval_before_run=True,
+        ),
+    )
+    # Add/remove adaptive interval hook
+    if config.get("use_adaptive_interval", False):
+        update_or_add_custom_hook(
+            config,
+            ConfigDict(
+                {
+                    "type": "AdaptiveTrainSchedulingHook",
+                    "max_interval": 5,
+                    "enable_adaptive_interval_hook": True,
+                    "enable_eval_before_run": True,
+                    **config.pop("adaptive_validation_interval", {}),
+                }
+            ),
+        )
+    else:
+        config.pop("adaptive_validation_interval", None)
+
+
+def patch_early_stopping(config: Config):
+    """Update early stop settings for OTX training.
+
+    This function can be removed by adding custom hook cfg into recipe.py directly.
+    """
+    if "early_stop" in config:
+        remove_custom_hook(config, "EarlyStoppingHook")
+        early_stop = config.get("early_stop", False)
+        if early_stop:
+            early_stop_hook = ConfigDict(
+                type="LazyEarlyStoppingHook",
+                start=early_stop.start,
+                patience=early_stop.patience,
+                iteration_patience=early_stop.iteration_patience,
+                interval=1,
+                metric=config.early_stop_metric,
+                priority=75,
+            )
+            update_or_add_custom_hook(config, early_stop_hook)
+        else:
+            remove_custom_hook(config, "LazyEarlyStoppingHook")
+
+    # make sure model to be in a training mode even after model is evaluated (mmcv bug)
+    update_or_add_custom_hook(
+        config,
+        ConfigDict(type="ForceTrainModeHook", priority="LOWEST"),
+    )
+
+
+def patch_persistent_workers(config: Config):
+    """If num_workers is 0, persistent_workers must be False."""
+    data_cfg = config.data
+    for subset in ["train", "val", "test", "unlabeled"]:
+        if subset not in data_cfg:
+            continue
+        dataloader_cfg = data_cfg.get(f"{subset}_dataloader", ConfigDict())
+        workers_per_gpu = dataloader_cfg.get(
+            "workers_per_gpu",
+            data_cfg.get("workers_per_gpu", 0),
+        )
+        if workers_per_gpu == 0:
+            dataloader_cfg["persistent_workers"] = False
+            data_cfg[f"{subset}_dataloader"] = dataloader_cfg
+
+
+def patch_from_hyperparams(config: Config, hyperparams):
+    """Patch config parameters from hyperparams."""
+    params = hyperparams.learning_parameters
+    warmup_iters = int(params.learning_rate_warmup_iters)
+    lr_config = (
+        ConfigDict(warmup_iters=warmup_iters)
+        if warmup_iters > 0
+        else ConfigDict(warmup_iters=warmup_iters, warmup=None)
+    )
+
+    if params.enable_early_stopping and config.get("evaluation", None):
+        early_stop = ConfigDict(
+            start=int(params.early_stop_start),
+            patience=int(params.early_stop_patience),
+            iteration_patience=int(params.early_stop_iteration_patience),
+        )
+    else:
+        early_stop = False
+
+    runner = ConfigDict(max_epochs=int(params.num_iters))
+    if config.get("runner", None) and config.runner.get("type").startswith("IterBasedRunner"):
+        runner = ConfigDict(max_iters=int(params.num_iters))
+
+    hparams = ConfigDict(
+        optimizer=ConfigDict(lr=params.learning_rate),
+        lr_config=lr_config,
+        early_stop=early_stop,
+        data=ConfigDict(
+            samples_per_gpu=int(params.batch_size),
+            workers_per_gpu=int(params.num_workers),
+        ),
+        runner=runner,
+    )
+
+    hparams["use_adaptive_interval"] = hyperparams.learning_parameters.use_adaptive_interval
+    config.merge_from_dict(hparams)
 
 
-@check_input_parameters_type()
 def align_data_config_with_recipe(data_config: ConfigDict, config: Union[Config, ConfigDict]):
     """Align data_cfg with recipe_cfg."""
     # we assumed config has 'otx_dataset' and 'labels' key in it
     # by 'patch_datasets' function
 
     data_config = data_config.data
     config = config.data
@@ -426,36 +541,35 @@
     "scale_factor",
     "flip",
     "flip_direction",
     "img_norm_cfg",
 )
 
 
-def get_meta_keys(pipeline_step):
+def get_meta_keys(pipeline_step, add_meta_keys: List[str] = []):
     """Update meta_keys for ignore_labels."""
     meta_keys = list(pipeline_step.get("meta_keys", DEFAULT_META_KEYS))
     meta_keys.append("ignored_labels")
+    meta_keys += add_meta_keys
     pipeline_step["meta_keys"] = set(meta_keys)
     return pipeline_step
 
 
-@check_input_parameters_type()
 def prepare_work_dir(config: Union[Config, ConfigDict]) -> str:
     """Prepare configs of working directory."""
     base_work_dir = config.work_dir
     checkpoint_dirs = glob.glob(os.path.join(base_work_dir, "checkpoints_round_*"))
     train_round_checkpoint_dir = os.path.join(base_work_dir, f"checkpoints_round_{len(checkpoint_dirs)}")
     os.makedirs(train_round_checkpoint_dir)
     config.work_dir = train_round_checkpoint_dir
     if "meta" not in config.runner:
         config.runner.meta = ConfigDict()
     config.runner.meta.exp_name = f"train_round_{len(checkpoint_dirs)}"
     return train_round_checkpoint_dir
 
 
-@check_input_parameters_type()
 def get_data_cfg(config: Union[Config, ConfigDict], subset: str = "train") -> Config:
     """Return dataset configs."""
     data_cfg = config.data[subset]
     while "dataset" in data_cfg:
         data_cfg = data_cfg.dataset
     return data_cfg
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/apis.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/apis.py`

 * *Files 4% similar despite different names*

```diff
@@ -170,14 +170,15 @@
         )
 
 
 if is_mmdeploy_enabled():
     import mmdeploy.apis.openvino as openvino_api
     from mmdeploy.apis import build_task_processor, extract_model, torch2onnx
     from mmdeploy.apis.openvino import get_input_info_from_cfg, get_mo_options_from_cfg
+    from mmdeploy.core import reset_mark_function_count
 
     # from mmdeploy.core import FUNCTION_REWRITER
     from mmdeploy.utils import get_ir_config, get_partition_config
 
     class MMdeployExporter:
         """MMdeployExporter for mmdeploy exporting."""
 
@@ -209,49 +210,82 @@
 
                 input_data = cv2.imread(input_data_cfg.get("file_path"))
                 # image assumed to be RGB format under OTX
                 input_data = cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB)
             else:
                 input_data = np.zeros(input_data_cfg["shape"], dtype=np.uint8)
 
+            partition_cfgs = get_partition_config(deploy_cfg)
+            if partition_cfgs:
+                MMdeployExporter.extract_partition(
+                    output_dir,
+                    input_data,
+                    cfg,
+                    deploy_cfg,
+                    model_name=model_name,
+                )
+
             onnx_paths = []
             onnx_paths.append(
                 MMdeployExporter.torch2onnx(
                     output_dir,
                     input_data,
                     cfg,
                     deploy_cfg,
                     model_name=model_name,
                 )
             )
 
-            partition_cfgs = get_partition_config(deploy_cfg)
-            if partition_cfgs:
-                partition_cfgs = partition_cfgs.get("partition_cfg", None)
-                onnx_paths.extend(
-                    MMdeployExporter.partition_onnx(
-                        output_dir,
-                        onnx_paths[0],
-                        partition_cfgs,
-                    )
-                )
-
-            for i, onnx_path in enumerate(onnx_paths):
-                mo_options = {}
-                if i > 0:
-                    mo_options = partition_cfgs[i - 1].get("mo_options", {})
+            for onnx_path in onnx_paths:
                 deploy_cfg_ = deepcopy(deploy_cfg)
-                update_deploy_cfg(onnx_path, deploy_cfg_, mo_options)
+                update_deploy_cfg(onnx_path, deploy_cfg_)
                 MMdeployExporter.onnx2openvino(
                     output_dir,
                     onnx_path,
                     deploy_cfg_,
                 )
 
         @staticmethod
+        def extract_partition(
+            output_dir: str,
+            input_data: Any,
+            cfg: mmcv.Config,
+            deploy_cfg: mmcv.Config,
+            *,
+            model_name: str = "model",
+        ):
+            """Function for extracting partition."""
+
+            model_onnx = MMdeployExporter.torch2onnx(
+                output_dir,
+                input_data,
+                cfg,
+                deploy_cfg,
+                model_name=model_name,
+            )
+
+            partition_cfgs = get_partition_config(deploy_cfg)
+            partition_cfgs = partition_cfgs.get("partition_cfg", None)
+            partition_onnx = MMdeployExporter.partition_onnx(
+                output_dir,
+                model_onnx,
+                partition_cfgs,
+            )
+
+            deploy_cfg_ = deepcopy(deploy_cfg)
+            update_deploy_cfg(partition_onnx[0], deploy_cfg_)
+            MMdeployExporter.onnx2openvino(
+                output_dir,
+                partition_onnx[0],
+                deploy_cfg_,
+            )
+            deploy_cfg["partition_config"]["apply_marks"] = False
+            reset_mark_function_count()
+
+        @staticmethod
         def torch2onnx(
             output_dir: str,
             input_data: Any,
             cfg: mmcv.Config,
             deploy_cfg: mmcv.Config,
             *,
             model_name: str = "model",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/mmdeploy.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/mmdeploy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/mmdeploy/utils/utils.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmdeploy/utils/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/compression.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/compression.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/config.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/config.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/patches.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/patches.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/nncf/utils/utils.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/nncf/utils/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/composed_dataloader.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/composed_dataloader.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/balanced_sampler.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/balanced_sampler.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/cls_incr_sampler.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/torch/dataloaders/samplers/cls_incr_sampler.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/configs/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/configs/configuration_enums.py` & `otx-1.2.0rc1/otx/algorithms/common/configs/configuration_enums.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/configs/training_base.py` & `otx-1.2.0rc1/otx/algorithms/common/configs/training_base.py`

 * *Files 3% similar despite different names*

```diff
@@ -303,14 +303,26 @@
             default_value=False,
             header="Enable tiling",
             description="Set to True to allow tiny objects to be better detected.",
             warning="Tiling trades off speed for accuracy as it increases the number of images to be processed.",
             affects_outcome_of=ModelLifecycle.NONE,
         )
 
+        enable_tile_classifier = configurable_boolean(
+            default_value=False,
+            header="Enable tile classifier",
+            description="Enabling tile classifier enhances the speed of tiling inference by incorporating a tile "
+            "classifier into the instance segmentation model. This feature prevents the detector from "
+            "making predictions on tiles that do not contain any objects, thus optimizing its "
+            "speed performance.",
+            warning="The tile classifier prioritizes inference speed over training speed, it requires more training "
+            "in order to achieve its optimized performance.",
+            affects_outcome_of=ModelLifecycle.NONE,
+        )
+
         enable_adaptive_params = configurable_boolean(
             default_value=True,
             header="Enable adaptive tiling parameters",
             description="Config tile size and tile overlap adaptively based on annotated dataset statistic",
             warning="",
             affects_outcome_of=ModelLifecycle.NONE,
         )
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/tasks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,15 @@
-"""Task Initialization of OTX Common Algorithms."""
+"""Initialization of OCR-Lite-HRnet-18 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
-
-from .training_base import BaseTask
-
-__all__ = ["BaseTask"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/tasks/nncf_base.py` & `otx-1.2.0rc1/otx/algorithms/common/tasks/nncf_task.py`

 * *Files 2% similar despite different names*

```diff
@@ -49,52 +49,49 @@
     OptimizationMethod,
 )
 from otx.api.entities.optimization_parameters import (
     OptimizationParameters,
     default_progress_callback,
 )
 from otx.api.entities.subset import Subset
-from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.serialization.label_mapper import label_schema_to_bytes
 from otx.api.usecases.tasks.interfaces.optimization_interface import (
     IOptimizationTask,
     OptimizationType,
 )
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
-
-from .training_base import BaseTask
 
 logger = get_logger()
 
 
-class NNCFBaseTask(BaseTask, IOptimizationTask):  # pylint: disable=too-many-instance-attributes
+class NNCFBaseTask(IOptimizationTask):  # pylint: disable=too-many-instance-attributes
     """NNCFBaseTask."""
 
-    @check_input_parameters_type()
-    def __init__(self, task_environment: TaskEnvironment, **kwargs):
-        super().__init__(task_environment, **kwargs)
-
-        # Set default model attributes.
+    def __init__(self):
         check_nncf_is_enabled()
         self._nncf_data_to_build = None
         self._nncf_state_dict_to_build: Dict[str, torch.Tensor] = {}
         self._nncf_preset = None
         self._optimization_methods: List[OptimizationMethod] = []
         self._precision = [ModelPrecision.FP32]
 
         # Extra control variables.
         self._training_work_dir = None
         self._is_training = False
         self._should_stop = False
         self._optimization_type = ModelOptimizationType.NNCF
+        self._time_monitor = None
 
-        self._set_attributes_by_hyperparams()
+        # Variables will be set in training backend task
+        self._data_cfg = None
+        self._model_ckpt = None
+        self._model_dir = None
+        self._labels = None
+        self._recipe_cfg = None
+        self._hyperparams = None
+        self._task_environment = None
 
         logger.info("Task initialization completed")
 
     def _set_attributes_by_hyperparams(self):
         quantization = self._hyperparams.nncf_optimization.enable_quantization
         pruning = self._hyperparams.nncf_optimization.enable_pruning
         if quantization and pruning:
@@ -131,16 +128,15 @@
                     otx_dataset=subset,
                     labels=self._labels,
                 )
 
         return data_cfg
 
     def _init_nncf_cfg(self):
-        base_dir = os.path.abspath(os.path.dirname(self.template_file_path))
-        nncf_config_path = os.path.join(base_dir, "compression_config.json")
+        nncf_config_path = os.path.join(self._model_dir, "compression_config.json")
 
         with open(nncf_config_path, encoding="UTF-8") as nncf_config_file:
             common_nncf_config = json.load(nncf_config_file)
 
         optimization_config = compose_nncf_config(common_nncf_config, [self._nncf_preset])
 
         max_acc_drop = self._hyperparams.nncf_optimization.maximal_accuracy_degradation / 100
@@ -154,16 +150,15 @@
             # Force evaluation interval
             self._recipe_cfg.evaluation.interval = 1
         else:
             logger.info("NNCF config has no accuracy_aware_training parameters")
 
         return ConfigDict(optimization_config)
 
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
+    def _prepare_optimize(self):
         assert self._recipe_cfg is not None
 
         # TODO: more delicate configuration change control in MPA side
 
         # last batch size of 1 causes undefined behaviour for batch normalization
         # when initializing and training NNCF
         if self._data_cfg is not None:
@@ -261,15 +256,14 @@
     def _optimize_post_hook(
         self,
         dataset: DatasetEntity,
         output_model: ModelEntity,
     ):
         pass
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def optimize(
         self,
         optimization_type: OptimizationType,
         dataset: DatasetEntity,
         output_model: ModelEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
@@ -319,15 +313,14 @@
         output_model.precision = self._precision
 
         self._is_training = False
 
     def _save_model_post_hook(self, modelinfo):
         pass
 
-    @check_input_parameters_type()
     def save_model(self, output_model: ModelEntity):
         """Saving model function for NNCF Task."""
         assert self._recipe_cfg is not None
 
         buffer = io.BytesIO()
         hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
         labels = {label.name: label.color.rgb_tuple for label in self._labels}
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/tasks/training_base.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/task.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,292 +1,120 @@
-"""BaseTask for Classification/Detection/Segmentation."""
+"""Task of OTX Segmentation using mmsegmentation training backend."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-
-import abc
+import glob
 import io
 import os
-import shutil
-import tempfile
+import time
+from contextlib import nullcontext
 from copy import deepcopy
-from typing import Dict, List, Optional, Union
+from typing import Any, Dict, Optional, Union
 
-import numpy as np
 import torch
-from mmcv.utils.config import Config, ConfigDict
-
-from otx.algorithms.common.adapters.mmcv.hooks import OTXLoggerHook
-from otx.algorithms.common.adapters.mmcv.hooks.cancel_hook import CancelInterfaceHook
-from otx.algorithms.common.adapters.mmcv.tasks.builder import build
-from otx.algorithms.common.adapters.mmcv.tasks.stage import Stage
+from mmcv.runner import wrap_fp16_model
+from mmcv.utils import Config, ConfigDict, get_git_hash
+from mmseg import __version__
+from mmseg.apis import train_segmentor
+from mmseg.datasets import build_dataloader, build_dataset
+from mmseg.utils import collect_env
+
+from otx.algorithms.common.adapters.mmcv.hooks.recording_forward_hook import (
+    BaseRecordingForwardHook,
+    FeatureVectorHook,
+)
 from otx.algorithms.common.adapters.mmcv.utils import (
-    align_data_config_with_recipe,
+    build_data_parallel,
     get_configs_by_pairs,
+    patch_data_pipeline,
+    patch_from_hyperparams,
 )
 from otx.algorithms.common.adapters.mmcv.utils.config_utils import (
     MPAConfig,
-    add_custom_hook_if_not_exists,
-    remove_custom_hook,
     update_or_add_custom_hook,
 )
-from otx.algorithms.common.configs import TrainType
-from otx.algorithms.common.utils import UncopiableDefaultDict
+from otx.algorithms.common.configs.training_base import TrainType
+from otx.algorithms.common.utils import set_random_seed
+from otx.algorithms.common.utils.data import get_dataset
 from otx.algorithms.common.utils.logger import get_logger
+from otx.algorithms.segmentation.adapters.mmseg.configurer import (
+    IncrSegmentationConfigurer,
+    SegmentationConfigurer,
+    SemiSLSegmentationConfigurer,
+)
+from otx.algorithms.segmentation.adapters.mmseg.utils.builder import build_segmentor
+from otx.algorithms.segmentation.adapters.mmseg.utils.exporter import SegmentationExporter
+from otx.algorithms.segmentation.task import OTXSegmentationTask
+
+# from otx.algorithms.segmentation.utils import get_det_model_api_configuration
+from otx.api.configuration import cfg_helper
+from otx.api.configuration.helper.utils import ids_to_strings
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.label import LabelEntity
-from otx.api.entities.model import ModelEntity, ModelPrecision, OptimizationMethod
+from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.model import (
+    ModelEntity,
+    ModelPrecision,
+)
+from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
-from otx.api.serialization.label_mapper import LabelSchemaMapper
-from otx.api.usecases.reporting.time_monitor_callback import TimeMonitorCallback
-from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
-from otx.api.usecases.tasks.interfaces.export_interface import IExportTask
-from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
-from otx.api.usecases.tasks.interfaces.unload_interface import IUnload
-from otx.api.utils.argument_checks import check_input_parameters_type
+from otx.api.serialization.label_mapper import label_schema_to_bytes
 from otx.core.data import caching
 
 logger = get_logger()
-TRAIN_TYPE_DIR_PATH = {
-    TrainType.Incremental.name: ".",
-    TrainType.Selfsupervised.name: "selfsl",
-    TrainType.Semisupervised.name: "semisl",
-}
-
-
-# pylint: disable=too-many-instance-attributes, protected-access
-class BaseTask(IInferenceTask, IExportTask, IEvaluationTask, IUnload):
-    """BaseTask for OTX Algorithms."""
-
-    _task_environment: TaskEnvironment
-
-    @check_input_parameters_type()
-    def __init__(self, task_config, task_environment: TaskEnvironment, output_path: Optional[str] = None):
-        self._task_config = task_config
-        self._task_environment = task_environment
-        self._hyperparams = task_environment.get_hyper_parameters(self._task_config)  # type: ConfigDict
-        self._model_name = task_environment.model_template.name
-        self._task_type = task_environment.model_template.task_type
-        self._labels = task_environment.get_labels(include_empty=False)
-        self.confidence_threshold = self._get_confidence_threshold(self._hyperparams)
-        # Set default model attributes.
-        self._model_label_schema = []  # type: List[LabelEntity]
-        self._optimization_methods = []  # type: List[OptimizationMethod]
-        self._model_ckpt = None
-        self._resume = False
-        self._anchors = {}  # type: Dict[str, int]
-        self._work_dir_is_temp = False
-        if output_path is None:
-            output_path = tempfile.mkdtemp(prefix="OTX-task-")
-            self._work_dir_is_temp = True
-        self._output_path = output_path
-        logger.info(f"created output path at {self._output_path}")
-        if task_environment.model is not None:
-            logger.info("loading the model from the task env.")
-            state_dict = self._load_model_ckpt(self._task_environment.model)
-            if state_dict:
-                self._model_ckpt = os.path.join(self._output_path, "env_model_ckpt.pth")
-                if os.path.exists(self._model_ckpt):
-                    os.remove(self._model_ckpt)
-                torch.save(state_dict, self._model_ckpt)
-                self._model_label_schema = self._load_model_label_schema(self._task_environment.model)
-                self._resume = self._load_resume_info(self._task_environment.model)
-
-        # property below will be initialized by initialize()
-        self._recipe_cfg = None
-        self._stage_module = None
-        self._precision = [ModelPrecision.FP32]
-        self._data_cfg = None
-        self._mode = None
-        self._time_monitor = None  # type: Optional[TimeMonitorCallback]
-        self._learning_curves = UncopiableDefaultDict(OTXLoggerHook.Curve)
-        self._is_training = False
-        self._should_stop = False
-        self.cancel_interface = None  # type: Optional[CancelInterfaceHook]
-        self.reserved_cancel = False
-        self.on_hook_initialized = self.OnHookInitialized(self)
-
-        # Initialize Train type related var
-        self._train_type = self._hyperparams.algo_backend.train_type
-        self._model_dir = os.path.join(
-            os.path.abspath(os.path.dirname(self.template_file_path)), TRAIN_TYPE_DIR_PATH[self._train_type.name]
-        )
 
-        # to override configuration at runtime
-        self.override_configs = {}  # type: Dict[str, str]
+# TODO Remove unnecessary pylint disable
+# pylint: disable=too-many-lines
 
-    def _run_task(self, stage_module, mode=None, dataset=None, **kwargs):
-        self._initialize(kwargs)
-        stage_module = self._update_stage_module(stage_module)
 
-        if mode is not None:
-            self._mode = mode
+class MMSegmentationTask(OTXSegmentationTask):
+    """Task class for OTX segmentation using mmsegmentation training backend."""
 
-        # deepcopy all configs to make sure
-        # changes under MPA and below does not take an effect to OTX for clear distinction
-        recipe_cfg = deepcopy(self._recipe_cfg)
-        data_cfg = deepcopy(self._data_cfg)
-        assert recipe_cfg is not None, "'recipe_cfg' is not initialized."
+    # pylint: disable=too-many-instance-attributes
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__(task_environment, output_path)
+        self._data_cfg: Optional[Config] = None
+        self._recipe_cfg: Optional[Config] = None
+
+    # pylint: disable=too-many-locals, too-many-branches, too-many-statements
+    def _init_task(self, export: bool = False):  # noqa
+        """Initialize task."""
+        self._recipe_cfg = MPAConfig.fromfile(os.path.join(self._model_dir, "model.py"))
+        self._recipe_cfg.domain = self._task_type.domain
+        self._config = self._recipe_cfg
 
-        # update model config -> model label schema
-        data_classes = [label.name for label in self._labels]
-        model_classes = [label.name for label in self._model_label_schema]
-        recipe_cfg["model_classes"] = model_classes
-        if dataset is not None:
-            train_data_cfg = Stage.get_data_cfg(data_cfg, "train")
-            train_data_cfg["data_classes"] = data_classes
-            new_classes = np.setdiff1d(data_classes, model_classes).tolist()
-            train_data_cfg["new_classes"] = new_classes
-
-        logger.info(  # pylint: disable=logging-not-lazy
-            "running task... kwargs = "
-            + str({k: v if k != "model_builder" else object.__repr__(v) for k, v in kwargs.items()})
-        )
-
-        common_cfg = ConfigDict(dict(output_path=self._output_path, resume=self._resume))
-
-        # build workflow using recipe configuration
-        workflow = build(
-            recipe_cfg,
-            self._mode,
-            stage_type=stage_module,
-            common_cfg=common_cfg,
-        )
-
-        # run workflow with task specific model config and data config
-        output = workflow.run(
-            model_cfg=recipe_cfg,
-            data_cfg=data_cfg,
-            ir_model_path=None,
-            ir_weight_path=None,
-            model_ckpt=self._model_ckpt,
-            mode=self._mode,
-            **kwargs,
-        )
-        logger.info("run task done.")
-        return output
+        set_random_seed(self._recipe_cfg.get("seed", 5), logger, self._recipe_cfg.get("deterministic", False))
 
-    def _delete_scratch_space(self):
-        """Remove model checkpoints and mpa logs."""
-        if os.path.exists(self._output_path):
-            shutil.rmtree(self._output_path, ignore_errors=False)
-
-    def _pre_task_run(self):
-        pass
-
-    @property
-    def project_path(self):
-        """Return output path with logs."""
-        return self._output_path
-
-    @property
-    def model_name(self):
-        """Name of Model Template."""
-        return self._task_environment.model_template.name
-
-    @property
-    def labels(self):
-        """Label List of Task Environment."""
-        return self._task_environment.get_labels(False)
-
-    @property
-    def template_file_path(self):
-        """Model Template file path."""
-        return self._task_environment.model_template.model_template_path
-
-    @property
-    def data_pipeline_path(self):
-        """Base Data Pipeline file path."""
-        # TODO: Temporarily use data_pipeline.py next to model.py.may change later.
-        if self._hyperparams.tiling_parameters.enable_tiling:
-            return os.path.join(self._model_dir, "tile_pipeline.py")
-        return os.path.join(self._model_dir, "data_pipeline.py")
-
-    @property
-    def hyperparams(self):
-        """Hyper Parameters configuration."""
-        return self._hyperparams
-
-    # pylint: disable-next=too-many-branches,too-many-statements
-    def _initialize(self, options=None):  # noqa: C901
-        """Prepare configurations to run a task through MPA's stage."""
-        if options is None:
-            options = {}
-
-        export = options.get("export", False)
-        fp16_export = options.get("enable_fp16", False)
-
-        logger.info("initializing....")
-        self._init_recipe()
+        # Belows may go to the configure function
+        patch_data_pipeline(self._recipe_cfg, self.data_pipeline_path)
 
         if not export:
-            # FIXME: Temporary remedy for CVS-88098
-            recipe_hparams = self._init_recipe_hparam()
-            if len(recipe_hparams) > 0:
-                self._recipe_cfg.merge_from_dict(recipe_hparams)
+            patch_from_hyperparams(self._recipe_cfg, self._hyperparams)
 
         if "custom_hooks" in self.override_configs:
             override_custom_hooks = self.override_configs.pop("custom_hooks")
             for override_custom_hook in override_custom_hooks:
                 update_or_add_custom_hook(self._recipe_cfg, ConfigDict(override_custom_hook))
         if len(self.override_configs) > 0:
             logger.info(f"before override configs merging = {self._recipe_cfg}")
             self._recipe_cfg.merge_from_dict(self.override_configs)
             logger.info(f"after override configs merging = {self._recipe_cfg}")
 
-        # Remove FP16 config if running on CPU device and revert to FP32
-        # https://github.com/pytorch/pytorch/issues/23377
-        if not torch.cuda.is_available() and "fp16" in self._recipe_cfg:
-            logger.info("Revert FP16 to FP32 on CPU device")
-            if isinstance(self._recipe_cfg, Config):
-                del self._recipe_cfg._cfg_dict["fp16"]
-            elif isinstance(self._recipe_cfg, ConfigDict):
-                del self._recipe_cfg["fp16"]
-
-        # default adaptive hook for evaluating before and after training
-        add_custom_hook_if_not_exists(
-            self._recipe_cfg,
-            ConfigDict(
-                type="AdaptiveTrainSchedulingHook",
-                enable_adaptive_interval_hook=False,
-                enable_eval_before_run=True,
-            ),
-        )
-        # Add/remove adaptive interval hook
-        if self._recipe_cfg.get("use_adaptive_interval", False):
-            update_or_add_custom_hook(
-                self._recipe_cfg,
-                ConfigDict(
-                    {
-                        "type": "AdaptiveTrainSchedulingHook",
-                        "max_interval": 5,
-                        "enable_adaptive_interval_hook": True,
-                        "enable_eval_before_run": True,
-                        **self._recipe_cfg.pop("adaptive_validation_interval", {}),
-                    }
-                ),
-            )
-        else:
-            self._recipe_cfg.pop("adaptive_validation_interval", None)
-
-        self.set_early_stopping_hook()
-
-        # add Cancel tranining hook
+        # add Cancel training hook
         update_or_add_custom_hook(
             self._recipe_cfg,
             ConfigDict(type="CancelInterfaceHook", init_callback=self.on_hook_initialized),
         )
         if self._time_monitor is not None:
             update_or_add_custom_hook(
                 self._recipe_cfg,
@@ -295,130 +123,330 @@
                     time_monitor=self._time_monitor,
                     verbose=True,
                     priority=71,
                 ),
             )
         self._recipe_cfg.log_config.hooks.append({"type": "OTXLoggerHook", "curves": self._learning_curves})
 
-        # make sure model to be in a training mode even after model is evaluated (mmcv bug)
-        update_or_add_custom_hook(
-            self._recipe_cfg,
-            ConfigDict(type="ForceTrainModeHook", priority="LOWEST"),
+        # Update recipe with caching modules
+        self._update_caching_modules(self._recipe_cfg.data)
+
+        logger.info("initialized.")
+
+    # pylint: disable=too-many-arguments
+    def configure(
+        self,
+        training=True,
+        subset="train",
+        ir_options=None,
+    ):
+        """Patch mmcv configs for OTX segmentation settings."""
+
+        # deepcopy all configs to make sure
+        # changes under MPA and below does not take an effect to OTX for clear distinction
+        recipe_cfg = deepcopy(self._recipe_cfg)
+        data_cfg = deepcopy(self._data_cfg)
+        assert recipe_cfg is not None, "'recipe_cfg' is not initialized."
+
+        if self._data_cfg is not None:
+            data_classes = [label.name for label in self._labels]
+        else:
+            data_classes = None
+        model_classes = [label.name for label in self._model_label_schema]
+
+        recipe_cfg.work_dir = self._output_path
+        recipe_cfg.resume = self._resume
+
+        if self._train_type == TrainType.Incremental:
+            configurer = IncrSegmentationConfigurer()
+        elif self._train_type == TrainType.Semisupervised:
+            configurer = SemiSLSegmentationConfigurer()
+        else:
+            configurer = SegmentationConfigurer()
+        cfg = configurer.configure(
+            recipe_cfg, self._model_ckpt, data_cfg, training, subset, ir_options, data_classes, model_classes
         )
+        self._config = cfg
+        return cfg
 
-        # if num_workers is 0, persistent_workers must be False
-        data_cfg = self._recipe_cfg.data
-        for subset in ["train", "val", "test", "unlabeled"]:
-            if subset not in data_cfg:
-                continue
-            dataloader_cfg = data_cfg.get(f"{subset}_dataloader", ConfigDict())
-            workers_per_gpu = dataloader_cfg.get(
-                "workers_per_gpu",
-                data_cfg.get("workers_per_gpu", 0),
+    def build_model(
+        self,
+        cfg: Config,
+        fp16: bool = False,
+        **kwargs,
+    ) -> torch.nn.Module:
+        """Build model from model_builder."""
+        model_builder = getattr(self, "model_builder", build_segmentor)
+        model = model_builder(cfg, **kwargs)
+        if bool(fp16):
+            wrap_fp16_model(model)
+        return model
+
+    def _infer_model(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ):
+        """Main infer function."""
+        self._data_cfg = ConfigDict(
+            data=ConfigDict(
+                train=ConfigDict(
+                    otx_dataset=None,
+                    labels=self._labels,
+                ),
+                test=ConfigDict(
+                    otx_dataset=dataset,
+                    labels=self._labels,
+                ),
             )
-            if workers_per_gpu == 0:
-                dataloader_cfg["persistent_workers"] = False
-                data_cfg[f"{subset}_dataloader"] = dataloader_cfg
+        )
 
-        # Update recipe with caching modules
-        self._update_caching_modules(data_cfg)
+        dump_features = True
 
-        if self._data_cfg is not None:
-            align_data_config_with_recipe(self._data_cfg, self._recipe_cfg)
+        self._init_task()
 
-        if export:
-            if fp16_export:
-                self._precision[0] = ModelPrecision.FP16
-            options["deploy_cfg"] = self._init_deploy_cfg()
-            if options.get("precision", None) is None:
-                assert len(self._precision) == 1
-                options["precision"] = str(self._precision[0])
-
-            options["deploy_cfg"]["dump_features"] = options["dump_features"]
-            if options["dump_features"]:
-                output_names = options["deploy_cfg"]["ir_config"]["output_names"]
-                if "feature_vector" not in output_names:
-                    options["deploy_cfg"]["ir_config"]["output_names"].append("feature_vector")
-                if options["deploy_cfg"]["codebase_config"]["task"] != "Segmentation":
-                    if "saliency_map" not in output_names:
-                        options["deploy_cfg"]["ir_config"]["output_names"].append("saliency_map")
+        cfg = self.configure(False, "test", None)
+        logger.info("infer!")
 
-        self._initialize_post_hook(options)
+        # FIXME: Currently segmentor does not support multi batch inference.
+        if "test" in cfg.data and "test_dataloader" in cfg.data:
+            cfg.data.test_dataloader["samples_per_gpu"] = 1
+
+        # Data loader
+        mm_dataset = build_dataset(cfg.data.test)
+        dataloader = build_dataloader(
+            mm_dataset,
+            samples_per_gpu=cfg.data.test_dataloader.get("samples_per_gpu", 1),
+            workers_per_gpu=cfg.data.test_dataloader.get("workers_per_gpu", 0),
+            num_gpus=len(cfg.gpu_ids),
+            dist=cfg.distributed,
+            seed=cfg.get("seed", None),
+            persistent_workers=False,
+            shuffle=False,
+        )
 
-        logger.info("initialized.")
+        # Target classes
+        if "task_adapt" in cfg:
+            target_classes = cfg.task_adapt.final
+            if len(target_classes) < 1:
+                raise KeyError(
+                    f"target_classes={target_classes} is empty check the metadata from model ckpt or recipe "
+                    "configuration"
+                )
+        else:
+            target_classes = mm_dataset.CLASSES
+
+        # Model
+        model = self.build_model(cfg, fp16=cfg.get("fp16", False))
+        model.CLASSES = target_classes
+        model.eval()
+        feature_model = model.model_s if self._train_type == TrainType.Semisupervised else model
+        model = build_data_parallel(model, cfg, distributed=False)
+
+        # InferenceProgressCallback (Time Monitor enable into Infer task)
+        time_monitor = None
+        if cfg.get("custom_hooks", None):
+            time_monitor = [hook.time_monitor for hook in cfg.custom_hooks if hook.type == "OTXProgressHook"]
+            time_monitor = time_monitor[0] if time_monitor else None
+        if time_monitor is not None:
+
+            # pylint: disable=unused-argument
+            def pre_hook(module, inp):
+                time_monitor.on_test_batch_begin(None, None)
+
+            def hook(module, inp, outp):
+                time_monitor.on_test_batch_end(None, None)
 
-    def _initialize_post_hook(self, options=None):
-        pass
+            model.register_forward_pre_hook(pre_hook)
+            model.register_forward_hook(hook)
+
+        eval_predictions = []
+        feature_vectors = []
+
+        if not dump_features:
+            feature_vector_hook: Union[nullcontext, BaseRecordingForwardHook] = nullcontext()
+        else:
+            feature_vector_hook = FeatureVectorHook(feature_model)
 
-    @abc.abstractmethod
-    def _init_recipe(self):
-        """Initialize the MPA's target recipe (inclusive of stage type)."""
-        raise NotImplementedError("this method should be implemented")
-
-    def _init_model_cfg(self) -> Union[Config, None]:
-        """Initialize model_cfg for override recipe's model configuration."""
-        raise NotImplementedError("this method should be implemented")
-
-    def _init_train_data_cfg(self, dataset: DatasetEntity) -> Union[Config, None]:
-        """Initialize data_cfg for override recipe's data configuration."""
-        return ConfigDict(data=dataset) if dataset else self._data_cfg
-
-    def _init_test_data_cfg(self, dataset: DatasetEntity) -> Union[Config, None]:
-        """Initialize data_cfg for override recipe's data configuration."""
-        return ConfigDict(data=dataset) if dataset else self._data_cfg
-
-    def _init_recipe_hparam(self) -> dict:
-        """Initialize recipe hyperparamter as dict."""
-        assert self._recipe_cfg is not None
-
-        params = self._hyperparams.learning_parameters
-        warmup_iters = int(params.learning_rate_warmup_iters)
-        lr_config = (
-            ConfigDict(warmup_iters=warmup_iters)
-            if warmup_iters > 0
-            else ConfigDict(warmup_iters=warmup_iters, warmup=None)
+        with feature_vector_hook:
+            for data in dataloader:
+                with torch.no_grad():
+                    result = model(return_loss=False, output_logits=True, **data)
+                eval_predictions.append(result)
+                if isinstance(feature_vector_hook, nullcontext):
+                    feature_vectors = [None] * len(mm_dataset)
+                else:
+                    feature_vectors = feature_vector_hook.records
+
+        assert len(eval_predictions) == len(feature_vectors), (
+            "Number of elements should be the same, however, number of outputs are ",
+            f"{len(eval_predictions)} and {len(feature_vectors)}",
         )
 
-        if params.enable_early_stopping and self._recipe_cfg.get("evaluation", None):
-            early_stop = ConfigDict(
-                start=int(params.early_stop_start),
-                patience=int(params.early_stop_patience),
-                iteration_patience=int(params.early_stop_iteration_patience),
-            )
+        outputs = dict(
+            classes=target_classes,
+            eval_predictions=eval_predictions,
+            feature_vectors=feature_vectors,
+        )
+        return outputs
+
+    # pylint: disable=too-many-branches, too-many-statements
+    def _train_model(
+        self,
+        dataset: DatasetEntity,
+    ):
+        """Train function in MMSegmentationTask."""
+        logger.info("init data cfg.")
+        self._data_cfg = ConfigDict(data=ConfigDict())
+
+        for cfg_key, subset in zip(
+            ["train", "val", "unlabeled"],
+            [Subset.TRAINING, Subset.VALIDATION, Subset.UNLABELED],
+        ):
+            subset = get_dataset(dataset, subset)
+            if subset and self._data_cfg is not None:
+                self._data_cfg.data[cfg_key] = ConfigDict(
+                    otx_dataset=subset,
+                    labels=self._labels,
+                )
+
+        self._is_training = True
+
+        self._init_task()
+
+        cfg = self.configure(True, "train", None)
+        logger.info("train!")
+
+        timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime())
+
+        # Environment
+        logger.info(f"cfg.gpu_ids = {cfg.gpu_ids}, distributed = {cfg.distributed}")
+        env_info_dict = collect_env()
+        env_info = "\n".join([(f"{k}: {v}") for k, v in env_info_dict.items()])
+        dash_line = "-" * 60 + "\n"
+        logger.info(f"Environment info:\n{dash_line}{env_info}\n{dash_line}")
+
+        # Data
+        datasets = [build_dataset(cfg.data.train)]
+
+        # FIXME: Currently segmentor does not support multi batch evaluation.
+        # For the Self-SL case, there is no val data. So, need to check the
+
+        if "val" in cfg.data and "val_dataloader" in cfg.data:
+            cfg.data.val_dataloader["samples_per_gpu"] = 1
+
+        # Target classes
+        if "task_adapt" in cfg:
+            target_classes = cfg.task_adapt.final
         else:
-            early_stop = False
+            target_classes = datasets[0].CLASSES
 
-        runner = ConfigDict(max_epochs=int(params.num_iters))
-        if self._recipe_cfg.get("runner", None) and self._recipe_cfg.runner.get("type").startswith("IterBasedRunner"):
-            runner = ConfigDict(max_iters=int(params.num_iters))
-
-        return ConfigDict(
-            optimizer=ConfigDict(lr=params.learning_rate),
-            lr_config=lr_config,
-            early_stop=early_stop,
-            data=ConfigDict(
-                samples_per_gpu=int(params.batch_size),
-                workers_per_gpu=int(params.num_workers),
-            ),
-            runner=runner,
+        # Metadata
+        meta = dict()
+        meta["env_info"] = env_info
+        meta["seed"] = cfg.seed
+        meta["exp_name"] = cfg.work_dir
+        if cfg.checkpoint_config is not None:
+            cfg.checkpoint_config.meta = dict(
+                mmseg_version=__version__ + get_git_hash()[:7],
+                CLASSES=target_classes,
+            )
+
+        # Model
+        model = self.build_model(cfg, fp16=cfg.get("fp16", False))
+        model.train()
+        model.CLASSES = target_classes
+
+        if cfg.distributed:
+            torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
+            if cfg.dist_params.get("linear_scale_lr", False):
+                new_lr = len(cfg.gpu_ids) * cfg.optimizer.lr
+                logger.info(
+                    f"enabled linear scaling rule to the learning rate. \
+                    changed LR from {cfg.optimizer.lr} to {new_lr}"
+                )
+                cfg.optimizer.lr = new_lr
+
+        validate = bool(cfg.data.get("val", None))
+        train_segmentor(
+            model,
+            datasets,
+            cfg,
+            distributed=cfg.distributed,
+            validate=validate,
+            timestamp=timestamp,
+            meta=meta,
+        )
+
+        # Save outputs
+        output_ckpt_path = os.path.join(cfg.work_dir, "latest.pth")
+        best_ckpt_path = glob.glob(os.path.join(cfg.work_dir, "best_mDice_*.pth"))
+        if len(best_ckpt_path) > 0:
+            output_ckpt_path = best_ckpt_path[0]
+        best_ckpt_path = glob.glob(os.path.join(cfg.work_dir, "best_mIoU_*.pth"))
+        if len(best_ckpt_path) > 0:
+            output_ckpt_path = best_ckpt_path[0]
+        return dict(
+            final_ckpt=output_ckpt_path,
         )
 
-    def _update_stage_module(self, stage_module: str):
-        return stage_module
+    def _explain_model(self):
+        """Explain function of OTX Segmentation Task."""
+        raise NotImplementedError
+
+    # pylint: disable=too-many-statements
+    def _export_model(
+        self,
+        precision: ModelPrecision = ModelPrecision.FP32,
+        dump_features: bool = True,
+    ):
+        """Export function of OTX Segmentation Task."""
+        # copied from OTX inference_task.py
+        self._init_task(export=True)
+
+        cfg = self.configure(False, "test", None)
+
+        self._precision[0] = precision
+        export_options: Dict[str, Any] = {}
+        export_options["deploy_cfg"] = self._init_deploy_cfg(cfg)
+        if export_options.get("precision", None) is None:
+            assert len(self._precision) == 1
+            export_options["precision"] = str(self._precision[0])
+
+        export_options["deploy_cfg"]["dump_features"] = dump_features
+        if dump_features:
+            output_names = export_options["deploy_cfg"]["ir_config"]["output_names"]
+            if "feature_vector" not in output_names:
+                output_names.append("feature_vector")
+            if export_options["deploy_cfg"]["codebase_config"]["task"] != "Segmentation":
+                if "saliency_map" not in output_names:
+                    output_names.append("saliency_map")
+        export_options["model_builder"] = getattr(self, "model_builder", build_segmentor)
+
+        if self._precision[0] == ModelPrecision.FP16:
+            export_options["deploy_cfg"]["backend_config"]["mo_options"]["flags"].append("--compress_to_fp16")
+
+        exporter = SegmentationExporter()
+        results = exporter.run(
+            cfg,
+            **export_options,
+        )
+        return results
 
-    def _init_deploy_cfg(self) -> Union[Config, None]:
-        base_dir = os.path.abspath(os.path.dirname(self.template_file_path))
+    # This should moved somewhere
+    def _init_deploy_cfg(self, cfg: Config) -> Union[Config, None]:
+        base_dir = os.path.abspath(os.path.dirname(self._task_environment.model_template.model_template_path))
         deploy_cfg_path = os.path.join(base_dir, "deployment.py")
         deploy_cfg = None
         if os.path.exists(deploy_cfg_path):
             deploy_cfg = MPAConfig.fromfile(deploy_cfg_path)
 
             def patch_input_preprocessing(deploy_cfg):
                 normalize_cfg = get_configs_by_pairs(
-                    self._recipe_cfg.data.test.pipeline,
+                    cfg.data.test.pipeline,
                     dict(type="Normalize"),
                 )
                 assert len(normalize_cfg) == 1
                 normalize_cfg = normalize_cfg[0]
 
                 options = dict(flags=[], args={})
                 # NOTE: OTX loads image in RGB format
@@ -453,15 +481,15 @@
                 mo_options.args = ConfigDict(options["args"])
                 # make sure no duplicates
                 mo_options.flags.extend(options["flags"])
                 mo_options.flags = list(set(mo_options.flags))
 
             def patch_input_shape(deploy_cfg):
                 resize_cfg = get_configs_by_pairs(
-                    self._recipe_cfg.data.test.pipeline,
+                    cfg.data.test.pipeline,
                     dict(type="Resize"),
                 )
                 assert len(resize_cfg) == 1
                 resize_cfg = resize_cfg[0]
                 size = resize_cfg.size
                 if isinstance(size, int):
                     size = (size, size)
@@ -472,175 +500,60 @@
 
             patch_input_preprocessing(deploy_cfg)
             if not deploy_cfg.backend_config.get("model_inputs", []):
                 patch_input_shape(deploy_cfg)
 
         return deploy_cfg
 
-    def _load_model_ckpt(self, model: Optional[ModelEntity]):
-        if model and "weights.pth" in model.model_adapters:
-            # If a model has been trained and saved for the task already, create empty model and load weights here
-            buffer = io.BytesIO(model.get_data("weights.pth"))
-            model_data = torch.load(buffer, map_location=torch.device("cpu"))
-
-            # set confidence_threshold as well
-            self.confidence_threshold = model_data.get("confidence_threshold", self.confidence_threshold)
-            if model_data.get("anchors"):
-                self._anchors = model_data["anchors"]
-
-            # Get config
-            if model_data.get("config"):
-                tiling_parameters = model_data.get("config").get("tiling_parameters")
-                if tiling_parameters and tiling_parameters["enable_tiling"]["value"]:
-                    logger.info("Load tiling parameters")
-                    self._hyperparams.tiling_parameters.enable_tiling = tiling_parameters["enable_tiling"]["value"]
-                    self._hyperparams.tiling_parameters.tile_size = tiling_parameters["tile_size"]["value"]
-                    self._hyperparams.tiling_parameters.tile_overlap = tiling_parameters["tile_overlap"]["value"]
-                    self._hyperparams.tiling_parameters.tile_max_number = tiling_parameters["tile_max_number"]["value"]
-            return model_data
-        return None
-
-    def _load_model_label_schema(self, model: Optional[ModelEntity]):
-        # If a model has been trained and saved for the task already, create empty model and load weights here
-        if model and "label_schema.json" in model.model_adapters:
-            import json
-
-            buffer = json.loads(model.get_data("label_schema.json").decode("utf-8"))
-            model_label_schema = LabelSchemaMapper().backward(buffer)
-            return model_label_schema.get_labels(include_empty=False)
-        return self._labels
-
-    def _load_resume_info(self, model: Optional[ModelEntity]):
-        if model and "resume" in model.model_adapters:
-            return model.model_adapters.get("resume", False)
-        return False
-
-    @staticmethod
-    def _get_confidence_threshold(hyperparams):
-        confidence_threshold = 0.3
-        if hasattr(hyperparams, "postprocessing") and hasattr(hyperparams.postprocessing, "confidence_threshold"):
-            confidence_threshold = hyperparams.postprocessing.confidence_threshold
-        return confidence_threshold
-
-    @staticmethod
-    def _is_docker():
-        """Checks whether the task runs in docker container.
-
-        :return bool: True if task runs in docker
-        """
-        path = "/proc/self/cgroup"
-        is_in_docker = False
-        if os.path.isfile(path):
-            with open(path, encoding="UTF-8") as f:
-                is_in_docker = is_in_docker or any("docker" in line for line in f)
-        is_in_docker = is_in_docker or os.path.exists("/.dockerenv")
-        return is_in_docker
-
-    def cancel_hook_initialized(self, cancel_interface: CancelInterfaceHook):
-        """Initialization of cancel_interface hook."""
-        logger.info("cancel hook is initialized")
-        self.cancel_interface = cancel_interface
-        if self.reserved_cancel and self.cancel_interface:
-            self.cancel_interface.cancel()
-
-    def unload(self):
-        """Unload the task."""
-        if self._work_dir_is_temp:
-            self._delete_scratch_space()
-        if self._is_docker():
-            logger.warning("Got unload request. Unloading models. Throwing Segmentation Fault on purpose")
-            import ctypes
-
-            ctypes.string_at(0)
-        else:
-            logger.warning("Got unload request, but not on Docker. Only clearing CUDA cache")
-            torch.cuda.empty_cache()
-            logger.warning(
-                f"Done unloading. " f"Torch is still occupying {torch.cuda.memory_allocated()} bytes of GPU memory"
-            )
-
-    def cleanup(self):
-        """Clean up work directory if user specified it."""
-        if self._work_dir_is_temp:
-            self._delete_scratch_space()
-
-    class OnHookInitialized:
-        """OnHookInitialized class."""
-
-        def __init__(self, task_instance):
-            self.task_instance = task_instance
-            self.__findable = False  # a barrier to block segmentation fault
-
-        def __call__(self, cancel_interface):
-            """Function call in OnHookInitialized."""
-            if isinstance(self.task_instance, int) and self.__findable:
-                import ctypes
-
-                # NOTE: BE AWARE OF SEGMENTATION FAULT
-                self.task_instance = ctypes.cast(self.task_instance, ctypes.py_object).value
-            self.task_instance.cancel_hook_initialized(cancel_interface)
-
-        def __repr__(self):
-            """Function repr in OnHookInitialized."""
-            return f"'{__name__}.OnHookInitialized'"
-
-        def __deepcopy__(self, memo):
-            """Function deepcopy in OnHookInitialized."""
-            cls = self.__class__
-            result = cls.__new__(cls)
-            memo[id(self)] = result
-            result.task_instance = self.task_instance
-            result.__findable = True  # pylint: disable=unused-private-member
-            return result
-
-        def __reduce__(self):
-            """Function reduce in OnHookInitialized."""
-            return (self.__class__, (id(self.task_instance),))
-
+    # This should be removed
     def update_override_configurations(self, config):
         """Update override_configs."""
         logger.info(f"update override config with: {config}")
         config = ConfigDict(**config)
         self.override_configs.update(config)
 
-    def set_early_stopping_hook(self):
-        """Update Early-stopping Hook."""
-        if "early_stop" in self._recipe_cfg:
-            remove_custom_hook(self._recipe_cfg, "EarlyStoppingHook")
-            early_stop = self._recipe_cfg.get("early_stop", False)
-            if early_stop:
-                early_stop_hook = ConfigDict(
-                    type="LazyEarlyStoppingHook",
-                    start=early_stop.start,
-                    patience=early_stop.patience,
-                    iteration_patience=early_stop.iteration_patience,
-                    interval=1,
-                    metric=self._recipe_cfg.early_stop_metric,
-                    priority=75,
-                )
-                update_or_add_custom_hook(self._recipe_cfg, early_stop_hook)
-            else:
-                remove_custom_hook(self._recipe_cfg, "LazyEarlyStoppingHook")
+    def save_model(self, output_model: ModelEntity):
+        """Save best model weights in SegmentationTrainTask."""
+        logger.info("called save_model")
+        buffer = io.BytesIO()
+        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
+        labels = {label.name: label.color.rgb_tuple for label in self._labels}
+        model_ckpt = torch.load(self._model_ckpt)
+        modelinfo = {
+            "model": model_ckpt,
+            "config": hyperparams_str,
+            "labels": labels,
+            "VERSION": 1,
+        }
+
+        torch.save(modelinfo, buffer)
+        output_model.set_data("weights.pth", buffer.getvalue())
+        output_model.set_data(
+            "label_schema.json",
+            label_schema_to_bytes(self._task_environment.label_schema),
+        )
+        output_model.precision = self._precision
 
+    # These need to be moved somewhere
     def _update_caching_modules(self, data_cfg: Config) -> None:
         def _find_max_num_workers(cfg: dict):
             num_workers = [0]
             for key, value in cfg.items():
                 if key == "workers_per_gpu" and isinstance(value, int):
                     num_workers += [value]
                 elif isinstance(value, dict):
                     num_workers += [_find_max_num_workers(value)]
 
             return max(num_workers)
 
         def _get_mem_cache_size():
-            if not hasattr(self.hyperparams.algo_backend, "mem_cache_size"):
+            if not hasattr(self._hyperparams.algo_backend, "mem_cache_size"):
                 return 0
 
-            return self.hyperparams.algo_backend.mem_cache_size
+            return self._hyperparams.algo_backend.mem_cache_size
 
         max_num_workers = _find_max_num_workers(data_cfg)
         mem_cache_size = _get_mem_cache_size()
 
         mode = "multiprocessing" if max_num_workers > 0 else "singleprocessing"
         caching.MemCacheHandlerSingleton.create(mode, mem_cache_size)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/tools/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -17,22 +17,29 @@
 from .callback import (
     InferenceProgressCallback,
     OptimizationProgressCallback,
     TrainingProgressCallback,
 )
 from .data import get_cls_img_indices, get_image, get_old_new_img_indices
 from .ir import embed_ir_model_data
-from .utils import UncopiableDefaultDict, get_arg_spec, get_task_class, load_template
+from .utils import (
+    UncopiableDefaultDict,
+    get_arg_spec,
+    get_task_class,
+    load_template,
+    set_random_seed,
+)
 
 __all__ = [
     "embed_ir_model_data",
     "get_cls_img_indices",
     "get_old_new_img_indices",
     "TrainingProgressCallback",
     "InferenceProgressCallback",
     "OptimizationProgressCallback",
     "UncopiableDefaultDict",
     "load_template",
     "get_task_class",
     "get_arg_spec",
     "get_image",
+    "set_random_seed",
 ]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/callback.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/data.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/data.py`

 * *Files 5% similar despite different names*

```diff
@@ -25,24 +25,19 @@
 import numpy as np
 
 from otx.api.entities.annotation import NullAnnotationSceneEntity
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.image import Image
 from otx.api.entities.subset import Subset
-from otx.api.utils.argument_checks import (
-    IMAGE_FILE_EXTENSIONS,
-    DirectoryPathCheck,
-    check_input_parameters_type,
-)
+from otx.api.utils.argument_checks import IMAGE_FILE_EXTENSIONS
 
 logger = logging.getLogger(__name__)
 
 
-@check_input_parameters_type({"file_list_path": DirectoryPathCheck})
 def get_unlabeled_filename(base_root: str, file_list_path: str):
     """This method checks and gets image file paths, which are listed in file_list_path.
 
     The content of file_list_path is expected to specify relative paths of each image file to base_root line by line.
     It returns the list of image filenames only which will compose unlabeled dataset.
 
     Args:
@@ -62,15 +57,14 @@
     for fn in file_names:
         file_path = os.path.join(base_root, fn.strip())
         if is_valid(file_path) and os.path.isfile(file_path):
             unlabeled_files.append(file_path)
     return unlabeled_files
 
 
-@check_input_parameters_type({"data_root_dir": DirectoryPathCheck})
 def load_unlabeled_dataset_items(
     data_root_dir: str,
     file_list_path: Optional[str] = None,
 ):
     """This method loads unlabeled dataset items from images in data_root_dir.
 
     Args:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/distance_utils.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/distance_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/ext_loader.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/ext_loader.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/ir.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/ir.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/logger.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/logger.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 """Module for defining custom logger."""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
+# ruff: noqa: PLW0603
+
 import functools
 import logging
 import os
 import sys
 from typing import Callable
 
 import torch.distributed as dist
```

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/mask_to_bbox.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/mask_to_bbox.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/mo_wrapper.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/mo_wrapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/task_adapt.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/task_adapt.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/common/utils/utils.py` & `otx-1.2.0rc1/otx/algorithms/common/utils/utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -12,47 +12,46 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 import importlib
 import inspect
+import os
+import random
 from collections import defaultdict
 from typing import Callable, Optional, Tuple
 
+import numpy as np
+import torch
 import yaml
 
-from otx.api.utils.argument_checks import YamlFilePathCheck, check_input_parameters_type
-
 
 class UncopiableDefaultDict(defaultdict):
     """Defauldict type object to avoid deepcopy."""
 
     def __deepcopy__(self, memo):
         """Deepcopy."""
         return self
 
 
-@check_input_parameters_type({"path": YamlFilePathCheck})
 def load_template(path):
     """Loading model template function."""
     with open(path, encoding="UTF-8") as f:
         template = yaml.safe_load(f)
     return template
 
 
-@check_input_parameters_type()
 def get_task_class(path: str):
     """Return Task classes."""
     module_name, class_name = path.rsplit(".", 1)
     module = importlib.import_module(module_name)
     return getattr(module, class_name)
 
 
-@check_input_parameters_type()
 def get_arg_spec(  # noqa: C901  # pylint: disable=too-many-branches
     fn: Callable,  # pylint: disable=invalid-name
     depth: Optional[int] = None,
 ) -> Tuple[str, ...]:
     """Get argument spec of function."""
 
     args = set()
@@ -90,7 +89,29 @@
             if method is None:
                 break
             spec = inspect.getfullargspec(method)
             args.update(spec.args[1:])
             if spec.varkw is None and spec.varargs is None:
                 break
     return tuple(args)
+
+
+def set_random_seed(seed, logger, deterministic=False):
+    """Set random seed.
+
+    Args:
+        seed (int): Seed to be used.
+        logger (logging.Logger): logger for logging seed info
+        deterministic (bool): Whether to set the deterministic option for
+            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`
+            to True and `torch.backends.cudnn.benchmark` to False.
+            Default: False.
+    """
+    random.seed(seed)
+    np.random.seed(seed)
+    torch.manual_seed(seed)
+    torch.cuda.manual_seed_all(seed)
+    os.environ["PYTHONHASHSEED"] = str(seed)
+    logger.info(f"Training seed was set to {seed} w/ deterministic={deterministic}.")
+    if deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Adapters for Detection."""
+"""Model configurations."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/dataset.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,25 +28,20 @@
 from mmdet.datasets.pipelines import Compose
 
 from otx.algorithms.common.utils.data import get_old_new_img_indices
 from otx.algorithms.detection.adapters.mmdet.evaluation import eval_segm
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import Domain, LabelEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 from otx.api.utils.shape_factory import ShapeFactory
 
 from .tiling import Tile
 
 
 # pylint: disable=invalid-name, too-many-locals, too-many-instance-attributes, super-init-not-called
-@check_input_parameters_type()
 def get_annotation_mmdet_format(
     dataset_item: DatasetItemEntity,
     labels: List[LabelEntity],
     domain: Domain,
     min_size: int = -1,
 ) -> dict:
     """Function to convert a OTX annotation to mmdetection format.
@@ -152,15 +147,14 @@
                 index=index,
                 ann_info=dict(label_list=self.labels),
                 ignored_labels=ignored_labels,
             )
 
             return data_info
 
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     def __init__(
         self,
         otx_dataset: DatasetEntity,
         labels: List[LabelEntity],
         pipeline: Sequence[dict],
         domain: Domain,
         test_mode: bool = False,
@@ -202,45 +196,41 @@
         """
         self.flag = np.zeros(len(self), dtype=np.uint8)
 
     def _rand_another(self, idx):
         _ = idx
         return np.random.choice(len(self))
 
-    @check_input_parameters_type()
     def prepare_train_img(self, idx: int) -> dict:
         """Get training data and annotations after pipeline.
 
         :param idx: int, Index of data.
         :return dict: Training data and annotation after pipeline with new keys introduced by pipeline.
         """
         item = copy(self.data_infos[idx])  # Copying dict(), not contents
         self.pre_pipeline(item)
         return self.pipeline(item)
 
-    @check_input_parameters_type()
     def prepare_test_img(self, idx: int) -> dict:
         """Get testing data after pipeline.
 
         :param idx: int, Index of data.
         :return dict: Testing data after pipeline with new keys introduced by pipeline.
         """
         item = copy(self.data_infos[idx])  # Copying dict(), not contents
         self.pre_pipeline(item)
         return self.pipeline(item)
 
     @staticmethod
-    @check_input_parameters_type()
     def pre_pipeline(results: Dict[str, Any]):
         """Prepare results dict for pipeline. Add expected keys to the dict."""
         results["bbox_fields"] = []
         results["mask_fields"] = []
         results["seg_fields"] = []
 
-    @check_input_parameters_type()
     def get_ann_info(self, idx: int):
         """This method is used for evaluation of predictions.
 
         The CustomDataset class implements a method
         CustomDataset.evaluate, which uses the class method get_ann_info to retrieve annotations.
 
         :param idx: index of the dataset item for which to get the annotations
@@ -386,14 +376,15 @@
         return self.pipeline(self.tile_dataset[idx])
 
     def evaluate(self, results, **kwargs) -> Dict[str, float]:
         """Evaluation on Tile dataset.
 
         Args:
             results (list[list | tuple]): Testing results of the dataset.
+            **kwargs: Addition keyword arguments.
 
         Returns:
             dict[str, float]: evaluation metric.
         """
         self.merged_results = self.tile_dataset.merge(results)
         return self.dataset.evaluate(self.merged_results, **kwargs)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/load_pipelines.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/load_pipelines.py`

 * *Files 7% similar despite different names*

```diff
@@ -18,15 +18,14 @@
 from mmdet.datasets.builder import PIPELINES
 
 import otx.core.data.pipelines.load_image_from_otx_dataset as load_image_base
 from otx.algorithms.detection.adapters.mmdet.datasets.dataset import (
     get_annotation_mmdet_format,
 )
 from otx.api.entities.label import Domain
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 
 # pylint: disable=too-many-instance-attributes, too-many-arguments
 @PIPELINES.register_module()
 class LoadImageFromOTXDataset(load_image_base.LoadImageFromOTXDataset):
     """Pipeline element that loads an image from a OTX Dataset on the fly."""
 
@@ -36,15 +35,14 @@
     """Pipeline element that loads an annotation from a OTX Dataset on the fly.
 
     Expected entries in the 'results' dict that should be passed to this pipeline element are:
         results['dataset_item']: dataset_item from which to load the annotation
         results['ann_info']['label_list']: list of all labels in the project
     """
 
-    @check_input_parameters_type()
     def __init__(
         self,
         min_size: int,
         with_bbox: bool = True,
         with_label: bool = True,
         with_mask: bool = False,
         with_seg: bool = False,
@@ -74,15 +72,14 @@
 
     @staticmethod
     def _load_masks(results, ann_info):
         results["mask_fields"].append("gt_masks")
         results["gt_masks"] = copy.deepcopy(ann_info["masks"])
         return results
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of LoadAnnotationFromOTXDataset."""
         dataset_item = results["dataset_item"]
         label_list = results["ann_info"]["label_list"]
         ann_info = get_annotation_mmdet_format(dataset_item, label_list, self.domain, self.min_size)
         if self.with_bbox:
             results = self._load_bboxes(results, ann_info)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/torchvision2mmdet.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/pipelines/torchvision2mmdet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/task_adapt_dataset.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/task_adapt_dataset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/datasets/tiling.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/datasets/tiling.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 from tqdm import tqdm
 
 
 def timeit(func) -> Callable:
     """Decorator to measure time of function execution.
 
     Args:
-        func:
+        func: Function to be the target for measuring.
 
     Returns:
         Callable function with time measurement.
     """
 
     def wrapper(*args, **kwargs):
         begin = time()
@@ -92,64 +92,49 @@
         for p in pipeline:
             if p.type == "PhotoMetricDistortion":
                 self.img2fp32 = True
                 break
 
         self.dataset = dataset
         self.tiles = self.gen_tile_ann()
-        self.cache_tiles()
-
-    @timeit
-    def cache_tiles(self):
-        """Cache tiles to disk."""
-        pbar = tqdm(total=len(self.tiles))
-        pre_img_idx = None
-        for i, tile in enumerate(self.tiles):
-            tile["tile_path"] = osp.join(
-                self.tmp_folder, "_".join([str(i), tile["uuid"], tile["ori_filename"], ".jpg"])
-            )
-            x_1, y_1, x_2, y_2 = tile["tile_box"]
-            dataset_idx = tile["dataset_idx"]
-            if dataset_idx != pre_img_idx:
-                ori_img = self.dataset[dataset_idx]["img"]
-                pre_img_idx = dataset_idx
-
-            mmcv.imwrite(ori_img[y_1:y_2, x_1:x_2, :], tile["tile_path"])
-            pbar.update(1)
 
     @timeit
     def gen_tile_ann(self) -> List[Dict]:
         """Generate tile information and tile annotation from dataset.
 
         Returns:
             List[Dict]: A list of tiles generated from the dataset. Each item comprises tile annotation and tile
                         coordinates relative to the original image.
         """
         tiles = []
-        pbar = tqdm(total=len(self.dataset))
+        cache_result = []
+        for result in tqdm(self.dataset, desc="Loading dataset annotations..."):
+            cache_result.append(result)
 
-        for idx, result in enumerate(self.dataset):
+        pbar = tqdm(total=len(self.dataset) * 2, desc="Generating tile annotations...")
+        for idx, result in enumerate(cache_result):
             tiles.append(self.gen_single_img(result, dataset_idx=idx))
+            pbar.update(1)
 
-        for idx, result in enumerate(self.dataset):
+        for idx, result in enumerate(cache_result):
             tiles.extend(self.gen_tiles_single_img(result, dataset_idx=idx))
             pbar.update(1)
         return tiles
 
     def gen_single_img(self, result: Dict, dataset_idx: int) -> Dict:
         """Add full-size image for inference or training.
 
         Args:
             result (Dict): the original image-level result (i.e. the original image annotation)
             dataset_idx (int): the image index this tile belongs to
 
         Returns:
             Dict: annotation with some other useful information for data pipeline.
         """
-        result["tile_box"] = (0, 0, result["dataset_item"].width, result["dataset_item"].height)
+        result["tile_box"] = (0, 0, result["img_shape"][1], result["img_shape"][0])
         result["dataset_idx"] = dataset_idx
         result["original_shape_"] = result["img_shape"]
         result["uuid"] = str(uuid.uuid4())
         return result
 
     # pylint: disable=too-many-locals
     def gen_tiles_single_img(self, result: Dict, dataset_idx: int) -> List[Dict]:
@@ -159,19 +144,19 @@
             result (Dict): the original image-level result (i.e. the original image annotation)
             dataset_idx (int): the image index this tile belongs to
 
         Returns:
             List[Dict]: a list of tile annotation with some other useful information for data pipeline.
         """
         tile_list = []
-        gt_bboxes = result.pop("gt_bboxes", np.zeros((0, 4), dtype=np.float32))
-        gt_masks = result.pop("gt_masks", None)
-        gt_bboxes_ignore = result.pop("gt_bboxes_ignore", np.zeros((0, 4), dtype=np.float32))
-        gt_labels = result.pop("gt_labels", np.array([], dtype=np.int64))
-        img_shape = result.pop("img_shape")
+        gt_bboxes = result.get("gt_bboxes", np.zeros((0, 4), dtype=np.float32))
+        gt_masks = result.get("gt_masks", None)
+        gt_bboxes_ignore = result.get("gt_bboxes_ignore", np.zeros((0, 4), dtype=np.float32))
+        gt_labels = result.get("gt_labels", np.array([], dtype=np.int64))
+        img_shape = result.get("img_shape")
         height, width = img_shape[:2]
         _tile = self.prepare_result(result)
 
         num_patches_h = int((height - self.tile_size) / self.stride) + 1
         num_patches_w = int((width - self.tile_size) / self.stride) + 1
         for (_, _), (loc_i, loc_j) in zip(
             product(range(num_patches_h), range(num_patches_w)),
@@ -376,46 +361,54 @@
             if self.img2fp32:
                 img = img.astype(np.float32)
             result["img"] = img
             return result
         dataset_idx = result["dataset_idx"]
         x_1, y_1, x_2, y_2 = result["tile_box"]
         ori_img = self.dataset[dataset_idx]["img"]
+        cropped_tile = ori_img[y_1:y_2, x_1:x_2, :]
+        tile_path = osp.join(
+            self.tmp_folder, "_".join([str(dataset_idx), result["uuid"], result["ori_filename"], ".jpg"])
+        )
+        self.tiles[idx]["tile_path"] = tile_path
+        mmcv.imwrite(cropped_tile, tile_path)
         if self.img2fp32:
-            ori_img = ori_img.astype(np.float32)
-        result["img"] = ori_img[y_1:y_2, x_1:x_2, :]
+            cropped_tile = cropped_tile.astype(np.float32)
+        result["img"] = cropped_tile
         return result
 
     @staticmethod
     def readjust_tile_mask(tile_rle: Dict):
         """Shift tile-level mask to image-level mask.
 
         Args:
-            tile_rle (Dict): _description_
+            tile_rle (Dict): tile-level mask result.
 
         Returns:
-            _type_: _description_
+            np.ndarray: image-level mask result.
         """
         x1, y1, x2, y2 = tile_rle.pop("tile_box")
         height, width = tile_rle.pop("img_size")
         tile_mask = mask_util.decode(tile_rle)
         tile_mask = np.pad(tile_mask, ((y1, height - y2), (x1, width - x2)))
         return mask_util.encode(tile_mask)
 
-    def process_masks(self, tile_masks: List[Dict]):
+    def process_masks(self, tile_masks: List) -> List[np.ndarray]:
         """Decode Mask Result to Numpy mask, add paddings then encode masks again.
 
         Args:
-            tile_masks (_type_): _description_
+            tile_masks (List): list of tile-level mask results.
 
         Returns:
-            _type_: _description_
+            List[np.ndarray]: list of image-level mask results.
         """
-        with Pool(self.nproc) as pool:
-            results = pool.map(Tile.readjust_tile_mask, tile_masks)
+        results = []
+        if tile_masks:
+            with Pool(self.nproc) as pool:
+                results = pool.map(Tile.readjust_tile_mask, tile_masks)
         return results
 
     # pylint: disable=too-many-locals
     @timeit
     def merge(self, results: List[List]) -> Union[List[Tuple[np.ndarray, list]], List[np.ndarray]]:
         """Merge/Aggregate tile-level prediction to image-level prediction.
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/evaluation/mean_ap_seg.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/evaluation/mean_ap_seg.py`

 * *Files 1% similar despite different names*

```diff
@@ -215,14 +215,15 @@
             Default: 0.5.
         dataset (list[str] | str | None): Dataset name or dataset classes,
             there are minor differences in metrics for different datsets, e.g.
             "voc07", "imagenet_det", etc. Default: None.
         logger (logging.Logger | str | None): The way to print the mAP
             summary. See `mmcv.utils.print_log()` for details. Default: None.
         nproc (int): Processes used for computing tpfpmiou_func. Default: 4.
+        metric (str): Metric to be returned which is one of ["mAP", "mIoU"]. Default: "mAP".
 
     Returns:
         tuple: (mIoU, [dict, dict, ...])
     """
     assert len(det_results) == len(annotations)
 
     num_imgs = len(det_results)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/hooks/det_saliency_map_hook.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/hooks/det_class_probability_map_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 from otx.algorithms.detection.adapters.mmdet.models.heads.custom_yolox_head import (
     CustomYOLOXHead,
 )
 
 # pylint: disable=too-many-locals
 
 
-class DetSaliencyMapHook(BaseRecordingForwardHook):
+class DetClassProbabilityMapHook(BaseRecordingForwardHook):
     """Saliency map hook for object detection models."""
 
     def __init__(self, module: torch.nn.Module) -> None:
         super().__init__(module)
         self._neck = module.neck if module.with_neck else None
         self._bbox_head = module.bbox_head
         self._num_cls_out_channels = module.bbox_head.cls_out_channels  # SSD-like heads also have background class
@@ -112,11 +112,11 @@
                 map_results = map(
                     forward_single, x, self._bbox_head.multi_level_cls_convs, self._bbox_head.multi_level_conv_cls
                 )
                 cls_scores = list(map_results)
             else:
                 raise NotImplementedError(
                     "Not supported detection head provided. "
-                    "DetSaliencyMapHook supports only the following single stage detectors: "
+                    "DetClassProbabilityMap supports only the following single stage detectors: "
                     "YOLOXHead, ATSSHead, SSDHead, VFNetHead."
                 )
         return cls_scores
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/imgclsmob.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/imgclsmob.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/mmov_backbone.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/backbones/mmov_backbone.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_rpn_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_rpn_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_ssd_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_ssd_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_yolov3_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_yolov3_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """Initial file for mmdetection detectors."""
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 from .custom_atss_detector import CustomATSS
 from .custom_maskrcnn_detector import CustomMaskRCNN
+from .custom_maskrcnn_tile_optimized import CustomMaskRCNNTileOptimized
 from .custom_single_stage_detector import CustomSingleStageDetector
 from .custom_two_stage_detector import CustomTwoStageDetector
 from .custom_vfnet_detector import CustomVFNet
 from .custom_yolox_detector import CustomYOLOX
 from .l2sp_detector_mixin import L2SPDetectorMixin
 from .sam_detector_mixin import SAMDetectorMixin
 from .unbiased_teacher import UnbiasedTeacher
@@ -19,8 +20,9 @@
     "CustomSingleStageDetector",
     "CustomTwoStageDetector",
     "CustomVFNet",
     "CustomYOLOX",
     "L2SPDetectorMixin",
     "SAMDetectorMixin",
     "UnbiasedTeacher",
+    "CustomMaskRCNNTileOptimized",
 ]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_atss_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_atss_detector.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 
 from otx.algorithms.common.adapters.mmcv.hooks.recording_forward_hook import (
     FeatureVectorHook,
 )
 from otx.algorithms.common.adapters.mmdeploy.utils import is_mmdeploy_enabled
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.common.utils.task_adapt import map_class_names
-from otx.algorithms.detection.adapters.mmdet.hooks.det_saliency_map_hook import (
-    DetSaliencyMapHook,
+from otx.algorithms.detection.adapters.mmdet.hooks.det_class_probability_map_hook import (
+    DetClassProbabilityMapHook,
 )
 
 from .l2sp_detector_mixin import L2SPDetectorMixin
 from .sam_detector_mixin import SAMDetectorMixin
 
 logger = get_logger()
 
@@ -95,15 +95,15 @@
         feat = self.extract_feat(img)
         outs = self.bbox_head(feat)
         bbox_results = self.bbox_head.get_bboxes(*outs, img_metas=img_metas, cfg=self.test_cfg, **kwargs)
 
         if ctx.cfg["dump_features"]:
             feature_vector = FeatureVectorHook.func(feat)
             cls_scores = outs[0]
-            saliency_map = DetSaliencyMapHook(self).func(feature_map=cls_scores, cls_scores_provided=True)
+            saliency_map = DetClassProbabilityMapHook(self).func(feature_map=cls_scores, cls_scores_provided=True)
             return (*bbox_results, feature_vector, saliency_map)
 
         return bbox_results
 
     @mark("custom_atss_forward", inputs=["input"], outputs=["dets", "labels", "feats", "saliencies"])
     def __forward_impl(ctx, self, img, img_metas, **kwargs):
         """Internal Function for __forward_impl."""
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_single_stage_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_single_stage_detector.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 
 from otx.algorithms.common.adapters.mmcv.hooks.recording_forward_hook import (
     FeatureVectorHook,
 )
 from otx.algorithms.common.adapters.mmdeploy.utils import is_mmdeploy_enabled
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.common.utils.task_adapt import map_class_names
-from otx.algorithms.detection.adapters.mmdet.hooks.det_saliency_map_hook import (
-    DetSaliencyMapHook,
+from otx.algorithms.detection.adapters.mmdet.hooks.det_class_probability_map_hook import (
+    DetClassProbabilityMapHook,
 )
 
 from .l2sp_detector_mixin import L2SPDetectorMixin
 from .sam_detector_mixin import SAMDetectorMixin
 
 logger = get_logger()
 
@@ -58,14 +58,15 @@
                 For details on the values of these keys see
                 :class:`mmdet.datasets.pipelines.Collect`.
             gt_bboxes (list[Tensor]): Each item are the truth boxes for each
                 image in [tl_x, tl_y, br_x, br_y] format.
             gt_labels (list[Tensor]): Class indices corresponding to each box
             gt_bboxes_ignore (None | list[Tensor]): Specify which bounding
                 boxes can be ignored when computing the loss.
+            **kwargs (Any): Addition keyword arguments.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
         batch_input_shape = tuple(img[0].size()[-2:])
         for img_meta in img_metas:
             img_meta["batch_input_shape"] = batch_input_shape
@@ -152,15 +153,15 @@
         feat = self.extract_feat(img)
         outs = self.bbox_head(feat)
         bbox_results = self.bbox_head.get_bboxes(*outs, img_metas=img_metas, cfg=self.test_cfg, **kwargs)
 
         if ctx.cfg["dump_features"]:
             feature_vector = FeatureVectorHook.func(feat)
             cls_scores = outs[0]
-            saliency_map = DetSaliencyMapHook(self).func(cls_scores, cls_scores_provided=True)
+            saliency_map = DetClassProbabilityMapHook(self).func(cls_scores, cls_scores_provided=True)
             return (*bbox_results, feature_vector, saliency_map)
 
         return bbox_results
 
     @mark("custom_ssd_forward", inputs=["input"], outputs=["dets", "labels", "feats", "saliencies"])
     def __forward_impl(ctx, self, img, img_metas, **kwargs):
         """Internal Function for __forward_impl."""
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_two_stage_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_two_stage_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_vfnet_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_vfnet_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_yolox_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/custom_yolox_detector.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 
 from otx.algorithms.common.adapters.mmcv.hooks.recording_forward_hook import (
     FeatureVectorHook,
 )
 from otx.algorithms.common.adapters.mmdeploy.utils import is_mmdeploy_enabled
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.common.utils.task_adapt import map_class_names
-from otx.algorithms.detection.adapters.mmdet.hooks.det_saliency_map_hook import (
-    DetSaliencyMapHook,
+from otx.algorithms.detection.adapters.mmdet.hooks.det_class_probability_map_hook import (
+    DetClassProbabilityMapHook,
 )
 
 from .l2sp_detector_mixin import L2SPDetectorMixin
 from .sam_detector_mixin import SAMDetectorMixin
 
 logger = get_logger()
 
@@ -82,15 +82,15 @@
             for model_t, ckpt_t in enumerate(model2chkpt):
                 if ckpt_t >= 0:
                     model_param[model_t].copy_(chkpt_param[ckpt_t])
 
             # Replace checkpoint weight by mixed weights
             chkpt_dict[chkpt_name] = model_param
 
-    def onnx_export(self, img, img_metas, with_nms=True):
+    def onnx_export(self, img, img_metas):
         """Test function without test time augmentation.
 
         Args:
             img (torch.Tensor): input images.
             img_metas (list[dict]): List of image information.
 
         Returns:
@@ -133,15 +133,15 @@
         feat = self.extract_feat(img)
         outs = self.bbox_head(feat)
         bbox_results = self.bbox_head.get_bboxes(*outs, img_metas=img_metas, cfg=self.test_cfg, **kwargs)
 
         if ctx.cfg["dump_features"]:
             feature_vector = FeatureVectorHook.func(feat)
             cls_scores = outs[0]
-            saliency_map = DetSaliencyMapHook(self).func(cls_scores, cls_scores_provided=True)
+            saliency_map = DetClassProbabilityMapHook(self).func(cls_scores, cls_scores_provided=True)
             return (*bbox_results, feature_vector, saliency_map)
 
         return bbox_results
 
     @mark("custom_yolox_forward", inputs=["input"], outputs=["dets", "labels", "feats", "saliencies"])
     def __forward_impl(ctx, self, img, img_metas, **kwargs):
         """Internal Function for __forward_impl."""
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/l2sp_detector_mixin.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/l2sp_detector_mixin.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/unbiased_teacher.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/detectors/unbiased_teacher.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/cross_dataset_detector_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/cross_dataset_detector_head.py`

 * *Files 1% similar despite different names*

```diff
@@ -107,14 +107,15 @@
         Args:
             points (list[Tensor]): Points of each fpn level, each has shape
                 (num_points, 2).
             gt_bboxes_list (list[Tensor]): Ground truth bboxes of each image,
                 each has shape (num_gt, 4).
             gt_labels_list (list[Tensor]): Ground truth labels of each box,
                 each has shape (num_gt,).
+            img_metas (list[dict]): Meta information for the image.
 
         Returns:
             tuple:
                 concat_lvl_labels (list[Tensor]): Labels of each level. \
                 concat_lvl_bbox_targets (list[Tensor]): BBox targets of each \
                     level.
         """
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_anchor_generator.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_anchor_generator.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_atss_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_atss_head.py`

 * *Files 3% similar despite different names*

```diff
@@ -126,27 +126,31 @@
         bbox_targets,
         valid_label_mask,
         num_total_samples,
     ):
         """Compute loss of a single scale level.
 
         Args:
+            anchors (Tensor): Box reference for each scale level with shape
+                (N, num_total_anchors, 4).
             cls_score (Tensor): Box scores for each scale level
                 Has shape (N, num_anchors * num_classes, H, W).
             bbox_pred (Tensor): Box energies / deltas for each scale
                 level with shape (N, num_anchors * 4, H, W).
-            anchors (Tensor): Box reference for each scale level with shape
-                (N, num_total_anchors, 4).
+            centerness (list[Tensor]): Centerness for each scale
+                level with shape (N, num_anchors * num_classes, H, W)
             labels (Tensor): Labels of each anchors with shape
                 (N, num_total_anchors).
             label_weights (Tensor): Label weights of each anchor with shape
                 (N, num_total_anchors)
             bbox_targets (Tensor): BBox regression targets of each anchor wight
                 shape (N, num_total_anchors, 4).
-            num_total_samples (int): Number os positive samples that is
+            valid_label_mask (Tensor): Label mask for consideration of ignored
+                label with shape (N, num_total_anchors, 1).
+            num_total_samples (int): Number of positive samples that is
                 reduced over all GPUs.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
 
         anchors = anchors.reshape(-1, 4)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_retina_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_retina_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_roi_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_roi_head.py`

 * *Files 4% similar despite different names*

```diff
@@ -70,14 +70,15 @@
             sampling_results (List[obj:SamplingResults]): Assign results of
                 all images in a batch after sampling.
             gt_bboxes (list[Tensor]): Gt_bboxes of all images in a batch,
                 each tensor has shape (num_gt, 4),  the last dimension 4
                 represents [tl_x, tl_y, br_x, br_y].
             gt_labels (list[Tensor]): Gt_labels of all images in a batch,
                 each tensor has shape (num_gt,).
+            img_metas (list[dict]): Meta information of each image.
             rcnn_train_cfg (obj:ConfigDict): `train_cfg` of RCNN.
             concat (bool): Whether to concatenate the results of all
                 the images in a single batch.
 
         Returns:
             Tuple[Tensor]: Ground truth for proposals in a single image.
             Containing the following list of Tensors:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_ssd_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_ssd_head.py`

 * *Files 0% similar despite different names*

```diff
@@ -90,15 +90,15 @@
         """Compute loss of a single image.
 
         Args:
             cls_score (Tensor): Box scores for eachimage
                 Has shape (num_total_anchors, num_classes).
             bbox_pred (Tensor): Box energies / deltas for each image
                 level with shape (num_total_anchors, 4).
-            anchors (Tensor): Box reference for each scale level with shape
+            anchor (Tensor): Box reference for each scale level with shape
                 (num_total_anchors, 4).
             labels (Tensor): Labels of each anchors with shape
                 (num_total_anchors,).
             label_weights (Tensor): Label weights of each anchor with shape
                 (num_total_anchors,)
             bbox_targets (Tensor): BBox regression targets of each anchor
                 weight shape (num_total_anchors, 4).
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_vfnet_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/heads/custom_vfnet_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/cross_focal_loss.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/cross_focal_loss.py`

 * *Files 2% similar despite different names*

```diff
@@ -43,22 +43,21 @@
     if valid_label_mask is not None:
         neg_mask = targets.sum(axis=1) == 0 if use_vfl else targets == num_classes
         neg_idx = neg_mask.nonzero(as_tuple=True)[0]
         cross_mask[neg_idx] = valid_label_mask[neg_idx].type(torch.int8)
 
     if use_vfl:
         calculate_loss_func = varifocal_loss
+    elif torch.cuda.is_available() and inputs.is_cuda:
+        calculate_loss_func = sigmoid_focal_loss
     else:
-        if torch.cuda.is_available() and inputs.is_cuda:
-            calculate_loss_func = sigmoid_focal_loss
-        else:
-            inputs_size = inputs.size(1)
-            targets = F.one_hot(targets, num_classes=inputs_size + 1)
-            targets = targets[:, :inputs_size]
-            calculate_loss_func = py_sigmoid_focal_loss
+        inputs_size = inputs.size(1)
+        targets = F.one_hot(targets, num_classes=inputs_size + 1)
+        targets = targets[:, :inputs_size]
+        calculate_loss_func = py_sigmoid_focal_loss
 
     loss = (
         calculate_loss_func(inputs, targets, weight=weight, gamma=gamma, alpha=alpha, reduction="none", avg_factor=None)
         * cross_mask
     )
 
     if reduction == "mean":
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/losses/l2sp_loss.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/losses/l2sp_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_fpn.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_fpn.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_yolov3_neck.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/necks/mmov_yolov3_neck.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/mmov_bbox_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/bbox_heads/mmov_bbox_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/mmov_mask_head.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/mmov_mask_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/builder.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/nncf/patches.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/patches.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/tasks/exporter.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/exporter.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,56 +1,52 @@
-"""Export task for OTX Detection with MMDET."""
+"""Exporter for OTX Detection task with MMDETECTION training backend."""
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import numpy as np
-from mmcv.runner import wrap_fp16_model
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
-from otx.algorithms.common.adapters.mmcv.tasks.registry import STAGES
-from otx.algorithms.common.adapters.mmdeploy.utils import sync_batchnorm_2_batchnorm
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
+from otx.algorithms.common.adapters.mmdeploy.utils.utils import (
+    sync_batchnorm_2_batchnorm,
+)
 from otx.algorithms.common.utils.logger import get_logger
-
-from .stage import DetectionStage
+from otx.algorithms.detection.adapters.mmdet.utils.builder import build_detector
 
 logger = get_logger()
 
 
-@STAGES.register_module()
-class DetectionExporter(ExporterMixin, DetectionStage):
-    """Export class for object detection."""
+class DetectionExporter(Exporter):
+    """Exporter for OTX Detection using mmdetection training backend."""
 
-    def run(self, model_cfg, model_ckpt, data_cfg, **kwargs):  # noqa: C901
+    def run(self, cfg, **kwargs):  # noqa: C901
         """Run exporter stage."""
 
         precision = kwargs.get("precision", "FP32")
-        model_builder = kwargs.get("model_builder", self.MODEL_BUILDER)
+        model_builder = kwargs.get("model_builder", build_detector)
 
         def model_builder_helper(*args, **kwargs):
             model = model_builder(*args, **kwargs)
             # TODO: handle various input size
             model = sync_batchnorm_2_batchnorm(model, 2)
 
-            if precision == "FP16":
-                wrap_fp16_model(model)
-            elif precision == "INT8":
+            if precision == "INT8":
                 from nncf.torch.nncf_network import NNCFNetwork
 
                 assert isinstance(model, NNCFNetwork)
 
             return model
 
         kwargs["model_builder"] = model_builder_helper
 
-        return super().run(model_cfg, model_ckpt, data_cfg, **kwargs)
+        return super().run(cfg, **kwargs)
 
     @staticmethod
     def naive_export(output_dir, model_builder, precision, cfg, model_name="model"):
-        """Export using pytorch backend."""
+        """Export using torch.onnx directly."""
         from mmdet.apis.inference import LoadImage
         from mmdet.datasets.pipelines import Compose
 
         from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
 
         def get_fake_data(cfg, orig_img_shape=(128, 128, 3)):
             pipeline = [LoadImage()] + cfg.data.test.pipeline[1:]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/builder.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/mmdet/utils/config_utils.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/utils/config_utils.py`

 * *Files 16% similar despite different names*

```diff
@@ -29,40 +29,35 @@
     prepare_work_dir,
     remove_from_config,
     update_config,
 )
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.detection.configs.base import DetectionConfig
 from otx.algorithms.detection.utils.data import (
+    adaptive_tile_params,
     format_list_to_str,
     get_anchor_boxes,
     get_sizes_from_dataset_entity,
 )
-from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.datasets import DatasetEntity, DatasetPurpose
 from otx.api.entities.label import Domain, LabelEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    DirectoryPathCheck,
-    check_input_parameters_type,
-)
 
 try:
     from sklearn.cluster import KMeans
 
     __all__ = ["KMeans"]
 
     KMEANS_IMPORT = True
 except ImportError:
     KMEANS_IMPORT = False
 
 
 logger = get_logger()
 
 
-@check_input_parameters_type({"work_dir": DirectoryPathCheck})
 def patch_config(
     config: Config,
     work_dir: str,
     labels: List[LabelEntity],
 ):  # pylint: disable=too-many-branches
     """Update config function."""
 
@@ -84,24 +79,22 @@
 
     set_data_classes(config, labels)
 
     config.gpu_ids = range(1)
     config.work_dir = work_dir
 
 
-@check_input_parameters_type()
 def patch_model_config(
     config: Config,
     labels: List[LabelEntity],
 ):
     """Patch model config."""
     set_num_classes(config, len(labels))
 
 
-@check_input_parameters_type()
 def set_hyperparams(config: Config, hyperparams: DetectionConfig):
     """Set function for hyperparams (DetectionConfig)."""
     config.data.samples_per_gpu = int(hyperparams.learning_parameters.batch_size)
     config.data.workers_per_gpu = int(hyperparams.learning_parameters.num_workers)
     config.optimizer.lr = float(hyperparams.learning_parameters.learning_rate)
 
     total_iterations = int(hyperparams.learning_parameters.num_iters)
@@ -111,15 +104,14 @@
         config.lr_config.warmup = None
     if is_epoch_based_runner(config.runner):
         config.runner.max_epochs = total_iterations
     else:
         config.runner.max_iters = total_iterations
 
 
-@check_input_parameters_type()
 def patch_adaptive_repeat_dataset(
     config: Union[Config, ConfigDict],
     num_samples: int,
     decay: float = -0.002,
     factor: float = 30,
 ):
     """Patch the repeat times and training epochs adatively.
@@ -145,15 +137,14 @@
             new_epoch = math.ceil(cur_epoch / new_repeat)
             if new_epoch == 1:
                 return
             config.runner.max_epochs = new_epoch
             data_train.times = new_repeat
 
 
-@check_input_parameters_type()
 def prepare_for_training(
     config: Union[Config, ConfigDict],
     data_config: ConfigDict,
 ) -> Union[Config, ConfigDict]:
     """Prepare configs for training phase."""
     prepare_work_dir(config)
 
@@ -176,25 +167,23 @@
 
     if train_num_samples > 0:
         patch_adaptive_repeat_dataset(config, train_num_samples)
 
     return config
 
 
-@check_input_parameters_type()
 def set_data_classes(config: Config, labels: List[LabelEntity]):
     """Setter data classes into config."""
     # Save labels in data configs.
     for subset in ("train", "val", "test"):
         for cfg in get_dataset_configs(config, subset):
             cfg.labels = labels
             #  config.data[subset].labels = labels
 
 
-@check_input_parameters_type()
 def set_num_classes(config: Config, num_classes: int):
     """Set num classes."""
     # Set proper number of classes in model's detection heads.
     head_names = ("mask_head", "bbox_head", "segm_head")
     if "roi_head" in config.model:
         for head_name in head_names:
             if head_name in config.model.roi_head:
@@ -207,25 +196,28 @@
         for head_name in head_names:
             if head_name in config.model:
                 config.model[head_name].num_classes = num_classes
     # FIXME. ?
     # self.config.model.CLASSES = label_names
 
 
-@check_input_parameters_type()
 def patch_datasets(
     config: Config,
     domain: Domain = Domain.DETECTION,
     subsets: Optional[List[str]] = None,
     **kwargs,
 ):
     """Update dataset configs."""
     assert "data" in config
     assert "type" in kwargs
 
+    # This code is for nncf, if we don't consider nncf, this code could be
+    # domain = config.get("domain", Domain.DETECTION)
+    domain = config.get("domain", domain)
+
     if subsets is None:
         subsets = ["train", "val", "test", "unlabeled"]
 
     def update_pipeline(cfg):
         if subset == "train":
             for collect_cfg in get_configs_by_pairs(cfg, dict(type="Collect")):
                 get_meta_keys(collect_cfg)
@@ -283,15 +275,14 @@
             False,
         )
     ):
         return True
     return False
 
 
-@check_input_parameters_type({"dataset": DatasetParamTypeCheck})
 def cluster_anchors(recipe_config: Config, dataset: DatasetEntity):
     """Update configs for cluster_anchors."""
     if not KMEANS_IMPORT:
         raise ImportError(
             "Sklearn package is not installed. To enable anchor boxes clustering, please install "
             "packages from requirements/optional.txt or just scikit-learn package."
         )
@@ -322,7 +313,63 @@
         f"Anchor boxes heights have been updated from {format_list_to_str(prev_generator.heights)} "
         f"to {format_list_to_str(heights)}"
     )
     config_generator = recipe_config.model.bbox_head.anchor_generator
     config_generator.widths, config_generator.heights = widths, heights
 
     recipe_config.model.bbox_head.anchor_generator = config_generator
+
+
+def patch_tiling(config, hparams, dataset=None):
+    """Update config for tiling.
+
+    Args:
+        config (dict): MPA config containing configuration settings.
+        hparams (DetectionConfig): DetectionConfig containing hyperparameters.
+        dataset (DatasetEntity, optional): A dataset entity. Defaults to None.
+
+    Returns:
+        dict: The updated configuration dictionary.
+    """
+    if hparams.tiling_parameters.enable_tiling:
+        logger.info("Tiling enabled")
+
+        if dataset and dataset.purpose != DatasetPurpose.INFERENCE and hparams.tiling_parameters.enable_adaptive_params:
+            adaptive_tile_params(hparams.tiling_parameters, dataset)
+            tiling_params = ConfigDict(
+                tile_size=int(hparams.tiling_parameters.tile_size),
+                overlap_ratio=float(hparams.tiling_parameters.tile_overlap),
+                max_per_img=int(hparams.tiling_parameters.tile_max_number),
+            )
+            config.update(
+                ConfigDict(
+                    data=ConfigDict(
+                        train=tiling_params,
+                        val=tiling_params,
+                        test=tiling_params,
+                    )
+                )
+            )
+
+        if dataset and dataset.purpose == DatasetPurpose.INFERENCE:
+            config.get("data", ConfigDict()).get("val_dataloader", ConfigDict()).update(ConfigDict(samples_per_gpu=1))
+            config.get("data", ConfigDict()).get("test_dataloader", ConfigDict()).update(ConfigDict(samples_per_gpu=1))
+            config.get("data", ConfigDict(samples_per_gpu=1))
+
+        if hparams.tiling_parameters.enable_tile_classifier:
+            logger.info("Tile classifier enabled")
+            logger.info(f"Patch model from: {config.model.type} to CustomMaskRCNNTileOptimized")
+            config.model.type = "CustomMaskRCNNTileOptimized"
+
+            if config.model.backbone.type == "efficientnet_b2b":
+                learning_rate = 0.002
+                logger.info(
+                    f"Patched {config.model.backbone.type} LR: "
+                    f"{hparams.learning_parameters.learning_rate} -> {learning_rate}"
+                )
+                hparams.learning_parameters.learning_rate = learning_rate
+
+            config.data.train.filter_empty_gt = False
+
+        config.update(dict(evaluation=dict(iou_thr=[0.5])))
+
+    return config
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/openvino_models.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/model_wrappers/openvino_models.py`

 * *Files 8% similar despite different names*

```diff
@@ -29,30 +29,46 @@
 
 
 class OTXMaskRCNNModel(MaskRCNNModel):
     """OpenVINO model wrapper for OTX MaskRCNN model."""
 
     __model__ = "OTX_MaskRCNN"
 
+    def __init__(self, model_adapter, configuration, preload=False):
+        super().__init__(model_adapter, configuration, preload)
+        self.resize_mask = True
+
+    def _check_io_number(self, number_of_inputs, number_of_outputs):
+        """Checks whether the number of model inputs/outputs is supported.
+
+        Args:
+            number_of_inputs (int, Tuple(int)): number of inputs supported by wrapper.
+              Use -1 to omit the check
+            number_of_outputs (int, Tuple(int)): number of outputs supported by wrapper.
+              Use -1 to omit the check
+
+        Raises:
+            WrapperError: if the model has unsupported number of inputs/outputs
+        """
+        super()._check_io_number(number_of_inputs, -1)
+
     def _get_outputs(self):
         output_match_dict = {}
         output_names = ["boxes", "labels", "masks", "feature_vector", "saliency_map"]
         for output_name in output_names:
             for node_name, node_meta in self.outputs.items():
                 if output_name in node_meta.names:
                     output_match_dict[output_name] = node_name
                     break
         return output_match_dict
 
     def postprocess(self, outputs, meta):
         """Post process function for OTX MaskRCNN model."""
 
         # pylint: disable-msg=too-many-locals
-        resize_mask = meta.get("resize_mask", True)
-
         # FIXME: here, batch dim of IR must be 1
         boxes = outputs[self.output_blob_name["boxes"]]
         boxes = boxes.squeeze(0)
         assert boxes.ndim == 2
         masks = outputs[self.output_blob_name["masks"]]
         masks = masks.squeeze(0)
         assert masks.ndim == 3
@@ -77,25 +93,32 @@
         scale_y = meta["resized_shape"][0] / meta["original_shape"][0]
         boxes[:, 0::2] /= scale_x
         boxes[:, 1::2] /= scale_y
 
         resized_masks = []
         for box, cls, raw_mask in zip(boxes, classes, masks):
             raw_cls_mask = raw_mask[cls, ...] if self.is_segmentoly else raw_mask
-            if resize_mask:
+            if self.resize_mask:
                 resized_masks.append(self._segm_postprocess(box, raw_cls_mask, *meta["original_shape"][:-1]))
             else:
                 resized_masks.append(raw_cls_mask)
 
         return scores, classes, boxes, resized_masks
 
     def segm_postprocess(self, *args, **kwargs):
         """Post-process for segmentation masks."""
         return self._segm_postprocess(*args, **kwargs)
 
+    def disable_mask_resizing(self):
+        """Disable mask resizing.
+
+        There is no need to resize mask in tile as it will be processed at the end.
+        """
+        self.resize_mask = False
+
 
 class OTXSSDModel(SSD):
     """OpenVINO model wrapper for OTX SSD model."""
 
     __model__ = "OTX_SSD"
 
     def __init__(self, model_adapter, configuration=None, preload=False):
@@ -125,15 +148,19 @@
     def __init__(self, layers, input_size, labels_layer="labels", default_label=0):
         try:
             self.labels_layer = find_layer_by_name(labels_layer, layers)
         except ValueError:
             self.labels_layer = None
             self.default_label = default_label
 
-        self.bboxes_layer = self.find_layer_bboxes_output(layers)
+        try:
+            self.bboxes_layer = self.find_layer_bboxes_output(layers)
+        except ValueError:
+            self.bboxes_layer = find_layer_by_name("boxes", layers)
+
         self.input_size = input_size
 
     @staticmethod
     def find_layer_bboxes_output(layers):
         """find_layer_bboxes_output."""
         filter_outputs = [name for name, data in layers.items() if len(data.shape) == 3 and data.shape[-1] == 5]
         if not filter_outputs:
@@ -142,21 +169,23 @@
             raise ValueError("More than 1 candidate for output with bounding boxes.")
         return filter_outputs[0]
 
     def __call__(self, outputs):
         """Parse bboxes."""
         # FIXME: here, batch dim of IR must be 1
         bboxes = outputs[self.bboxes_layer]
-        bboxes = bboxes.squeeze(0)
+        if bboxes.shape[0] == 1:
+            bboxes = bboxes.squeeze(0)
         assert bboxes.ndim == 2
         scores = bboxes[:, 4]
         bboxes = bboxes[:, :4]
         bboxes[:, 0::2] /= self.input_size[0]
         bboxes[:, 1::2] /= self.input_size[1]
         if self.labels_layer:
             labels = outputs[self.labels_layer]
         else:
             labels = np.full(len(bboxes), self.default_label, dtype=bboxes.dtype)
-        labels = labels.squeeze(0)
+        if labels.shape[0] == 1:
+            labels = labels.squeeze(0)
 
         detections = [Detection(*bbox, score, label) for label, score, bbox in zip(labels, scores, bboxes)]
         return detections
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/__init__.py` & `otx-1.2.0rc1/otx/cli/tools/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-"""Model configurations."""
+"""OTX cli tools."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/configuration.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_detection_static.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_detection_static.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_dynamic.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/deployments/base_instance_segmentation_dynamic.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/single_stage_detector.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/single_stage_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/base/models/unbiased_teacher.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/base/models/unbiased_teacher.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/configuration.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/compression_config.json`

 * *Files 8% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9878472222222222%*

 * *Differences: {"'base'": "{'nncf_config': {'input_info': {'sample_size': {insert: [(2, 1024), (3, 1024)], "*

 * *           "delete: [3, 2]}}, 'log_dir': '/tmp'}}",*

 * * "'nncf_quantization'": "{'nncf_config': {'compression': {0: {'initializer': "*

 * *                        "OrderedDict([('range', OrderedDict([('num_init_samples', 1000)])), "*

 * *                        "('batchnorm_adaptation', OrderedDict([('num_bn_adaptation_samples', "*

 * *                        '1000)]))])}}}}'}*

```diff
@@ -3,34 +3,42 @@
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    640,
-                    640
+                    1024,
+                    1024
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
                     "maximal_absolute_accuracy_degradation": 0.01,
                     "maximal_total_epochs": 20
                 }
             },
             "compression": [
                 {
-                    "algorithm": "quantization"
+                    "algorithm": "quantization",
+                    "initializer": {
+                        "batchnorm_adaptation": {
+                            "num_bn_adaptation_samples": 1000
+                        },
+                        "range": {
+                            "num_init_samples": 1000
+                        }
+                    }
                 }
             ]
         },
         "optimizer": {
             "lr": 0.0005
         }
     },
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/compression_config.json`

 * *Files 8% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9878472222222222%*

 * *Differences: {"'base'": "{'nncf_config': {'input_info': {'sample_size': {insert: [(2, 1024), (3, 1024)], "*

 * *           "delete: [3, 2]}}, 'log_dir': '/tmp'}}",*

 * * "'nncf_quantization'": "{'nncf_config': {'compression': {0: {'initializer': "*

 * *                        "OrderedDict([('range', OrderedDict([('num_init_samples', 1000)])), "*

 * *                        "('batchnorm_adaptation', OrderedDict([('num_bn_adaptation_samples', "*

 * *                        '1000)]))])}}}}'}*

```diff
@@ -3,34 +3,42 @@
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    640,
-                    640
+                    1024,
+                    1024
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
                     "maximal_absolute_accuracy_degradation": 0.01,
                     "maximal_total_epochs": 20
                 }
             },
             "compression": [
                 {
-                    "algorithm": "quantization"
+                    "algorithm": "quantization",
+                    "initializer": {
+                        "batchnorm_adaptation": {
+                            "num_bn_adaptation_samples": 1000
+                        },
+                        "range": {
+                            "num_init_samples": 1000
+                        }
+                    }
                 }
             ]
         },
         "optimizer": {
             "lr": 0.0005
         }
     },
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/semisl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/template.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Object Detection for YOLOX
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/cspdarknet_yolox/tile_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
-# TODO[EUGENE]: SKIP MOSAIC AND MultiImageMixDataset in tiling
+# NOTE: SKIP MOSAIC AND MultiImageMixDataset in tiling
 
 dataset_type = "CocoDataset"
 
 img_scale = (640, 640)
 
 tile_cfg = dict(
     tile_size=400, min_area_ratio=0.9, overlap_ratio=0.2, iou_threshold=0.45, max_per_img=1500, filter_empty_gt=True
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/compression_config.json`

 * *Files 6% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'input_info': {'sample_size': {insert: [(2, 864), (3, 864)], delete: "*

 * *           "[3, 2]}}, 'log_dir': '/tmp'}}",*

 * * "'nncf_quantization_pruning'": "{'nncf_config': {'compression': {0: {'ignored_scopes': "*

 * *                                "['{re}CustomSingleStageDetector/CustomSSDHead\\\\[bbox_head\\\\].*']}}}}"}*

```diff
@@ -3,19 +3,19 @@
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    992,
-                    736
+                    864,
+                    864
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
@@ -51,14 +51,17 @@
                     "maximal_total_epochs": 100,
                     "patience_epochs": 5
                 }
             },
             "compression": [
                 {
                     "algorithm": "filter_pruning",
+                    "ignored_scopes": [
+                        "{re}CustomSingleStageDetector/CustomSSDHead\\[bbox_head\\].*"
+                    ],
                     "params": {
                         "filter_importance": "geometric_median",
                         "pruning_flops_target": 0.1,
                         "schedule": "baseline"
                     }
                 },
                 {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/model.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,20 +13,23 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
-    "../../../../../recipes/stages/detection/incremental.py",
-    "../../../../common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml",
-    "../../base/models/detector.py",
+    "../../../../../../recipes/stages/detection/semisl.py",
+    "../../../../../common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml",
+    "../../../base/models/detector.py",
 ]
 
 model = dict(
+    super_type="UnbiasedTeacher",
+    pseudo_conf_thresh=0.25,
+    unlabeled_loss_weight=1.0,
     type="CustomATSS",
     neck=dict(
         type="FPN",
         in_channels=[24, 32, 96, 320],
         out_channels=64,
         start_level=1,
         add_extra_convs="on_output",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/compression_config.json`

 * *Files 7% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.99609375%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -7,15 +7,15 @@
                 "sample_size": [
                     1,
                     3,
                     992,
                     736
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of ATSS model for Detection Task."""
+"""Model Configuration of SSD model for Detection Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -15,80 +15,88 @@
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
     "../../../../../../recipes/stages/detection/semisl.py",
     "../../../../../common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml",
-    "../../../base/models/detector.py",
+    "../../../base/models/single_stage_detector.py",
 ]
 
+__width_mult = 1.0
+
 model = dict(
     super_type="UnbiasedTeacher",
     pseudo_conf_thresh=0.25,
     unlabeled_loss_weight=1.0,
-    type="CustomATSS",
-    neck=dict(
-        type="FPN",
-        in_channels=[24, 32, 96, 320],
-        out_channels=64,
-        start_level=1,
-        add_extra_convs="on_output",
-        num_outs=5,
-        relu_before_extra_convs=True,
-    ),
+    type="CustomSingleStageDetector",
     bbox_head=dict(
-        type="CustomATSSHead",
-        num_classes=2,
-        in_channels=64,
-        stacked_convs=4,
-        feat_channels=64,
+        type="CustomSSDHead",
+        num_classes=80,
+        in_channels=(int(__width_mult * 96), int(__width_mult * 320)),
+        use_depthwise=True,
+        norm_cfg=dict(type="BN"),
+        act_cfg=dict(type="ReLU"),
+        init_cfg=dict(type="Xavier", layer="Conv2d", distribution="uniform"),
+        loss_balancing=False,
         anchor_generator=dict(
-            type="AnchorGenerator",
-            ratios=[1.0],
-            octave_base_scale=8,
-            scales_per_octave=1,
-            strides=[8, 16, 32, 64, 128],
+            type="SSDAnchorGeneratorClustered",
+            strides=(16, 32),
+            reclustering_anchors=True,
+            widths=[
+                [
+                    38.641007923271076,
+                    92.49516032784699,
+                    271.4234764938237,
+                    141.53469410876247,
+                ],
+                [
+                    206.04136086566515,
+                    386.6542727907841,
+                    716.9892752215089,
+                    453.75609561761405,
+                    788.4629155558277,
+                ],
+            ],
+            heights=[
+                [
+                    48.9243877087132,
+                    147.73088476194903,
+                    158.23569788707474,
+                    324.14510379107367,
+                ],
+                [
+                    587.6216059488938,
+                    381.60024152086544,
+                    323.5988913027747,
+                    702.7486097568518,
+                    741.4865860938451,
+                ],
+            ],
         ),
         bbox_coder=dict(
             type="DeltaXYWHBBoxCoder",
-            target_means=[0.0, 0.0, 0.0, 0.0],
-            target_stds=[0.1, 0.1, 0.2, 0.2],
-        ),
-        loss_cls=dict(type="FocalLoss", use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=1.0),
-        loss_bbox=dict(type="GIoULoss", loss_weight=2.0),
-        loss_centerness=dict(type="CrossEntropyLoss", use_sigmoid=True, loss_weight=1.0),
-        use_qfl=False,
-        qfl_cfg=dict(
-            type="QualityFocalLoss",
-            use_sigmoid=True,
-            beta=2.0,
-            loss_weight=1.0,
+            target_means=(0.0, 0.0, 0.0, 0.0),
+            target_stds=(0.1, 0.1, 0.2, 0.2),
         ),
     ),
     train_cfg=dict(
-        assigner=dict(type="ATSSAssigner", topk=9),
-        allowed_border=-1,
-        pos_weight=-1,
-        debug=False,
-    ),
-    test_cfg=dict(
-        nms_pre=1000,
-        min_bbox_size=0,
-        score_thr=0.05,
-        nms=dict(type="nms", iou_threshold=0.6),
-        max_per_img=100,
+        assigner=dict(
+            pos_iou_thr=0.4,
+            neg_iou_thr=0.4,
+        ),
+        use_giou=False,
+        use_focal=False,
     ),
     backbone=dict(
         out_indices=(
-            2,
-            3,
             4,
             5,
         )
     ),
 )
 
 load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/object_detection/v2/mobilenet_v2-atss.pth"
+/models/object_detection/v2/mobilenet_v2-2s_ssd-992x736.pth"
 
 fp16 = dict(loss_scale=512.0)
+ignore = False
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/template.yaml`

 * *Files 8% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Object Detection for ATSS
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_atss/semisl/compression_config.json`

 * *Files 18% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9921875%*

 * *Differences: {"'base'": "{'nncf_config': {'input_info': {'sample_size': {insert: [(2, 992), (3, 736)], delete: "*

 * *           "[3, 2]}}, 'log_dir': '/tmp'}}",*

 * * "'nncf_quantization_pruning'": "{'nncf_config': {'compression': {0: {delete: "*

 * *                                "['ignored_scopes']}}}}"}*

```diff
@@ -3,19 +3,19 @@
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    864,
-                    864
+                    992,
+                    736
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
@@ -51,17 +51,14 @@
                     "maximal_total_epochs": 100,
                     "patience_epochs": 5
                 }
             },
             "compression": [
                 {
                     "algorithm": "filter_pruning",
-                    "ignored_scopes": [
-                        "{re}CustomSingleStageDetector/CustomSSDHead\\[bbox_head\\].*"
-                    ],
                     "params": {
                         "filter_importance": "geometric_median",
                         "pruning_flops_target": 0.1,
                         "schedule": "baseline"
                     }
                 },
                 {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/compression_config.json`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.99609375%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -7,15 +7,15 @@
                 "sample_size": [
                     1,
                     3,
                     864,
                     864
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/model.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model Configuration of SSD model for Detection Task."""
+"""Model Configuration of VFNet model for Detection Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -13,90 +13,90 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
-    "../../../../../../recipes/stages/detection/semisl.py",
-    "../../../../../common/adapters/mmcv/configs/backbones/mobilenet_v2_w1.yaml",
-    "../../../base/models/single_stage_detector.py",
+    "../../../../../recipes/stages/detection/incremental.py",
+    "../../../../common/adapters/mmcv/configs/backbones/resnet50.yaml",
+    "../../base/models/detector.py",
 ]
 
-__width_mult = 1.0
-
 model = dict(
-    super_type="UnbiasedTeacher",
-    pseudo_conf_thresh=0.25,
-    unlabeled_loss_weight=1.0,
-    type="CustomSingleStageDetector",
+    type="CustomVFNet",
+    neck=dict(
+        type="FPN",
+        in_channels=[256, 512, 1024, 2048],
+        out_channels=256,
+        start_level=1,
+        add_extra_convs="on_output",
+        num_outs=5,
+        relu_before_extra_convs=True,
+    ),
     bbox_head=dict(
-        type="CustomSSDHead",
-        num_classes=80,
-        in_channels=(int(__width_mult * 96), int(__width_mult * 320)),
-        use_depthwise=True,
-        norm_cfg=dict(type="BN"),
-        act_cfg=dict(type="ReLU"),
-        init_cfg=dict(type="Xavier", layer="Conv2d", distribution="uniform"),
-        loss_balancing=False,
-        anchor_generator=dict(
-            type="SSDAnchorGeneratorClustered",
-            strides=(16, 32),
-            reclustering_anchors=True,
-            widths=[
-                [
-                    38.641007923271076,
-                    92.49516032784699,
-                    271.4234764938237,
-                    141.53469410876247,
-                ],
-                [
-                    206.04136086566515,
-                    386.6542727907841,
-                    716.9892752215089,
-                    453.75609561761405,
-                    788.4629155558277,
-                ],
-            ],
-            heights=[
-                [
-                    48.9243877087132,
-                    147.73088476194903,
-                    158.23569788707474,
-                    324.14510379107367,
-                ],
-                [
-                    587.6216059488938,
-                    381.60024152086544,
-                    323.5988913027747,
-                    702.7486097568518,
-                    741.4865860938451,
-                ],
-            ],
-        ),
-        bbox_coder=dict(
-            type="DeltaXYWHBBoxCoder",
-            target_means=(0.0, 0.0, 0.0, 0.0),
-            target_stds=(0.1, 0.1, 0.2, 0.2),
+        type="CustomVFNetHead",
+        num_classes=2,
+        in_channels=256,
+        stacked_convs=3,
+        feat_channels=256,
+        strides=[8, 16, 32, 64, 128],
+        center_sampling=False,
+        dcn_on_last_conv=False,
+        use_atss=True,
+        use_vfl=True,
+        loss_cls=dict(
+            type="VarifocalLoss",
+            use_sigmoid=True,
+            alpha=0.75,
+            gamma=2.0,
+            iou_weighted=True,
+            loss_weight=1.0,
         ),
+        loss_bbox=dict(type="GIoULoss", loss_weight=1.5),
+        loss_bbox_refine=dict(type="GIoULoss", loss_weight=2.0),
     ),
     train_cfg=dict(
-        assigner=dict(
-            pos_iou_thr=0.4,
-            neg_iou_thr=0.4,
-        ),
-        use_giou=False,
-        use_focal=False,
+        assigner=dict(type="ATSSAssigner", topk=9),
+        allowed_border=-1,
+        pos_weight=-1,
+        debug=False,
     ),
-    backbone=dict(
-        out_indices=(
-            4,
-            5,
-        )
+    test_cfg=dict(
+        nms_pre=1000,
+        min_bbox_size=0,
+        score_thr=0.01,
+        nms=dict(type="nms", iou_threshold=0.5),
+        max_per_img=100,
     ),
 )
 
 load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/object_detection/v2/mobilenet_v2-2s_ssd-992x736.pth"
+/models/object_detection/v2/resnet50-vfnet.pth"
 
-fp16 = dict(loss_scale=512.0)
-ignore = False
+__img_norm_cfg = dict(
+    mean=[123.675, 116.28, 103.53],
+    std=[58.395, 57.12, 57.375],
+    to_rgb=True,
+)
+
+data = dict(
+    pipeline_options=dict(
+        MinIouRandomCrop=dict(min_crop_size=0.1),
+        Resize=dict(
+            img_scale=[(1344, 480), (1344, 960)],
+            multiscale_mode="range",
+        ),
+        Normalize=dict(**__img_norm_cfg),
+        MultiScaleFlipAug=dict(
+            img_scale=(1344, 800),
+            flip=False,
+            transforms=[
+                dict(type="Resize", keep_ratio=False),
+                dict(type="Normalize", **__img_norm_cfg),
+                dict(type="Pad", size_divisor=32),
+                dict(type="ImageToTensor", keys=["img"]),
+                dict(type="Collect", keys=["img"]),
+            ],
+        ),
+    ),
+)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/template.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Object Detection for SSD
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/mobilenetv2_ssd/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9947916666666666%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -7,15 +7,15 @@
                 "sample_size": [
                     1,
                     3,
                     1333,
                     800
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/model.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model Configuration of VFNet model for Detection Task."""
+"""Semi-SL model configuration of OCR-Lite-HRnet-18 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -13,90 +13,48 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
-    "../../../../../recipes/stages/detection/incremental.py",
-    "../../../../common/adapters/mmcv/configs/backbones/resnet50.yaml",
-    "../../base/models/detector.py",
+    "../../../../../recipes/stages/segmentation/semisl.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
 ]
 
 model = dict(
-    type="CustomVFNet",
-    neck=dict(
-        type="FPN",
-        in_channels=[256, 512, 1024, 2048],
-        out_channels=256,
-        start_level=1,
-        add_extra_convs="on_output",
-        num_outs=5,
-        relu_before_extra_convs=True,
-    ),
-    bbox_head=dict(
-        type="CustomVFNetHead",
+    type="MeanTeacherSegmentor",
+    orig_type="OTXEncoderDecoder",
+    unsup_weight=0.1,
+    train_cfg=dict(mix_loss=dict(enable=False, weight=0.1)),
+    test_cfg=dict(mode="whole", output_scale=5.0),
+    pretrained=None,
+    decode_head=dict(
+        type="FCNHead",
+        in_channels=[40, 80, 160, 320],
+        in_index=[0, 1, 2, 3],
+        input_transform="multiple_select",
+        channels=40,
+        kernel_size=1,
+        num_convs=1,
+        concat_input=False,
+        dropout_ratio=-1,
         num_classes=2,
-        in_channels=256,
-        stacked_convs=3,
-        feat_channels=256,
-        strides=[8, 16, 32, 64, 128],
-        center_sampling=False,
-        dcn_on_last_conv=False,
-        use_atss=True,
-        use_vfl=True,
-        loss_cls=dict(
-            type="VarifocalLoss",
-            use_sigmoid=True,
-            alpha=0.75,
-            gamma=2.0,
-            iou_weighted=True,
-            loss_weight=1.0,
-        ),
-        loss_bbox=dict(type="GIoULoss", loss_weight=1.5),
-        loss_bbox_refine=dict(type="GIoULoss", loss_weight=2.0),
-    ),
-    train_cfg=dict(
-        assigner=dict(type="ATSSAssigner", topk=9),
-        allowed_border=-1,
-        pos_weight=-1,
-        debug=False,
-    ),
-    test_cfg=dict(
-        nms_pre=1000,
-        min_bbox_size=0,
-        score_thr=0.01,
-        nms=dict(type="nms", iou_threshold=0.5),
-        max_per_img=100,
+        norm_cfg=dict(type="BN", requires_grad=True),
+        align_corners=False,
+        enable_aggregator=True,
+        enable_out_norm=False,
+        loss_decode=[
+            dict(
+                type="CrossEntropyLoss",
+                use_sigmoid=False,
+                loss_weight=1.0,
+            ),
+        ],
     ),
 )
+__norm_cfg = dict(type="BN", requires_grad=True)
 
 load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/object_detection/v2/resnet50-vfnet.pth"
+/models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth"
 
-__img_norm_cfg = dict(
-    mean=[123.675, 116.28, 103.53],
-    std=[58.395, 57.12, 57.375],
-    to_rgb=True,
-)
-
-data = dict(
-    pipeline_options=dict(
-        MinIouRandomCrop=dict(min_crop_size=0.1),
-        Resize=dict(
-            img_scale=[(1344, 480), (1344, 960)],
-            multiscale_mode="range",
-        ),
-        Normalize=dict(**__img_norm_cfg),
-        MultiScaleFlipAug=dict(
-            img_scale=(1344, 800),
-            flip=False,
-            transforms=[
-                dict(type="Resize", keep_ratio=False),
-                dict(type="Normalize", **__img_norm_cfg),
-                dict(type="Pad", size_divisor=32),
-                dict(type="ImageToTensor", keys=["img"]),
-                dict(type="Collect", keys=["img"]),
-            ],
-        ),
-    ),
-)
+fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/template_experimental.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/template_experimental.yaml`

 * *Files 13% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 task_type: DETECTION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Object Detection for VFNet
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/detection/resnet50_vfnet/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/configuration.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-description: Configuration for an instance segmentation task
-header: Configuration for an instance segmentation task
+description: Configuration for an rotated detection task
+header: Configuration for an rotated detection task
 learning_parameters:
   batch_size:
     affects_outcome_of: TRAINING
     default_value: 5
     description:
       The number of training samples seen in each iteration of training.
       Increasing this value improves training time and may make the training more
@@ -258,30 +258,14 @@
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: Incremental
     visible_in_ui: True
     warning: null
-  mem_cache_size:
-    affects_outcome_of: TRAINING
-    default_value: 0
-    description: Size of memory pool for caching decoded data to load data faster (bytes).
-    editable: true
-    header: Size of memory pool
-    max_value: 9223372036854775807
-    min_value: 0
-    type: INTEGER
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    visible_in_ui: false
-    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
 type: CONFIGURABLE_PARAMETERS
 visible_in_ui: true
 pot_parameters:
   description: POT Parameters
   header: POT Parameters
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/compression_config.json`

 * *Files 10% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.8365885416666666%*

 * *Differences: {"'base'": "{'nncf_config': {'target_metric_name': 'mDice', 'input_info': {'sample_size': {insert: "*

 * *           "[(2, 512), (3, 512)], delete: [3, 2]}}, 'log_dir': '/tmp'}, 'params_config': "*

 * *           "OrderedDict([('iters', 0), ('open_layers', [])]), 'checkpoint_config': "*

 * *           "OrderedDict([('interval', -1)])}",*

 * * "'nncf_quantization'": "{'optimizer': {'lr': 0.0001}, 'nncf_config': {'compression': {0: "*

 * *                        "{'initializer': {'range': {'num_init_samples': 500}, "*

 * *                 []*

```diff
@@ -1,48 +1,72 @@
 {
     "base": {
+        "checkpoint_config": {
+            "interval": -1
+        },
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    1024,
-                    1024
+                    512,
+                    512
                 ]
             },
-            "log_dir": ".",
-            "target_metric_name": "mAP"
+            "log_dir": "/tmp",
+            "target_metric_name": "mDice"
+        },
+        "params_config": {
+            "iters": 0,
+            "open_layers": []
         }
     },
     "nncf_quantization": {
+        "lr_config": {
+            "_delete_": true,
+            "by_epoch": true,
+            "fixed": null,
+            "fixed_iters": 0,
+            "policy": "customstep",
+            "step": [
+                90
+            ],
+            "warmup": null,
+            "warmup_iters": 0
+        },
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
-                    "maximal_absolute_accuracy_degradation": 0.01,
-                    "maximal_total_epochs": 20
+                    "maximal_absolute_accuracy_degradation": 1.0,
+                    "maximal_total_epochs": 180
                 }
             },
             "compression": [
                 {
                     "algorithm": "quantization",
+                    "ignored_scopes": [
+                        "{re}.*cross_resolution_weighting.*__mul__.*",
+                        "{re}.*spatial_weighting.*__mul__.*"
+                    ],
                     "initializer": {
                         "batchnorm_adaptation": {
-                            "num_bn_adaptation_samples": 1000
+                            "num_bn_adaptation_samples": 500
                         },
                         "range": {
-                            "num_init_samples": 1000
+                            "num_init_samples": 500
                         }
-                    }
+                    },
+                    "preset": "mixed"
                 }
             ]
         },
         "optimizer": {
-            "lr": 0.0005
+            "lr": 0.0001
         }
     },
     "order_of_parts": [
         "nncf_quantization"
     ]
 }
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/template.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: INSTANCE_SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Instance Segmentation for MaskRCNN-EfficientNetB2B
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9947916666666666%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -7,15 +7,15 @@
                 "sample_size": [
                     1,
                     3,
                     1344,
                     800
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/template.yaml`

 * *Files 26% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: INSTANCE_SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Instance Segmentation for MaskRCNN-ResNet50
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/configuration.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,10 @@
-description: Configuration for an rotated detection task
-header: Configuration for an rotated detection task
+description: Configuration for an semantic segmentation task
+header: Configuration for an semantic segmentation task
+id: ""
 learning_parameters:
   batch_size:
     affects_outcome_of: TRAINING
     default_value: 5
     description:
       The number of training samples seen in each iteration of training.
       Increasing this value improves training time and may make the training more
@@ -38,20 +39,41 @@
     min_value: 1.0e-07
     type: FLOAT
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    value: 0.01
+    value: 0.001
     visible_in_ui: true
     warning: null
     auto_hpo_state: NOT_POSSIBLE
+  learning_rate_fixed_iters:
+    affects_outcome_of: TRAINING
+    auto_hpo_state: not_possible
+    auto_hpo_value: null
+    default_value: 100
+    description: ""
+    editable: true
+    header: Number of iterations for fixed learning rate
+    max_value: 5000
+    min_value: 0
+    type: INTEGER
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: 100
+    visible_in_ui: true
+    warning: null
   learning_rate_warmup_iters:
     affects_outcome_of: TRAINING
+    auto_hpo_state: not_possible
+    auto_hpo_value: null
     default_value: 100
     description: ""
     editable: true
     header: Number of iterations for learning rate warmup
     max_value: 10000
     min_value: 0
     type: INTEGER
@@ -61,14 +83,16 @@
       rules: []
       type: UI_RULES
     value: 100
     visible_in_ui: true
     warning: null
   num_checkpoints:
     affects_outcome_of: NONE
+    auto_hpo_state: not_possible
+    auto_hpo_value: null
     default_value: 5
     description: ""
     editable: true
     header: Number of checkpoints that is done during the single training round
     max_value: 100
     min_value: 1
     type: INTEGER
@@ -78,14 +102,16 @@
       rules: []
       type: UI_RULES
     value: 5
     visible_in_ui: true
     warning: null
   num_iters:
     affects_outcome_of: TRAINING
+    auto_hpo_state: not_possible
+    auto_hpo_value: null
     default_value: 1
     description:
       Increasing this value causes the results to be more robust but training
       time will be longer.
     editable: true
     header: Number of training iterations
     max_value: 100000
@@ -97,14 +123,16 @@
       rules: []
       type: UI_RULES
     value: 1
     visible_in_ui: true
     warning: null
   num_workers:
     affects_outcome_of: NONE
+    auto_hpo_state: not_possible
+    auto_hpo_value: null
     default_value: 0
     description:
       Increasing this value might improve training speed however it might
       cause out of memory errors. If the number of workers is set to zero, data loading
       will happen in the main training thread.
     editable: true
     header: Number of cpu threads to use during batch generation
@@ -146,27 +174,27 @@
       operator: AND
       rules: []
       type: UI_RULES
     value: 3
     visible_in_ui: false
   early_stop_patience:
     affects_outcome_of: TRAINING
-    default_value: 10
+    default_value: 8
     description: Training will stop if the model does not improve within the number of epochs of patience.
     editable: true
     header: Patience for early stopping
     max_value: 50
     min_value: 0
     type: INTEGER
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    value: 10
+    value: 8
     visible_in_ui: true
     warning: This is applied exclusively when early stopping is enabled.
   early_stop_iteration_patience:
     affects_outcome_of: TRAINING
     default_value: 0
     description:
       Training will stop if the model does not improve within the number of iterations of patience.
@@ -180,28 +208,30 @@
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: 0
     visible_in_ui: true
     warning: This is applied exclusively when early stopping is enabled.
-  use_adaptive_interval:
+  enable_supcon:
     affects_outcome_of: TRAINING
-    default_value: true
-    description: Depending on the size of iteration per epoch, adaptively update the validation interval and related values.
+    default_value: false
+    description:
+      Enable an auxiliar supervised contrastive loss, which might increase robustness
+      and accuracy for small datasets.
     editable: true
-    header: Use adaptive validation interval
+    header: Enable Supervised Contrastive helper loss
     type: BOOLEAN
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     visible_in_ui: true
-    warning: This will automatically control the patience and interval when early stopping is enabled.
+    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
 postprocessing:
   confidence_threshold:
     affects_outcome_of: INFERENCE
     default_value: 0.35
     description:
@@ -213,16 +243,15 @@
     min_value: 0
     type: FLOAT
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    # value: 0.35
-    value: 0.01
+    value: 0.35
     visible_in_ui: true
     warning: null
   description: Postprocessing
   header: Postprocessing
   result_based_confidence_threshold:
     affects_outcome_of: INFERENCE
     default_value: true
@@ -248,24 +277,41 @@
     default_value: Incremental
     description: Training scheme option that determines how to train the model
     editable: True
     enum_name: TrainType
     header: Train type
     options:
       Incremental: "Incremental"
-      SEMISUPEVISED: "Semisupervised"
+      Semisupervised: "Semisupervised"
+      Selfsupervised: "Selfsupervised"
     type: SELECTABLE
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: Incremental
     visible_in_ui: True
     warning: null
+  mem_cache_size:
+    affects_outcome_of: TRAINING
+    default_value: 0
+    description: Size of memory pool for caching decoded data to load data faster (bytes).
+    editable: true
+    header: Size of memory pool
+    max_value: 9223372036854775807
+    min_value: 0
+    type: INTEGER
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    visible_in_ui: false
+    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
 type: CONFIGURABLE_PARAMETERS
 visible_in_ui: true
 pot_parameters:
   description: POT Parameters
   header: POT Parameters
@@ -301,31 +347,14 @@
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: 300
     visible_in_ui: True
     warning: null
-  stat_requests_number:
-    affects_outcome_of: NONE
-    default_value: 0
-    description: Number of requests during statistics collection
-    editable: true
-    header: Number of requests
-    max_value: 9223372036854775807
-    min_value: 0
-    type: INTEGER
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: 0
-    visible_in_ui: false
-    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
 nncf_optimization:
   description: Optimization by NNCF
   header: Optimization by NNCF
   enable_quantization:
     affects_outcome_of: INFERENCE
@@ -387,100 +416,7 @@
       rules: []
       type: UI_RULES
     value: 1.0
     visible_in_ui: True
     warning: null
   type: PARAMETER_GROUP
   visible_in_ui: True
-
-tiling_parameters:
-  header: Tiling
-  description: Crop dataset to tiles
-
-  enable_tiling:
-    header: Enable tiling
-    description: Set to True to allow tiny objects to be better detected.
-    default_value: false
-    editable: true
-    affects_outcome_of: TRAINING
-    type: BOOLEAN
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: true
-    visible_in_ui: true
-    warning: Tiling trades off speed for accuracy as it increases the number of images to be processed.
-
-  enable_adaptive_params:
-    header: Enable adaptive tiling parameters
-    description: Config tile size and tile overlap adaptively based on annotated dataset statistic
-    default_value: True
-    editable: true
-    affects_outcome_of: TRAINING
-    type: BOOLEAN
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: true
-    visible_in_ui: true
-    warning: null
-
-  tile_size:
-    header: Tile Image Size
-    description: Tile Image Size
-    affects_outcome_of: TRAINING
-    default_value: 400
-    min_value: 100
-    max_value: 1024
-    type: INTEGER
-    editable: true
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: 400
-    visible_in_ui: true
-    warning: null
-
-  tile_overlap:
-    header: Tile Overlap
-    description: Overlap between each two neighboring tiles.
-    affects_outcome_of: TRAINING
-    default_value: 0.2
-    min_value: 0.0
-    max_value: 1.0
-    type: FLOAT
-    editable: true
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: 0.2
-    visible_in_ui: true
-    warning: null
-
-  tile_max_number:
-    header: Max object per image
-    description: Max object per image
-    affects_outcome_of: TRAINING
-    default_value: 1500
-    min_value: 1
-    max_value: 10000
-    type: INTEGER
-    editable: true
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: 1500
-    visible_in_ui: true
-    warning: null
-
-  type: PARAMETER_GROUP
-  visible_in_ui: true
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/compression_config.json`

 * *Files 11% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.8365885416666666%*

 * *Differences: {"'base'": "{'nncf_config': {'target_metric_name': 'mDice', 'input_info': {'sample_size': {insert: "*

 * *           "[(2, 512), (3, 512)], delete: [3, 2]}}, 'log_dir': '/tmp'}, 'params_config': "*

 * *           "OrderedDict([('iters', 0), ('open_layers', [])]), 'checkpoint_config': "*

 * *           "OrderedDict([('interval', -1)])}",*

 * * "'nncf_quantization'": "{'optimizer': {'lr': 0.0001}, 'nncf_config': {'compression': {0: "*

 * *                        "{'initializer': {'range': {'num_init_samples': 500}, "*

 * *                 []*

```diff
@@ -1,48 +1,71 @@
 {
     "base": {
+        "checkpoint_config": {
+            "interval": -1
+        },
         "find_unused_parameters": true,
         "nncf_config": {
             "compression": [],
             "input_info": {
                 "sample_size": [
                     1,
                     3,
-                    1024,
-                    1024
+                    512,
+                    512
                 ]
             },
-            "log_dir": ".",
-            "target_metric_name": "mAP"
+            "log_dir": "/tmp",
+            "target_metric_name": "mDice"
+        },
+        "params_config": {
+            "iters": 0,
+            "open_layers": []
         }
     },
     "nncf_quantization": {
+        "lr_config": {
+            "_delete_": true,
+            "fixed": null,
+            "fixed_iters": 0,
+            "policy": "customstep",
+            "step": [
+                20
+            ],
+            "warmup": null,
+            "warmup_iters": 0
+        },
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
-                    "maximal_absolute_accuracy_degradation": 0.01,
-                    "maximal_total_epochs": 20
+                    "maximal_absolute_accuracy_degradation": 1.0,
+                    "maximal_total_epochs": 40
                 }
             },
             "compression": [
                 {
                     "algorithm": "quantization",
+                    "ignored_scopes": [
+                        "{re}.*cross_resolution_weighting.*__mul__.*",
+                        "{re}.*spatial_weighting.*__mul__.*"
+                    ],
                     "initializer": {
                         "batchnorm_adaptation": {
-                            "num_bn_adaptation_samples": 1000
+                            "num_bn_adaptation_samples": 500
                         },
                         "range": {
-                            "num_init_samples": 1000
+                            "num_init_samples": 500
                         }
-                    }
+                    },
+                    "preset": "mixed"
                 }
             ]
         },
         "optimizer": {
-            "lr": 0.0005
+            "lr": 0.0001
         }
     },
     "order_of_parts": [
         "nncf_quantization"
     ]
 }
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/template.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 # Description.
-model_template_id: Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_EfficientNetB2B
-name: MaskRCNN-EfficientNetB2B
+model_template_id: Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_ResNet50
+name: MaskRCNN-ResNet50
 task_type: ROTATED_DETECTION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Rotated object detection for MaskRCNN-EfficientNetB2B
+summary: Class-Incremental Rotated object detection for MaskRCNN-ResNet50
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
         default_value: 4
         auto_hpo_state: POSSIBLE
       learning_rate:
-        default_value: 0.015
+        default_value: 0.001
         auto_hpo_state: POSSIBLE
       learning_rate_warmup_iters:
         default_value: 100
       num_iters:
         default_value: 100
     pot_parameters:
       stat_requests_number:
@@ -54,9 +54,9 @@
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 68.48
-size: 13.27
+gigaflops: 533.8
+size: 177.9
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/compression_config.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9947916666666666%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -7,15 +7,15 @@
                 "sample_size": [
                     1,
                     3,
                     1344,
                     800
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mAP"
         }
     },
     "nncf_quantization": {
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/model.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/template.yaml` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/template.yaml`

 * *Files 24% similar despite different names*

```diff
@@ -1,47 +1,45 @@
 # Description.
-model_template_id: Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_ResNet50
-name: MaskRCNN-ResNet50
-task_type: ROTATED_DETECTION
+model_template_id: Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR
+name: Lite-HRNet-18-mod2
+task_type: SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Rotated object detection for MaskRCNN-ResNet50
+summary: Class-Incremental Semantic Segmentation with middle-sized architecture which based on the Lite-HRNet backbone for the balance between the fast inference and long training.
 application: ~
 
 # Algo backend.
-framework: OTEDetection v2.9.1
+framework: OTXSegmentation v0.14.0
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.detection.tasks.DetectionTrainTask
-  openvino: otx.algorithms.detection.tasks.OpenVINODetectionTask
-  nncf: otx.algorithms.detection.tasks.DetectionNNCFTask
+  base: otx.algorithms.segmentation.adapters.mmseg.task.MMSegmentationTask
+  openvino: otx.algorithms.segmentation.adapters.openvino.task.OpenVINOSegmentationTask
+  nncf: otx.algorithms.segmentation.adapters.mmseg.nncf.task.SegmentationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
-        default_value: 4
-        auto_hpo_state: POSSIBLE
+        default_value: 8
       learning_rate:
         default_value: 0.001
         auto_hpo_state: POSSIBLE
+      learning_rate_fixed_iters:
+        default_value: 0
       learning_rate_warmup_iters:
         default_value: 100
       num_iters:
-        default_value: 100
-    pot_parameters:
-      stat_requests_number:
-        default_value: 1
+        default_value: 300
     nncf_optimization:
       enable_quantization:
         default_value: true
       enable_pruning:
         default_value: false
       pruning_supported:
         default_value: false
@@ -54,9 +52,9 @@
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 533.8
-size: 177.9
+gigaflops: 3.63
+size: 4.8
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/tile_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/tile_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tasks/nncf.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/mmdet/nncf/task.py`

 * *Files 16% similar despite different names*

```diff
@@ -15,75 +15,73 @@
 # and limitations under the License.
 
 
 from functools import partial
 from typing import Optional
 
 import otx.algorithms.detection.adapters.mmdet.nncf.patches  # noqa: F401  # pylint: disable=unused-import
-from otx.algorithms.common.adapters.mmcv.utils import remove_from_config
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
+from otx.algorithms.common.tasks.nncf_task import NNCFBaseTask
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.detection.adapters.mmdet.nncf import build_nncf_detector
+from otx.algorithms.detection.adapters.mmdet.task import MMDetectionTask
 from otx.algorithms.detection.adapters.mmdet.utils.config_utils import (
     should_cluster_anchors,
 )
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.optimization_parameters import OptimizationParameters
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.subset import Subset
+from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
 
-from .inference import DetectionInferenceTask
-from .train import DetectionTrainTask
-
 logger = get_logger()
 
 
-class DetectionNNCFTask(NNCFBaseTask, DetectionInferenceTask):  # pylint: disable=too-many-ancestors
+# pylint: disable=too-many-ancestors
+class DetectionNNCFTask(NNCFBaseTask, MMDetectionTask):
     """DetectionNNCFTask."""
 
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__()
+        super(NNCFBaseTask, self).__init__(task_environment, output_path)
+        self._set_attributes_by_hyperparams()
+
+    def _init_task(self, dataset: Optional[DatasetEntity] = None, export: bool = False):
+        super(NNCFBaseTask, self)._init_task(dataset, export)
+        self._prepare_optimize(export)
+
+    def _prepare_optimize(self, export=False):
+        super()._prepare_optimize()
 
-        export = options.get("export", False)
-        options["model_builder"] = partial(
+        self.model_builder = partial(
             self.model_builder,
             nncf_model_builder=build_nncf_detector,
             return_compression_ctrl=False,
             is_export=export,
         )
 
-        # do not configure regularization
-        if "l2sp_weight" in self._recipe_cfg.model or "l2sp_weight" in self._recipe_cfg.model:
-            remove_from_config(self._recipe_cfg.model, "l2sp_weight")
-
     def _optimize(
         self,
         dataset: DatasetEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
-        results = self._run_task(
-            "DetectionTrainer",
-            mode="train",
-            dataset=dataset,
-            parameters=optimization_parameters,
-        )
+        results = self._train_model(dataset)
 
         return results
 
     def _optimize_post_hook(
         self,
         dataset: DatasetEntity,
         output_model: ModelEntity,
     ):
         # get prediction on validation set
         val_dataset = dataset.get_subset(Subset.VALIDATION)
-        val_preds, val_map = self._infer_detector(val_dataset, InferenceParameters(is_evaluation=True))
+        val_preds, val_map = self._infer_model(val_dataset, InferenceParameters(is_evaluation=True))
 
         preds_val_dataset = val_dataset.with_empty_annotations()
         self._add_predictions_to_dataset(val_preds, preds_val_dataset, 0.0)
 
         result_set = ResultSetEntity(
             model=output_model,
             ground_truth_dataset=val_dataset,
@@ -104,15 +102,15 @@
         else:
             metric = MetricsHelper.compute_f_measure(result_set, vary_confidence_threshold=False)
 
         performance = metric.get_performance()
         logger.info(f"Final model performance: {str(performance)}")
         performance.dashboard_metrics.extend(
             # pylint: disable-next=protected-access
-            DetectionTrainTask._generate_training_metrics(self._learning_curves, val_map)
+            self._generate_training_metrics(self._learning_curves, val_map)
         )
         output_model.performance = performance
 
     def _save_model_post_hook(self, modelinfo):
         if self._recipe_cfg is not None and should_cluster_anchors(self._recipe_cfg):
             modelinfo["anchors"] = {}
             self._update_anchors(modelinfo["anchors"], self._recipe_cfg.model.bbox_head.anchor_generator)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tasks/openvino.py` & `otx-1.2.0rc1/otx/algorithms/detection/adapters/openvino/task.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,16 +16,17 @@
 
 import copy
 import io
 import json
 import multiprocessing
 import os
 import tempfile
+import time
 import warnings
-from typing import Any, Dict, Optional, Tuple, Union
+from typing import Any, Dict, List, Optional, Tuple, Union
 from zipfile import ZipFile
 
 import attr
 import numpy as np
 from addict import Dict as ADDict
 from compression.api import DataLoader
 from compression.engines.ie_engine import IEEngine
@@ -34,17 +35,23 @@
 from compression.pipeline.initializer import create_pipeline
 from openvino.model_zoo.model_api.adapters import OpenvinoAdapter, create_core
 from openvino.model_zoo.model_api.models import Model
 
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.detection.adapters.openvino import model_wrappers
 from otx.algorithms.detection.configs.base import DetectionConfig
-from otx.api.configuration.helper.utils import config_to_bytes
+from otx.api.configuration.helper.utils import (
+    config_to_bytes,
+    flatten_config_values,
+    flatten_detection_config_groups,
+    merge_a_into_b,
+)
 from otx.api.entities.annotation import AnnotationSceneEntity
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import (
     InferenceParameters,
     default_progress_callback,
 )
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.model import (
@@ -73,53 +80,45 @@
 from otx.api.usecases.tasks.interfaces.deployment_interface import IDeploymentTask
 from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
 from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
 from otx.api.usecases.tasks.interfaces.optimization_interface import (
     IOptimizationTask,
     OptimizationType,
 )
-from otx.api.utils import Tiler
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 from otx.api.utils.dataset_utils import add_saliency_maps_to_dataset_item
 from otx.api.utils.detection_utils import detection2array
+from otx.api.utils.tiler import Tiler
 
 logger = get_logger()
 
 
 # pylint: disable=too-many-locals
 class BaseInferencerWithConverter(BaseInferencer):
     """BaseInferencerWithConverter class in OpenVINO task."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         configuration: dict,
         model: Model,
         converter: IPredictionToAnnotationConverter,
     ) -> None:
         self.configuration = configuration
         self.model = model
         self.converter = converter
 
-    @check_input_parameters_type()
     def pre_process(self, image: np.ndarray) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
         """Pre-process function of OpenVINO Detection Inferencer."""
         return self.model.preprocess(image)
 
-    @check_input_parameters_type()
     def post_process(self, prediction: Dict[str, np.ndarray], metadata: Dict[str, Any]) -> AnnotationSceneEntity:
         """Post-process function of OpenVINO Detection Inferencer."""
         detections = self.model.postprocess(prediction, metadata)
 
         return self.converter.convert_to_annotation(detections, metadata)
 
-    @check_input_parameters_type()
     def predict(self, image: np.ndarray):
         """Predict function of OpenVINO Detection Inferencer."""
         image, metadata = self.pre_process(image)
         raw_predictions = self.forward(image)
         predictions = self.post_process(raw_predictions, metadata)
         if "feature_vector" not in raw_predictions or "saliency_map" not in raw_predictions:
             warnings.warn(
@@ -130,47 +129,22 @@
         else:
             features = (
                 raw_predictions["feature_vector"].reshape(-1),
                 raw_predictions["saliency_map"][0],
             )
         return predictions, features
 
-    @check_input_parameters_type()
     def forward(self, image: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
         """Forward function of OpenVINO Detection Inferencer."""
         return self.model.infer_sync(image)
 
-    # TODO [Eugene]: implement unittest for tiling predict
-    @check_input_parameters_type()
-    def predict_tile(
-        self, image: np.ndarray, tile_size: int, overlap: float, max_number: int
-    ) -> Tuple[AnnotationSceneEntity, Tuple[np.ndarray, np.ndarray]]:
-        """Run prediction by tiling image to small patches.
-
-        Args:
-            image (np.ndarray): input image
-            tile_size (int): tile crop size
-            overlap (float): overlap ratio between tiles
-            max_number (int): max number of predicted objects allowed
-
-        Returns:
-            detections: AnnotationSceneEntity
-            features: list including saliency map and feature vector
-        """
-        segm = isinstance(self.converter, (MaskToAnnotationConverter, RotatedRectToAnnotationConverter))
-        tiler = Tiler(tile_size=tile_size, overlap=overlap, max_number=max_number, model=self.model, segm=segm)
-        detections, features = tiler.predict(image)
-        detections = self.converter.convert_to_annotation(detections, metadata={"original_shape": image.shape})
-        return detections, features
-
 
 class OpenVINODetectionInferencer(BaseInferencerWithConverter):
     """Inferencer implementation for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         hparams: DetectionConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
         device: str = "CPU",
@@ -200,26 +174,24 @@
             )
         }
         model = Model.create_model("OTX_SSD", model_adapter, configuration, preload=True)
         converter = DetectionToAnnotationConverter(label_schema)
 
         super().__init__(configuration, model, converter)
 
-    @check_input_parameters_type()
     def post_process(self, prediction: Dict[str, np.ndarray], metadata: Dict[str, Any]) -> AnnotationSceneEntity:
         """Detection specific post-process."""
         detections = self.model.postprocess(prediction, metadata)
         detections = detection2array(detections)
         return self.converter.convert_to_annotation(detections, metadata)
 
 
 class OpenVINOMaskInferencer(BaseInferencerWithConverter):
     """Mask Inferencer implementation for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         hparams: DetectionConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
         device: str = "CPU",
@@ -246,15 +218,14 @@
 
         super().__init__(configuration, model, converter)
 
 
 class OpenVINORotatedRectInferencer(BaseInferencerWithConverter):
     """Rotated Rect Inferencer implementation for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         hparams: DetectionConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
         device: str = "CPU",
@@ -278,23 +249,90 @@
         model = Model.create_model("OTX_MaskRCNN", model_adapter, configuration, preload=True)
 
         converter = RotatedRectToAnnotationConverter(label_schema)
 
         super().__init__(configuration, model, converter)
 
 
+class OpenVINOTileClassifierWrapper(BaseInferencerWithConverter):
+    """Wrapper for OpenVINO Tiling.
+
+    Args:
+        inferencer (BaseInferencerWithConverter): inferencer to wrap
+        tile_size (int): tile size
+        overlap (float): overlap ratio between tiles
+        max_number (int): maximum number of objects per image
+        tile_classifier_model_file (Union[str, bytes, None], optional): tile classifier xml. Defaults to None.
+        tile_classifier_weight_file (Union[str, bytes, None], optional): til classifier weight bin. Defaults to None.
+        device (str, optional): device to run inference on, such as CPU, GPU or MYRIAD. Defaults to "CPU".
+        num_requests (int, optional): number of request for OpenVINO adapter. Defaults to 1.
+        mode (str, optional): run inference in sync or async mode. Defaults to "async".
+    """
+
+    def __init__(
+        self,
+        inferencer: BaseInferencerWithConverter,
+        tile_size: int = 400,
+        overlap: float = 0.5,
+        max_number: int = 100,
+        tile_classifier_model_file: Union[str, bytes, None] = None,
+        tile_classifier_weight_file: Union[str, bytes, None] = None,
+        device: str = "CPU",
+        num_requests: int = 1,
+        mode: str = "async",
+    ):  # pylint: disable=too-many-arguments
+        assert mode in ["async", "sync"], "mode should be async or sync"
+        classifier = None
+        if tile_classifier_model_file is not None or tile_classifier_weight_file is not None:
+            adapter = OpenvinoAdapter(
+                create_core(),
+                tile_classifier_model_file,
+                tile_classifier_weight_file,
+                device=device,
+                max_num_requests=num_requests,
+            )
+            classifier = Model(model_adapter=adapter, preload=True)
+
+        self.tiler = Tiler(
+            tile_size=tile_size,
+            overlap=overlap,
+            max_number=max_number,
+            detector=inferencer.model,
+            classifier=classifier,
+            mode=mode,
+            segm=bool(isinstance(inferencer.converter, (MaskToAnnotationConverter, RotatedRectToAnnotationConverter))),
+        )
+
+        super().__init__(inferencer.configuration, inferencer.model, inferencer.converter)
+
+    def predict(
+        self, image: np.ndarray, mode: str = "async"
+    ) -> Tuple[AnnotationSceneEntity, Tuple[np.ndarray, np.ndarray]]:
+        """Run prediction by tiling image to small patches.
+
+        Args:
+            image (np.ndarray): input image
+            mode (str, optional): run inference in sync or async mode. Defaults to 'async'.
+
+        Returns:
+            detections: AnnotationSceneEntity
+            features: list including saliency map and feature vector
+        """
+        detections, features = self.tiler.predict(image, mode)
+        detections = self.converter.convert_to_annotation(detections, metadata={"original_shape": image.shape})
+        return detections, features
+
+
 class OTXOpenVinoDataLoader(DataLoader):
     """Data loader for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def __init__(self, dataset: DatasetEntity, inferencer: BaseInferencer):
         self.dataset = dataset
         self.inferencer = inferencer
 
-    @check_input_parameters_type()
     def __getitem__(self, index: int):
         """Return dataset item from index."""
         image = self.dataset[index].numpy
         annotation = self.dataset[index].annotation_scene
         inputs, metadata = self.inferencer.pre_process(image)
 
         return (index, annotation), inputs, metadata
@@ -303,15 +341,14 @@
         """Length of OTXOpenVinoDataLoader."""
         return len(self.dataset)
 
 
 class OpenVINODetectionTask(IDeploymentTask, IInferenceTask, IEvaluationTask, IOptimizationTask):
     """Task implementation for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(self, task_environment: TaskEnvironment):
         logger.info("Loading OpenVINO OTXDetectionTask")
         self.task_environment = task_environment
         self.model = self.task_environment.model
         self.task_type = self.task_environment.model_template.task_type
         self.confidence_threshold: float = 0.0
         self.config = self.load_config()
@@ -319,30 +356,40 @@
         logger.info("OpenVINO task initialization completed")
 
     @property
     def hparams(self):
         """Hparams of OpenVINO Detection Task."""
         return self.task_environment.get_hyper_parameters(DetectionConfig)
 
-    def load_config(self) -> Dict:
+    def load_config(self) -> ADDict:
         """Load configurable parameters from model adapter.
 
         Returns:
-            Dict: config dictionary
+            ADDict: config dictionary
         """
+        config = vars(self.hparams)
+        flatten_detection_config_groups(config)
         try:
             if self.model is not None and self.model.get_data("config.json"):
-                return json.loads(self.model.get_data("config.json"))
+                json_dict = json.loads(self.model.get_data("config.json"))
+                flatten_config_values(json_dict)
+                config = merge_a_into_b(json_dict, config)
         except Exception as e:  # pylint: disable=broad-except
             logger.warning(f"Failed to load config.json: {e}")
-        return {}
+        config = ADDict(config)
+        return config
 
     def load_inferencer(
         self,
-    ) -> Union[OpenVINODetectionInferencer, OpenVINOMaskInferencer]:
+    ) -> Union[
+        OpenVINODetectionInferencer,
+        OpenVINOMaskInferencer,
+        OpenVINORotatedRectInferencer,
+        OpenVINOTileClassifierWrapper,
+    ]:
         """load_inferencer function of OpenVINO Detection Task."""
         if self.model is None:
             raise RuntimeError("load_inferencer failed, model is None")
         _hparams = copy.deepcopy(self.hparams)
         self.confidence_threshold = float(
             np.frombuffer(self.model.get_data("confidence_threshold"), dtype=np.float32)[0]
         )
@@ -350,22 +397,46 @@
         args = [
             _hparams,
             self.task_environment.label_schema,
             self.model.get_data("openvino.xml"),
             self.model.get_data("openvino.bin"),
         ]
         if self.task_type == TaskType.DETECTION:
-            return OpenVINODetectionInferencer(*args)
+            inferencer: BaseInferencerWithConverter = OpenVINODetectionInferencer(*args)
         if self.task_type == TaskType.INSTANCE_SEGMENTATION:
-            return OpenVINOMaskInferencer(*args)
+            inferencer = OpenVINOMaskInferencer(*args)
         if self.task_type == TaskType.ROTATED_DETECTION:
-            return OpenVINORotatedRectInferencer(*args)
-        raise RuntimeError(f"Unknown OpenVINO Inferencer TaskType: {self.task_type}")
+            inferencer = OpenVINORotatedRectInferencer(*args)
+        if self.config.tiling_parameters.enable_tiling:
+            logger.info("Tiling is enabled. Wrap inferencer with tile inference.")
+            tile_classifier_model_file, tile_classifier_weight_file = None, None
+            if self.config.tiling_parameters.enable_tile_classifier:
+                logger.info("Tile classifier is enabled. Load tile classifier model.")
+                tile_classifier_model_file = self.model.get_data("tile_classifier.xml")
+                tile_classifier_weight_file = self.model.get_data("tile_classifier.bin")
+            inferencer = OpenVINOTileClassifierWrapper(
+                inferencer,
+                self.config.tiling_parameters.tile_size,
+                self.config.tiling_parameters.tile_overlap,
+                self.config.tiling_parameters.tile_max_number,
+                tile_classifier_model_file,
+                tile_classifier_weight_file,
+            )
+        if not isinstance(
+            inferencer,
+            (
+                OpenVINODetectionInferencer,
+                OpenVINOMaskInferencer,
+                OpenVINORotatedRectInferencer,
+                OpenVINOTileClassifierWrapper,
+            ),
+        ):
+            raise RuntimeError(f"Unknown OpenVINO Inferencer TaskType: {self.task_type}")
+        return inferencer
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def infer(
         self,
         dataset: DatasetEntity,
         inference_parameters: Optional[InferenceParameters] = None,
     ) -> DatasetEntity:
         """Infer function of OpenVINODetectionTask."""
         logger.info("Start OpenVINO inference")
@@ -377,68 +448,57 @@
             explain_predicted_classes = inference_parameters.explain_predicted_classes
         else:
             update_progress_callback = default_progress_callback
             add_saliency_map = True
             process_saliency_maps = False
             explain_predicted_classes = True
 
-        tile_enabled = bool(self.config and self.config["tiling_parameters"]["enable_tiling"]["value"])
-
-        if tile_enabled:
-            tile_size = self.config["tiling_parameters"]["tile_size"]["value"]
-            tile_overlap = self.config["tiling_parameters"]["tile_overlap"]["value"]
-            max_number = self.config["tiling_parameters"]["tile_max_number"]["value"]
-            logger.info("Run inference with tiling")
-
+        total_time = 0.0
         dataset_size = len(dataset)
         for i, dataset_item in enumerate(dataset, 1):
-            if tile_enabled:
-                predicted_scene, features = self.inferencer.predict_tile(
-                    dataset_item.numpy,
-                    tile_size=tile_size,
-                    overlap=tile_overlap,
-                    max_number=max_number,
-                )
-            else:
-                predicted_scene, features = self.inferencer.predict(dataset_item.numpy)
-
+            start_time = time.perf_counter()
+            predicted_scene, features = self.inferencer.predict(dataset_item.numpy)
             dataset_item.append_annotations(predicted_scene.annotations)
             feature_vector, saliency_map = features
             if feature_vector is not None:
                 representation_vector = TensorEntity(name="representation_vector", numpy=feature_vector.reshape(-1))
                 dataset_item.append_metadata_item(representation_vector, model=self.model)
 
             if add_saliency_map and saliency_map is not None:
                 labels = self.task_environment.get_labels().copy()
                 if saliency_map.shape[0] == len(labels) + 1:
                     # Include the background as the last category
                     labels.append(LabelEntity("background", Domain.DETECTION))
 
-                predicted_scored_labels = []
+                predicted_scored_labels: List = []
                 for bbox in predicted_scene.annotations:
                     predicted_scored_labels += bbox.get_labels()
 
                 add_saliency_maps_to_dataset_item(
                     dataset_item=dataset_item,
                     saliency_map=saliency_map,
                     model=self.model,
                     labels=labels,
                     predicted_scored_labels=predicted_scored_labels,
                     explain_predicted_classes=explain_predicted_classes,
                     process_saliency_maps=process_saliency_maps,
                 )
             update_progress_callback(int(i / dataset_size * 100), None)
+            end_time = time.perf_counter() - start_time
+            logger.info(f"{end_time} secs")
+            total_time += end_time
+        logger.info(f"Avg time per image: {total_time/len(dataset)} secs")
+        logger.info(f"Total time: {total_time} secs")
         logger.info("OpenVINO inference completed")
         return dataset
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def explain(
         self,
         dataset: DatasetEntity,
-        explain_parameters: Optional[InferenceParameters] = None,
+        explain_parameters: Optional[ExplainParameters] = None,
     ) -> DatasetEntity:
         """Explain function of OpenVINODetectionTask."""
         logger.info("Start OpenVINO explain")
 
         update_progress_callback = default_progress_callback
         process_saliency_maps = False
         explain_predicted_classes = True
@@ -449,21 +509,26 @@
 
         dataset_size = len(dataset)
         for i, dataset_item in enumerate(dataset, 1):
             predicted_scene, features = self.inferencer.predict(dataset_item.numpy)
             dataset_item.append_annotations(predicted_scene.annotations)
             update_progress_callback(int(i / dataset_size * 100), None)
             _, saliency_map = features
+            if saliency_map is None:
+                raise RuntimeError(
+                    "There is no Saliency Map in OpenVINO IR model output. "
+                    "Please export model to OpenVINO IR with dump_features"
+                )
 
             labels = self.task_environment.get_labels().copy()
             if saliency_map.shape[0] == len(labels) + 1:
                 # Include the background as the last category
                 labels.append(LabelEntity("background", Domain.DETECTION))
 
-            predicted_scored_labels = []
+            predicted_scored_labels: List = []
             for bbox in predicted_scene.annotations:
                 predicted_scored_labels += bbox.get_labels()
 
             add_saliency_maps_to_dataset_item(
                 dataset_item=dataset_item,
                 saliency_map=saliency_map,
                 model=self.model,
@@ -471,49 +536,52 @@
                 predicted_scored_labels=predicted_scored_labels,
                 explain_predicted_classes=explain_predicted_classes,
                 process_saliency_maps=process_saliency_maps,
             )
         logger.info("OpenVINO explain completed")
         return dataset
 
-    @check_input_parameters_type()
     def evaluate(
         self,
         output_resultset: ResultSetEntity,
         evaluation_metric: Optional[str] = None,
     ):
         """Evaluate function of OpenVINODetectionTask."""
         logger.info("Start OpenVINO metric evaluation")
         if evaluation_metric is not None:
             logger.warning(
                 f"Requested to use {evaluation_metric} metric, but parameter is ignored. Use F-measure instead."
             )
         output_resultset.performance = MetricsHelper.compute_f_measure(output_resultset).get_performance()
         logger.info("OpenVINO metric evaluation completed")
 
-    @check_input_parameters_type()
     def deploy(self, output_model: ModelEntity) -> None:
         """Deploy function of OpenVINODetectionTask."""
         logger.info("Deploying the model")
 
         work_dir = os.path.dirname(demo.__file__)
         parameters = {}
         parameters["type_of_model"] = self.inferencer.model.__model__
         parameters["converter_type"] = str(self.task_type)
         parameters["model_parameters"] = self.inferencer.configuration
         parameters["model_parameters"]["labels"] = LabelSchemaMapper.forward(self.task_environment.label_schema)
-        parameters["tiling_parameters"] = self.config["tiling_parameters"]
+        if self.config.tiling_parameters.get("type"):
+            self.config.tiling_parameters["type"] = str(self.config.tiling_parameters["type"])
+        parameters["tiling_parameters"] = self.config.tiling_parameters
 
         zip_buffer = io.BytesIO()
         with ZipFile(zip_buffer, "w") as arch:
             # model files
             if self.model is None:
                 raise ValueError("Deploy failed, model is None")
             arch.writestr(os.path.join("model", "model.xml"), self.model.get_data("openvino.xml"))
             arch.writestr(os.path.join("model", "model.bin"), self.model.get_data("openvino.bin"))
+            if self.config.tiling_parameters.enable_tiling and self.config.tiling_parameters.enable_tile_classifier:
+                arch.writestr(os.path.join("model", "tile_classifier.xml"), self.model.get_data("tile_classifier.xml"))
+                arch.writestr(os.path.join("model", "tile_classifier.bin"), self.model.get_data("tile_classifier.bin"))
             arch.writestr(
                 os.path.join("model", "config.json"),
                 json.dumps(parameters, ensure_ascii=False, indent=4),
             )
             # model_wrappers files
             for root, _, files in os.walk(os.path.dirname(model_wrappers.__file__)):
                 for file in files:
@@ -533,15 +601,14 @@
             )
             arch.write(os.path.join(work_dir, "LICENSE"), os.path.join("python", "LICENSE"))
             arch.write(os.path.join(work_dir, "README.md"), os.path.join("python", "README.md"))
             arch.write(os.path.join(work_dir, "demo.py"), os.path.join("python", "demo.py"))
         output_model.exportable_code = zip_buffer.getvalue()
         logger.info("Deploying completed")
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def optimize(
         self,
         optimization_type: OptimizationType,
         dataset: DatasetEntity,
         output_model: ModelEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tasks/train.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/dataset.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,255 +1,266 @@
-"""Train Task of OTX Detection."""
+"""Base MMDataset for Segmentation Task."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-import io
-from typing import Any, Iterable, List, Optional
+from abc import ABCMeta
+from typing import Any, Dict, List, Optional, Sequence
 
 import numpy as np
-import torch
-from mmcv.utils import ConfigDict
+from mmseg.datasets.builder import DATASETS
+from mmseg.datasets.custom import CustomDataset
+from mmseg.datasets.pipelines import Compose
 
-from otx.algorithms.common.utils.callback import TrainingProgressCallback
-from otx.algorithms.common.utils.data import get_dataset
-from otx.algorithms.common.utils.logger import get_logger
-from otx.algorithms.detection.adapters.mmdet.utils.config_utils import (
-    should_cluster_anchors,
-)
-from otx.algorithms.detection.utils.data import adaptive_tile_params
-from otx.api.configuration import cfg_helper
-from otx.api.configuration.helper.utils import ids_to_strings
+from otx.algorithms.common.utils.data import get_old_new_img_indices
+from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.inference_parameters import InferenceParameters
-from otx.api.entities.metrics import (
-    BarChartInfo,
-    BarMetricsGroup,
-    CurveMetric,
-    LineChartInfo,
-    LineMetricsGroup,
-    MetricsGroup,
-    ScoreMetric,
-    VisualizationType,
-)
-from otx.api.entities.model import ModelEntity
-from otx.api.entities.resultset import ResultSetEntity
-from otx.api.entities.subset import Subset
-from otx.api.entities.train_parameters import TrainParameters, default_progress_callback
-from otx.api.serialization.label_mapper import label_schema_to_bytes
-from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.tasks.interfaces.training_interface import ITrainingTask
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
-
-from .inference import DetectionInferenceTask
-
-logger = get_logger()
-
-
-# pylint: disable=too-many-locals, too-many-instance-attributes, too-many-ancestors
-class DetectionTrainTask(DetectionInferenceTask, ITrainingTask):
-    """Train Task Implementation of OTX Detection."""
-
-    @check_input_parameters_type()
-    def save_model(self, output_model: ModelEntity):
-        """Save best model weights in DetectionTrainTask."""
-        logger.info("called save_model")
-        buffer = io.BytesIO()
-        hyperparams_str = ids_to_strings(cfg_helper.convert(self._hyperparams, dict, enum_to_str=True))
-        labels = {label.name: label.color.rgb_tuple for label in self._labels}
-        model_ckpt = torch.load(self._model_ckpt)
-        modelinfo = {
-            "model": model_ckpt,
-            "config": hyperparams_str,
-            "labels": labels,
-            "confidence_threshold": self.confidence_threshold,
-            "VERSION": 1,
-        }
-        if self._recipe_cfg is not None and should_cluster_anchors(self._recipe_cfg):
-            modelinfo["anchors"] = {}
-            self._update_anchors(modelinfo["anchors"], self._recipe_cfg.model.bbox_head.anchor_generator)
-
-        torch.save(modelinfo, buffer)
-        output_model.set_data("weights.pth", buffer.getvalue())
-        output_model.set_data(
-            "label_schema.json",
-            label_schema_to_bytes(self._task_environment.label_schema),
-        )
-        output_model.precision = self._precision
-
-    def cancel_training(self):
-        """Cancel training function in DetectionTrainTask.
-
-        Sends a cancel training signal to gracefully stop the optimizer. The signal consists of creating a
-        '.stop_training' file in the current work_dir. The runner checks for this file periodically.
-        The stopping mechanism allows stopping after each iteration, but validation will still be carried out. Stopping
-        will therefore take some time.
+from otx.api.entities.label import LabelEntity
+from otx.api.utils.segmentation_utils import mask_from_dataset_item
+
+
+# pylint: disable=invalid-name, too-many-locals, too-many-instance-attributes, super-init-not-called
+def get_annotation_mmseg_format(dataset_item: DatasetItemEntity, labels: List[LabelEntity]) -> dict:
+    """Function to convert a OTX annotation to mmsegmentation format.
+
+    This is used both in the OTXDataset class defined in this file
+    as in the custom pipeline element 'LoadAnnotationFromOTXDataset'
+
+    :param dataset_item: DatasetItem for which to get annotations
+    :param labels: List of labels in the project
+    :return dict: annotation information dict in mmseg format
+    """
+
+    gt_seg_map = mask_from_dataset_item(dataset_item, labels)
+    gt_seg_map = gt_seg_map.squeeze(2).astype(np.uint8)
+
+    ann_info = dict(gt_semantic_seg=gt_seg_map)
+
+    return ann_info
+
+
+@DATASETS.register_module()
+class OTXSegDataset(CustomDataset, metaclass=ABCMeta):
+    """Wrapper that allows using a OTX dataset to train mmsegmentation models.
+
+    This wrapper is not based on the filesystem,
+    but instead loads the items here directly from the OTX Dataset object.
+
+    The wrapper overwrites some methods of the CustomDataset class: prepare_train_img, prepare_test_img and prepipeline
+    Naming of certain attributes might seem a bit peculiar but this is due to the conventions set in CustomDataset. For
+    instance, CustomDatasets expects the dataset items to be stored in the attribute data_infos, which is why it is
+    named like that and not dataset_items.
+
+    """
+
+    class _DataInfoProxy:
+        """This class is intended to be a wrapper to use it in CustomDataset-derived class as `self.data_infos`.
+
+        Instead of using list `data_infos` as in CustomDataset, our implementation of dataset OTXDataset
+        uses this proxy class with overriden __len__ and __getitem__; this proxy class
+        forwards data access operations to otx_dataset and converts the dataset items to the view
+        convenient for mmsegmentation.
         """
-        logger.info("Cancel training requested.")
-        self._should_stop = True
-        if self.cancel_interface is not None:
-            self.cancel_interface.cancel()
-        else:
-            logger.info("but training was not started yet. reserved it to cancel")
-            self.reserved_cancel = True
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
-    def train(
+        def __init__(
+            self,
+            otx_dataset,
+            labels=None,
+            **kwargs,  # pylint: disable=unused-argument
+        ):
+            self.otx_dataset = otx_dataset
+            self.labels = labels
+            self.label_idx = {label.id: i for i, label in enumerate(labels)}
+
+        def __len__(self):
+            return len(self.otx_dataset)
+
+        def __getitem__(self, index):
+            """Prepare a dict 'data_info' that is expected by the mmseg pipeline to handle images and annotations.
+
+            :return data_info: dictionary that contains the image and image metadata, as well as the labels of
+            the objects in the image
+            """
+            dataset = self.otx_dataset
+            item = dataset[index]
+            ignored_labels = np.array([self.label_idx[lbs.id] + 1 for lbs in item.ignored_labels])
+
+            data_info = dict(
+                dataset_item=item,
+                width=item.width,
+                height=item.height,
+                index=index,
+                ann_info=dict(labels=self.labels),
+                ignored_labels=ignored_labels,
+            )
+
+            return data_info
+
+    def __init__(
         self,
-        dataset: DatasetEntity,
-        output_model: ModelEntity,
-        train_parameters: Optional[TrainParameters] = None,
+        otx_dataset: DatasetEntity,
+        pipeline: Sequence[dict],
+        classes: Optional[List[str]] = None,
+        test_mode: bool = False,
+        **kwargs,
     ):
-        """Train function in DetectionTrainTask."""
-        logger.info("train()")
-        # Check for stop signal when training has stopped.
-        # If should_stop is true, training was cancelled and no new
-        if self._should_stop:
-            logger.info("Training cancelled.")
-            self._should_stop = False
-            self._is_training = False
-            return
-
-        # Set OTE LoggerHook & Time Monitor
-        if train_parameters:
-            update_progress_callback = train_parameters.update_progress
-        else:
-            update_progress_callback = default_progress_callback
-        self._time_monitor = TrainingProgressCallback(update_progress_callback)
+        self.otx_dataset = otx_dataset
+        self.test_mode = test_mode
 
-        self._data_cfg = self._init_train_data_cfg(dataset)
-        self._is_training = True
+        self.ignore_index = 255
+        self.reduce_zero_label = False
+        self.label_map = None
+
+        dataset_labels = self.otx_dataset.get_labels(include_empty=False)
+        self.project_labels = sorted(self.filter_labels(dataset_labels, classes))
+        self.CLASSES, self.PALETTE = self.get_classes_and_palette(classes, None)
+
+        # Instead of using list data_infos as in CustomDataset, this implementation of dataset
+        # uses a proxy class with overriden __len__ and __getitem__; this proxy class
+        # forwards data access operations to otx_dataset.
+        # Note that list `data_infos` cannot be used here, since OTX dataset class does not have interface to
+        # get only annotation of a data item, so we would load the whole data item (including image)
+        # even if we need only checking aspect ratio of the image; due to it
+        # this implementation of dataset does not uses such tricks as skipping images with wrong aspect ratios or
+        # small image size, since otherwise reading the whole dataset during initialization will be required.
+        self.data_infos = OTXSegDataset._DataInfoProxy(self.otx_dataset, self.project_labels)
 
-        if bool(self._hyperparams.tiling_parameters.enable_tiling) and bool(
-            self._hyperparams.tiling_parameters.enable_adaptive_params
-        ):
-            adaptive_tile_params(self._hyperparams.tiling_parameters, dataset)
+        self.pipeline = Compose(pipeline)
 
-        results = self._run_task(
-            "DetectionTrainer",
-            mode="train",
-            dataset=dataset,
-            parameters=train_parameters,
-        )
-
-        # Check for stop signal when training has stopped. If should_stop is true, training was cancelled and no new
-        if self._should_stop:
-            logger.info("Training cancelled.")
-            self._should_stop = False
-            self._is_training = False
-            return
-
-        # get output model
-        model_ckpt = results.get("final_ckpt")
-        if model_ckpt is None:
-            logger.error("cannot find final checkpoint from the results.")
-            # output_model.model_status = ModelStatus.FAILED
-            return
-        # update checkpoint to the newly trained model
-        self._model_ckpt = model_ckpt
-
-        # get prediction on validation set
-        self._is_training = False
-        val_dataset = dataset.get_subset(Subset.VALIDATION)
-        val_preds, val_map = self._infer_detector(val_dataset, InferenceParameters(is_evaluation=True))
-
-        preds_val_dataset = val_dataset.with_empty_annotations()
-        self._add_predictions_to_dataset(val_preds, preds_val_dataset, 0.0)
-
-        result_set = ResultSetEntity(
-            model=output_model,
-            ground_truth_dataset=val_dataset,
-            prediction_dataset=preds_val_dataset,
-        )
-
-        # adjust confidence threshold
-        if self._hyperparams.postprocessing.result_based_confidence_threshold:
-            best_confidence_threshold = None
-            logger.info("Adjusting the confidence threshold")
-            metric = MetricsHelper.compute_f_measure(result_set, vary_confidence_threshold=True)
-            if metric.best_confidence_threshold:
-                best_confidence_threshold = metric.best_confidence_threshold.value
-            if best_confidence_threshold is None:
-                raise ValueError("Cannot compute metrics: Invalid confidence threshold!")
-            logger.info(f"Setting confidence threshold to {best_confidence_threshold} based on results")
-            self.confidence_threshold = best_confidence_threshold
-        else:
-            metric = MetricsHelper.compute_f_measure(result_set, vary_confidence_threshold=False)
+    @staticmethod
+    def filter_labels(all_labels: List[LabelEntity], label_names: List[str]) -> List[LabelEntity]:
+        """Filter and collect actual label entities."""
+        filtered_labels = []
+        for label_name in label_names:
+            matches = [label for label in all_labels if label.name == label_name]
+            if len(matches) == 0:
+                continue
 
-        # compose performance statistics
-        # TODO[EUGENE]: HOW TO ADD A MAE CURVE FOR TaskType.COUNTING?
-        performance = metric.get_performance()
-        performance.dashboard_metrics.extend(
-            DetectionTrainTask._generate_training_metrics(self._learning_curves, val_map)
-        )
-        logger.info(f"Final model performance: {str(performance)}")
-        # save resulting model
-        self.save_model(output_model)
-        output_model.performance = performance
-        # output_model.model_status = ModelStatus.SUCCESS
-        logger.info("train done.")
-
-    def _init_train_data_cfg(self, dataset: DatasetEntity):
-        logger.info("init data cfg.")
-        data_cfg = ConfigDict(data=ConfigDict())
-
-        for cfg_key, subset in zip(
-            ["train", "val", "unlabeled"],
-            [Subset.TRAINING, Subset.VALIDATION, Subset.UNLABELED],
-        ):
-            subset = get_dataset(dataset, subset)
-            if subset:
-                data_cfg.data[cfg_key] = ConfigDict(
-                    otx_dataset=subset,
-                    labels=self._labels,
-                )
+            assert len(matches) == 1
 
-        return data_cfg
+            filtered_labels.append(matches[0])
 
-    @staticmethod
-    def _generate_training_metrics(learning_curves, scores) -> Iterable[MetricsGroup[Any, Any]]:
-        """Get Training metrics (epochs & scores).
+        return filtered_labels
+
+    def __len__(self):
+        """Total number of samples of data."""
 
-        Parses the mmdetection logs to get metrics from the latest training run
-        :return output List[MetricsGroup]
+        return len(self.data_infos)
+
+    def pre_pipeline(self, results: Dict[str, Any]):
+        """Prepare results dict for pipeline."""
+
+        results["seg_fields"] = []
+
+    def prepare_train_img(self, idx: int) -> dict:
+        """Get training data and annotations after pipeline.
+
+        Args:
+            idx (int): Index of data.
+
+        Returns:
+            dict: Training data and annotation after pipeline with new keys introduced by pipeline.
         """
-        output: List[MetricsGroup] = []
 
-        # Learning curves.
-        for key, curve in learning_curves.items():
-            len_x, len_y = len(curve.x), len(curve.y)
-            if len_x != len_y:
-                logger.warning(f"Learning curve {key} has inconsistent number of coordinates ({len_x} vs {len_y}.")
-                len_x = min(len_x, len_y)
-                curve.x = curve.x[:len_x]
-                curve.y = curve.y[:len_x]
-            metric_curve = CurveMetric(
-                xs=np.nan_to_num(curve.x).tolist(),
-                ys=np.nan_to_num(curve.y).tolist(),
-                name=key,
-            )
-            visualization_info = LineChartInfo(name=key, x_axis_label="Epoch", y_axis_label=key)
-            output.append(LineMetricsGroup(metrics=[metric_curve], visualization_info=visualization_info))
+        item = self.data_infos[idx]
 
-        # Final mAP value on the validation set.
-        output.append(
-            BarMetricsGroup(
-                metrics=[ScoreMetric(value=scores, name="mAP")],
-                visualization_info=BarChartInfo("Validation score", visualization_type=VisualizationType.RADIAL_BAR),
-            )
-        )
+        self.pre_pipeline(item)
+        out = self.pipeline(item)
+
+        return out
+
+    def prepare_test_img(self, idx: int) -> dict:
+        """Get testing data after pipeline.
+
+        Args:
+            idx (int): Index of data.
+
+        Returns:
+            dict: Testing data after pipeline with new keys introduced by pipeline.
+        """
+
+        item = self.data_infos[idx]
+
+        self.pre_pipeline(item)
+        out = self.pipeline(item)
+
+        return out
+
+    def get_ann_info(self, idx: int):
+        """This method is used for evaluation of predictions.
+
+        The CustomDataset class implements a method
+        CustomDataset.evaluate, which uses the class method get_ann_info to retrieve annotations.
+
+        :param idx: index of the dataset item for which to get the annotations
+        :return ann_info: dict that contains the coordinates of the bboxes and their corresponding labels
+        """
+
+        dataset_item = self.otx_dataset[idx]
+        ann_info = get_annotation_mmseg_format(dataset_item, self.project_labels)
+
+        return ann_info
+
+    def get_gt_seg_maps(self, efficient_test: bool = False):
+        """Get ground truth segmentation maps for evaluation."""
+
+        gt_seg_maps = []
+        for item_id in range(len(self)):
+            ann_info = self.get_ann_info(item_id)
+            gt_seg_maps.append(ann_info["gt_semantic_seg"])
+        if efficient_test:
+            pass
+
+        return gt_seg_maps
+
+
+@DATASETS.register_module()
+class MPASegDataset(OTXSegDataset, metaclass=ABCMeta):
+    """Wrapper dataset that allows using a OTX dataset to train models."""
+
+    def __init__(self, **kwargs):
+        pipeline = []
+        test_mode = kwargs.get("test_mode", False)
+        if "dataset" in kwargs:
+            dataset = kwargs["dataset"]
+            otx_dataset = dataset.otx_dataset
+            pipeline = dataset.pipeline
+            classes = dataset.labels
+            new_classes = dataset.new_classes
+        else:
+            otx_dataset = kwargs["otx_dataset"]
+            pipeline = kwargs["pipeline"]
+            classes = kwargs["labels"]
+            new_classes = kwargs.get("new_classes", [])
+
+        if test_mode is False:
+            self.img_indices = get_old_new_img_indices(classes, new_classes, otx_dataset)
+
+        if classes:
+            classes = [c.name for c in classes]
+            classes = ["background"] + classes
+        else:
+            classes = []
+        super().__init__(otx_dataset=otx_dataset, pipeline=pipeline, classes=classes)
 
-        return output
+        self.CLASSES = [label.name for label in self.project_labels]
+        if "background" not in self.CLASSES:
+            self.CLASSES = ["background"] + self.CLASSES
+
+        if self.label_map is None:
+            self.label_map = {}
+            for i, c in enumerate(self.CLASSES):
+                if c not in classes:
+                    self.label_map[i] = -1
+                else:
+                    self.label_map[i] = classes.index(c)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tools/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tools/detection_sample.py` & `otx-1.2.0rc1/otx/algorithms/detection/tools/detection_sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tools/detection_semisl_sample.py` & `otx-1.2.0rc1/otx/algorithms/detection/tools/detection_semisl_sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/tools/instance_segmentation_sample.py` & `otx-1.2.0rc1/otx/algorithms/detection/tools/instance_segmentation_sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/detection/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/utils/data.py` & `otx-1.2.0rc1/otx/algorithms/detection/utils/data.py`

 * *Files 4% similar despite different names*

```diff
@@ -36,38 +36,29 @@
 from otx.api.entities.id import ID
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.polygon import Point, Polygon
 from otx.api.entities.shapes.rectangle import Rectangle
 from otx.api.entities.subset import Subset
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    DirectoryPathCheck,
-    JsonFilePathCheck,
-    OptionalDirectoryPathCheck,
-    check_input_parameters_type,
-)
 from otx.api.utils.shape_factory import ShapeFactory
 
 
 # pylint: disable=too-many-instance-attributes, too-many-arguments
-@check_input_parameters_type({"path": JsonFilePathCheck})
 def get_classes_from_annotation(path):
     """Return classes from annotation."""
     with open(path, encoding="UTF-8") as read_file:
         content = json.load(read_file)
         categories = [v["name"] for v in sorted(content["categories"], key=lambda x: x["id"])]
     return categories
 
 
 class LoadAnnotations:
     """Load Annotations class."""
 
-    @check_input_parameters_type()
     def __init__(self, with_bbox: bool = True, with_label: bool = True, with_mask: bool = False):
         self.with_bbox = with_bbox
         self.with_label = with_label
         self.with_mask = with_mask
 
     @staticmethod
     def _load_bboxes(results):
@@ -89,15 +80,14 @@
     @staticmethod
     def _load_masks(results):
         gt_masks = results["ann_info"]["masks"]
         results["gt_masks"] = gt_masks
         results["mask_fields"].append("gt_masks")
         return results
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of LoadAnnotations."""
         if self.with_bbox:
             results = LoadAnnotations._load_bboxes(results)
             if results is None:
                 return None
         if self.with_label:
@@ -114,15 +104,14 @@
         repr_str += f"with_label={self.with_label})"
         return repr_str
 
 
 class CocoDataset:
     """CocoDataset."""
 
-    @check_input_parameters_type({"ann_file": JsonFilePathCheck, "data_root": OptionalDirectoryPathCheck})
     def __init__(
         self,
         ann_file: str,
         classes: Optional[Sequence[str]] = None,
         data_root: Optional[str] = None,
         img_prefix: str = "",
         test_mode: bool = False,
@@ -151,80 +140,73 @@
             valid_inds = self._filter_imgs()
             self.data_infos = [self.data_infos[i] for i in valid_inds]
 
     def __len__(self):
         """Length of CocoDataset."""
         return len(self.data_infos)
 
-    @check_input_parameters_type()
     def pre_pipeline(self, results: Dict[str, Any]):
         """Initialize pipeline."""
         results["img_prefix"] = self.img_prefix
         results["bbox_fields"] = []
         results["mask_fields"] = []
         results["seg_fields"] = []
 
     def _rand_another(self, idx):
         """Get Random indices."""
         pool = np.where(self.flag == self.flag[idx])[0]
         return np.random.choice(pool)
 
-    @check_input_parameters_type()
     def __getitem__(self, idx: int):
         """Return dataset item from index."""
         return self.prepare_img(idx)
 
     def __iter__(self):
         """Iterator of CocoDataset."""
         for i in range(len(self)):
             yield self[i]
 
-    @check_input_parameters_type()
     def prepare_img(self, idx: int):
         """Load Annotations function with images."""
         img_info = self.data_infos[idx]
         ann_info = self.get_ann_info(idx)
         results = dict(img_info=img_info, ann_info=ann_info)
         self.pre_pipeline(results)
         return LoadAnnotations(with_mask=self.with_mask)(results)
 
-    @check_input_parameters_type()
     def get_classes(self, classes: Optional[Sequence[str]] = None):
         """Return classes function."""
         if classes is None:
             return get_classes_from_annotation(self.ann_file)
 
         if isinstance(classes, (tuple, list)):
             return classes
 
         raise ValueError(f"Unsupported type {type(classes)} of classes.")
 
-    @check_input_parameters_type({"ann_file": JsonFilePathCheck})
     def load_annotations(self, ann_file):
         """Load annotations function from coco."""
         self.coco = COCO(ann_file)
         self.cat_ids = self.coco.get_cat_ids(cat_names=self.classes)
         self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}
         self.img_ids = self.coco.get_img_ids()
         data_infos = []
         for i in self.img_ids:
             info = self.coco.load_imgs([i])[0]
             info["filename"] = info["file_name"]
             data_infos.append(info)
         return data_infos
 
-    @check_input_parameters_type()
     def get_ann_info(self, idx: int):
         """Getting Annotation info."""
         img_id = self.data_infos[idx]["id"]
         ann_ids = self.coco.get_ann_ids(img_ids=[img_id])
         ann_info = self.coco.load_anns(ann_ids)
         return self._parse_ann_info(self.data_infos[idx], ann_info)
 
-    @check_input_parameters_type()
     def get_cat_ids(self, idx: int):
         """Getting cat_ids."""
         img_id = self.data_infos[idx]["id"]
         ann_ids = self.coco.get_ann_ids(img_ids=[img_id])
         ann_info = self.coco.load_anns(ann_ids)
         return [ann["category_id"] for ann in ann_info]
 
@@ -302,28 +284,26 @@
             masks=gt_masks_ann,
             seg_map=seg_map,
         )
 
         return ann
 
 
-@check_input_parameters_type()
 def find_label_by_name(labels: List[LabelEntity], name: str, domain: Domain):
     """Return label from name."""
     matching_labels = [label for label in labels if label.name == name]
     if len(matching_labels) == 1:
         return matching_labels[0]
     if len(matching_labels) == 0:
         label = LabelEntity(name=name, domain=domain, id=ID(len(labels)))
         labels.append(label)
         return label
     raise ValueError("Found multiple matching labels")
 
 
-@check_input_parameters_type({"ann_file_path": JsonFilePathCheck, "data_root_dir": DirectoryPathCheck})
 def load_dataset_items_coco_format(
     ann_file_path: str,
     data_root_dir: str,
     domain: Domain,
     subset: Subset = Subset.NONE,
     labels_list: Optional[List[LabelEntity]] = None,
     with_mask: bool = False,
@@ -407,15 +387,14 @@
             subset=subset,
         )
         dataset_items.append(dataset_item)
 
     return dataset_items
 
 
-@check_input_parameters_type({"dataset": DatasetParamTypeCheck})
 def get_sizes_from_dataset_entity(dataset: DatasetEntity, target_wh: List[int]):
     """Function to get sizes of instances in DatasetEntity and to resize it to the target size.
 
     :param dataset: DatasetEntity in which to get statistics
     :param target_wh: target width and height of the dataset
     :return list: tuples with width and height of each instance
     """
@@ -429,15 +408,14 @@
                 box = ShapeFactory.shape_as_rectangle(ann.shape)
                 width = box.width * target_wh[0]
                 height = box.height * target_wh[1]
                 wh_stats.append((width, height))
     return wh_stats
 
 
-@check_input_parameters_type()
 def get_anchor_boxes(wh_stats: List[tuple], group_as: List[int]):
     """Get anchor box widths & heights."""
     from sklearn.cluster import KMeans
 
     kmeans = KMeans(init="k-means++", n_clusters=sum(group_as), random_state=0).fit(wh_stats)
     centers = kmeans.cluster_centers_
 
@@ -450,15 +428,14 @@
     group_as = np.cumsum(group_as[:-1])
     widths, heights = np.split(widths, group_as), np.split(heights, group_as)
     widths = [width.tolist() for width in widths]
     heights = [height.tolist() for height in heights]
     return widths, heights
 
 
-@check_input_parameters_type()
 def format_list_to_str(value_lists: list):
     """Decrease floating point digits in logs."""
     str_value = ""
     for value_list in value_lists:
         str_value += "[" + ", ".join(f"{value:.2f}" for value in value_list) + "], "
     return f"[{str_value[:-2]}]"
```

### Comparing `otx-1.1.2rc1/otx/algorithms/detection/utils/utils.py` & `otx-1.2.0rc1/otx/algorithms/detection/utils/utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -20,23 +20,21 @@
 import numpy as np
 
 from otx.api.entities.color import Color
 from otx.api.entities.id import ID
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
 from otx.api.entities.model_template import TaskType
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 # pylint: disable=invalid-name
 
 
 class ColorPalette:
     """ColorPalette class."""
 
-    @check_input_parameters_type()
     def __init__(self, n: int, rng: Optional[random.Random] = None):
         assert n > 0
 
         if rng is None:
             rng = random.Random(0xACE)
 
         candidates_num = 100
@@ -63,30 +61,28 @@
         distances = [cls._dist(o, color_candidate) for o in colors_set]
         return np.min(distances)
 
     @staticmethod
     def _hsv2rgb(h, s, v):
         return tuple(round(c * 255) for c in colorsys.hsv_to_rgb(h, s, v))
 
-    @check_input_parameters_type()
     def __getitem__(self, n: int):
         """Return item from index function ColorPalette."""
         return self.palette[n % len(self.palette)]
 
     def __len__(self):
         """Return length of ColorPalette."""
         return len(self.palette)
 
 
-@check_input_parameters_type()
 def generate_label_schema(label_names: Sequence[str], label_domain: Domain = Domain.DETECTION):
     """Generating label_schema function."""
     colors = ColorPalette(len(label_names)) if len(label_names) > 0 else []
     not_empty_labels = [
-        LabelEntity(name=name, color=colors[i], domain=label_domain, id=ID(f"{i:08}"))
+        LabelEntity(name=name, color=colors[i], domain=label_domain, id=ID(f"{i:08}"))  # type: ignore
         for i, name in enumerate(label_names)
     ]
     emptylabel = LabelEntity(
         name="Empty label",
         color=Color(42, 43, 46),
         is_empty=True,
         domain=label_domain,
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,15 +11,14 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-
 from .datasets import MPASegDataset
 from .models import (
     ClassIncrEncoderDecoder,
     ConstantScalarScheduler,
     CrossEntropyLossWithIgnore,
     CustomFCNHead,
     DetConB,
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/dataset.py` & `otx-1.2.0rc1/otx/core/data/adapter/segmentation_dataset_adapter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,277 +1,240 @@
-"""Base MMDataset for Segmentation Task."""
+"""Segmentation Dataset Adapter."""
 
-# Copyright (C) 2023 Intel Corporation
+# Copyright (C) 2022 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
 #
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions
-# and limitations under the License.
 
-from abc import ABCMeta
-from typing import Any, Dict, List, Optional, Sequence
+import json
 
+# pylint: disable=invalid-name, too-many-locals, no-member, too-many-nested-blocks, too-many-branches
+import os
+from typing import Dict, List, Optional
+
+import cv2
 import numpy as np
-from mmseg.datasets.builder import DATASETS
-from mmseg.datasets.custom import CustomDataset
-from mmseg.datasets.pipelines import Compose
+from datumaro.components.annotation import AnnotationType, Mask
+from datumaro.components.dataset import Dataset as DatumaroDataset
+from datumaro.plugins.data_formats.common_semantic_segmentation import (
+    CommonSemanticSegmentationBase,
+    make_categories,
+)
+from datumaro.plugins.transforms import MasksToPolygons
+from datumaro.util.meta_file_util import parse_meta_file
+from skimage.segmentation import felzenszwalb
 
-from otx.algorithms.common.utils.data import get_old_new_img_indices
+from otx.algorithms.common.utils.logger import get_logger
+from otx.api.entities.annotation import Annotation
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.label import LabelEntity
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
-from otx.api.utils.segmentation_utils import mask_from_dataset_item
-
-
-# pylint: disable=invalid-name, too-many-locals, too-many-instance-attributes, super-init-not-called
-@check_input_parameters_type()
-def get_annotation_mmseg_format(dataset_item: DatasetItemEntity, labels: List[LabelEntity]) -> dict:
-    """Function to convert a OTX annotation to mmsegmentation format.
-
-    This is used both in the OTXDataset class defined in this file
-    as in the custom pipeline element 'LoadAnnotationFromOTXDataset'
+from otx.api.entities.id import ID
+from otx.api.entities.image import Image
+from otx.api.entities.model_template import TaskType
+from otx.api.entities.subset import Subset
+from otx.core.data.adapter.base_dataset_adapter import BaseDatasetAdapter
 
-    :param dataset_item: DatasetItem for which to get annotations
-    :param labels: List of labels in the project
-    :return dict: annotation information dict in mmseg format
-    """
-
-    gt_seg_map = mask_from_dataset_item(dataset_item, labels)
-    gt_seg_map = gt_seg_map.squeeze(2).astype(np.uint8)
-
-    ann_info = dict(gt_semantic_seg=gt_seg_map)
-
-    return ann_info
 
+class SegmentationDatasetAdapter(BaseDatasetAdapter):
+    """Segmentation adapter inherited from BaseDatasetAdapter.
 
-@DATASETS.register_module()
-class OTXSegDataset(CustomDataset, metaclass=ABCMeta):
-    """Wrapper that allows using a OTX dataset to train mmsegmentation models.
-
-    This wrapper is not based on the filesystem,
-    but instead loads the items here directly from the OTX Dataset object.
-
-    The wrapper overwrites some methods of the CustomDataset class: prepare_train_img, prepare_test_img and prepipeline
-    Naming of certain attributes might seem a bit peculiar but this is due to the conventions set in CustomDataset. For
-    instance, CustomDatasets expects the dataset items to be stored in the attribute data_infos, which is why it is
-    named like that and not dataset_items.
-
+    It converts DatumaroDataset --> DatasetEntity for semantic segmentation task
     """
 
-    class _DataInfoProxy:
-        """This class is intended to be a wrapper to use it in CustomDataset-derived class as `self.data_infos`.
-
-        Instead of using list `data_infos` as in CustomDataset, our implementation of dataset OTXDataset
-        uses this proxy class with overriden __len__ and __getitem__; this proxy class
-        forwards data access operations to otx_dataset and converts the dataset items to the view
-        convenient for mmsegmentation.
-        """
-
-        def __init__(
-            self,
-            otx_dataset,
-            labels=None,
-            **kwargs,  # pylint: disable=unused-argument
-        ):
-            self.otx_dataset = otx_dataset
-            self.labels = labels
-            self.label_idx = {label.id: i for i, label in enumerate(labels)}
-
-        def __len__(self):
-            return len(self.otx_dataset)
-
-        def __getitem__(self, index):
-            """Prepare a dict 'data_info' that is expected by the mmseg pipeline to handle images and annotations.
-
-            :return data_info: dictionary that contains the image and image metadata, as well as the labels of
-            the objects in the image
-            """
-            dataset = self.otx_dataset
-            item = dataset[index]
-            ignored_labels = np.array([self.label_idx[lbs.id] + 1 for lbs in item.ignored_labels])
-
-            data_info = dict(
-                dataset_item=item,
-                width=item.width,
-                height=item.height,
-                index=index,
-                ann_info=dict(labels=self.labels),
-                ignored_labels=ignored_labels,
-            )
-
-            return data_info
-
-    @check_input_parameters_type({"otx_dataset": DatasetParamTypeCheck})
     def __init__(
         self,
-        otx_dataset: DatasetEntity,
-        pipeline: Sequence[dict],
-        classes: Optional[List[str]] = None,
-        test_mode: bool = False,
+        task_type: TaskType,
+        train_data_roots: Optional[str] = None,
+        val_data_roots: Optional[str] = None,
+        test_data_roots: Optional[str] = None,
+        unlabeled_data_roots: Optional[str] = None,
     ):
-        self.otx_dataset = otx_dataset
-        self.test_mode = test_mode
+        super().__init__(task_type, train_data_roots, val_data_roots, test_data_roots, unlabeled_data_roots)
+        self.updated_label_id: Dict[int, int] = {}
 
-        self.ignore_index = 255
-        self.reduce_zero_label = False
-        self.label_map = None
-
-        dataset_labels = self.otx_dataset.get_labels(include_empty=False)
-        self.project_labels = sorted(self.filter_labels(dataset_labels, classes))
-        self.CLASSES, self.PALETTE = self.get_classes_and_palette(classes, None)
-
-        # Instead of using list data_infos as in CustomDataset, this implementation of dataset
-        # uses a proxy class with overriden __len__ and __getitem__; this proxy class
-        # forwards data access operations to otx_dataset.
-        # Note that list `data_infos` cannot be used here, since OTX dataset class does not have interface to
-        # get only annotation of a data item, so we would load the whole data item (including image)
-        # even if we need only checking aspect ratio of the image; due to it
-        # this implementation of dataset does not uses such tricks as skipping images with wrong aspect ratios or
-        # small image size, since otherwise reading the whole dataset during initialization will be required.
-        self.data_infos = OTXSegDataset._DataInfoProxy(self.otx_dataset, self.project_labels)
-
-        self.pipeline = Compose(pipeline)
-
-    @staticmethod
-    @check_input_parameters_type()
-    def filter_labels(all_labels: List[LabelEntity], label_names: List[str]) -> List[LabelEntity]:
-        """Filter and collect actual label entities."""
-        filtered_labels = []
-        for label_name in label_names:
-            matches = [label for label in all_labels if label.name == label_name]
-            if len(matches) == 0:
-                continue
-
-            assert len(matches) == 1
-
-            filtered_labels.append(matches[0])
-
-        return filtered_labels
-
-    def __len__(self):
-        """Total number of samples of data."""
-
-        return len(self.data_infos)
-
-    @check_input_parameters_type()
-    def pre_pipeline(self, results: Dict[str, Any]):
-        """Prepare results dict for pipeline."""
-
-        results["seg_fields"] = []
-
-    @check_input_parameters_type()
-    def prepare_train_img(self, idx: int) -> dict:
-        """Get training data and annotations after pipeline.
+    def get_otx_dataset(self) -> DatasetEntity:
+        """Convert DatumaroDataset to DatasetEntity for Segmentation."""
+        # Prepare label information
+        label_information = self._prepare_label_information(self.dataset)
+        self.label_entities = label_information["label_entities"]
+
+        dataset_items: List[DatasetItemEntity] = []
+        used_labels: List[int] = []
+
+        if hasattr(self, "data_type_candidates"):
+            if self.data_type_candidates[0] == "voc":
+                self.set_voc_labels()
 
-        Args:
-            idx (int): Index of data.
+            if self.data_type_candidates[0] == "common_semantic_segmentation":
+                self.set_common_labels()
 
-        Returns:
-            dict: Training data and annotation after pipeline with new keys introduced by pipeline.
-        """
+        else:
+            # For datasets used for self-sl.
+            # They are not included in any data type and `data_type_candidates` is not set,
+            # so they must be handled independently. But, setting `self.updated_label_id` is compatible
+            # with "common_semantic_segmentation", so we can use it.
+            self.set_common_labels()
+
+        for subset, subset_data in self.dataset.items():
+            for _, datumaro_items in subset_data.subsets().items():
+                for datumaro_item in datumaro_items:
+                    image = Image(file_path=datumaro_item.media.path)
+                    shapes: List[Annotation] = []
+                    for ann in datumaro_item.annotations:
+                        if ann.type == AnnotationType.mask:
+                            # TODO: consider case -> didn't include the background information
+                            datumaro_polygons = MasksToPolygons.convert_mask(ann)
+                            for d_polygon in datumaro_polygons:
+                                new_label = self.updated_label_id.get(d_polygon.label, None)
+                                if new_label is not None:
+                                    d_polygon.label = new_label
+                                else:
+                                    continue
+
+                                shapes.append(self._get_polygon_entity(d_polygon, image.width, image.height))
+                                if d_polygon.label not in used_labels:
+                                    used_labels.append(d_polygon.label)
+
+                    if len(shapes) > 0 or subset == Subset.UNLABELED:
+                        dataset_item = DatasetItemEntity(image, self._get_ann_scene_entity(shapes), subset=subset)
+                        dataset_items.append(dataset_item)
+
+        self.remove_unused_label_entities(used_labels)
+        return DatasetEntity(items=dataset_items)
+
+    def set_voc_labels(self):
+        """Set labels for common_semantic_segmentation dataset."""
+        # Remove background & ignored label in VOC from datumaro
+        self._remove_labels(["background", "ignored"])
+
+    def set_common_labels(self):
+        """Set labels for common_semantic_segmentation dataset."""
+        # Remove background if in label_entities
+        is_removed = self._remove_labels(["background"])
+
+        # Shift label id since datumaro always extracts bg polygon with label 0
+        if is_removed is False:
+            self.updated_label_id = {k + 1: v for k, v in self.updated_label_id.items()}
+
+    def _remove_labels(self, label_names: List):
+        """Remove background label in label entity set."""
+        is_removed = False
+        new_label_entities = []
+        for i, entity in enumerate(self.label_entities):
+            if entity.name not in label_names:
+                new_label_entities.append(entity)
+            else:
+                is_removed = True
+
+        self.label_entities = new_label_entities
+
+        for i, entity in enumerate(self.label_entities):
+            self.updated_label_id[int(entity.id)] = i
+            entity.id = ID(i)
 
-        item = self.data_infos[idx]
+        return is_removed
 
-        self.pre_pipeline(item)
-        out = self.pipeline(item)
 
-        return out
+class SelfSLSegmentationDatasetAdapter(SegmentationDatasetAdapter):
+    """Self-SL for segmentation adapter inherited from SegmentationDatasetAdapter."""
 
-    @check_input_parameters_type()
-    def prepare_test_img(self, idx: int) -> dict:
-        """Get testing data after pipeline.
+    # pylint: disable=protected-access
+    def _import_dataset(
+        self,
+        train_data_roots: Optional[str] = None,
+        val_data_roots: Optional[str] = None,
+        test_data_roots: Optional[str] = None,
+        unlabeled_data_roots: Optional[str] = None,
+        pseudo_mask_dir: str = "detcon_mask",
+    ) -> Dict[Subset, DatumaroDataset]:
+        """Import custom Self-SL dataset for using DetCon.
+
+        Self-SL for semantic segmentation using DetCon uses pseudo masks as labels,
+        but Datumaro cannot load this custom data structure because it is not in Datumaro format.
+        So, it is required to manually load and set annotations.
 
         Args:
-            idx (int): Index of data.
+            train_data_roots (Optional[str]): Path for training data.
+            val_data_roots (Optional[str]): Path for validation data
+            test_data_roots (Optional[str]): Path for test data.
+            unlabeled_data_roots (Optional[str]): Path for unlabeled data.
+            pseudo_mask_dir (str): Directory to save pseudo masks. Defaults to "detcon_mask".
 
         Returns:
-            dict: Testing data after pipeline with new keys introduced by pipeline.
+            DatumaroDataset: Datumaro Dataset
         """
+        if train_data_roots is None:
+            raise ValueError("train_data_root must be set.")
 
-        item = self.data_infos[idx]
+        logger = get_logger()
+        logger.warning(f"Please check if {train_data_roots} is data roots only for images, not annotations.")
 
-        self.pre_pipeline(item)
-        out = self.pipeline(item)
+        dataset = {}
+        dataset[Subset.TRAINING] = DatumaroDataset.import_from(train_data_roots, format="image_dir")
+        self.is_train_phase = True
+
+        # Load pseudo masks
+        img_dir = None
+        total_labels = []
+        for item in dataset[Subset.TRAINING]:
+            img_path = item.media.path
+            if img_dir is None:
+                # Get image directory
+                img_dir = train_data_roots.split("/")[-1]
+            pseudo_mask_path = img_path.replace(img_dir, pseudo_mask_dir)
+            if pseudo_mask_path.endswith(".jpg"):
+                pseudo_mask_path = pseudo_mask_path.replace(".jpg", ".png")
+
+            if not os.path.isfile(pseudo_mask_path):
+                # Create pseudo mask
+                pseudo_mask = self.create_pseudo_masks(item.media.data, pseudo_mask_path)  # type: ignore
+            else:
+                # Load created pseudo mask
+                pseudo_mask = cv2.imread(pseudo_mask_path, cv2.IMREAD_GRAYSCALE)
+
+            # Set annotations into each item
+            annotations = []
+            labels = np.unique(pseudo_mask)
+            for label_id in labels:
+                if label_id not in total_labels:
+                    # Stack label_id to save dataset_meta.json
+                    total_labels.append(label_id)
+                annotations.append(
+                    Mask(image=CommonSemanticSegmentationBase._lazy_extract_mask(pseudo_mask, label_id), label=label_id)
+                )
+            item.annotations = annotations
+
+        pseudo_mask_roots = train_data_roots.replace(img_dir, pseudo_mask_dir)  # type: ignore
+        if not os.path.isfile(os.path.join(pseudo_mask_roots, "dataset_meta.json")):
+            # Save dataset_meta.json for newly created pseudo masks
+            # FIXME: Because background class is ignored when generating polygons, meta is set with len(labels)-1.
+            # It must be considered to set the whole labels later.
+            # (-> {i: f"target{i+1}" for i in range(max(total_labels)+1)})
+            meta = {"label_map": {i + 1: f"target{i+1}" for i in range(max(total_labels))}}
+            with open(os.path.join(pseudo_mask_roots, "dataset_meta.json"), "w", encoding="UTF-8") as f:
+                json.dump(meta, f, indent=4)
+
+        # Make categories for pseudo masks
+        label_map = parse_meta_file(os.path.join(pseudo_mask_roots, "dataset_meta.json"))
+        dataset[Subset.TRAINING].define_categories(make_categories(label_map))
 
-        return out
+        return dataset
 
-    @check_input_parameters_type()
-    def get_ann_info(self, idx: int):
-        """This method is used for evaluation of predictions.
+    def create_pseudo_masks(self, img: np.array, pseudo_mask_path: str, mode: str = "FH") -> None:
+        """Create pseudo masks for self-sl for semantic segmentation using DetCon.
 
-        The CustomDataset class implements a method
-        CustomDataset.evaluate, which uses the class method get_ann_info to retrieve annotations.
+        Args:
+            img (np.array) : A sample to create a pseudo mask.
+            pseudo_mask_path (str): The path to save a pseudo mask.
+            mode (str): The mode to create a pseudo mask. Defaults to "FH".
 
-        :param idx: index of the dataset item for which to get the annotations
-        :return ann_info: dict that contains the coordinates of the bboxes and their corresponding labels
+        Returns:
+            np.array: a created pseudo mask for item.
         """
-
-        dataset_item = self.otx_dataset[idx]
-        ann_info = get_annotation_mmseg_format(dataset_item, self.project_labels)
-
-        return ann_info
-
-    @check_input_parameters_type()
-    def get_gt_seg_maps(self, efficient_test: bool = False):
-        """Get ground truth segmentation maps for evaluation."""
-
-        gt_seg_maps = []
-        for item_id in range(len(self)):
-            ann_info = self.get_ann_info(item_id)
-            gt_seg_maps.append(ann_info["gt_semantic_seg"])
-        if efficient_test:
-            pass
-
-        return gt_seg_maps
-
-
-@DATASETS.register_module()
-class MPASegDataset(OTXSegDataset, metaclass=ABCMeta):
-    """Wrapper dataset that allows using a OTX dataset to train models."""
-
-    def __init__(self, **kwargs):
-        pipeline = []
-        test_mode = kwargs.get("test_mode", False)
-        if "dataset" in kwargs:
-            dataset = kwargs["dataset"]
-            otx_dataset = dataset.otx_dataset
-            pipeline = dataset.pipeline
-            classes = dataset.labels
-            new_classes = dataset.new_classes
+        if mode == "FH":
+            pseudo_mask = felzenszwalb(img, scale=1000, min_size=1000)
         else:
-            otx_dataset = kwargs["otx_dataset"]
-            pipeline = kwargs["pipeline"]
-            classes = kwargs["labels"]
-            new_classes = kwargs.get("new_classes", [])
-
-        if test_mode is False:
-            self.img_indices = get_old_new_img_indices(classes, new_classes, otx_dataset)
-
-        if classes:
-            classes = [c.name for c in classes]
-            classes = ["background"] + classes
-        else:
-            classes = []
-        super().__init__(otx_dataset=otx_dataset, pipeline=pipeline, classes=classes)
+            raise ValueError((f'{mode} is not supported to create pseudo masks for DetCon. Choose one of ["FH"].'))
+
+        os.makedirs(os.path.dirname(pseudo_mask_path), exist_ok=True)
+        cv2.imwrite(pseudo_mask_path, pseudo_mask.astype(np.uint8))
 
-        self.CLASSES = [label.name for label in self.project_labels]
-        if "background" not in self.CLASSES:
-            self.CLASSES = ["background"] + self.CLASSES
-
-        if self.label_map is None:
-            self.label_map = {}
-            for i, c in enumerate(self.CLASSES):
-                if c not in classes:
-                    self.label_map[i] = -1
-                else:
-                    self.label_map[i] = classes.index(c)
+        return pseudo_mask
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,21 +1,15 @@
-"""OTX Algorithms - Segmentation pipelines."""
+"""Initialization of OCR-Lite-HRnet-s-mod2 model for Semi-SL Segmentation Task."""
 
-# Copyright (C) 2023 Intel Corporation
+# Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
-
-from .compose import MaskCompose, ProbCompose
-from .loads import LoadAnnotationFromOTXDataset, LoadImageFromOTXDataset
-from .transforms import TwoCropTransform
-
-__all__ = ["MaskCompose", "ProbCompose", "LoadImageFromOTXDataset", "LoadAnnotationFromOTXDataset", "TwoCropTransform"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/compose.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/compose.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/loads.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/loads.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,14 @@
 
 from mmseg.datasets.builder import PIPELINES
 
 import otx.core.data.pipelines.load_image_from_otx_dataset as load_image_base
 from otx.algorithms.segmentation.adapters.mmseg.datasets.dataset import (
     get_annotation_mmseg_format,
 )
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 
 # pylint: disable=too-many-instance-attributes, too-many-arguments
 @PIPELINES.register_module()
 class LoadImageFromOTXDataset(load_image_base.LoadImageFromOTXDataset):
     """Pipeline element that loads an image from a OTX Dataset on the fly."""
 
@@ -39,15 +38,14 @@
         results['ann_info']['label_list']: list of all labels in the project
 
     """
 
     def __init__(self):
         pass
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of LoadAnnotationFromOTXDataset."""
         dataset_item = results["dataset_item"]
         labels = results["ann_info"]["labels"]
 
         ann_info = get_annotation_mmseg_format(dataset_item, labels)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/transforms.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/transforms.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,16 +14,14 @@
 from mmseg.datasets.builder import PIPELINES
 from mmseg.datasets.pipelines import Compose
 from mmseg.datasets.pipelines.formatting import to_tensor
 from PIL import Image
 from torchvision import transforms as T
 from torchvision.transforms import functional as F
 
-from otx.api.utils.argument_checks import check_input_parameters_type
-
 
 @PIPELINES.register_module(force=True)
 class Normalize:
     """Normalize the image.
 
     Added key is "img_norm_cfg".
 
@@ -164,15 +162,14 @@
     """
 
     def __init__(self, view0: List, view1: List):
         self.view0 = Compose([build_from_cfg(p, PIPELINES) for p in view0])
         self.view1 = Compose([build_from_cfg(p, PIPELINES) for p in view1])
         self.is_both = True
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of TwoCropTransform.
 
         Args:
             results (dict): Inputs to be transformed.
 
         Returns:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 from .backbones import LiteHRNet, MMOVBackbone
-from .heads import CustomFCNHead, MMOVDecodeHead
+from .heads import CustomFCNHead, DetConHead, MMOVDecodeHead
 from .losses import CrossEntropyLossWithIgnore, DetConLoss
 from .necks import SelfSLMLP
 from .schedulers import (
     ConstantScalarScheduler,
     PolyScalarScheduler,
     StepScalarScheduler,
 )
@@ -41,8 +41,9 @@
     "PolyScalarScheduler",
     "StepScalarScheduler",
     "DetConB",
     "CrossEntropyLossWithIgnore",
     "SupConDetConB",
     "ClassIncrEncoderDecoder",
     "MeanTeacherSegmentor",
+    "DetConHead",
 ]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/litehrnet.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/litehrnet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/mmov_backbone.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/backbones/mmov_backbone.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-"""Semantic segmentation heads."""
+"""Model Wrapper Initialization of OTX Segmentation."""
 
-# Copyright (C) 2023 Intel Corporation
+# Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
+from .blur import BlurSegmentation
 
-from .custom_fcn_head import CustomFCNHead
-from .mmov_decode_head import MMOVDecodeHead
-
-__all__ = ["MMOVDecodeHead", "CustomFCNHead"]
+__all__ = ["BlurSegmentation"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/custom_fcn_head.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/custom_fcn_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mixin.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mixin.py`

 * *Files 2% similar despite different names*

```diff
@@ -206,14 +206,15 @@
                 'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.
                 For details on the values of these keys see
                 `mmseg/datasets/pipelines/formatting.py:Collect`.
             gt_semantic_seg (Tensor): Semantic segmentation masks
                 used if the architecture supports semantic segmentation task.
             train_cfg (dict): The training config.
             pixel_weights (Tensor): Pixels weights.
+            return_logits (bool): Flag to retun the logit with losses.
 
         Returns:
             dict[str, Tensor]: a dictionary of loss components
         """
 
         seg_logits = self.forward(inputs)
         losses = self.losses(seg_logits, gt_semantic_seg, train_cfg, pixel_weights)
@@ -285,14 +286,15 @@
                 and 'ignored_labels'.
                 For details on the values of these keys see
                 `mmseg/datasets/pipelines/formatting.py:Collect`.
             gt_semantic_seg (Tensor): Semantic segmentation masks
                 used if the architecture supports semantic segmentation task.
             train_cfg (dict): The training config.
             pixel_weights (Tensor): Pixels weights.
+            return_logits (bool): Flag to retun the logit with losses.
 
         Returns:
             dict[str, Tensor]: a dictionary of loss components
         """
         seg_logits = self(inputs)
         valid_label_mask = get_valid_label_mask_per_batch(img_metas, self.num_classes)
         losses = self.losses(
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mmov_decode_head.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/heads/mmov_decode_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_pixel_loss.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_pixel_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_weighted_loss.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/base_weighted_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/cross_entropy_loss_with_ignore.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/cross_entropy_loss_with_ignore.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/detcon_loss.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/detcon_loss.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,19 +38,19 @@
         super().__init__()
         assert temperature > 0
         self.temperature = torch.tensor(temperature)
         self.use_replicator_loss = use_replicator_loss
 
     def get_distributed_tensors(self, target1, target2, batch_size, num_samples, num_features, device):
         """Grab tensors across replicas during distributed training."""
-        num_gpus = torch.cuda.device_count()
-        if num_gpus > 1 and torch.distributed.is_initialized() and self.use_replicator_loss:
+        if dist.is_initialized() and self.use_replicator_loss:
             # Grab tensor across replicas and expand first dimension
-            target1_large = [torch.zeros_like(target1) for _ in range(num_gpus)]
-            target2_large = [torch.zeros_like(target2) for _ in range(num_gpus)]
+            world_size = dist.get_world_size()
+            target1_large = [torch.zeros_like(target1) for _ in range(world_size)]
+            target2_large = [torch.zeros_like(target2) for _ in range(world_size)]
             dist.all_gather(target1_large, target1)
             dist.all_gather(target2_large, target2)
             target1_large = torch.cat(target1_large, dim=0)
             target2_large = torch.cat(target2_large, dim=0)
 
             # Fold into batch dimension
             target1_large = target1_large.reshape(-1, num_samples, num_features)
@@ -160,8 +160,8 @@
             torch.cat([logits_dict["ba"], logits_dict["bb"]], dim=2).reshape((batch_size, num_samples, -1)),
         ]
 
         loss_a = manual_cross_entropy(logits_concat[0], labels_concat[0], weight=weights[0])
         loss_b = manual_cross_entropy(logits_concat[1], labels_concat[1], weight=weights[1])
         loss = loss_a + loss_b
 
-        return dict(loss=loss)
+        return loss
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/otx_pixel_base.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/losses/otx_pixel_base.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/selfsl_mlp.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/necks/selfsl_mlp.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/base.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/base.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/constant.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/constant.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/poly.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/poly.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/step.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/schedulers/step.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/class_incr_encoder_decoder.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/class_incr_encoder_decoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -51,14 +51,15 @@
                 has: 'img_shape', 'scale_factor', 'flip', and may also contain
                 'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.
                 For details on the values of these keys see
                 `mmseg/datasets/pipelines/formatting.py:Collect`.
             gt_semantic_seg (Tensor): Semantic segmentation masks
                 used if the architecture supports semantic segmentation task.
             aux_img (Tensor): Auxiliary images.
+            **kwargs (Any): Addition keyword arguments.
 
         Returns:
             dict[str, Tensor]: a dictionary of loss components
         """
         if aux_img is not None:
             mix_loss_enabled = False
             mix_loss_cfg = self.train_cfg.get("mix_loss", None)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/detcon.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/detcon.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 
 import torch
 import torch.distributed as dist
 from mmcv.runner import load_checkpoint
 from mmseg.models.builder import (  # pylint: disable=no-name-in-module
     SEGMENTORS,
     build_backbone,
-    build_loss,
+    build_head,
     build_neck,
 )
 from mmseg.ops import resize
 from torch import nn
 
 from otx.algorithms.common.utils.logger import get_logger
 
@@ -120,15 +120,17 @@
 
         return sampled_masks, sampled_mask_ids
 
 
 # pylint: disable=too-many-arguments, dangerous-default-value, too-many-instance-attributes
 @SEGMENTORS.register_module()
 class DetConB(nn.Module):
-    """Implementation of 'Efficient Visual Pretraining with Contrastive Detection' \
+    """DetCon Implementation.
+
+    Implementation of 'Efficient Visual Pretraining with Contrastive Detection'
         (https://arxiv.org/abs/2103.10957).
 
     Args:
         backbone (dict): Config dict for module of backbone ConvNet.
         neck (dict, optional): Config dict for module of deep features to compact feature vectors.
             Default: None.
         head (dict, optional): Config dict for module of loss functions. Default: None.
@@ -138,15 +140,14 @@
         num_classes (int): The number of classes to be considered as pseudo classes. Default: 256.
         num_samples (int): The number of samples to be sampled. Default: 16.
         downsample (int): The ratio of the mask size to the feature size. Default: 32.
         input_transform (str): Input transform of features from backbone. Default: "resize_concat".
         in_index (list): Feature index to be used for DetCon if the backbone outputs
             multi-scale features wrapped by list or tuple. Default: [0].
         align_corners (bool): Whether apply `align_corners` during resize. Default: False.
-        loss_cfg (dict): DetCon loss configuration.
     """
 
     def __init__(
         self,
         backbone: Dict[str, Any],
         neck: Optional[Dict[str, Any]] = None,
         head: Optional[Dict[str, Any]] = None,
@@ -154,15 +155,14 @@
         base_momentum: float = 0.996,
         num_classes: int = 256,
         num_samples: int = 16,
         downsample: int = 32,
         input_transform: str = "resize_concat",
         in_index: Union[List[int], int] = [0],
         align_corners: bool = False,
-        loss_cfg: Optional[Dict[str, Any]] = None,
         **kwargs,
     ):
         super().__init__()
 
         self.base_momentum = base_momentum
         self.momentum = base_momentum
         self.num_classes = num_classes
@@ -177,24 +177,21 @@
         self.target_backbone = build_backbone(backbone)
 
         # build projector
         self.online_projector = build_neck(neck)
         self.target_projector = build_neck(neck)
 
         # build head with predictor
-        self.predictor = build_neck(head)
+        self.predictor = build_head(head)
 
         # set maskpooling
         self.mask_pool = MaskPooling(num_classes, num_samples, downsample)
 
         self.init_weights(pretrained=pretrained)
 
-        # build detcon loss
-        self.detcon_loss = build_loss(loss_cfg)
-
         # Hooks for super_type transparent weight save
         self._register_state_dict_hook(self.state_dict_hook)
 
     def init_weights(self, pretrained: Optional[str] = None):
         """Initialize the weights of model.
 
         Args:
@@ -315,48 +312,30 @@
             return_embedding (bool): Whether returning embeddings from the online backbone.
                 It can be used for SupCon. Default: False.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
         assert img.ndim == 5 and gt_semantic_seg.ndim == 5
-        img1, img2 = img[:, 0], img[:, 1]
-        mask1, mask2 = gt_semantic_seg[:, :, 0], gt_semantic_seg[:, :, 1]
+        batch_size = img.shape[0]
+        imgs = torch.cat((img[:, 0], img[:, 1]), dim=0)
+        masks = torch.cat((gt_semantic_seg[:, :, 0], gt_semantic_seg[:, :, 1]), dim=0)
 
-        embd1 = self.online_backbone(img1)
-        proj1, id1 = self.sample_masked_feats(embd1, mask1, self.online_projector)
-        proj2, id2 = self.sample_masked_feats(self.online_backbone(img2), mask2, self.online_projector)
+        embds = self.online_backbone(imgs)
+        projs, ids = self.sample_masked_feats(embds, masks, self.online_projector)
 
         with torch.no_grad():
             self._momentum_update()
-            proj1_tgt, id1_tgt = self.sample_masked_feats(self.target_backbone(img1), mask1, self.target_projector)
-            proj2_tgt, id2_tgt = self.sample_masked_feats(self.target_backbone(img2), mask2, self.target_projector)
+            projs_tgt, ids_tgt = self.sample_masked_feats(self.target_backbone(imgs), masks, self.target_projector)
 
         # predictor
-        # TODO (sungchul): predictor + loss -> head?
-        pred1, pred2 = self.predictor(proj1), self.predictor(proj2)
-        pred1 = pred1.reshape((-1, self.num_samples, pred1.shape[-1]))
-        pred2 = pred2.reshape((-1, self.num_samples, pred2.shape[-1]))
-        proj1_tgt = proj1_tgt.reshape((-1, self.num_samples, proj1_tgt.shape[-1]))
-        proj2_tgt = proj2_tgt.reshape((-1, self.num_samples, proj2_tgt.shape[-1]))
-
-        # decon loss
-        loss = self.detcon_loss(
-            pred1=pred1,
-            pred2=pred2,
-            target1=proj1_tgt,
-            target2=proj2_tgt,
-            pind1=id1,
-            pind2=id2,
-            tind1=id1_tgt,
-            tind2=id2_tgt,
-        )
+        loss = self.predictor(projs, projs_tgt, ids, ids_tgt, batch_size, self.num_samples)
 
         if return_embedding:
-            return loss, embd1
+            return loss, embds, masks
         return loss
 
     def forward(self, img, img_metas, return_loss=True, **kwargs):
         """Calls either :func:`forward_train` or :func:`forward_test` depending on whether ``return_loss`` is ``True``.
 
         Note this setting will change the expected inputs. When
         ``return_loss=True``, img and img_meta are single-nested (i.e. Tensor
@@ -378,14 +357,15 @@
         this method, such as GAN.
 
         Args:
             data_batch (dict): The output of dataloader.
             optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of
                 runner is passed to ``train_step()``. This argument is unused
                 and reserved.
+            **kwargs (Any): Addition keyword arguments.
 
         Returns:
             dict: It should contain at least 3 keys: ``loss``, ``log_vars``,
                 ``num_samples``.
                 ``loss`` is a tensor for back propagation, which can be a
                 weighted sum of multiple losses.
                 ``log_vars`` contains all the variables to be sent to the
@@ -482,15 +462,14 @@
         base_momentum: float = 0.996,
         num_classes: int = 256,
         num_samples: int = 16,
         downsample: int = 32,
         input_transform: str = "resize_concat",
         in_index: Union[List[int], int] = [0],
         align_corners: bool = False,
-        loss_cfg: Optional[Dict[str, Any]] = None,
         train_cfg: Optional[Dict[str, Any]] = None,
         test_cfg: Optional[Dict[str, Any]] = None,
         **kwargs,
     ):
         super().__init__(backbone=backbone, decode_head=decode_head, train_cfg=train_cfg, test_cfg=test_cfg, **kwargs)
 
         self.detconb = DetConB(
@@ -501,15 +480,14 @@
             base_momentum=base_momentum,
             num_classes=num_classes,
             num_samples=num_samples,
             downsample=downsample,
             input_transform=input_transform,
             in_index=in_index,
             align_corners=align_corners,
-            loss_cfg=loss_cfg,
             **kwargs,
         )
         self.backbone = self.detconb.online_backbone
         # TODO (sungchul): Is state_dict_hook needed to save segmentor only?
         # 1. use state_dict_hook : we can save memory as only saving backbone + decode_head.
         # 2. save all : we can use additional training with the whole weights (backbone + decode_head + detcon).
 
@@ -526,31 +504,32 @@
 
         Args:
             img (Tensor): Input images.
             img_metas (list[dict]): Input information.
             gt_semantic_seg (Tensor): Ground truth masks.
                 It is used to organize features among the same classes.
             pixel_weights (Tensor): Pixels weights.
+            **kwargs (Any): Addition keyword arguments.
 
         Returns:
             dict[str, Tensor]: A dictionary of loss components.
         """
         losses = {}
         if img.ndim == 4:
             # supervised learning with interval
-            embd = self.detconb.online_backbone(img)
-            mask = gt_semantic_seg
+            embds = self.detconb.online_backbone(img)
+            masks = gt_semantic_seg
         else:
             # supcon training
-            mask = gt_semantic_seg[:, :, 0]
-            loss_detcon, embd = self.detconb.forward_train(
+            loss_detcon, embds, masks = self.detconb.forward_train(
                 img=img, img_metas=img_metas, gt_semantic_seg=gt_semantic_seg, return_embedding=True
             )
             losses.update(dict(loss_detcon=loss_detcon["loss"]))
+            img_metas += img_metas
 
         # decode head
         loss_decode, _ = self._decode_head_forward_train(
-            embd, img_metas, gt_semantic_seg=mask, pixel_weights=pixel_weights
+            embds, img_metas, gt_semantic_seg=masks, pixel_weights=pixel_weights
         )
         losses.update(loss_decode)
 
         return losses
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mean_teacher_segmentor.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mean_teacher_segmentor.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mixin.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/mixin.py`

 * *Files 1% similar despite different names*

```diff
@@ -130,14 +130,15 @@
                 has: 'img_shape', 'scale_factor', 'flip', and may also contain
                 'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.
                 For details on the values of these keys see
                 `mmseg/datasets/pipelines/formatting.py:Collect`.
             gt_semantic_seg (Tensor): Semantic segmentation masks
                 used if the architecture supports semantic segmentation task.
             pixel_weights (Tensor): Pixels weights.
+            **kwargs (Any): Addition keyword arguments.
 
         Returns:
             dict[str, Tensor]: a dictionary of loss components
         """
 
         losses = dict()
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/otx_encoder_decoder.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/segmentors/otx_encoder_decoder.py`

 * *Files 5% similar despite different names*

```diff
@@ -16,19 +16,18 @@
     """OTX encoder decoder."""
 
     def simple_test(self, img, img_meta, rescale=True, output_logits=False):
         """Simple test with single image."""
         seg_logit = self.inference(img, img_meta, rescale)
         if output_logits:
             seg_pred = seg_logit
+        elif self.out_channels == 1:
+            seg_pred = (seg_logit > self.decode_head.threshold).to(seg_logit).squeeze(1)
         else:
-            if self.out_channels == 1:
-                seg_pred = (seg_logit > self.decode_head.threshold).to(seg_logit).squeeze(1)
-            else:
-                seg_pred = seg_logit.argmax(dim=1)
+            seg_pred = seg_logit.argmax(dim=1)
         if torch.onnx.is_in_onnx_export():
             # our inference backend only support 4D output
             if seg_pred.dim() != 4:
                 seg_pred = seg_pred.unsqueeze(0)
             return seg_pred
         seg_pred = seg_pred.cpu().numpy()
         seg_pred = list(seg_pred)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/aggregator.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/aggregator.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/angular_pw_conv.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/angular_pw_conv.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/asymmetric_position_attention.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/asymmetric_position_attention.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/channel_shuffle.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/channel_shuffle.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/local_attention.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/local_attention.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/loss_equalizer.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/loss_equalizer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/normalize.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/normalize.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/psp_layer.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/models/utils/psp_layer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/data_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""NNCF utils for mmseg."""
+"""Data Pipeline of HR-Net model for Segmentation Task."""
 
 # Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -10,14 +10,9 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-from .builder import build_nncf_segmentor
-from .hooks import CustomstepLrUpdaterHook
-
-__all__ = [
-    "build_nncf_segmentor",
-    "CustomstepLrUpdaterHook",
-]
+# pylint: disable=invalid-name
+_base_ = ["../../base/data/semisl/data_pipeline.py"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/builder.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/hooks.py` & `otx-1.2.0rc1/otx/algorithms/common/adapters/mmcv/hooks/lr_updater_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""NNCF task related hooks."""
+"""Module for defining LrUpdaterHook and CustomLRUpdateHook for self-supervised learning using mmseg."""
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import math
 
 from mmcv.runner.hooks import HOOKS, LrUpdaterHook
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/tasks/exporter.py` & `otx-1.2.0rc1/otx/algorithms/classification/adapters/mmcls/utils/exporter.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,63 +1,63 @@
-"""Export task for OTX Segmentation with MMSEG."""
-# Copyright (C) 2022 Intel Corporation
+"""Exporter for OTX Classification task with MMClassification training backend."""
+# Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import numpy as np
 from mmcv.runner import wrap_fp16_model
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
-from otx.algorithms.common.adapters.mmcv.tasks.registry import STAGES
-from otx.algorithms.common.adapters.mmdeploy.utils import sync_batchnorm_2_batchnorm
+from otx.algorithms.classification.adapters.mmcls.utils.builder import build_classifier
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
+from otx.algorithms.common.adapters.mmdeploy.utils.utils import (
+    sync_batchnorm_2_batchnorm,
+)
 from otx.algorithms.common.utils.logger import get_logger
 
-from .stage import SegStage
-
 logger = get_logger()
 
 
-@STAGES.register_module()
-class SegExporter(ExporterMixin, SegStage):
-    """Class for segmentation model export."""
+class ClassificationExporter(Exporter):
+    """Exporter for OTX Classification using mmclassification training backend."""
 
-    def run(self, model_cfg, model_ckpt, data_cfg, **kwargs):  # noqa: C901
+    def run(self, cfg, **kwargs):  # noqa: C901
         """Run exporter stage."""
 
         precision = kwargs.get("precision", "FP32")
-        model_builder = kwargs.get("model_builder", self.MODEL_BUILDER)
+        model_builder = kwargs.get("model_builder", build_classifier)
 
         def model_builder_helper(*args, **kwargs):
             model = model_builder(*args, **kwargs)
             # TODO: handle various input size
             model = sync_batchnorm_2_batchnorm(model, 2)
 
+            if hasattr(model, "is_export"):
+                model.is_export = True
+
             if precision == "FP16":
                 wrap_fp16_model(model)
             elif precision == "INT8":
                 from nncf.torch.nncf_network import NNCFNetwork
 
                 assert isinstance(model, NNCFNetwork)
 
             return model
 
         kwargs["model_builder"] = model_builder_helper
-
-        return super().run(model_cfg, model_ckpt, data_cfg, **kwargs)
+        return super().run(cfg, **kwargs)
 
     @staticmethod
     def naive_export(output_dir, model_builder, precision, cfg, model_name="model"):
-        """Export using pytorch backend."""
-        from mmseg.apis.inference import LoadImage
-        from mmseg.datasets.pipelines import Compose
+        """Export procedure with pytorch backend."""
+        from mmcls.datasets.pipelines import Compose
 
         from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
 
         def get_fake_data(cfg, orig_img_shape=(128, 128, 3)):
-            pipeline = [LoadImage()] + cfg.data.test.pipeline[1:]
+            pipeline = cfg.data.test.pipeline
             pipeline = Compose(pipeline)
             data = dict(img=np.zeros(orig_img_shape, dtype=np.uint8))
             data = pipeline(data)
             return data
 
         fake_data = get_fake_data(cfg)
         opset_version = 11
@@ -65,11 +65,11 @@
         NaiveExporter.export2openvino(
             output_dir,
             model_builder,
             cfg,
             fake_data,
             precision=precision,
             model_name=model_name,
-            input_names=["input"],
-            output_names=["output"],
+            input_names=["data"],
+            output_names=["logits"],
             opset_version=opset_version,
         )
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,17 +19,19 @@
     patch_config,
     patch_datasets,
     patch_evaluation,
     prepare_for_training,
     set_hyperparams,
 )
 from .data_utils import get_valid_label_mask_per_batch, load_dataset_items
+from .exporter import SegmentationExporter
 
 __all__ = [
     "patch_config",
+    "SegmentationExporter",
     "patch_datasets",
     "patch_evaluation",
     "prepare_for_training",
     "set_hyperparams",
     "load_dataset_items",
     "build_scalar_scheduler",
     "build_segmentor",
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/builder.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/config_utils.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/config_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -31,23 +31,18 @@
     prepare_work_dir,
     remove_from_config,
     remove_from_configs_by_type,
     update_config,
 )
 from otx.algorithms.segmentation.configs.base import SegmentationConfig
 from otx.api.entities.label import Domain, LabelEntity
-from otx.api.utils.argument_checks import (
-    DirectoryPathCheck,
-    check_input_parameters_type,
-)
 
 logger = logging.getLogger(__name__)
 
 
-@check_input_parameters_type({"work_dir": DirectoryPathCheck})
 def patch_config(
     config: Config,
     work_dir: str,
     labels: List[LabelEntity],
 ):  # pylint: disable=too-many-branches
     """Update config function."""
 
@@ -76,15 +71,14 @@
 
     remove_from_config(config, "img_norm_cfg")
 
     config.gpu_ids = range(1)
     config.work_dir = work_dir
 
 
-@check_input_parameters_type()
 def patch_model_config(
     config: Config,
     labels: List[LabelEntity],
     distributed: bool = False,
 ):
     """Patch model config."""
     label_names = ["background"] + [label.name for label in labels]
@@ -92,15 +86,14 @@
 
     if "test_cfg" not in config.model:
         config.model.test_cfg = ConfigDict()
     config.model.test_cfg.return_repr_vector = True
     set_distributed_mode(config, distributed)
 
 
-@check_input_parameters_type()
 def set_hyperparams(config: Config, hyperparams: SegmentationConfig):
     """Set function for hyperparams (SegmentationConfig)."""
     config.data.samples_per_gpu = int(hyperparams.learning_parameters.batch_size)
     config.data.workers_per_gpu = int(hyperparams.learning_parameters.num_workers)
     config.optimizer.lr = float(hyperparams.learning_parameters.learning_rate)
 
     # set proper number of iterations
@@ -124,15 +117,14 @@
         config.runner.max_iters = total_iterations
 
     # rescale the learning schedules
     schedule_scale = float(total_iterations) / float(init_num_iterations) if init_num_iterations > 0 else 0.0
     rescale_num_iterations(config, schedule_scale)
 
 
-@check_input_parameters_type()
 def rescale_num_iterations(config: Union[Config, ConfigDict], schedule_scale: float):
     """Rescale number of iterations for lr scheduler."""
     if config.lr_config.policy == "customstep":
         config.lr_config.step = [int(schedule_scale * step) for step in config.lr_config.step]
     elif config.lr_config.policy == "customcos":
         config.lr_config.periods = [int(schedule_scale * period) for period in config.lr_config.periods]
 
@@ -162,15 +154,14 @@
             for head in heads:
                 _rescale_num_iters(head, schedule_scale)
         elif isinstance(heads, dict):
             _rescale_num_iters(heads, schedule_scale)
         config.model[head_type] = heads
 
 
-@check_input_parameters_type()
 def patch_adaptive_repeat_dataset(
     config: Union[Config, ConfigDict], num_samples: int, decay: float = 0.002, factor: float = 10
 ):
     """Patch the repeat times and training epochs adatively."""
     if config.data.train.type != "RepeatDataset":
         return
 
@@ -195,15 +186,14 @@
     schedule_scale = float(new_max_epoch) / float(init_max_epoch)
     config.params_config.iters = math.ceil(schedule_scale * config.params_config.iters)
     config.lr_config.fixed_iters = math.ceil(schedule_scale * config.lr_config.fixed_iters)
     config.lr_config.warmup_iters = math.ceil(schedule_scale * config.lr_config.warmup_iters)
     rescale_num_iterations(config, schedule_scale)
 
 
-@check_input_parameters_type()
 def prepare_for_training(
     config: Config,
     data_config: ConfigDict,
 ) -> Config:
     """Prepare configs for training phase."""
     prepare_work_dir(config)
 
@@ -226,15 +216,14 @@
 
     if train_num_samples > 0:
         patch_adaptive_repeat_dataset(config, train_num_samples)
 
     return config
 
 
-@check_input_parameters_type()
 def set_distributed_mode(config: Config, distributed: bool):
     """Setter distributed into config."""
     if distributed:
         return
 
     norm_cfg = {"type": "BN", "requires_grad": True}
 
@@ -253,28 +242,26 @@
         if isinstance(head, (tuple, list)):
             for sub_head in head:
                 _replace_syncbn(sub_head, norm_cfg)
         else:
             _replace_syncbn(head, norm_cfg)
 
 
-@check_input_parameters_type()
 def set_data_classes(config: Config, label_names: List[str]):
     """Setter data classes into config."""
     # Save labels in data configs.
     for subset in ("train", "val", "test"):
         cfg = config.data[subset]
         if cfg.type == "RepeatDataset":
             cfg.dataset.classes = label_names
         else:
             cfg.classes = label_names
         config.data[subset].classes = label_names
 
 
-@check_input_parameters_type()
 def set_num_classes(config: Config, num_classes: int):
     """Setter num_classes function."""
     assert num_classes > 1
 
     for head_type in ("decode_head", "auxiliary_head"):
         heads = config.model.get(head_type, None)
         if heads is None:
@@ -286,15 +273,14 @@
                     continue
 
                 head.num_classes = num_classes
         elif isinstance(heads, dict):
             heads["num_classes"] = num_classes
 
 
-@check_input_parameters_type()
 def patch_datasets(
     config: Config,
     domain: Domain = Domain.SEGMENTATION,
     subsets: Optional[List[str]] = None,
     **kwargs,
 ):
     """Update dataset configs."""
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/mmseg/utils/data_utils.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/utils/data_utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -34,47 +34,38 @@
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.id import ID
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.polygon import Point, Polygon
 from otx.api.entities.subset import Subset
-from otx.api.utils.argument_checks import (
-    DirectoryPathCheck,
-    JsonFilePathCheck,
-    OptionalDirectoryPathCheck,
-    check_input_parameters_type,
-)
 
 logger = get_logger()
 
 # pylint: disable=too-many-locals
 
 
-@check_input_parameters_type({"annot_path": JsonFilePathCheck})
 def get_classes_from_annotation(annot_path):
     """Getter function of classes from annotation."""
     with open(annot_path, encoding="UTF-8") as input_stream:
         content = json.load(input_stream)
         labels_map = content["labels_map"]
 
         categories = [(v["name"], v["id"]) for v in sorted(labels_map, key=lambda tup: int(tup["id"]))]
 
     return categories
 
 
-@check_input_parameters_type({"value": OptionalDirectoryPathCheck})
 def abs_path_if_valid(value):
     """Valid function of abs_path."""
     if value:
         return os.path.abspath(value)
     return None
 
 
-@check_input_parameters_type()
 def create_annotation_from_hard_seg_map(hard_seg_map: np.ndarray, labels: List[LabelEntity]):
     """Creation function from hard seg_map."""
     height, width = hard_seg_map.shape[:2]
     unique_labels = np.unique(hard_seg_map)
 
     annotations: List[Annotation] = []
     for label_id in unique_labels:
@@ -111,49 +102,45 @@
                     id=ID(f"{label_id:08}"),
                 )
             )
 
     return annotations
 
 
-@check_input_parameters_type({"ann_dir": OptionalDirectoryPathCheck})
 def load_labels_from_annotation(ann_dir):
     """Load labels function from annotation."""
     if ann_dir is None:
         return []
 
     labels_map_path = os.path.join(ann_dir, "meta.json")
     labels = get_classes_from_annotation(labels_map_path)
 
     return labels
 
 
-@check_input_parameters_type()
 def add_labels(cur_labels: List[LabelEntity], new_labels: List[tuple]):
     """Add labels function."""
     for label_name, label_id in new_labels:
         matching_labels = [label for label in cur_labels if label.name == label_name]
         if len(matching_labels) > 1:
             raise ValueError("Found multiple matching labels")
         if len(matching_labels) == 0:
             label_id = label_id if label_id is not None else len(cur_labels)
             label = LabelEntity(name=label_name, domain=Domain.SEGMENTATION, id=ID(f"{label_id:08}"))
             cur_labels.append(label)
 
 
-@check_input_parameters_type()
 def check_labels(cur_labels: List[LabelEntity], new_labels: List[tuple]):
     """Check labels function."""
     cur_names = {label.name for label in cur_labels}
     new_names = {label[0] for label in new_labels}
     if cur_names != new_names:
         raise ValueError("Class names don't match from file to file")
 
 
-@check_input_parameters_type()
 def get_extended_label_names(labels: List[LabelEntity]):
     """Getter function of extended label names."""
     target_labels = [v.name for v in sorted(labels, key=lambda x: x.id)]
     all_labels = ["background"] + target_labels
     return all_labels
 
 
@@ -164,15 +151,14 @@
         valid_label_mask = torch.Tensor([1 for _ in range(num_classes)])
         if "ignored_labels" in meta and meta["ignored_labels"]:
             valid_label_mask[meta["ignored_labels"]] = 0
         valid_label_mask_per_batch.append(valid_label_mask)
     return valid_label_mask_per_batch
 
 
-@check_input_parameters_type()
 def create_pseudo_masks(ann_file_path: str, data_root_dir: str, mode="FH"):
     """Create pseudo masks for Self-SL using DetCon."""
     if not os.path.isdir(ann_file_path):
         logger.info(
             (
                 f"Creating pseudo masks with mode={mode} is required. "
                 f"It may take some time. Once this process has been performed, "
@@ -207,15 +193,14 @@
         # Considering background class, labels_map in meta.json should have one less than the number of labels.
         # If we don't need to consider background class, it will be updated to consider all labels.
         meta = {"labels_map": [{"name": f"target{i+1}", "id": i + 1} for i in range(max(total_labels))]}
         with open(os.path.join(ann_file_path, "meta.json"), "w", encoding="UTF-8") as f:
             json.dump(meta, f, indent=4)
 
 
-@check_input_parameters_type({"ann_file_path": DirectoryPathCheck, "data_root_dir": DirectoryPathCheck})
 def load_dataset_items(
     ann_file_path: str,
     data_root_dir: str,
     subset: Subset = Subset.NONE,
     labels_list: Optional[List[LabelEntity]] = None,
 ):
     """Load dataset items."""
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model Wrapper Initialization of OTX Segmentation."""
+"""Configs Initialization of OTX Segmentation."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -10,10 +10,11 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-from .blur import BlurSegmentation
+from .configuration import SegmentationConfig
+from .configuration_enums import Models
 
-__all__ = ["BlurSegmentation"]
+__all__ = ["SegmentationConfig", "Models"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/blur.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/model_wrappers/blur.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,19 +19,17 @@
 
 import cv2
 import numpy as np
 from openvino.model_zoo.model_api.adapters.model_adapter import ModelAdapter
 from openvino.model_zoo.model_api.models import SegmentationModel
 from openvino.model_zoo.model_api.models.types import NumericalValue
 
-from otx.api.utils.argument_checks import check_input_parameters_type
 from otx.api.utils.segmentation_utils import create_hard_prediction_from_soft_prediction
 
 
-@check_input_parameters_type()
 def get_activation_map(features: Union[np.ndarray, Iterable, int, float]):
     """Getter activation_map functions."""
     min_soft_score = np.min(features)
     max_soft_score = np.max(features)
     factor = 255.0 / (max_soft_score - min_soft_score + 1e-12)
 
     float_act_map = factor * (features - min_soft_score)
@@ -42,15 +40,14 @@
 
 
 class BlurSegmentation(SegmentationModel):
     """BlurSegmentation class of openvino model wrapper."""
 
     __model__ = "blur_segmentation"
 
-    @check_input_parameters_type()
     def __init__(self, model_adapter: ModelAdapter, configuration: Optional[dict] = None, preload: bool = False):
         super().__init__(model_adapter, configuration, preload)
         self.out_channels = 0
 
     @classmethod
     def parameters(cls):
         """BlurSegmentation.parameters function."""
@@ -76,15 +73,14 @@
         elif len(layer_shape) == 4:
             self.out_channels = layer_shape[1]
         else:
             raise Exception(f"Unexpected output layer shape {layer_shape}. Only 4D and 3D output layers are supported")
 
         return layer_name
 
-    @check_input_parameters_type()
     def postprocess(self, outputs: Dict[str, np.ndarray], meta: Dict[str, Any]):
         """BlurSegmentation.postprocess function."""
         predictions = outputs[self.output_blob_name].squeeze()
         soft_prediction = np.transpose(predictions, axes=(1, 2, 0))
 
         hard_prediction = create_hard_prediction_from_soft_prediction(
             soft_prediction=soft_prediction, soft_threshold=self.soft_threshold, blur_strength=self.blur_strength
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/models/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -9,12 +9,7 @@
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
-
-from .configuration import SegmentationConfig
-from .configuration_enums import Models
-
-__all__ = ["SegmentationConfig", "Models"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/configuration.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/configuration_enums.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/configuration_enums.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/supcon/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Base data pipeline configurations folder."""
+"""SupCon data pipeline configurations folder."""
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/common/tasks/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-"""SupCon data pipeline configurations folder."""
+"""Task Initialization of OTX Common Algorithms."""
+
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/data/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/data/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_static.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/base/deployments/base_segmentation_static.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/base/models/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/utils/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Configs Initialization of OTX Segmentation."""
+"""Collection of utils for task implementation in Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/configuration.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/instance_segmentation/configuration.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,9 @@
-description: Configuration for an semantic segmentation task
-header: Configuration for an semantic segmentation task
-id: ""
+description: Configuration for an instance segmentation task
+header: Configuration for an instance segmentation task
 learning_parameters:
   batch_size:
     affects_outcome_of: TRAINING
     default_value: 5
     description:
       The number of training samples seen in each iteration of training.
       Increasing this value improves training time and may make the training more
@@ -39,41 +38,20 @@
     min_value: 1.0e-07
     type: FLOAT
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    value: 0.001
+    value: 0.01
     visible_in_ui: true
     warning: null
     auto_hpo_state: NOT_POSSIBLE
-  learning_rate_fixed_iters:
-    affects_outcome_of: TRAINING
-    auto_hpo_state: not_possible
-    auto_hpo_value: null
-    default_value: 100
-    description: ""
-    editable: true
-    header: Number of iterations for fixed learning rate
-    max_value: 5000
-    min_value: 0
-    type: INTEGER
-    ui_rules:
-      action: DISABLE_EDITING
-      operator: AND
-      rules: []
-      type: UI_RULES
-    value: 100
-    visible_in_ui: true
-    warning: null
   learning_rate_warmup_iters:
     affects_outcome_of: TRAINING
-    auto_hpo_state: not_possible
-    auto_hpo_value: null
     default_value: 100
     description: ""
     editable: true
     header: Number of iterations for learning rate warmup
     max_value: 10000
     min_value: 0
     type: INTEGER
@@ -83,16 +61,14 @@
       rules: []
       type: UI_RULES
     value: 100
     visible_in_ui: true
     warning: null
   num_checkpoints:
     affects_outcome_of: NONE
-    auto_hpo_state: not_possible
-    auto_hpo_value: null
     default_value: 5
     description: ""
     editable: true
     header: Number of checkpoints that is done during the single training round
     max_value: 100
     min_value: 1
     type: INTEGER
@@ -102,16 +78,14 @@
       rules: []
       type: UI_RULES
     value: 5
     visible_in_ui: true
     warning: null
   num_iters:
     affects_outcome_of: TRAINING
-    auto_hpo_state: not_possible
-    auto_hpo_value: null
     default_value: 1
     description:
       Increasing this value causes the results to be more robust but training
       time will be longer.
     editable: true
     header: Number of training iterations
     max_value: 100000
@@ -123,16 +97,14 @@
       rules: []
       type: UI_RULES
     value: 1
     visible_in_ui: true
     warning: null
   num_workers:
     affects_outcome_of: NONE
-    auto_hpo_state: not_possible
-    auto_hpo_value: null
     default_value: 0
     description:
       Increasing this value might improve training speed however it might
       cause out of memory errors. If the number of workers is set to zero, data loading
       will happen in the main training thread.
     editable: true
     header: Number of cpu threads to use during batch generation
@@ -174,27 +146,27 @@
       operator: AND
       rules: []
       type: UI_RULES
     value: 3
     visible_in_ui: false
   early_stop_patience:
     affects_outcome_of: TRAINING
-    default_value: 8
+    default_value: 10
     description: Training will stop if the model does not improve within the number of epochs of patience.
     editable: true
     header: Patience for early stopping
     max_value: 50
     min_value: 0
     type: INTEGER
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    value: 8
+    value: 10
     visible_in_ui: true
     warning: This is applied exclusively when early stopping is enabled.
   early_stop_iteration_patience:
     affects_outcome_of: TRAINING
     default_value: 0
     description:
       Training will stop if the model does not improve within the number of iterations of patience.
@@ -208,30 +180,28 @@
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: 0
     visible_in_ui: true
     warning: This is applied exclusively when early stopping is enabled.
-  enable_supcon:
+  use_adaptive_interval:
     affects_outcome_of: TRAINING
-    default_value: false
-    description:
-      Enable an auxiliar supervised contrastive loss, which might increase robustness
-      and accuracy for small datasets.
+    default_value: true
+    description: Depending on the size of iteration per epoch, adaptively update the validation interval and related values.
     editable: true
-    header: Enable Supervised Contrastive helper loss
+    header: Use adaptive validation interval
     type: BOOLEAN
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     visible_in_ui: true
-    warning: null
+    warning: This will automatically control the patience and interval when early stopping is enabled.
   type: PARAMETER_GROUP
   visible_in_ui: true
 postprocessing:
   confidence_threshold:
     affects_outcome_of: INFERENCE
     default_value: 0.35
     description:
@@ -243,15 +213,16 @@
     min_value: 0
     type: FLOAT
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
-    value: 0.35
+    # value: 0.35
+    value: 0.01
     visible_in_ui: true
     warning: null
   description: Postprocessing
   header: Postprocessing
   result_based_confidence_threshold:
     affects_outcome_of: INFERENCE
     default_value: true
@@ -277,16 +248,15 @@
     default_value: Incremental
     description: Training scheme option that determines how to train the model
     editable: True
     enum_name: TrainType
     header: Train type
     options:
       Incremental: "Incremental"
-      Semisupervised: "Semisupervised"
-      Selfsupervised: "Selfsupervised"
+      SEMISUPEVISED: "Semisupervised"
     type: SELECTABLE
     ui_rules:
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: Incremental
@@ -347,14 +317,31 @@
       action: DISABLE_EDITING
       operator: AND
       rules: []
       type: UI_RULES
     value: 300
     visible_in_ui: True
     warning: null
+  stat_requests_number:
+    affects_outcome_of: NONE
+    default_value: 0
+    description: Number of requests during statistics collection
+    editable: true
+    header: Number of requests
+    max_value: 9223372036854775807
+    min_value: 0
+    type: INTEGER
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: 0
+    visible_in_ui: false
+    warning: null
   type: PARAMETER_GROUP
   visible_in_ui: true
 nncf_optimization:
   description: Optimization by NNCF
   header: Optimization by NNCF
   enable_quantization:
     affects_outcome_of: INFERENCE
@@ -416,7 +403,116 @@
       rules: []
       type: UI_RULES
     value: 1.0
     visible_in_ui: True
     warning: null
   type: PARAMETER_GROUP
   visible_in_ui: True
+
+tiling_parameters:
+  header: Tiling
+  description: Crop dataset to tiles
+
+  enable_tiling:
+    header: Enable tiling
+    description: Set to True to allow tiny objects to be better detected.
+    default_value: false
+    editable: true
+    affects_outcome_of: TRAINING
+    type: BOOLEAN
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: true
+    visible_in_ui: true
+    warning: Tiling trades off speed for accuracy as it increases the number of images to be processed.
+
+  enable_tile_classifier:
+    header: Enable tile classifier
+    description: Enabling tile classifier enhances the speed of tiling inference by incorporating a tile classifier into the instance segmentation model. This feature prevents the detector from making predictions on tiles that do not contain any objects, thus optimizing its speed performance.
+    default_value: false
+    editable: true
+    affects_outcome_of: TRAINING
+    type: BOOLEAN
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: true
+    visible_in_ui: true
+    warning: The tile classifier prioritizes inference speed over training speed, it requires more training in order to achieve its optimized performance.
+
+  enable_adaptive_params:
+    header: Enable adaptive tiling parameters
+    description: Config tile size and tile overlap adaptively based on annotated dataset statistic
+    default_value: True
+    editable: true
+    affects_outcome_of: TRAINING
+    type: BOOLEAN
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: true
+    visible_in_ui: true
+    warning: null
+
+  tile_size:
+    header: Tile Image Size
+    description: Tile Image Size
+    affects_outcome_of: TRAINING
+    default_value: 400
+    min_value: 100
+    max_value: 1024
+    type: INTEGER
+    editable: true
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: 400
+    visible_in_ui: true
+    warning: null
+
+  tile_overlap:
+    header: Tile Overlap
+    description: Overlap between each two neighboring tiles.
+    affects_outcome_of: TRAINING
+    default_value: 0.2
+    min_value: 0.0
+    max_value: 1.0
+    type: FLOAT
+    editable: true
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: 0.2
+    visible_in_ui: true
+    warning: null
+
+  tile_max_number:
+    header: Max object per image
+    description: Max object per image
+    affects_outcome_of: TRAINING
+    default_value: 1500
+    min_value: 1
+    max_value: 10000
+    type: INTEGER
+    editable: true
+    ui_rules:
+      action: DISABLE_EDITING
+      operator: AND
+      rules: []
+      type: UI_RULES
+    value: 1500
+    visible_in_ui: true
+    warning: null
+
+  type: PARAMETER_GROUP
+  visible_in_ui: true
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-18 model for Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-18-mod2 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/compression_config.json`

 * *Files 5% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9973958333333334%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}"}*

```diff
@@ -10,15 +10,15 @@
                 "sample_size": [
                     1,
                     3,
                     512,
                     512
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mDice"
         },
         "params_config": {
             "iters": 0,
             "open_layers": []
         }
     },
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/pot_optimization_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/pot_optimization_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/model.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of OCR-Lite-HRnet-18 model for Self-SL Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-s-mod2 model for Self-SL Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -14,44 +14,49 @@
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
     "../../../../../recipes/stages/segmentation/selfsl.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_s.py",
 ]
 
-
 model = dict(
     type="DetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnetsv2_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
-    downsample=4,
+    downsample=8,
     input_transform="resize_concat",
-    in_index=[0, 1, 2, 3],
+    in_index=[0, 1, 2],
     neck=dict(
         type="SelfSLMLP",
-        in_channels=600,
+        in_channels=420,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
-    loss_cfg=dict(type="DetConLoss", temperature=0.1),
 )
 
 load_from = None
 
 resume_from = None
 
 fp16 = None
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,60 +1,60 @@
-"""Semi-SL model configuration of OCR-Lite-HRnet-18 model for Segmentation Task."""
-
-# Copyright (C) 2022 Intel Corporation
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions
-# and limitations under the License.
-
-# pylint: disable=invalid-name
-
-_base_ = [
-    "../../../../../recipes/stages/segmentation/semisl.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
-]
-
-model = dict(
-    type="MeanTeacherSegmentor",
-    orig_type="OTXEncoderDecoder",
-    unsup_weight=0.1,
-    train_cfg=dict(mix_loss=dict(enable=False, weight=0.1)),
-    test_cfg=dict(mode="whole", output_scale=5.0),
-    pretrained=None,
-    decode_head=dict(
-        type="FCNHead",
-        in_channels=[40, 80, 160, 320],
-        in_index=[0, 1, 2, 3],
-        input_transform="multiple_select",
-        channels=40,
-        kernel_size=1,
-        num_convs=1,
-        concat_input=False,
-        dropout_ratio=-1,
-        num_classes=2,
-        norm_cfg=dict(type="BN", requires_grad=True),
-        align_corners=False,
-        enable_aggregator=True,
-        enable_out_norm=False,
-        loss_decode=[
-            dict(
-                type="CrossEntropyLoss",
-                use_sigmoid=False,
-                loss_weight=1.0,
-            ),
-        ],
-    ),
-)
-__norm_cfg = dict(type="BN", requires_grad=True)
-
-load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth"
-
-fp16 = dict(loss_scale=512.0)
+"""Semi-SL model configuration of OCR-Lite-HRnet-18-mod2 model for Segmentation Task."""
+
+# Copyright (C) 2022 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions
+# and limitations under the License.
+
+# pylint: disable=invalid-name
+
+_base_ = [
+    "../../../../../recipes/stages/segmentation/semisl.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
+]
+
+model = dict(
+    type="MeanTeacherSegmentor",
+    orig_type="OTXEncoderDecoder",
+    unsup_weight=0.1,
+    train_cfg=dict(mix_loss=dict(enable=False, weight=0.1)),
+    test_cfg=dict(mode="whole", output_scale=5.0),
+    pretrained=None,
+    decode_head=dict(
+        type="FCNHead",
+        in_channels=[40, 80, 160, 320],
+        in_index=[0, 1, 2, 3],
+        input_transform="multiple_select",
+        channels=40,
+        kernel_size=1,
+        num_convs=1,
+        concat_input=False,
+        dropout_ratio=-1,
+        num_classes=2,
+        norm_cfg=dict(type="BN", requires_grad=True),
+        align_corners=False,
+        enable_aggregator=True,
+        enable_out_norm=False,
+        loss_decode=[
+            dict(
+                type="CrossEntropyLoss",
+                use_sigmoid=False,
+                loss_weight=1.0,
+            ),
+        ],
+    ),
+)
+__norm_cfg = dict(type="BN", requires_grad=True)
+
+load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
+/models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth"
+
+fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/template.yaml` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/template.yaml`

 * *Files 10% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 task_type: SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
 summary: Class-Incremental Semantic Segmentation with middle-sized architecture which based on the Lite-HRNet backbone for the balance between the fast inference and long training. (deprecated in next version)
 application: ~
 
 # Algo backend.
-framework: OTESegmentation v0.14.0
+framework: OTXSegmentation v0.14.0
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.segmentation.tasks.SegmentationTrainTask
-  openvino: otx.algorithms.segmentation.tasks.OpenVINOSegmentationTask
-  nncf: otx.algorithms.segmentation.tasks.SegmentationNNCFTask
+  base: otx.algorithms.segmentation.adapters.mmseg.task.MMSegmentationTask
+  openvino: otx.algorithms.segmentation.adapters.openvino.task.OpenVINOSegmentationTask
+  nncf: otx.algorithms.segmentation.adapters.mmseg.nncf.task.SegmentationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-18-mod2 model for Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-s-mod2 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/compression_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/compression_config.json`

 * *Files 19% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9915364583333334%*

 * *Differences: {"'base'": "{'nncf_config': {'log_dir': '/tmp'}}",*

 * * "'nncf_quantization'": "{'lr_config': {'step': [20], delete: ['by_epoch']}, 'nncf_config': "*

 * *                        "{'compression': {0: {'initializer': {'range': {'num_init_samples': 5}, "*

 * *                        "'batchnorm_adaptation': {'num_bn_adaptation_samples': 5}}}}, "*

 * *                        "'accuracy_aware_training': {'params': {'maximal_total_epochs': 40}}}}"}*

```diff
@@ -10,56 +10,55 @@
                 "sample_size": [
                     1,
                     3,
                     512,
                     512
                 ]
             },
-            "log_dir": ".",
+            "log_dir": "/tmp",
             "target_metric_name": "mDice"
         },
         "params_config": {
             "iters": 0,
             "open_layers": []
         }
     },
     "nncf_quantization": {
         "lr_config": {
             "_delete_": true,
-            "by_epoch": true,
             "fixed": null,
             "fixed_iters": 0,
             "policy": "customstep",
             "step": [
-                90
+                20
             ],
             "warmup": null,
             "warmup_iters": 0
         },
         "nncf_config": {
             "accuracy_aware_training": {
                 "mode": "early_exit",
                 "params": {
                     "maximal_absolute_accuracy_degradation": 1.0,
-                    "maximal_total_epochs": 180
+                    "maximal_total_epochs": 40
                 }
             },
             "compression": [
                 {
                     "algorithm": "quantization",
                     "ignored_scopes": [
                         "{re}.*cross_resolution_weighting.*__mul__.*",
                         "{re}.*spatial_weighting.*__mul__.*"
                     ],
                     "initializer": {
                         "batchnorm_adaptation": {
-                            "num_bn_adaptation_samples": 500
+                            "num_bn_adaptation_samples": 5
                         },
                         "range": {
-                            "num_init_samples": 500
+                            "num_init_samples": 5
                         }
                     },
                     "preset": "mixed"
                 }
             ]
         },
         "optimizer": {
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/pot_optimization_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/pot_optimization_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18/selfsl/model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of OCR-Lite-HRnet-18-mod2 model for Self-SL Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-18 model for Self-SL Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -20,36 +20,43 @@
     "../../../../../recipes/stages/segmentation/selfsl.py",
     "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
 ]
 
 
 model = dict(
     type="DetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnet18_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
     downsample=4,
     input_transform="resize_concat",
     in_index=[0, 1, 2, 3],
     neck=dict(
         type="SelfSLMLP",
         in_channels=600,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
     loss_cfg=dict(type="DetConLoss", temperature=0.1),
 )
 
 load_from = None
 
 resume_from = None
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Semi-SL model configuration of OCR-Lite-HRnet-18-mod2 model for Segmentation Task."""
+"""Semi-SL model configuration of OCR-Lite-HRnet-x-mod3 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -12,49 +12,55 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
+
 _base_ = [
     "../../../../../recipes/stages/segmentation/semisl.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_x.py",
 ]
 
 model = dict(
     type="MeanTeacherSegmentor",
     orig_type="OTXEncoderDecoder",
     unsup_weight=0.1,
     train_cfg=dict(mix_loss=dict(enable=False, weight=0.1)),
     test_cfg=dict(mode="whole", output_scale=5.0),
     pretrained=None,
     decode_head=dict(
         type="FCNHead",
-        in_channels=[40, 80, 160, 320],
-        in_index=[0, 1, 2, 3],
+        in_channels=[18, 60, 80, 160, 320],
+        in_index=[0, 1, 2, 3, 4],
         input_transform="multiple_select",
-        channels=40,
+        channels=60,
         kernel_size=1,
         num_convs=1,
         concat_input=False,
         dropout_ratio=-1,
         num_classes=2,
         norm_cfg=dict(type="BN", requires_grad=True),
         align_corners=False,
         enable_aggregator=True,
+        aggregator_min_channels=60,
+        aggregator_merge_norm=None,
+        aggregator_use_concat=False,
         enable_out_norm=False,
+        enable_loss_equalizer=True,
         loss_decode=[
             dict(
                 type="CrossEntropyLoss",
                 use_sigmoid=False,
                 loss_weight=1.0,
             ),
         ],
     ),
 )
+
 __norm_cfg = dict(type="BN", requires_grad=True)
 
 load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth"
+/models/custom_semantic_segmentation/litehrnetxv3_imagenet1k_rsc.pth"
 
 fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of OCR-Lite-HRnet-18-mod2 model for SupCon Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-s-mod2 model for SupCon Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -14,66 +14,81 @@
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
     "../../../../../recipes/stages/segmentation/supcon.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_s.py",
 ]
 
 model = dict(
     type="SupConDetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnet18_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnetsv2_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
-    downsample=4,
+    downsample=8,
     input_transform="resize_concat",
-    in_index=[0, 1, 2, 3],
+    in_index=[0, 1, 2],
     neck=dict(
         type="SelfSLMLP",
-        in_channels=600,
+        in_channels=420,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
-    loss_cfg=dict(type="DetConLoss", temperature=0.1),
     decode_head=dict(
         type="FCNHead",
-        in_channels=[40, 80, 160, 320],
-        in_index=[0, 1, 2, 3],
+        in_channels=[60, 120, 240],
+        in_index=[0, 1, 2],
         input_transform="multiple_select",
-        channels=40,
+        channels=60,
         kernel_size=1,
         num_convs=1,
         concat_input=False,
         dropout_ratio=-1,
         num_classes=2,
         norm_cfg=dict(type="BN", requires_grad=True),
         align_corners=False,
         enable_aggregator=True,
+        aggregator_merge_norm=None,
+        aggregator_use_concat=False,
         enable_out_norm=False,
+        enable_loss_equalizer=True,
         loss_decode=[
             dict(
                 type="CrossEntropyLoss",
                 use_sigmoid=False,
                 loss_weight=1.0,
             ),
         ],
+        init_cfg=dict(
+            type="Normal",
+            mean=0,
+            std=0.01,
+            override=dict(name="conv_seg"),
+        ),
     ),
 )
 
 load_from = None
 
 resume_from = None
 
-fp16 = dict(_delete_=True, loss_scale=512.0)
+fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/template.yaml` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/template.yaml`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,37 @@
 # Description.
-model_template_id: Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR
-name: Lite-HRNet-18-mod2
+model_template_id: Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR
+name: Lite-HRNet-s-mod2
 task_type: SEGMENTATION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Semantic Segmentation with middle-sized architecture which based on the Lite-HRNet backbone for the balance between the fast inference and long training.
+summary: Class-Incremental Semantic Segmentation with lightweight architecture which based on the Lite-HRNet backbone for the fast inference and training on the limited amount of data.
 application: ~
 
 # Algo backend.
-framework: OTESegmentation v0.14.0
+framework: OTXSegmentation v0.14.0
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.segmentation.tasks.SegmentationTrainTask
-  openvino: otx.algorithms.segmentation.tasks.OpenVINOSegmentationTask
-  nncf: otx.algorithms.segmentation.tasks.SegmentationNNCFTask
+  base: otx.algorithms.segmentation.adapters.mmseg.task.MMSegmentationTask
+  openvino: otx.algorithms.segmentation.adapters.openvino.task.OpenVINOSegmentationTask
+  nncf: otx.algorithms.segmentation.adapters.mmseg.nncf.task.SegmentationNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
         default_value: 8
+        auto_hpo_state: POSSIBLE
       learning_rate:
         default_value: 0.001
         auto_hpo_state: POSSIBLE
       learning_rate_fixed_iters:
         default_value: 0
       learning_rate_warmup_iters:
         default_value: 100
@@ -52,9 +53,9 @@
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 3.63
-size: 4.8
+gigaflops: 1.82
+size: 3.5
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-s-mod2 model for Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-x-mod3 model for Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/pot_optimization_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/pot_optimization_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/selfsl/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of OCR-Lite-HRnet-s-mod2 model for Self-SL Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-18-mod2 model for Self-SL Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -14,41 +14,49 @@
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
     "../../../../../recipes/stages/segmentation/selfsl.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_s.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
 ]
 
+
 model = dict(
     type="DetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnetsv2_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnet18_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
-    downsample=8,
+    downsample=4,
     input_transform="resize_concat",
-    in_index=[0, 1, 2],
+    in_index=[0, 1, 2, 3],
     neck=dict(
         type="SelfSLMLP",
-        in_channels=420,
+        in_channels=600,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
     loss_cfg=dict(type="DetConLoss", temperature=0.1),
 )
 
 load_from = None
 
 resume_from = None
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-s-mod2 model for Semi-SL Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-x-mod3 model for Self-SL Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/semisl/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/supcon/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_18_mod2/supcon/model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Model configuration of OCR-Lite-HRnet-s-mod2 model for SupCon Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-18-mod2 model for SupCon Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -14,75 +14,72 @@
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
 _base_ = [
     "../../../../../recipes/stages/segmentation/supcon.py",
-    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_s.py",
+    "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_18.py",
 ]
 
 model = dict(
     type="SupConDetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnetsv2_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnet18_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
-    downsample=8,
+    downsample=4,
     input_transform="resize_concat",
-    in_index=[0, 1, 2],
+    in_index=[0, 1, 2, 3],
     neck=dict(
         type="SelfSLMLP",
-        in_channels=420,
+        in_channels=600,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
-    loss_cfg=dict(type="DetConLoss", temperature=0.1),
     decode_head=dict(
         type="FCNHead",
-        in_channels=[60, 120, 240],
-        in_index=[0, 1, 2],
+        in_channels=[40, 80, 160, 320],
+        in_index=[0, 1, 2, 3],
         input_transform="multiple_select",
-        channels=60,
+        channels=40,
         kernel_size=1,
         num_convs=1,
         concat_input=False,
         dropout_ratio=-1,
         num_classes=2,
         norm_cfg=dict(type="BN", requires_grad=True),
         align_corners=False,
         enable_aggregator=True,
-        aggregator_merge_norm=None,
-        aggregator_use_concat=False,
         enable_out_norm=False,
-        enable_loss_equalizer=True,
         loss_decode=[
             dict(
                 type="CrossEntropyLoss",
                 use_sigmoid=False,
                 loss_weight=1.0,
             ),
         ],
-        init_cfg=dict(
-            type="Normal",
-            mean=0,
-            std=0.01,
-            override=dict(name="conv_seg"),
-        ),
     ),
 )
 
 load_from = None
 
 resume_from = None
 
-fp16 = dict(_delete_=True, loss_scale=512.0)
+fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_s_mod2/template.yaml` & `otx-1.2.0rc1/otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/template.yaml`

 * *Files 22% similar despite different names*

```diff
@@ -1,46 +1,47 @@
 # Description.
-model_template_id: Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR
-name: Lite-HRNet-s-mod2
-task_type: SEGMENTATION
+model_template_id: Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_EfficientNetB2B
+name: MaskRCNN-EfficientNetB2B
+task_type: ROTATED_DETECTION
 task_family: VISION
 instantiation: "CLASS"
-summary: Class-Incremental Semantic Segmentation with lightweight architecture which based on the Lite-HRNet backbone for the fast inference and training on the limited amount of data.
+summary: Class-Incremental Rotated object detection for MaskRCNN-EfficientNetB2B
 application: ~
 
 # Algo backend.
-framework: OTESegmentation v0.14.0
+framework: OTXDetection v2.9.1
 
 # Task implementations.
 entrypoints:
-  base: otx.algorithms.segmentation.tasks.SegmentationTrainTask
-  openvino: otx.algorithms.segmentation.tasks.OpenVINOSegmentationTask
-  nncf: otx.algorithms.segmentation.tasks.SegmentationNNCFTask
+  base: otx.algorithms.detection.adapters.mmdet.task.MMDetectionTask
+  openvino: otx.algorithms.detection.adapters.openvino.task.OpenVINODetectionTask
+  nncf: otx.algorithms.detection.adapters.mmdet.nncf.task.DetectionNNCFTask
 
 # Capabilities.
 capabilities:
   - compute_representations
 
 # Hyperparameters.
 hyper_parameters:
   base_path: ../configuration.yaml
   parameter_overrides:
     learning_parameters:
       batch_size:
-        default_value: 8
+        default_value: 4
         auto_hpo_state: POSSIBLE
       learning_rate:
-        default_value: 0.001
+        default_value: 0.015
         auto_hpo_state: POSSIBLE
-      learning_rate_fixed_iters:
-        default_value: 0
       learning_rate_warmup_iters:
         default_value: 100
       num_iters:
-        default_value: 300
+        default_value: 100
+    pot_parameters:
+      stat_requests_number:
+        default_value: 1
     nncf_optimization:
       enable_quantization:
         default_value: true
       enable_pruning:
         default_value: false
       pruning_supported:
         default_value: false
@@ -53,9 +54,9 @@
 # Training resources.
 max_nodes: 1
 training_targets:
   - GPU
   - CPU
 
 # Stats.
-gigaflops: 1.82
-size: 3.5
+gigaflops: 68.48
+size: 13.27
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-x-mod3 model for Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-x-mod3 model for SupCon Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/compression_config.json` & `otx-1.2.0rc1/tests/assets/datumaro_multilabel/annotations/train.json`

 * *Files 26% similar despite different names*

#### Pretty-printed

 * *Differences: {'replace': "OrderedDict([('info', OrderedDict()), ('categories', OrderedDict([('label', "*

 * *            "OrderedDict([('label_groups', [OrderedDict([('name', 'tom'), ('group_type', "*

 * *            "'exclusive'), ('labels', ['tom'])]), OrderedDict([('name', 'mary'), ('group_type', "*

 * *            "'exclusive'), ('labels', ['mary'])])]), ('labels', [OrderedDict([('name', 'tom'), "*

 * *            "('parent', ''), ('attributes', [])]), OrderedDict([('name', 'mary'), ('parent', ''), "*

 * *            "('attributes', [])])]) []*

```diff
@@ -1,71 +1,72 @@
 {
-    "base": {
-        "checkpoint_config": {
-            "interval": -1
-        },
-        "find_unused_parameters": true,
-        "nncf_config": {
-            "compression": [],
-            "input_info": {
-                "sample_size": [
-                    1,
-                    3,
-                    512,
-                    512
-                ]
-            },
-            "log_dir": ".",
-            "target_metric_name": "mDice"
-        },
-        "params_config": {
-            "iters": 0,
-            "open_layers": []
+    "categories": {
+        "label": {
+            "attributes": [],
+            "label_groups": [
+                {
+                    "group_type": "exclusive",
+                    "labels": [
+                        "tom"
+                    ],
+                    "name": "tom"
+                },
+                {
+                    "group_type": "exclusive",
+                    "labels": [
+                        "mary"
+                    ],
+                    "name": "mary"
+                }
+            ],
+            "labels": [
+                {
+                    "attributes": [],
+                    "name": "tom",
+                    "parent": ""
+                },
+                {
+                    "attributes": [],
+                    "name": "mary",
+                    "parent": ""
+                }
+            ]
         }
     },
-    "nncf_quantization": {
-        "lr_config": {
-            "_delete_": true,
-            "fixed": null,
-            "fixed_iters": 0,
-            "policy": "customstep",
-            "step": [
-                20
+    "info": {},
+    "items": [
+        {
+            "annotations": [
+                {
+                    "group": 0,
+                    "id": 0,
+                    "label_id": 0,
+                    "type": "label"
+                },
+                {
+                    "group": 0,
+                    "id": 1,
+                    "label_id": 1,
+                    "type": "label"
+                }
             ],
-            "warmup": null,
-            "warmup_iters": 0
+            "id": "a",
+            "image": {
+                "path": "a.jpg"
+            }
         },
-        "nncf_config": {
-            "accuracy_aware_training": {
-                "mode": "early_exit",
-                "params": {
-                    "maximal_absolute_accuracy_degradation": 1.0,
-                    "maximal_total_epochs": 40
-                }
-            },
-            "compression": [
+        {
+            "annotations": [
                 {
-                    "algorithm": "quantization",
-                    "ignored_scopes": [
-                        "{re}.*cross_resolution_weighting.*__mul__.*",
-                        "{re}.*spatial_weighting.*__mul__.*"
-                    ],
-                    "initializer": {
-                        "batchnorm_adaptation": {
-                            "num_bn_adaptation_samples": 500
-                        },
-                        "range": {
-                            "num_init_samples": 500
-                        }
-                    },
-                    "preset": "mixed"
+                    "group": 0,
+                    "id": 0,
+                    "label_id": 0,
+                    "type": "label"
                 }
-            ]
-        },
-        "optimizer": {
-            "lr": 0.0001
+            ],
+            "id": "b",
+            "image": {
+                "path": "b.jpg"
+            }
         }
-    },
-    "order_of_parts": [
-        "nncf_quantization"
     ]
 }
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/pot_optimization_config.json` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/pot_optimization_config.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Initialization of OCR-Lite-HRnet-x-mod3 model for Self-SL Segmentation Task."""
+"""Initialization of OCR-Lite-HRnet-x-mod3 model for Semi-SL egmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/data_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/selfsl/model.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,38 +19,44 @@
 _base_ = [
     "../../../../../recipes/stages/segmentation/selfsl.py",
     "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_x.py",
 ]
 
 model = dict(
     type="DetConB",
-    pretrained="https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-        /models/custom_semantic_segmentation/litehrnetxv3_imagenet1k_rsc.pth",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnetxv3_imagenet1k_rsc.pth"
+    ),
     num_classes=256,
     num_samples=16,
     downsample=2,
     input_transform="resize_concat",
     in_index=[0, 1, 2, 3, 4],
     neck=dict(
         type="SelfSLMLP",
         in_channels=638,
         hid_channels=256,
         out_channels=128,
         norm_cfg=dict(type="BN1d", requires_grad=True),
         with_avg_pool=False,
     ),
     head=dict(
-        type="SelfSLMLP",
-        in_channels=128,
-        hid_channels=256,
-        out_channels=128,
-        norm_cfg=dict(type="BN1d", requires_grad=True),
-        with_avg_pool=False,
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
     ),
-    loss_cfg=dict(type="DetConLoss", temperature=0.1),
 )
 
 load_from = None
 
 resume_from = None
 
 fp16 = None
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/data_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,15 +1,18 @@
-"""Initialization of OCR-Lite-HRnet-x-mod3 model for Semi-SL egmentation Task."""
+"""Data Pipeline of HR-Net model for Segmentation Task."""
 
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
+
+# pylint: disable=invalid-name
+_base_ = ["../../base/data/supcon/data_pipeline.py"]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/classification/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,22 @@
-"""Data Pipeline of HR-Net model for Segmentation Task."""
+"""OTX Algorithms - Classification."""
 
-# Copyright (C) 2023 Intel Corporation
+# Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-# pylint: disable=invalid-name
-_base_ = ["../../base/data/semisl/data_pipeline.py"]
+MMCLS_AVAILABLE = True
+
+try:
+    import mmcls  # noqa: F401
+except ImportError:
+    MMCLS_AVAILABLE = False
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/model.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/model.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Semi-SL model configuration of OCR-Lite-HRnet-x-mod3 model for Segmentation Task."""
+"""Model configuration of OCR-Lite-HRnet-x-mod3 model for SupCon Segmentation Task."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -12,27 +12,51 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=invalid-name
 
-
 _base_ = [
-    "../../../../../recipes/stages/segmentation/semisl.py",
+    "../../../../../recipes/stages/segmentation/supcon.py",
     "../../../../common/adapters/mmcv/configs/backbones/lite_hrnet_x.py",
 ]
 
 model = dict(
-    type="MeanTeacherSegmentor",
-    orig_type="OTXEncoderDecoder",
-    unsup_weight=0.1,
-    train_cfg=dict(mix_loss=dict(enable=False, weight=0.1)),
-    test_cfg=dict(mode="whole", output_scale=5.0),
-    pretrained=None,
+    type="SupConDetConB",
+    pretrained=(
+        "https://storage.openvinotoolkit.org/repositories/"
+        "openvino_training_extensions/models/custom_semantic_segmentation/"
+        "litehrnetxv3_imagenet1k_rsc.pth"
+    ),
+    num_classes=256,
+    num_samples=16,
+    downsample=2,
+    input_transform="resize_concat",
+    in_index=[0, 1, 2, 3, 4],
+    neck=dict(
+        type="SelfSLMLP",
+        in_channels=638,
+        hid_channels=256,
+        out_channels=128,
+        norm_cfg=dict(type="BN1d", requires_grad=True),
+        with_avg_pool=False,
+    ),
+    head=dict(
+        type="DetConHead",
+        predictor=dict(
+            type="SelfSLMLP",
+            in_channels=128,
+            hid_channels=256,
+            out_channels=128,
+            norm_cfg=dict(type="BN1d", requires_grad=True),
+            with_avg_pool=False,
+        ),
+        loss_cfg=dict(type="DetConLoss", temperature=0.1),
+    ),
     decode_head=dict(
         type="FCNHead",
         in_channels=[18, 60, 80, 160, 320],
         in_index=[0, 1, 2, 3, 4],
         input_transform="multiple_select",
         channels=60,
         kernel_size=1,
@@ -54,13 +78,12 @@
                 use_sigmoid=False,
                 loss_weight=1.0,
             ),
         ],
     ),
 )
 
-__norm_cfg = dict(type="BN", requires_grad=True)
+load_from = None
 
-load_from = "https://storage.openvinotoolkit.org/repositories/openvino_training_extensions\
-/models/custom_semantic_segmentation/litehrnetxv3_imagenet1k_rsc.pth"
+resume_from = None
 
 fp16 = dict(loss_scale=512.0)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/__init__.py` & `otx-1.2.0rc1/otx/hpo/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,15 +1,25 @@
-"""Initialization of OCR-Lite-HRnet-x-mod3 model for SupCon Segmentation Task."""
+"""HPO package."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
+
+from .hpo_base import TrialStatus
+from .hpo_runner import run_hpo_loop
+from .hyperband import HyperBand
+
+__all__ = [
+    "run_hpo_loop",
+    "TrialStatus",
+    "HyperBand",
+]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/data_pipeline.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Data Pipeline of HR-Net model for Segmentation Task."""
+"""NNCF utils for mmseg."""
 
 # Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -10,9 +10,12 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-# pylint: disable=invalid-name
-_base_ = ["../../base/data/supcon/data_pipeline.py"]
+from .builder import build_nncf_segmentor
+
+__all__ = [
+    "build_nncf_segmentor",
+]
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/tasks/inference.py` & `otx-1.2.0rc1/tests/integration/api/segmentation/test_api_segmentation.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,287 +1,309 @@
-"""Inference Task of OTX Segmentation."""
-
+"""API Tests for segmentation training"""
 # Copyright (C) 2022 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
 #
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions
-# and limitations under the License.
 
-import os
-from typing import Dict, Optional
+import os.path as osp
+import random
+import time
+import warnings
+from concurrent.futures import ThreadPoolExecutor
+from typing import Optional
 
 import numpy as np
-from mmcv.utils import ConfigDict
+from bson import ObjectId
 
-from otx.algorithms.common.adapters.mmcv.utils import (
-    patch_data_pipeline,
-    patch_default_config,
-    patch_runner,
-    remove_from_configs_by_type,
+from otx.algorithms.common.tasks.training_base import BaseTask
+from otx.algorithms.segmentation.tasks import (
+    SegmentationInferenceTask,
+    SegmentationTrainTask,
 )
-from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
-from otx.algorithms.common.configs import TrainType
-from otx.algorithms.common.tasks import BaseTask
-from otx.algorithms.common.utils.callback import InferenceProgressCallback
-from otx.algorithms.common.utils.logger import get_logger
-from otx.algorithms.segmentation.adapters.mmseg.utils.builder import build_segmentor
-from otx.algorithms.segmentation.adapters.mmseg.utils.config_utils import (
-    patch_datasets,
-    patch_evaluation,
+from otx.api.configuration.helper import create
+from otx.api.entities.annotation import (
+    Annotation,
+    AnnotationSceneEntity,
+    AnnotationSceneKind,
 )
-from otx.algorithms.segmentation.adapters.openvino.model_wrappers.blur import (
-    get_activation_map,
-)
-from otx.algorithms.segmentation.configs.base import SegmentationConfig
+from otx.api.entities.color import Color
+from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.image import Image
 from otx.api.entities.inference_parameters import InferenceParameters
-from otx.api.entities.inference_parameters import (
-    default_progress_callback as default_infer_progress_callback,
-)
-from otx.api.entities.model import (
-    ModelEntity,
-    ModelFormat,
-    ModelOptimizationType,
-    ModelPrecision,
-)
-from otx.api.entities.result_media import ResultMediaEntity
+from otx.api.entities.label import Domain, LabelEntity
+from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
+from otx.api.entities.metrics import Performance
+from otx.api.entities.model import ModelEntity
+from otx.api.entities.model_template import parse_model_template
 from otx.api.entities.resultset import ResultSetEntity
+from otx.api.entities.shapes.ellipse import Ellipse
+from otx.api.entities.shapes.polygon import Point, Polygon
+from otx.api.entities.shapes.rectangle import Rectangle
+from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
-from otx.api.entities.tensor import TensorEntity
-from otx.api.serialization.label_mapper import label_schema_to_bytes
-from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
-from otx.api.usecases.tasks.interfaces.export_interface import ExportType, IExportTask
-from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
-from otx.api.usecases.tasks.interfaces.unload_interface import IUnload
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
-from otx.api.utils.segmentation_utils import (
-    create_annotation_from_segmentation_map,
-    create_hard_prediction_from_soft_prediction,
-)
-
-logger = get_logger()
-
+from otx.api.entities.train_parameters import TrainParameters
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType
+from tests.test_helpers import generate_random_annotated_image
+from tests.test_suite.e2e_test_system import e2e_pytest_api
+
+DEFAULT_SEG_TEMPLATE_DIR = osp.join("otx/algorithms/segmentation/configs", "ocr_lite_hrnet_18_mod2")
+
+
+def task_eval(task: BaseTask, model: ModelEntity, dataset: DatasetEntity) -> Performance:
+    start_time = time.time()
+    result_dataset = task.infer(dataset.with_empty_annotations())
+    end_time = time.time()
+    print(f"{len(dataset)} analysed in {end_time - start_time} seconds")
+    result_set = ResultSetEntity(model=model, ground_truth_dataset=dataset, prediction_dataset=result_dataset)
+    task.evaluate(result_set)
+    assert result_set.performance is not None
+    return result_set.performance
+
+
+class TestMPASegAPI:
+    """
+    Collection of tests for OTX API and OTX Model Templates
+    """
+
+    @e2e_pytest_api
+    def test_reading_segmentation_cls_incr_model_template(self):
+        segmentation_template = [
+            "ocr_lite_hrnet_18_mod2",
+            "ocr_lite_hrnet_s_mod2",
+            "ocr_lite_hrnet_x_mod3",
+        ]
+        for model_template in segmentation_template:
+            parse_model_template(osp.join("otx/algorithms/segmentation/configs", model_template, "template.yaml"))
+
+    @staticmethod
+    def generate_label_schema(label_names):
+        label_domain = Domain.SEGMENTATION
+        rgb = [int(i) for i in np.random.randint(0, 256, 3)]
+        colors = [Color(*rgb) for _ in range(len(label_names))]
+        not_empty_labels = [
+            LabelEntity(name=name, color=colors[i], domain=label_domain, id=i) for i, name in enumerate(label_names)
+        ]
+        empty_label = LabelEntity(
+            name="Empty label",
+            color=Color(42, 43, 46),
+            is_empty=True,
+            domain=label_domain,
+            id=len(not_empty_labels),
+        )
 
-RECIPE_TRAIN_TYPE = {
-    TrainType.Semisupervised: "semisl.py",
-    TrainType.Incremental: "incremental.py",
-    TrainType.Selfsupervised: "selfsl.py",
-}
-
-
-# pylint: disable=too-many-locals, too-many-instance-attributes, attribute-defined-outside-init
-class SegmentationInferenceTask(BaseTask, IInferenceTask, IExportTask, IEvaluationTask, IUnload):
-    """Inference Task Implementation of OTX Segmentation."""
-
-    @check_input_parameters_type()
-    def __init__(self, task_environment: TaskEnvironment, **kwargs):
-        # self._should_stop = False
-        self.freeze = True
-        self.metric = "mDice"
-        self._label_dictionary = {}  # type: Dict
-
-        super().__init__(SegmentationConfig, task_environment, **kwargs)
-        self._label_dictionary = dict(enumerate(sorted(self._labels), 1))
-
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
-    def infer(
-        self, dataset: DatasetEntity, inference_parameters: Optional[InferenceParameters] = None
-    ) -> DatasetEntity:
-        """Main infer function of OTX Segmentation."""
-        logger.info("infer()")
-
-        if inference_parameters is not None:
-            update_progress_callback = inference_parameters.update_progress
-            is_evaluation = inference_parameters.is_evaluation
-        else:
-            update_progress_callback = default_infer_progress_callback
-            is_evaluation = False
-
-        self._time_monitor = InferenceProgressCallback(len(dataset), update_progress_callback)
-
-        stage_module = "SegInferrer"
-        self._data_cfg = self._init_test_data_cfg(dataset)
-
-        dump_features = True
-
-        results = self._run_task(
-            stage_module,
-            mode="train",
-            dataset=dataset,
-            dump_features=dump_features,
+        label_schema = LabelSchemaEntity()
+        exclusive_group = LabelGroup(name="labels", labels=not_empty_labels, group_type=LabelGroupType.EXCLUSIVE)
+        empty_group = LabelGroup(name="empty", labels=[empty_label], group_type=LabelGroupType.EMPTY_LABEL)
+        label_schema.add_group(exclusive_group)
+        label_schema.add_group(empty_group)
+        return label_schema
+
+    def init_environment(self, params, model_template, number_of_images=10):
+        labels_names = ("rectangle", "ellipse", "triangle")
+        labels_schema = self.generate_label_schema(labels_names)
+        labels_list = labels_schema.get_labels(False)
+        environment = TaskEnvironment(
+            model=None,
+            hyper_parameters=params,
+            label_schema=labels_schema,
+            model_template=model_template,
         )
-        logger.debug(f"result of run_task {stage_module} module = {results}")
-        predictions = results["outputs"]
-        prediction_results = zip(predictions["eval_predictions"], predictions["feature_vectors"])
-        self._add_predictions_to_dataset(prediction_results, dataset, dump_soft_prediction=not is_evaluation)
-        return dataset
-
-    @check_input_parameters_type()
-    def evaluate(self, output_resultset: ResultSetEntity, evaluation_metric: Optional[str] = None):
-        """Evaluate function of OTX Segmentation Task."""
-        logger.info("called evaluate()")
-
-        if evaluation_metric is not None:
-            logger.warning(
-                f"Requested to use {evaluation_metric} metric, " "but parameter is ignored. Use mDice instead."
+
+        warnings.filterwarnings("ignore", message=".* coordinates .* are out of bounds.*")
+        items = []
+        for i in range(0, number_of_images):
+            image_numpy, shapes = generate_random_annotated_image(
+                image_width=640,
+                image_height=480,
+                labels=labels_list,
+                max_shapes=20,
+                min_size=50,
+                max_size=100,
+                random_seed=None,
             )
-        logger.info("Computing mDice")
-        metrics = MetricsHelper.compute_dice_averaged_over_pixels(output_resultset)
-        logger.info(f"mDice after evaluation: {metrics.overall_dice.value}")
-        output_resultset.performance = metrics.get_performance()
-
-    def unload(self):
-        """Unload the task."""
-        self.cleanup()
-
-    @check_input_parameters_type()
-    def export(
-        self,
-        export_type: ExportType,
-        output_model: ModelEntity,
-        precision: ModelPrecision = ModelPrecision.FP32,
-        dump_features: bool = False,
-    ):
-        """Export function of OTX Segmentation Task."""
-        logger.info("Exporting the model")
-        if export_type != ExportType.OPENVINO:
-            raise RuntimeError(f"not supported export type {export_type}")
-        output_model.model_format = ModelFormat.OPENVINO
-        output_model.optimization_type = ModelOptimizationType.MO
-
-        stage_module = "SegExporter"
-        results = self._run_task(
-            stage_module,
-            mode="train",
-            export=True,
-            dump_features=dump_features,
-            enable_fp16=(precision == ModelPrecision.FP16),
+            # Convert all shapes to polygons
+            out_shapes = []
+            for shape in shapes:
+                shape_labels = shape.get_labels(include_empty=True)
+
+                in_shape = shape.shape
+                if isinstance(in_shape, Rectangle):
+                    points = [
+                        Point(in_shape.x1, in_shape.y1),
+                        Point(in_shape.x2, in_shape.y1),
+                        Point(in_shape.x2, in_shape.y2),
+                        Point(in_shape.x1, in_shape.y2),
+                    ]
+                elif isinstance(in_shape, Ellipse):
+                    points = [Point(x, y) for x, y in in_shape.get_evenly_distributed_ellipse_coordinates()]
+                elif isinstance(in_shape, Polygon):
+                    points = in_shape.points
+
+                out_shapes.append(Annotation(Polygon(points=points), labels=shape_labels))
+
+            image = Image(data=image_numpy)
+            annotation = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=out_shapes)
+            items.append(DatasetItemEntity(media=image, annotation_scene=annotation))
+        warnings.resetwarnings()
+
+        rng = random.Random()
+        rng.shuffle(items)
+        for i, _ in enumerate(items):
+            subset_region = i / number_of_images
+            if subset_region >= 0.8:
+                subset = Subset.TESTING
+            elif subset_region >= 0.6:
+                subset = Subset.VALIDATION
+            else:
+                subset = Subset.TRAINING
+
+            items[i].subset = subset
+
+        dataset = DatasetEntity(items)
+
+        return environment, dataset
+
+    @staticmethod
+    def setup_configurable_parameters(template_dir, num_iters=10):
+        model_template = parse_model_template(osp.join(template_dir, "template.yaml"))
+
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        hyper_parameters.learning_parameters.learning_rate_fixed_iters = 0
+        hyper_parameters.learning_parameters.learning_rate_warmup_iters = 1
+        hyper_parameters.learning_parameters.num_iters = num_iters
+        hyper_parameters.learning_parameters.num_checkpoints = 1
+
+        return hyper_parameters, model_template
+
+    @e2e_pytest_api
+    def test_cancel_training_segmentation(self):
+        """
+        Tests starting and cancelling training.
+
+        Flow of the test:
+        - Creates a randomly annotated project with a small dataset.
+        - Start training and give cancel training signal after 10 seconds. Assert that training
+            stops within 35 seconds after that
+        - Start training and give cancel signal immediately. Assert that training stops within 25 seconds.
+
+        This test should be finished in under one minute on a workstation.
+        """
+        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=200)
+        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 64)
+
+        segmentation_task = SegmentationTrainTask(task_environment=segmentation_environment)
+
+        executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="train_thread")
+
+        output_model = ModelEntity(
+            dataset,
+            segmentation_environment.get_model_configuration(),
         )
-        outputs = results.get("outputs")
-        logger.debug(f"results of run_task = {outputs}")
-        if outputs is None:
-            raise RuntimeError(results.get("msg"))
-
-        bin_file = outputs.get("bin")
-        xml_file = outputs.get("xml")
-        if xml_file is None or bin_file is None:
-            raise RuntimeError("invalid status of exporting. bin and xml should not be None")
-        with open(bin_file, "rb") as f:
-            output_model.set_data("openvino.bin", f.read())
-        with open(xml_file, "rb") as f:
-            output_model.set_data("openvino.xml", f.read())
-        output_model.precision = self._precision
-        output_model.optimization_methods = self._optimization_methods
-        output_model.set_data("label_schema.json", label_schema_to_bytes(self._task_environment.label_schema))
-        logger.info("Exporting completed")
-
-    def _init_recipe(self):
-        logger.info("called _init_recipe()")
-        # TODO: Need to remove the hard coding for supcon only.
-        if (
-            self._train_type in RECIPE_TRAIN_TYPE
-            and self._train_type == TrainType.Incremental
-            and self._hyperparams.learning_parameters.enable_supcon
-            and not self._model_dir.endswith("supcon")
-        ):
-            self._model_dir = os.path.join(self._model_dir, "supcon")
-
-        self._recipe_cfg = self._init_model_cfg()
-        options_for_patch_datasets = {"type": "MPASegDataset"}
-        patch_default_config(self._recipe_cfg)
-        patch_runner(self._recipe_cfg)
-        patch_data_pipeline(self._recipe_cfg, self.data_pipeline_path)
-        patch_datasets(
-            self._recipe_cfg,
-            self._task_type.domain,
-            **options_for_patch_datasets,
-        )  # for OTX compatibility
-        patch_evaluation(self._recipe_cfg)  # for OTX compatibility
-        if self._recipe_cfg.get("evaluation", None):
-            self.metric = self._recipe_cfg.evaluation.metric
-
-        if self._recipe_cfg.get("override_configs", None):
-            self.override_configs.update(self._recipe_cfg.override_configs)
-
-        if not self.freeze:
-            remove_from_configs_by_type(self._recipe_cfg.custom_hooks, "FreezeLayers")
-
-    def _update_stage_module(self, stage_module: str):
-        module_prefix = {TrainType.Semisupervised: "SemiSL", TrainType.Incremental: "Incr"}
-        if self._train_type == TrainType.Semisupervised and stage_module == "SegExporter":
-            stage_module = "SemiSLSegExporter"
-        elif self._train_type in module_prefix and stage_module in ["SegTrainer", "SegInferrer"]:
-            stage_module = module_prefix[self._train_type] + stage_module
-
-        return stage_module
-
-    def _init_model_cfg(self):
-        model_cfg = MPAConfig.fromfile(os.path.join(self._model_dir, "model.py"))
-        return model_cfg
-
-    def _init_test_data_cfg(self, dataset: DatasetEntity):
-        data_cfg = ConfigDict(
-            data=ConfigDict(
-                train=ConfigDict(
-                    otx_dataset=None,
-                    labels=self._labels,
-                ),
-                test=ConfigDict(
-                    otx_dataset=dataset,
-                    labels=self._labels,
-                ),
-            )
+
+        training_progress_curve = []
+
+        def progress_callback(progress: float, score: Optional[float] = None):
+            training_progress_curve.append(progress)
+
+        train_parameters = TrainParameters()
+        train_parameters.update_progress = progress_callback
+
+        # Test stopping after some time
+        start_time = time.time()
+        train_future = executor.submit(segmentation_task.train, dataset, output_model, train_parameters)
+        # give train_thread some time to initialize the model
+        while not segmentation_task._is_training:
+            time.sleep(10)
+        segmentation_task.cancel_training()
+
+        # stopping process has to happen in less than 35 seconds
+        train_future.result()
+        assert training_progress_curve[-1] == 100
+        assert time.time() - start_time < 100, "Expected to stop within 100 seconds."
+
+        # Test stopping immediately
+        start_time = time.time()
+        train_future = executor.submit(segmentation_task.train, dataset, output_model)
+        segmentation_task.cancel_training()
+
+        train_future.result()
+        assert time.time() - start_time < 25  # stopping process has to happen in less than 25 seconds
+
+    @e2e_pytest_api
+    def test_training_progress_tracking(self):
+        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=5)
+        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 12)
+
+        task = SegmentationTrainTask(task_environment=segmentation_environment)
+        print("Task initialized, model training starts.")
+
+        training_progress_curve = []
+
+        def progress_callback(progress: float, score: Optional[float] = None):
+            training_progress_curve.append(progress)
+
+        train_parameters = TrainParameters()
+        train_parameters.update_progress = progress_callback
+        output_model = ModelEntity(
+            dataset,
+            segmentation_environment.get_model_configuration(),
         )
-        return data_cfg
+        task.train(dataset, output_model, train_parameters)
 
-    def _add_predictions_to_dataset(self, prediction_results, dataset, dump_soft_prediction):
-        """Loop over dataset again to assign predictions. Convert from MMSegmentation format to OTX format."""
+        assert len(training_progress_curve) > 0
+        assert np.all(training_progress_curve[1:] >= training_progress_curve[:-1])
 
-        for dataset_item, (prediction, feature_vector) in zip(dataset, prediction_results):
-            soft_prediction = np.transpose(prediction[0], axes=(1, 2, 0))
-            hard_prediction = create_hard_prediction_from_soft_prediction(
-                soft_prediction=soft_prediction,
-                soft_threshold=self._hyperparams.postprocessing.soft_threshold,
-                blur_strength=self._hyperparams.postprocessing.blur_strength,
-            )
-            annotations = create_annotation_from_segmentation_map(
-                hard_prediction=hard_prediction,
-                soft_prediction=soft_prediction,
-                label_map=self._label_dictionary,
-            )
-            dataset_item.append_annotations(annotations=annotations)
+    @e2e_pytest_api
+    def test_inference_progress_tracking(self):
+        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=10)
+        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 12)
+
+        task = SegmentationInferenceTask(task_environment=segmentation_environment)
+        print("Task initialized, model inference starts.")
+
+        inference_progress_curve = []
+
+        def progress_callback(progress: int):
+            assert isinstance(progress, int)
+            inference_progress_curve.append(progress)
+
+        inference_parameters = InferenceParameters()
+        inference_parameters.update_progress = progress_callback
+        task.infer(dataset.with_empty_annotations(), inference_parameters)
+
+        assert len(inference_progress_curve) > 0
+        assert np.all(inference_progress_curve[1:] >= inference_progress_curve[:-1])
+
+    @e2e_pytest_api
+    def test_inference_task(self):
+        # Prepare pretrained weights
+        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=2)
+        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 30)
+        val_dataset = dataset.get_subset(Subset.VALIDATION)
+
+        train_task = SegmentationTrainTask(task_environment=segmentation_environment)
+
+        training_progress_curve = []
+
+        def progress_callback(progress: float, score: Optional[float] = None):
+            training_progress_curve.append(progress)
+
+        train_parameters = TrainParameters()
+        train_parameters.update_progress = progress_callback
+        trained_model = ModelEntity(
+            dataset,
+            segmentation_environment.get_model_configuration(),
+        )
+        train_task.train(dataset, trained_model, train_parameters)
+        performance_after_train = task_eval(train_task, trained_model, val_dataset)
+
+        # Create InferenceTask
+        segmentation_environment.model = trained_model
+        inference_task = SegmentationInferenceTask(task_environment=segmentation_environment)
+
+        performance_after_load = task_eval(inference_task, trained_model, val_dataset)
+
+        assert performance_after_train == performance_after_load
 
-            if feature_vector is not None:
-                active_score = TensorEntity(name="representation_vector", numpy=feature_vector.reshape(-1))
-                dataset_item.append_metadata_item(active_score, model=self._task_environment.model)
-
-            if dump_soft_prediction:
-                for label_index, label in self._label_dictionary.items():
-                    if label_index == 0:
-                        continue
-                    current_label_soft_prediction = soft_prediction[:, :, label_index]
-                    class_act_map = get_activation_map(current_label_soft_prediction)
-                    result_media = ResultMediaEntity(
-                        name=label.name,
-                        type="soft_prediction",
-                        label=label,
-                        annotation_scene=dataset_item.annotation_scene,
-                        roi=dataset_item.roi,
-                        numpy=class_act_map,
-                    )
-                    dataset_item.append_metadata_item(result_media, model=self._task_environment.model)
-
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
-        options["model_builder"] = build_segmentor
+        # Export
+        exported_model = ModelEntity(dataset, segmentation_environment.get_model_configuration(), _id=ObjectId())
+        inference_task.export(ExportType.OPENVINO, exported_model)
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/tasks/nncf.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/mmseg/nncf/task.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,61 +14,67 @@
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 from functools import partial
 from typing import List, Optional
 
 import otx.algorithms.segmentation.adapters.mmseg.nncf.patches  # noqa: F401  # pylint: disable=unused-import
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
+from otx.algorithms.common.tasks.nncf_task import NNCFBaseTask
 from otx.algorithms.common.utils.logger import get_logger
 from otx.algorithms.segmentation.adapters.mmseg.nncf import build_nncf_segmentor
+from otx.algorithms.segmentation.adapters.mmseg.task import MMSegmentationTask
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.metrics import (
     CurveMetric,
     InfoMetric,
     LineChartInfo,
     MetricsGroup,
     Performance,
     ScoreMetric,
     VisualizationInfo,
     VisualizationType,
 )
-from otx.api.entities.model import ModelEntity
+from otx.api.entities.model import (
+    ModelEntity,
+)
 from otx.api.entities.optimization_parameters import OptimizationParameters
-
-from .inference import SegmentationInferenceTask
+from otx.api.entities.task_environment import TaskEnvironment
 
 logger = get_logger()
 
 
-class SegmentationNNCFTask(NNCFBaseTask, SegmentationInferenceTask):  # pylint: disable=too-many-ancestors
+class SegmentationNNCFTask(NNCFBaseTask, MMSegmentationTask):  # pylint: disable=too-many-ancestors
     """SegmentationNNCFTask."""
 
-    def _initialize_post_hook(self, options=None):
-        super()._initialize_post_hook(options)
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        super().__init__()  # type: ignore [call-arg]
+        super(NNCFBaseTask, self).__init__(task_environment, output_path)
+        self._set_attributes_by_hyperparams()
+
+    def _init_task(self, export: bool = False):  # noqa
+        super(NNCFBaseTask, self)._init_task(export)
+        self._prepare_optimize(export)
+
+    def _prepare_optimize(self, export=False):
+        super()._prepare_optimize()
 
-        export = options.get("export", False)
-        options["model_builder"] = partial(
+        self.model_builder = partial(
             self.model_builder,
             nncf_model_builder=build_nncf_segmentor,
             return_compression_ctrl=False,
             is_export=export,
         )
 
     def _optimize(
         self,
         dataset: DatasetEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
-        results = self._run_task(
-            "SegTrainer",
-            mode="train",
-            dataset=dataset,
-            parameters=optimization_parameters,
-        )
+        results = self._train_model(dataset)
+
         return results
 
     def _optimize_post_hook(
         self,
         dataset: DatasetEntity,
         output_model: ModelEntity,
     ):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/tasks/openvino.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/adapters/openvino/task.py`

 * *Files 6% similar despite different names*

```diff
@@ -68,27 +68,22 @@
 from otx.api.usecases.tasks.interfaces.deployment_interface import IDeploymentTask
 from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
 from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
 from otx.api.usecases.tasks.interfaces.optimization_interface import (
     IOptimizationTask,
     OptimizationType,
 )
-from otx.api.utils.argument_checks import (
-    DatasetParamTypeCheck,
-    check_input_parameters_type,
-)
 
 logger = get_logger()
 
 
 # pylint: disable=too-many-locals, too-many-statements, unused-argument
 class OpenVINOSegmentationInferencer(BaseInferencer):
     """Inferencer implementation for Segmentation using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(
         self,
         hparams: SegmentationConfig,
         label_schema: LabelSchemaEntity,
         model_file: Union[str, bytes],
         weight_file: Union[str, bytes, None] = None,
         device: str = "CPU",
@@ -115,54 +110,47 @@
             )
         }
         self.model = Model.create_model(
             hparams.postprocessing.class_name.value, model_adapter, self.configuration, preload=True
         )
         self.converter = SegmentationToAnnotationConverter(label_schema)
 
-    @check_input_parameters_type()
     def pre_process(self, image: np.ndarray) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
         """Pre-process function of OpenVINO Segmentation Inferencer."""
         return self.model.preprocess(image)
 
-    @check_input_parameters_type()
     def post_process(
         self, prediction: Dict[str, np.ndarray], metadata: Dict[str, Any]
     ) -> Tuple[AnnotationSceneEntity, Any, Any]:
         """Post-process function of OpenVINO Segmentation Inferencer."""
         hard_prediction = self.model.postprocess(prediction, metadata)
         soft_prediction = metadata["soft_prediction"]
         feature_vector = metadata["feature_vector"]
         predicted_scene = self.converter.convert_to_annotation(hard_prediction, metadata)
 
         return predicted_scene, feature_vector, soft_prediction
 
-    @check_input_parameters_type()
     def predict(self, image: np.ndarray) -> Tuple[AnnotationSceneEntity, Any, Any]:
         """Perform a prediction for a given input image."""
         image, metadata = self.pre_process(image)
         predictions = self.forward(image)
-        predictions = self.post_process(predictions, metadata)
-        return predictions
+        return self.post_process(predictions, metadata)
 
-    @check_input_parameters_type()
     def forward(self, image: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
         """Forward function of OpenVINO Segmentation Inferencer."""
         return self.model.infer_sync(image)
 
 
 class OTXOpenVinoDataLoader(DataLoader):
     """Data loader for OTXDetection using OpenVINO backend."""
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def __init__(self, dataset: DatasetEntity, inferencer: BaseInferencer):
         self.dataset = dataset
         self.inferencer = inferencer
 
-    @check_input_parameters_type()
     def __getitem__(self, index: int):
         """Return dataset item from index."""
         image = self.dataset[index].numpy
         annotation = self.dataset[index].annotation_scene
         inputs, metadata = self.inferencer.pre_process(image)
 
         return (index, annotation), inputs, metadata
@@ -171,15 +159,14 @@
         """Length of OTXOpenVinoDataLoader."""
         return len(self.dataset)
 
 
 class OpenVINOSegmentationTask(IDeploymentTask, IInferenceTask, IEvaluationTask, IOptimizationTask):
     """Task implementation for Segmentation using OpenVINO backend."""
 
-    @check_input_parameters_type()
     def __init__(self, task_environment: TaskEnvironment):
         self.task_environment = task_environment
         self.model = self.task_environment.model
         self.model_name = self.task_environment.model_template.model_template_id
         self.inferencer = self.load_inferencer()
 
         labels = task_environment.get_labels(include_empty=False)
@@ -199,15 +186,14 @@
         return OpenVINOSegmentationInferencer(
             self.hparams,
             self.task_environment.label_schema,
             self.model.get_data("openvino.xml"),
             self.model.get_data("openvino.bin"),
         )
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def infer(
         self, dataset: DatasetEntity, inference_parameters: Optional[InferenceParameters] = None
     ) -> DatasetEntity:
         """Infer function of OpenVINOSegmentationTask."""
         if inference_parameters is not None:
             update_progress_callback = inference_parameters.update_progress
             dump_soft_prediction = not inference_parameters.is_evaluation
@@ -240,24 +226,22 @@
                     )
                     dataset_item.append_metadata_item(result_media, model=self.model)
 
             update_progress_callback(int(i / dataset_size * 100), None)
 
         return dataset
 
-    @check_input_parameters_type()
     def evaluate(self, output_resultset: ResultSetEntity, evaluation_metric: Optional[str] = None):
         """Evaluate function of OpenVINOSegmentationTask."""
         logger.info("Computing mDice")
         metrics = MetricsHelper.compute_dice_averaged_over_pixels(output_resultset)
         logger.info(f"mDice after evaluation: {metrics.overall_dice.value}")
 
         output_resultset.performance = metrics.get_performance()
 
-    @check_input_parameters_type()
     def deploy(self, output_model: ModelEntity) -> None:
         """Deploy function of OpenVINOSegmentationTask."""
         logger.info("Deploying the model")
         if self.model is None:
             raise RuntimeError("deploy failed, model is None")
 
         work_dir = os.path.dirname(demo.__file__)
@@ -284,15 +268,14 @@
             arch.write(os.path.join(work_dir, "requirements.txt"), os.path.join("python", "requirements.txt"))
             arch.write(os.path.join(work_dir, "LICENSE"), os.path.join("python", "LICENSE"))
             arch.write(os.path.join(work_dir, "README.md"), os.path.join("python", "README.md"))
             arch.write(os.path.join(work_dir, "demo.py"), os.path.join("python", "demo.py"))
         output_model.exportable_code = zip_buffer.getvalue()
         logger.info("Deploying completed")
 
-    @check_input_parameters_type({"dataset": DatasetParamTypeCheck})
     def optimize(
         self,
         optimization_type: OptimizationType,
         dataset: DatasetEntity,
         output_model: ModelEntity,
         optimization_parameters: Optional[OptimizationParameters] = None,
     ):
```

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/tools/__init__.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/tools/segmentation_sample.py` & `otx-1.2.0rc1/otx/algorithms/segmentation/tools/segmentation_sample.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/algorithms/segmentation/utils/__init__.py` & `otx-1.2.0rc1/otx/core/data/manager/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-"""Collection of utils for task implementation in Segmentation Task."""
+"""OTX Core Data Utils."""
 
 # Copyright (C) 2022 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
+#
```

### Comparing `otx-1.1.2rc1/otx/api/configuration/__init__.py` & `otx-1.2.0rc1/otx/api/configuration/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/configurable_parameters.py` & `otx-1.2.0rc1/otx/api/configuration/configurable_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/default_model_parameters.py` & `otx-1.2.0rc1/otx/api/configuration/default_model_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/__init__.py` & `otx-1.2.0rc1/otx/api/configuration/elements/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/configurable_enum.py` & `otx-1.2.0rc1/otx/api/configuration/elements/configurable_enum.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/metadata_keys.py` & `otx-1.2.0rc1/otx/api/configuration/elements/metadata_keys.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/parameter_group.py` & `otx-1.2.0rc1/otx/api/configuration/elements/parameter_group.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/primitive_parameters.py` & `otx-1.2.0rc1/otx/api/configuration/elements/primitive_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/elements/utils.py` & `otx-1.2.0rc1/otx/api/configuration/elements/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/enums/auto_hpo_state.py` & `otx-1.2.0rc1/otx/api/configuration/enums/auto_hpo_state.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/enums/config_element_type.py` & `otx-1.2.0rc1/otx/api/configuration/enums/config_element_type.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/enums/model_lifecycle.py` & `otx-1.2.0rc1/otx/api/configuration/enums/model_lifecycle.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/enums/utils.py` & `otx-1.2.0rc1/otx/api/configuration/enums/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/__init__.py` & `otx-1.2.0rc1/otx/api/configuration/helper/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -7,18 +7,20 @@
 # SPDX-License-Identifier: Apache-2.0
 #
 
 
 from .convert import convert
 from .create import create
 from .substitute import substitute_values, substitute_values_for_lifecycle
-from .utils import config_to_bytes
+from .utils import config_to_bytes, flatten_config_values, merge_a_into_b
 from .validate import validate
 
 __all__ = [
     "create",
     "config_to_bytes",
     "validate",
     "convert",
     "substitute_values",
     "substitute_values_for_lifecycle",
+    "flatten_config_values",
+    "merge_a_into_b",
 ]
```

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/config_element_mapping.py` & `otx-1.2.0rc1/otx/api/configuration/helper/config_element_mapping.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/convert.py` & `otx-1.2.0rc1/otx/api/configuration/helper/convert.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/create.py` & `otx-1.2.0rc1/otx/api/configuration/helper/create.py`

 * *Files 1% similar despite different names*

```diff
@@ -33,15 +33,15 @@
 from .config_element_mapping import (
     GroupElementMapping,
     PrimitiveElementMapping,
     RuleElementMapping,
 )
 from .utils import deserialize_enum_value, input_to_config_dict
 
-ParameterGroupTypeVar = TypeVar("ParameterGroupTypeVar", bound=ParameterGroup)
+ParameterGroupTypeVar = TypeVar("ParameterGroupTypeVar", ParameterGroup, ConfigurableParameters)
 ExposureTypeVar = TypeVar("ExposureTypeVar", UIRules, Rule)
 
 METADATA_ENUMS = {
     metadata_keys.AFFECTS_OUTCOME_OF: ModelLifecycle,
     metadata_keys.AUTO_HPO_STATE: AutoHPOState,
 }
```

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/substitute.py` & `otx-1.2.0rc1/otx/api/configuration/helper/substitute.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/utils.py` & `otx-1.2.0rc1/otx/api/configuration/helper/utils.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """This module contains utility functions used within the configuration helper module."""
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 
+import copy
 import json
 import os
 from enum import Enum
 from typing import Any, List, Tuple, Type, Union
 
 import yaml
 from omegaconf import DictConfig, OmegaConf
@@ -183,7 +184,66 @@
         config: configurable parameters
 
     Retruns:
         JSON in bytes
     """
     config_dict = convert(config, dict, enum_to_str=True)
     return json.dumps(config_dict, indent=4).encode()
+
+
+def flatten_config_values(config: dict):
+    """Extracts the "value" field from any nested config.
+
+    Flattening the structure of the config dictionary. The original config dictionary is modified in-place.
+
+    Args:
+        config (dict): config dictionary
+    """
+    for key, value in config.items():
+        if isinstance(value, dict):
+            if "value" in value:
+                config[key] = value["value"]
+            else:
+                flatten_config_values(value)
+
+
+def flatten_detection_config_groups(config: dict):
+    """Converts all Detection Config Group objects in a config dictionary to their dictionary representation.
+
+    Args:
+        config (dict): config dictionary
+    """
+    for key, value in config.items():
+        if hasattr(value, "__dict__"):
+            config[key] = value.__dict__
+        elif isinstance(value, dict):
+            flatten_detection_config_groups(value)
+
+
+def merge_a_into_b(dict_a, dict_b):
+    """Inspired by mmcv.Config.merge_a_into_b by merging dict ``a`` into dict ``b`` (non-inplace).
+
+    Values in ``a`` will overwrite ``b``. ``b`` is copied first to avoid
+    in-place modifications.
+
+    Args:
+        dict_a (dict): The source dict to be merged into ``b``.
+        dict_b (dict): The origin dict to be fetch keys from ``a``.
+
+    Returns:
+        dict: The modified dict of ``b`` using ``a``.
+
+    Examples:
+        # Normally merge a into b.
+        >>> merge_a_into_b({'a': {'d': 5, 'e': 6}, 'b': 4}, {'a': {'c': 1, 'd': 4}, 'b': 3})
+        {'a': {'c': 1, 'd': 5, 'e': 6}, 'b': 4}
+    """
+    dict_b = copy.deepcopy(dict_b)
+    for key, value in dict_a.items():
+        if isinstance(value, dict):
+            if key in dict_b:
+                dict_b[key] = merge_a_into_b(value, dict_b[key])
+            else:
+                dict_b[key] = value
+        else:
+            dict_b[key] = value
+    return dict_b
```

### Comparing `otx-1.1.2rc1/otx/api/configuration/helper/validate.py` & `otx-1.2.0rc1/otx/api/configuration/helper/validate.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/ui_rules/rules.py` & `otx-1.2.0rc1/otx/api/configuration/ui_rules/rules.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/ui_rules/types.py` & `otx-1.2.0rc1/otx/api/configuration/ui_rules/types.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/configuration/ui_rules/utils.py` & `otx-1.2.0rc1/otx/api/configuration/ui_rules/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/annotation.py` & `otx-1.2.0rc1/otx/api/entities/annotation.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/color.py` & `otx-1.2.0rc1/otx/api/entities/color.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/coordinate.py` & `otx-1.2.0rc1/otx/api/entities/coordinate.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/dataset_item.py` & `otx-1.2.0rc1/otx/api/entities/dataset_item.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,34 +3,39 @@
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 # pylint: disable=cyclic-import
 
 import abc
 import copy
+from inspect import signature
 import itertools
 import logging
 from threading import Lock
-from typing import List, Optional, Sequence, Set, Tuple, Union
-
+from typing import List, Optional, Sequence, Set, Tuple, TypeVar, Union
+from bson import ObjectId
 import numpy as np
 
 from otx.api.entities.annotation import Annotation, AnnotationSceneEntity
+from otx.api.entities.id import ID
 from otx.api.entities.label import LabelEntity
 from otx.api.entities.media import IMedia2DEntity
 from otx.api.entities.metadata import IMetadata, MetadataItemEntity
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.rectangle import Rectangle
 from otx.api.entities.subset import Subset
 from otx.api.utils.shape_factory import ShapeFactory
 
 logger = logging.getLogger(__name__)
 
 
+T = TypeVar("T", bound="DatasetItemEntity")
+
+
 class DatasetItemEntity(metaclass=abc.ABCMeta):
     """DatasetItemEntity represents an item in the DatasetEntity.
 
     It holds a media item, annotation and an ROI. The ROI determines the region of interest for the dataset item, and
     is described by a shape entity.
 
     The fundamental properties of a dataset item are:
@@ -482,7 +487,56 @@
             name (str): the name of the metadata
             model (Optional[ModelEntity]): the model which was used to generate the metadata.
 
         Returns:
             Sequence[MetadataItemEntity]: a list of metadata items with `name` and generated by `model`.
         """
         return [meta for meta in self.get_metadata() if meta.data.name == name and meta.model == model]
+
+    def wrap(self: T, **kwargs) -> T:
+        """Creates a new DatasetItemEntity, overriding only the given arguments to the existing ones for this instance."""
+        params = {
+            name: getattr(self, name)
+            for name in signature(self.__class__.__init__).parameters.keys()
+            if hasattr(self, name)
+        }
+        params.update({"metadata": self.get_metadata()})
+        params.update(**kwargs)
+
+        return self.__class__(**params)
+
+
+# TODO: This should be removed in the near future and DatasetItemEntity should have id_ field.
+class DatasetItemEntityWithID(DatasetItemEntity):
+    def __init__(
+        self,
+        media: IMedia2DEntity,
+        annotation_scene: AnnotationSceneEntity,
+        roi: Optional[Annotation] = None,
+        metadata: Optional[List[MetadataItemEntity]] = None,
+        subset: Subset = Subset.NONE,
+        ignored_labels: Optional[Union[List[LabelEntity], Tuple[LabelEntity, ...], Set[LabelEntity]]] = None,
+        id_: Optional[Union[str, ObjectId]] = None,
+    ):
+        super().__init__(media, annotation_scene, roi, metadata, subset, ignored_labels)
+        self._id_ = ID(id_) if id_ is not None else ID(ObjectId())
+
+    @property
+    def id_(self) -> ID:
+        """
+        Returns the id of this entity
+
+        :return: ID of this entity
+        """
+        return self._id_
+
+    @id_.setter
+    def id_(self, value: ID) -> None:
+        """
+        Set the unique id for this entity
+
+        :param value: a unique ID to set
+        """
+        self._id_ = value
+
+    def __eq__(self, other):
+        return super().__eq__(other) and self.id_ == other.id_
```

### Comparing `otx-1.1.2rc1/otx/api/entities/datasets.py` & `otx-1.2.0rc1/otx/api/entities/datasets.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 # pylint: disable=redefined-builtin, invalid-name
 
 import collections.abc
 import copy
 import itertools
 import logging
 from enum import Enum
-from typing import Iterator, List, Optional, Union, cast, overload
+from typing import Generic, Iterator, List, Optional, TypeVar, Union, cast, overload
 
 from bson.objectid import ObjectId
 
 from otx.api.entities.annotation import AnnotationSceneEntity, AnnotationSceneKind
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.id import ID
 from otx.api.entities.label import LabelEntity
@@ -78,15 +78,18 @@
         if self.index >= len(self.dataset):
             raise StopIteration
         item = self.dataset[self.index]
         self.index += 1
         return item
 
 
-class DatasetEntity:
+TDatasetItemEntity = TypeVar("TDatasetItemEntity", bound="DatasetItemEntity")
+
+
+class DatasetEntity(Generic[TDatasetItemEntity]):
     """A dataset consists of a list of DatasetItemEntities and a purpose.
 
     ## With dataset items
 
         This way assumes the dataset item entities are constructed before the dataset entity is made.
 
         >>> from otx.api.entities.image import Image
@@ -142,15 +145,15 @@
         items (Optional[List[DatasetItemEntity]]): A list of dataset items to create dataset with. Defaults to None.
         purpose (DatasetPurpose): Purpose for dataset. Refer to :class:`DatasetPurpose` for more info.
             Defaults to DatasetPurpose.INFERENCE.
     """
 
     def __init__(
         self,
-        items: Optional[List[DatasetItemEntity]] = None,
+        items: Optional[List[TDatasetItemEntity]] = None,
         purpose: DatasetPurpose = DatasetPurpose.INFERENCE,
     ):
         self._items = [] if items is None else items
         self._purpose = purpose
 
     @property
     def purpose(self) -> DatasetPurpose:
@@ -266,15 +269,15 @@
             key (Union[slice, int]): key to fetch. Should be `slice` or `int`
 
         Returns:
             Union["DatasetItemEntity", List["DatasetItemEntity"]]: List of DatasetItemEntity or single DatasetItemEntity
         """
         return self._fetch(key)
 
-    def __iter__(self) -> Iterator[DatasetItemEntity]:
+    def __iter__(self) -> Iterator[TDatasetItemEntity]:
         """Return an iterator for the DatasetEntity.
 
         This iterator is able to iterate over the DatasetEntity lazily.
 
         Returns:
             DatasetIterator: DatasetIterator instance
         """
@@ -304,25 +307,26 @@
         Args:
             annotation_kind (AnnotationSceneKind): Sets the empty annotation to this kind.
                 Defaults to AnnotationSceneKind.PREDICTION
 
         Returns:
             DatasetEntity: a new dataset containing the same items, with empty annotation objects.
         """
-        new_dataset = DatasetEntity(purpose=self.purpose)
+        new_dataset = DatasetEntity[TDatasetItemEntity](purpose=self.purpose)
+
         for dataset_item in self:
             if isinstance(dataset_item, DatasetItemEntity):
                 empty_annotation = AnnotationSceneEntity(annotations=[], kind=annotation_kind)
 
                 # reset ROI
                 roi = copy.copy(dataset_item.roi)
                 roi.id_ = ID(ObjectId())
                 roi.set_labels([])
 
-                new_dataset_item = DatasetItemEntity(
+                new_dataset_item = dataset_item.wrap(
                     media=dataset_item.media,
                     annotation_scene=empty_annotation,
                     roi=roi,
                     subset=dataset_item.subset,
                     metadata=dataset_item.get_metadata(),
                 )
                 new_dataset.append(new_dataset_item)
@@ -347,29 +351,29 @@
         """
         dataset = DatasetEntity(
             items=[item for item in self._items if item.subset == subset],
             purpose=self.purpose,
         )
         return dataset
 
-    def remove(self, item: DatasetItemEntity) -> None:
+    def remove(self, item: TDatasetItemEntity) -> None:
         """Remove an item from the items.
 
         This function calls remove_at_indices function.
 
         Args:
             item (DatasetItemEntity): the item to be deleted.
 
         Raises:
             ValueError: if the input item is not in the dataset
         """
         index = self._items.index(item)
         self.remove_at_indices([index])
 
-    def append(self, item: DatasetItemEntity) -> None:
+    def append(self, item: TDatasetItemEntity) -> None:
         """Append a DatasetItemEntity to the dataset.
 
         Example:
             Appending a dataset item to a dataset
 
             >>> from otx.api.entities.image import Image
             >>> from otx.api.entities.annotation import NullAnnotationSceneEntity
```

### Comparing `otx-1.1.2rc1/otx/api/entities/graph.py` & `otx-1.2.0rc1/otx/api/entities/graph.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/id.py` & `otx-1.2.0rc1/otx/api/entities/id.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/image.py` & `otx-1.2.0rc1/otx/api/entities/image.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/inference_parameters.py` & `otx-1.2.0rc1/otx/api/entities/inference_parameters.py`

 * *Files 5% similar despite different names*

```diff
@@ -32,11 +32,10 @@
         explain_predicted_classes: If set to True, provide explanations only for predicted classes.
             Otherwise, explain all classes.
     """
 
     is_evaluation: bool = False
     update_progress: Callable[[int, Optional[float]], Any] = default_progress_callback
 
-    # TODO(negvet): use separate ExplainParameters dataclass for this
     explainer: str = ""
     process_saliency_maps: bool = False
     explain_predicted_classes: bool = True
```

### Comparing `otx-1.1.2rc1/otx/api/entities/interfaces/graph_interface.py` & `otx-1.2.0rc1/otx/api/entities/interfaces/graph_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/label.py` & `otx-1.2.0rc1/otx/api/entities/label.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/label_schema.py` & `otx-1.2.0rc1/otx/api/entities/label_schema.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/media.py` & `otx-1.2.0rc1/otx/api/entities/media.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/metadata.py` & `otx-1.2.0rc1/otx/api/entities/metadata.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/metrics.py` & `otx-1.2.0rc1/otx/api/entities/metrics.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/model.py` & `otx-1.2.0rc1/otx/api/entities/model.py`

 * *Files 1% similar despite different names*

```diff
@@ -117,14 +117,15 @@
         target_device_type: Optional[str] = None,
         optimization_type: ModelOptimizationType = ModelOptimizationType.NONE,
         optimization_methods: List[OptimizationMethod] = None,
         optimization_objectives: Dict[str, str] = None,
         performance_improvement: Dict[str, float] = None,
         model_size_reduction: float = 0.0,
         _id: Optional[ID] = None,
+        has_xai: bool = False,
     ):
         _id = ID() if _id is None else _id
         performance = NullPerformance() if performance is None else performance
         creation_date = now() if creation_date is None else creation_date
 
         optimization_methods = [] if optimization_methods is None else optimization_methods
         optimization_objectives = {} if optimization_objectives is None else optimization_objectives
@@ -156,14 +157,15 @@
         self.__target_device = target_device
         self.__target_device_type = target_device_type
         self.__optimization_type = optimization_type
         self.__optimization_methods = optimization_methods
         self.__optimization_objectives = optimization_objectives
         self.__performance_improvement = performance_improvement
         self.__model_size_reduction = model_size_reduction
+        self.__has_xai = has_xai
 
     @property
     def id_(self) -> ID:
         """Gets or sets the id of a Model."""
         return self.__id_
 
     @id_.setter
@@ -382,14 +384,23 @@
 
     @exportable_code.setter
     def exportable_code(self, data: Union[bytes, IDataSource]):
         """Set the exportable code using the exportable code adapter."""
         self.__exportable_code_adapter = ExportableCodeAdapter(data_source=data)
 
     @property
+    def has_xai(self) -> float:
+        """Get or set the xAI flag."""
+        return self.__has_xai
+
+    @has_xai.setter
+    def has_xai(self, value: bool):
+        self.__has_xai = value
+
+    @property
     def exportable_code_adapter(self) -> Optional[ExportableCodeAdapter]:
         """Returns the exportable code adapter."""
         return self.__exportable_code_adapter
 
     def get_data(self, key: str) -> bytes:
         """Fetches byte data for a certain model.
```

### Comparing `otx-1.1.2rc1/otx/api/entities/model_template.py` & `otx-1.2.0rc1/otx/api/entities/model_template.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/optimization_parameters.py` & `otx-1.2.0rc1/otx/api/entities/optimization_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/result_media.py` & `otx-1.2.0rc1/otx/api/entities/result_media.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/resultset.py` & `otx-1.2.0rc1/otx/api/entities/resultset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/scored_label.py` & `otx-1.2.0rc1/otx/api/entities/scored_label.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/shapes/ellipse.py` & `otx-1.2.0rc1/otx/api/entities/shapes/ellipse.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/shapes/polygon.py` & `otx-1.2.0rc1/otx/api/entities/shapes/polygon.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/shapes/rectangle.py` & `otx-1.2.0rc1/otx/api/entities/shapes/rectangle.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/shapes/shape.py` & `otx-1.2.0rc1/otx/api/entities/shapes/shape.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/subset.py` & `otx-1.2.0rc1/otx/api/entities/subset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/task_environment.py` & `otx-1.2.0rc1/otx/api/entities/task_environment.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/tensor.py` & `otx-1.2.0rc1/otx/api/entities/tensor.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/train_parameters.py` & `otx-1.2.0rc1/otx/api/entities/train_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/entities/url.py` & `otx-1.2.0rc1/otx/api/entities/url.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/serialization/datetime_mapper.py` & `otx-1.2.0rc1/otx/api/serialization/datetime_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/serialization/id_mapper.py` & `otx-1.2.0rc1/otx/api/serialization/id_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/serialization/label_mapper.py` & `otx-1.2.0rc1/otx/api/serialization/label_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/adapters/model_adapter.py` & `otx-1.2.0rc1/otx/api/usecases/adapters/model_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/__init__.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/accuracy.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/accuracy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/anomaly_metrics.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/anomaly_metrics.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/basic_operations.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/basic_operations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/dice.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/dice.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/f_measure.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/f_measure.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/evaluation/metrics_helper.py` & `otx-1.2.0rc1/otx/api/usecases/evaluation/metrics_helper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/LICENSE` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/LICENSE`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/README.md` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/README.md`

 * *Files 14% similar despite different names*

```diff
@@ -81,52 +81,79 @@
 
    ```bash
    set PYTHONPATH=%PYTHONPATH%;/path/to/model_wrappers
    ```
 
 ## Usecase
 
-Running the `demo.py` application with the `-h` option yields the following usage message:
+1. Running the `demo.py` application with the `-h` option yields the following usage message:
 
-```bash
-usage: demo.py [-h] -i INPUT -m MODELS [MODELS ...] [-it {sync,async}] [-l]
-Options:
-  -h, --help            Show this help message and exit.
-  -i INPUT, --input INPUT
-                        Required. An input to process. The input must be a
-                        single image, a folder of images, video file or camera
-                        id.
-  -m MODELS [MODELS ...], --models MODELS [MODELS ...]
-                        Required. Path to directory with trained model and
-                        configuration file. If you provide several models you
-                        will start the task chain pipeline with the provided
-                        models in the order in which they were specified
-  -it {sync,async}, --inference_type {sync,async}
-                        Optional. Type of inference for single model
-  -l, --loop            Optional. Enable reading the input in a loop.
-  --no_show
-                        Optional. If this flag is specified, the demo
-                        won't show the inference results on UI.
-```
-
-As a model, you can use path to model directory from generated zip. So you can use the following command to do inference with a pre-trained model:
-
-```bash
-python3 demo.py \
-  -i <path_to_video>/inputVideo.mp4 \
-  -m <path_to_model_directory>
-```
-
-You can press `Q` to stop inference during demo running.
-
-> **NOTE**: If you provide a single image as an input, the demo processes and renders it quickly, then exits. To continuously
-> visualize inference results on the screen, apply the `loop` option, which enforces processing a single image in a loop.
->
-> **NOTE**: Default configuration contains info about pre- and post processing for inference and is guaranteed to be correct.
-> Also you can change `config.json` that specifies needed parameters, but any changes should be made with caution.
+   ```bash
+   usage: demo.py [-h] -i INPUT -m MODELS [MODELS ...] [-it {sync,async}] [-l] [--no_show] [-d {CPU,GPU}] [--output OUTPUT]
+
+   Options:
+   -h, --help            Show this help message and exit.
+   -i INPUT, --input INPUT
+                           Required. An input to process. The input must be a single image, a folder of images, video file or camera id.
+   -m MODELS [MODELS ...], --models MODELS [MODELS ...]
+                           Required. Path to directory with trained model and configuration file. If you provide several models you will start the task chain pipeline with the provided models in the order in
+                           which they were specified.
+   -it {sync,async}, --inference_type {sync,async}
+                           Optional. Type of inference for single model.
+   -l, --loop            Optional. Enable reading the input in a loop.
+   --no_show             Optional. Disables showing inference results on UI.
+   -d {CPU,GPU}, --device {CPU,GPU}
+                           Optional. Device to infer the model.
+   --output OUTPUT       Optional. Output path to save input data with predictions.
+   ```
+
+2. As a `model`, you can use path to model directory from generated zip. You can pass as `input` a single image, a folder of images, a video file, or a web camera id. So you can use the following command to do inference with a pre-trained model:
+
+   ```bash
+   python3 demo.py \
+   -i <path_to_video>/inputVideo.mp4 \
+   -m <path_to_model_directory>
+   ```
+
+   You can press `Q` to stop inference during demo running.
+
+   > **NOTE**: If you provide a single image as input, the demo processes and renders it quickly, then exits. To continuously
+   > visualize inference results on the screen, apply the `--loop` option, which enforces processing a single image in a loop.
+   > In this case, you can stop the demo by pressing `Q` button or killing the process in the terminal (`Ctrl+C` for Linux).
+   >
+   > **NOTE**: Default configuration contains info about pre- and post processing for inference and is guaranteed to be correct.
+   > Also you can change `config.json` that specifies the confidence threshold and color for each class visualization, but any
+   > changes should be made with caution.
+
+3. To save inferenced results with predictions on it, you can specify the folder path, using `--output`.
+   It works for images, videos, image folders and web cameras. To prevent issues, do not specify it together with a `--loop` parameter.
+
+   ```bash
+   python3 demo.py \
+      --input <path_to_image>/inputImage.jpg \
+      --models ../model \
+      --output resulted_images
+   ```
+
+4. To run a demo on a web camera, you need to know its ID.
+   You can check a list of camera devices by running this command line on Linux system:
+
+   ```bash
+   sudo apt-get install v4l-utils
+   v4l2-ctl --list-devices
+   ```
+
+   The output will look like this:
+
+   ```bash
+   Integrated Camera (usb-0000:00:1a.0-1.6):
+      /dev/video0
+   ```
+
+   After that, you can use this `/dev/video0` as a camera ID for `--input`.
 
 ## Troubleshooting
 
 1. If you have access to the Internet through the proxy server only, please use pip with proxy call as demonstrated by command below:
 
    ```bash
    python -m pip install --proxy http://<usr_name>:<password>@<proxyserver_name>:<port#> <pkg_name>
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo.py`

 * *Files 5% similar despite different names*

```diff
@@ -70,14 +70,20 @@
         "-d",
         "--device",
         help="Optional. Device to infer the model.",
         choices=["CPU", "GPU"],
         default="CPU",
         type=str,
     )
+    args.add_argument(
+        "--output",
+        default=None,
+        type=str,
+        help="Optional. Output path to save input data with predictions.",
+    )
 
     return parser
 
 
 EXECUTORS = {
     "sync": SyncExecutor,
     "async": AsyncExecutor,
@@ -92,24 +98,28 @@
         print("You started the task chain pipeline with the provided models in the order in which they were specified")
     return EXECUTORS[type_inference]
 
 
 def main():
     """Main function that is used to run demo."""
     args = build_argparser().parse_args()
+
+    if args.loop and args.output:
+        raise ValueError("--loop and --output cannot be both specified")
+
     # create models
     models = []
     for model_dir in args.models:
         model = ModelContainer(model_dir, device=args.device)
         models.append(model)
 
     inferencer = get_inferencer_class(args.inference_type, models)
 
     # create visualizer
-    visualizer = create_visualizer(models[-1].task_type, no_show=args.no_show)
+    visualizer = create_visualizer(models[-1].task_type, no_show=args.no_show, output=args.output)
 
     if len(models) == 1:
         models = models[0]
 
     # create inferencer and run
     demo = inferencer(models, visualizer)
     demo.run(args.input, args.loop and not args.no_show)
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/asynchronous.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/asynchronous.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     ModelContainer,
 )
 from otx.api.usecases.exportable_code.demo.demo_package.utils import (
     create_output_converter,
 )
 from otx.api.usecases.exportable_code.streamer import get_streamer
 from otx.api.usecases.exportable_code.visualizers import Visualizer
+from otx.cli.tools.utils.demo.visualization import dump_frames
 
 
 class AsyncExecutor:
     """Async inferencer.
 
     Args:
         model: model for inference
@@ -34,33 +35,37 @@
 
     def run(self, input_stream: Union[int, str], loop: bool = False) -> None:
         """Async inference for input stream (image, video stream, camera)."""
         streamer = get_streamer(input_stream, loop)
         next_frame_id = 0
         next_frame_id_to_show = 0
         stop_visualization = False
+        saved_frames = []
 
         for frame in streamer:
             results = self.async_pipeline.get_result(next_frame_id_to_show)
             while results:
                 output = self.render_result(results)
                 next_frame_id_to_show += 1
                 self.visualizer.show(output)
+                if self.visualizer.output:
+                    saved_frames.append(frame)
                 if self.visualizer.is_quit():
                     stop_visualization = True
                 results = self.async_pipeline.get_result(next_frame_id_to_show)
             if stop_visualization:
                 break
             self.async_pipeline.submit_data(frame, next_frame_id, {"frame": frame})
             next_frame_id += 1
         self.async_pipeline.await_all()
         for next_frame_id_to_show in range(next_frame_id_to_show, next_frame_id):
             results = self.async_pipeline.get_result(next_frame_id_to_show)
             output = self.render_result(results)
             self.visualizer.show(output)
+        dump_frames(saved_frames, self.visualizer.output, input_stream, streamer)
 
     def render_result(self, results: Tuple[Any, dict]) -> np.ndarray:
         """Render for results of inference."""
         predictions, frame_meta = results
         annotation_scene = self.converter.convert_to_annotation(predictions, frame_meta)
         current_frame = frame_meta["frame"]
         output = self.visualizer.draw(current_frame, annotation_scene, frame_meta)
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/sync_pipeline.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/sync_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,14 +18,15 @@
 )
 from otx.api.usecases.exportable_code.demo.demo_package.utils import (
     create_output_converter,
 )
 from otx.api.usecases.exportable_code.streamer import get_streamer
 from otx.api.usecases.exportable_code.visualizers import Visualizer
 from otx.api.utils.shape_factory import ShapeFactory
+from otx.cli.tools.utils.demo.visualization import dump_frames
 
 
 class ChainExecutor:
     """Sync executor for task-chain inference.
 
     Args:
         models: list of models for inference
@@ -74,15 +75,20 @@
             ShapeFactory.shape_as_rectangle(parent_annotation.shape)
         )
         return new_item, item_annotation
 
     def run(self, input_stream: Union[int, str], loop: bool = False) -> None:
         """Run demo using input stream (image, video stream, camera)."""
         streamer = get_streamer(input_stream, loop)
+        saved_frames = []
 
         for frame in streamer:
             # getting result for single image
             annotation_scene = self.single_run(frame)
             output = self.visualizer.draw(frame, annotation_scene, {})
             self.visualizer.show(output)
+            if self.visualizer.output:
+                saved_frames.append(frame)
             if self.visualizer.is_quit():
                 break
+
+        dump_frames(saved_frames, self.visualizer.output, input_stream, streamer)
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/synchronous.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/executors/synchronous.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,14 +9,15 @@
     ModelContainer,
 )
 from otx.api.usecases.exportable_code.demo.demo_package.utils import (
     create_output_converter,
 )
 from otx.api.usecases.exportable_code.streamer import get_streamer
 from otx.api.usecases.exportable_code.visualizers import Visualizer
+from otx.cli.tools.utils.demo.visualization import dump_frames
 
 
 class SyncExecutor:
     """Synchronous executor for model inference.
 
     Args:
         model (ModelContainer): model for inference
@@ -27,16 +28,21 @@
         self.model = model
         self.visualizer = visualizer
         self.converter = create_output_converter(model.task_type, model.labels)
 
     def run(self, input_stream: Union[int, str], loop: bool = False) -> None:
         """Run demo using input stream (image, video stream, camera)."""
         streamer = get_streamer(input_stream, loop)
+        saved_frames = []
 
         for frame in streamer:
             # getting result include preprocessing, infer, postprocessing for sync infer
             predictions, frame_meta = self.model(frame)
             annotation_scene = self.converter.convert_to_annotation(predictions, frame_meta)
             output = self.visualizer.draw(frame, annotation_scene, frame_meta)
             self.visualizer.show(output)
+            if self.visualizer.output:
+                saved_frames.append(frame)
             if self.visualizer.is_quit():
                 break
+
+        dump_frames(saved_frames, self.visualizer.output, input_stream, streamer)
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/model_container.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/model_container.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,24 +2,24 @@
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import importlib
 import json
 from pathlib import Path
-from typing import Any, Tuple
+from typing import Any, Optional, Tuple
 
 import numpy as np
 from openvino.model_zoo.model_api.adapters import OpenvinoAdapter, create_core
 from openvino.model_zoo.model_api.models import Model
 
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.model_template import TaskType
 from otx.api.serialization.label_mapper import LabelSchemaMapper
-from otx.api.utils import Tiler
+from otx.api.utils.tiler import Tiler
 from otx.api.utils.detection_utils import detection2array
 
 from .utils import get_model_path, get_parameters
 
 
 class ModelContainer:
     """Class for storing the model wrapper based on Model API and needed parameters of model.
@@ -52,32 +52,37 @@
         self.core_model = Model.create_model(
             self.parameters["type_of_model"],
             model_adapter,
             self.model_parameters,
             preload=True,
         )
 
-        self.tiler = self.setup_tiler()
+        self.tiler = self.setup_tiler(model_dir, device)
 
-    def setup_tiler(self):
-        """Setup tiler.
+    def setup_tiler(self, model_dir, device) -> Optional[Tiler]:
+        """Setup tiler for model.
 
+        Args:
+            model_dir (str): model directory
+            device (str): device to run model on
         Returns:
-            Tiler: tiler module
+            Optional: Tiler object or None
         """
-        if (
-            not self.parameters.get("tiling_parameters")
-            or not self.parameters["tiling_parameters"]["enable_tiling"]["value"]
-        ):
+        if not self.parameters.get("tiling_parameters") or not self.parameters["tiling_parameters"]["enable_tiling"]:
             return None
 
-        tile_size = self.parameters["tiling_parameters"]["tile_size"]["value"]
-        tile_overlap = self.parameters["tiling_parameters"]["tile_overlap"]["value"]
-        max_number = self.parameters["tiling_parameters"]["tile_max_number"]["value"]
-        tiler = Tiler(tile_size, tile_overlap, max_number, self.core_model, self.segm)
+        classifier = {}
+        if self.parameters["tiling_parameters"].get("enable_tile_classifier", False):
+            adapter = OpenvinoAdapter(create_core(), get_model_path(model_dir / "tile_classifier.xml"), device=device)
+            classifier = Model(model_adapter=adapter, preload=True)
+
+        tile_size = self.parameters["tiling_parameters"]["tile_size"]
+        tile_overlap = self.parameters["tiling_parameters"]["tile_overlap"]
+        max_number = self.parameters["tiling_parameters"]["tile_max_number"]
+        tiler = Tiler(tile_size, tile_overlap, max_number, self.core_model, classifier, self.segm)
         return tiler
 
     @property
     def task_type(self) -> TaskType:
         """Task type property."""
         return self._task_type
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/demo_package/utils.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/demo_package/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -43,13 +43,13 @@
 def create_output_converter(task_type: TaskType, labels: LabelSchemaEntity):
     """Create annotation converter according to kind of task."""
 
     converter_type = task_type_to_label_domain(task_type)
     return create_converter(converter_type, labels)
 
 
-def create_visualizer(_task_type: TaskType, no_show: bool = False):
+def create_visualizer(_task_type: TaskType, no_show: bool = False, output: Optional[str] = None):
     """Create visualizer according to kind of task."""
 
     # TODO: use anomaly-specific visualizer for anomaly tasks
 
-    return Visualizer(window_name="Result", no_show=no_show)
+    return Visualizer(window_name="Result", no_show=no_show, output=output)
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/demo/setup.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/demo/setup.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/inference/inference.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/inference/inference.py`

 * *Files 3% similar despite different names*

```diff
@@ -59,39 +59,39 @@
         to the model, and return the predictions in a dictionary format.
 
         For instance, for a segmentation task, the predictions could be {"mask": mask}.
         """
         raise NotImplementedError
 
     @abc.abstractmethod
-    def post_process(self, prediction: Any, metadata: Any) -> AnnotationSceneEntity:
+    def post_process(self, prediction: Any, metadata: Any) -> Union[AnnotationSceneEntity, Tuple[Any, ...]]:
         """Post-process the raw predictions, and return the AnnotationSceneEntity.
 
         This method should include the post-processing methods that are applied to the raw predictions from the
         self.forward() stage.
         """
         raise NotImplementedError
 
     @abc.abstractmethod
-    def predict(self, image: np.ndarray) -> AnnotationSceneEntity:
+    def predict(self, image: np.ndarray) -> Union[AnnotationSceneEntity, Tuple[Any, ...]]:
         """This method performs a prediction."""
         raise NotImplementedError
 
 
 class BaseInferencer(IInferencer, abc.ABC):
     """Base class for standard inference.
 
     The user needs to implement the following:
         + `load_model`
         + `pre_process`
         + `forward`
         + `post_process`
     """
 
-    def predict(self, image: np.ndarray) -> AnnotationSceneEntity:
+    def predict(self, image: np.ndarray) -> Union[AnnotationSceneEntity, Tuple[Any, ...]]:
         """Perform a prediction for a given input image.
 
         Args:
             image: Input image
 
         Returns:
             Output predictions
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/prediction_to_annotation_converter.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/prediction_to_annotation_converter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/streamer/__init__.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/streamer/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/streamer/streamer.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/streamer/streamer.py`

 * *Files 2% similar despite different names*

```diff
@@ -160,14 +160,18 @@
                 yield cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
             else:
                 if self.loop:
                     self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                 else:
                     break
 
+    def fps(self):
+        """Returns a frequency of getting images from source."""
+        return self.cap.get(cv2.CAP_PROP_FPS)
+
     def get_type(self) -> MediaType:
         """Returns the type of media."""
         return MediaType.VIDEO
 
 
 class CameraStreamer(BaseStreamer):
     """Stream video frames from camera.
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/anomaly_visualizer.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/anomaly_visualizer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/exportable_code/visualizers/visualizer.py` & `otx-1.2.0rc1/otx/api/usecases/exportable_code/visualizers/visualizer.py`

 * *Files 2% similar despite different names*

```diff
@@ -62,22 +62,24 @@
     def __init__(
         self,
         window_name: Optional[str] = None,
         show_count: bool = False,
         is_one_label: bool = False,
         no_show: bool = False,
         delay: Optional[int] = None,
+        output: Optional[str] = None,
     ) -> None:
         self.window_name = "Window" if window_name is None else window_name
         self.shape_drawer = ShapeDrawer(show_count, is_one_label)
 
         self.delay = delay
         self.no_show = no_show
         if delay is None:
             self.delay = 1
+        self.output = output
 
     def draw(
         self,
         image: np.ndarray,
         annotation: AnnotationSceneEntity,
         meta: Optional[dict] = None,
     ) -> np.ndarray:
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/reporting/callback.py` & `otx-1.2.0rc1/otx/api/usecases/reporting/callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/reporting/time_monitor_callback.py` & `otx-1.2.0rc1/otx/api/usecases/reporting/time_monitor_callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/exceptions.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/exceptions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/image_computer_vision.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/image_computer_vision.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/image_deep_learning_task.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/image_deep_learning_task.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/deployment_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/deployment_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/evaluate_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/evaluate_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/explain_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/explain_interface.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,25 +4,25 @@
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import abc
 
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.explain_parameters import ExplainParameters
 
 
 class IExplainTask(metaclass=abc.ABCMeta):
     """A base interface for explain task."""
 
     @abc.abstractmethod
     def explain(
         self,
         dataset: DatasetEntity,
-        explain_parameters: InferenceParameters,
+        explain_parameters: ExplainParameters,
     ) -> DatasetEntity:
         """This is the method that is called upon explanation.
 
         Args:
             dataset: The input dataset to perform the explain on.
             explain_parameters: The parameters to use for the explain.
```

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/export_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/export_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/inference_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/inference_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/optimization_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/optimization_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/training_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/training_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/usecases/tasks/interfaces/unload_interface.py` & `otx-1.2.0rc1/otx/api/usecases/tasks/interfaces/unload_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/anomaly_utils.py` & `otx-1.2.0rc1/otx/api/utils/anomaly_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/argument_checks.py` & `otx-1.2.0rc1/otx/api/utils/argument_checks.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/dataset_utils.py` & `otx-1.2.0rc1/otx/api/utils/dataset_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/detection_utils.py` & `otx-1.2.0rc1/otx/api/utils/detection_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/importing.py` & `otx-1.2.0rc1/otx/api/utils/importing.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/labels_utils.py` & `otx-1.2.0rc1/otx/api/utils/labels_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/nms.py` & `otx-1.2.0rc1/otx/api/utils/nms.py`

 * *Files 17% similar despite different names*

```diff
@@ -56,15 +56,15 @@
 
     Args:
         detections (np.ndarray): labels, scores and boxes
         iou_threshold (float, optional): IoU threshold. Defaults to 0.45.
         max_num (int, optional): Max number of objects filter. Defaults to 200.
 
     Returns:
-        _type_: _description_
+        tuple: (dets, indices), Dets are boxes with scores. Indices are indices of kept boxes.
     """
     labels = detections[:, 0]
     scores = detections[:, 1]
     boxes = detections[:, 2:]
     max_coordinate = boxes.max()
     offsets = labels.astype(boxes.dtype) * (max_coordinate + 1)
     boxes_for_nms = boxes + offsets[:, None]
```

### Comparing `otx-1.1.2rc1/otx/api/utils/segmentation_utils.py` & `otx-1.2.0rc1/otx/api/utils/segmentation_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/shape_drawer.py` & `otx-1.2.0rc1/otx/api/utils/shape_drawer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/shape_factory.py` & `otx-1.2.0rc1/otx/api/utils/shape_factory.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/time_utils.py` & `otx-1.2.0rc1/otx/api/utils/time_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/api/utils/vis_utils.py` & `otx-1.2.0rc1/otx/api/utils/vis_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/__init__.py` & `otx-1.2.0rc1/otx/cli/builder/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/builder.py` & `otx-1.2.0rc1/otx/cli/builder/builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmcls.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmcls.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmdet.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmdet.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/mmseg.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/mmseg.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/omz.mmcls.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/omz.mmcls.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/otx.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/otx.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/builder/supported_backbone/torchvision.json` & `otx-1.2.0rc1/otx/cli/builder/supported_backbone/torchvision.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/manager/config_manager.py` & `otx-1.2.0rc1/otx/cli/manager/config_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """Configuration Manager ."""
 
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import shutil
+from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from datumaro.components.dataset import Dataset
 from datumaro.components.dataset_base import IDataset
 from omegaconf import OmegaConf
 
@@ -90,14 +91,15 @@
     def __init__(self, args, workspace_root: Optional[str] = None, mode: str = "train"):
         # Currently, Datumaro.auto_split() can support below 3 tasks
         # Classification, Detection, Segmentation
         self.otx_root = get_otx_root_path()
         self.workspace_root = Path(workspace_root) if workspace_root else Path(".")
         self.mode = mode
         self.rebuild: bool = False
+        self.create_date: str = datetime.now().strftime("%Y%m%d_%H%M%S")
 
         self.args = args
         self.template = args.template
         self.task_type: str = ""
         self.train_type: str = ""
         self.model: str = ""
 
@@ -117,14 +119,29 @@
         """
         if "data" in self.args and self.args.data:
             if Path(self.args.data).exists():
                 return Path(self.args.data)
             raise FileNotExistError(f"Not found: {self.args.data}")
         return self.workspace_root / "data.yaml"
 
+    @property
+    def output_path(self) -> Path:
+        """The path of output directory for workspace.
+
+        Returns:
+            Path: Path of output directory.
+        """
+        if "output" in self.args and self.args.output:
+            output_path = Path(self.args.output)
+        else:
+            output_path = self.workspace_root / "outputs" / f"{self.create_date}_{self.mode}"
+        if not output_path.exists():
+            output_path.mkdir(exist_ok=True, parents=True)
+        return output_path
+
     def check_workspace(self) -> bool:
         """Check that the class's workspace_root is an actual workspace folder.
 
         Returns:
             bool: true for workspace else false
         """
         has_template_yaml = (self.workspace_root / "template.yaml").exists()
@@ -169,15 +186,15 @@
             result = True
         return result
 
     def configure_data_config(self, update_data_yaml: bool = True) -> None:
         """Configure data_config according to the situation and create data.yaml."""
         data_yaml_path = self.data_config_file_path
         data_yaml = configure_dataset(self.args, data_yaml_path=data_yaml_path)
-        if self.mode in ("train", "build"):
+        if self.mode in ("train", "build", "optimize"):
             use_auto_split = data_yaml["data"]["train"]["data-roots"] and not data_yaml["data"]["val"]["data-roots"]
             # FIXME: Hardcoded for Self-Supervised Learning
             if use_auto_split and str(self.train_type).upper() != "SELFSUPERVISED":
                 splitted_dataset = self.auto_split_data(data_yaml["data"]["train"]["data-roots"], str(self.task_type))
                 default_data_folder_name = "splitted_dataset"
                 data_yaml = self._get_arg_data_yaml()
                 self._save_data(splitted_dataset, default_data_folder_name, data_yaml)
@@ -190,15 +207,19 @@
         """Check and return the train_type received as input args."""
         if not ignore_args:
             args_hyper_parameters = gen_params_dict_from_args(self.args)
             arg_algo_backend = args_hyper_parameters.get("algo_backend", False)
             if arg_algo_backend:
                 train_type = arg_algo_backend.get("train_type", {"value": "Incremental"})  # type: ignore
                 return train_type.get("value", "Incremental")
-            if hasattr(self.args, "train_type") and self.mode in ("build", "train") and self.args.train_type:
+            if (
+                hasattr(self.args, "train_type")
+                and self.mode in ("build", "train", "optimize")
+                and self.args.train_type
+            ):
                 self.train_type = self.args.train_type
                 if self.train_type not in TASK_TYPE_TO_SUB_DIR_NAME:
                     raise NotSupportedError(f"{self.train_type} is not currently supported by otx.")
             if self.train_type in TASK_TYPE_TO_SUB_DIR_NAME:
                 return self.train_type
 
         algo_backend = self.template.hyper_parameters.parameter_overrides.get("algo_backend", False)
@@ -256,15 +277,15 @@
             print(f"[*] Current auto-split can't support the {self.data_format} format.")
         return splitted_dataset
 
     def _get_arg_data_yaml(self):
         # TODO: This should modify data yaml format to data_config format.
         """Save the splitted dataset and data.yaml to the workspace."""
         data_yaml = self._create_empty_data_cfg()
-        if self.mode == "train":
+        if self.mode in ("train", "optimize"):
             if self.args.train_data_roots:
                 data_yaml["data"]["train"]["data-roots"] = self.args.train_data_roots
             if self.args.val_data_roots:
                 data_yaml["data"]["val"]["data-roots"] = self.args.val_data_roots
             if self.args.unlabeled_data_roots:
                 data_yaml["data"]["unlabeled"]["data-roots"] = self.args.unlabeled_data_roots
         elif self.mode == "test":
@@ -334,14 +355,16 @@
 
         Args:
             subsets (list, str): Defaults to ["train", "val", "unlabeled"].
 
         Returns:
             dict: dataset_config
         """
+        if str(self.train_type).upper() == "INCREMENTAL" and "unlabeled" in subsets:
+            subsets.remove("unlabeled")
         dataset_config = {"task_type": self.task_type, "train_type": self.train_type}
         for subset in subsets:
             if f"{subset}_subset" in self.data_config and self.data_config[f"{subset}_subset"]["data_root"]:
                 dataset_config.update({f"{subset}_data_roots": self.data_config[f"{subset}_subset"]["data_root"]})
         return dataset_config
 
     def update_data_config(self, data_yaml: dict) -> None:
@@ -359,15 +382,15 @@
             self.data_config["test_subset"] = {"data_root": data_yaml["data"]["test"]["data-roots"]}
         if "unlabeled" in data_yaml["data"] and data_yaml["data"]["unlabeled"]["data-roots"]:
             self.data_config["unlabeled_subset"] = {
                 "data_root": data_yaml["data"]["unlabeled"]["data-roots"],
                 "file_list": data_yaml["data"]["unlabeled"]["file-list"],
             }
         # FIXME: Hardcoded for Self-Supervised Learning
-        if self.mode == "train" and str(self.train_type).upper() == "SELFSUPERVISED":
+        if self.mode in ("train", "optimize") and str(self.train_type).upper() == "SELFSUPERVISED":
             self.data_config["val_subset"] = {"data_root": None}
 
     def _get_template(self, task_type: str, model: Optional[str] = None) -> ModelTemplate:
         """Returns the appropriate template for each situation.
 
         Args:
             task_type (str): The task_type registered in the registry. Used for filtering.
@@ -483,14 +506,20 @@
             if file_name.endswith(".py"):
                 try:
                     from otx.algorithms.common.adapters.mmcv.utils.config_utils import (
                         MPAConfig,
                     )
 
                     config = MPAConfig.fromfile(str(target_dir / file_name))
+                    # FIXME: In the CLI, there is currently no case for using the ignore label.
+                    # so the workspace's model patches ignore to False.
+                    # FIXME: Segmentation -> ignore=True
+                    if config.get("ignore", None) and str(self.task_type).upper() not in ("SEGMENTATION"):
+                        config.ignore = False
+                        print("In the CLI, Update ignore to false in model configuration.")
                     config.dump(str(dest_dir / file_name))
                 except Exception as exc:
                     raise CliException(f"{self.task_type} requires mmcv-full to be installed.") from exc
             elif file_name.endswith((".yml", ".yaml")):
                 config = OmegaConf.load(str(target_dir / file_name))
                 (dest_dir / file_name).write_text(OmegaConf.to_yaml(config))
             print(f"[*] \t- Updated: {str(dest_dir / file_name)}")
```

### Comparing `otx-1.1.2rc1/otx/cli/registry/__init__.py` & `otx-1.2.0rc1/otx/cli/registry/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/registry/registry.py` & `otx-1.2.0rc1/otx/cli/registry/registry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/__init__.py` & `otx-1.2.0rc1/tests/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,17 @@
-"""OTX cli tools."""
-
-# Copyright (C) 2021 Intel Corporation
+# Copyright (C) 2022-2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
+
+import os
+
+os.environ["FEATURE_FLAGS_OTX_ACTION_TASKS"] = "1"
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/build.py` & `otx-1.2.0rc1/otx/cli/tools/build.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,16 +13,14 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-from pathlib import Path
-
 from otx.cli.manager.config_manager import TASK_TYPE_TO_SUB_DIR_NAME, ConfigManager
 from otx.cli.utils.parser import get_parser_and_hprams_data
 
 SUPPORTED_TASKS = (
     "CLASSIFICATION",
     "DETECTION",
     "INSTANCE_SEGMENTATION",
@@ -64,16 +62,16 @@
     parser.add_argument(
         "--train-type",
         help=f"The currently supported options: {TASK_TYPE_TO_SUB_DIR_NAME.keys()}.",
         type=str,
         default="Incremental",
     )
     parser.add_argument(
-        "--work-dir",
-        help="Location where the workspace.",
+        "--workspace",
+        help="Path to the workspace where the command will run.",
         default=None,
     )
     parser.add_argument(
         "--model", help="Enter the name of the model you want to use. (Ex. EfficientNet-B0).", default=""
     )
     parser.add_argument(
         "--backbone",
@@ -84,24 +82,22 @@
     return parser.parse_args()
 
 
 def main():
     """Main function for model or backbone or task building."""
 
     args = get_args()
-    config_manager = ConfigManager(args, mode="build")
+    config_manager = ConfigManager(args, workspace_root=args.workspace, mode="build")
     if args.task:
         config_manager.task_type = args.task.upper()
-    if args.work_dir:
-        config_manager.workspace_root = Path(args.work_dir)
 
     # Auto-Configuration for model template
     config_manager.configure_template(model=args.model)
 
-    config_manager.build_workspace(new_workspace_path=args.work_dir)
+    config_manager.build_workspace(new_workspace_path=args.workspace)
 
     # Auto-Configuration for Dataset configuration
     config_manager.configure_data_config()
 
     # Build Backbone related
     if args.backbone:
         from otx.cli.builder import Builder
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/cli.py` & `otx-1.2.0rc1/otx/cli/tools/cli.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/demo.py` & `otx-1.2.0rc1/otx/cli/tools/demo.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 from otx.api.entities.annotation import AnnotationSceneEntity, AnnotationSceneKind
 from otx.api.entities.datasets import DatasetEntity, DatasetItemEntity
 from otx.api.entities.image import Image
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.cli.manager import ConfigManager
 from otx.cli.tools.utils.demo.images_capture import open_images_capture
-from otx.cli.tools.utils.demo.visualization import draw_predictions, put_text_on_rect_bg
+from otx.cli.tools.utils.demo.visualization import draw_predictions, dump_frames, put_text_on_rect_bg
 from otx.cli.utils.importing import get_impl_class
 from otx.cli.utils.io import read_label_schema, read_model
 from otx.cli.utils.parser import (
     add_hyper_parameters_sub_parser,
     get_parser_and_hprams_data,
 )
 
@@ -67,14 +67,20 @@
     parser.add_argument(
         "--display-perf",
         action="store_true",
         help="This option enables writing performance metrics on displayed frame. "
         "These metrics take into account not only model inference time, but also "
         "frame reading, pre-processing and post-processing.",
     )
+    parser.add_argument(
+        "--output",
+        default=None,
+        type=str,
+        help="Output path to save input data with predictions.",
+    )
 
     add_hyper_parameters_sub_parser(parser, hyper_parameters, modes=("INFERENCE",))
     override_param = [f"params.{param[2:].split('=')[0]}" for param in params if param.startswith("--")]
 
     return parser.parse_args(), override_param
 
 
@@ -89,28 +95,31 @@
     )
 
     dataset = DatasetEntity(items=[item])
 
     start_time = time.perf_counter()
     predicted_validation_dataset = task.infer(
         dataset,
-        InferenceParameters(is_evaluation=True),
+        InferenceParameters(is_evaluation=False),
     )
     elapsed_time = time.perf_counter() - start_time
     item = predicted_validation_dataset[0]
     return item.get_annotations(), elapsed_time
 
 
 def main():
     """Main function that is used for model demonstration."""
 
     # Dynamically create an argument parser based on override parameters.
     args, override_param = get_args()
 
-    config_manager = ConfigManager(args, mode="eval")
+    if args.loop and args.output:
+        raise ValueError("--loop and --output cannot be both specified")
+
+    config_manager = ConfigManager(args, mode="demo")
     # Auto-Configuration for model template
     config_manager.configure_template()
 
     # Update Hyper Parameter Configs
     hyper_parameters = config_manager.get_hyparams_config(override_param)
 
     # Get classes for Task, ConfigurableParameters and Dataset.
@@ -132,15 +141,15 @@
     environment.model = read_model(environment.get_model_configuration(), args.load_weights, None)
 
     task = task_class(task_environment=environment)
 
     capture = open_images_capture(args.input, args.loop)
 
     elapsed_times = deque(maxlen=10)
-    frame_index = 0
+    saved_frames = []
     while True:
         frame = capture.read()
         if frame is None:
             break
 
         predictions, elapsed_time = get_predictions(task, frame)
         elapsed_times.append(elapsed_time)
@@ -151,19 +160,24 @@
             put_text_on_rect_bg(
                 frame,
                 f"time: {elapsed_time:.4f} sec.",
                 (0, frame.shape[0] - 30),
                 color=(255, 255, 255),
             )
 
-        if args.delay >= 0:
+        if args.delay > 0:
             cv2.imshow("frame", frame)
             if cv2.waitKey(args.delay) == ESC_BUTTON:
                 break
         else:
-            print(f"{frame_index=}, {elapsed_time=}, {len(predictions)=}")
+            print(f"Frame: {elapsed_time=}, {len(predictions)=}")
+
+        if args.output:
+            saved_frames.append(frame)
+
+    dump_frames(saved_frames, args.output, args.input, capture)
 
     return dict(retcode=0, template=template.name)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/deploy.py` & `otx-1.2.0rc1/otx/cli/tools/deploy.py`

 * *Files 10% similar despite different names*

```diff
@@ -10,15 +10,14 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
-import os
 from pathlib import Path
 
 from otx.api.configuration.helper import create
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.cli.manager import ConfigManager
 from otx.cli.utils.importing import get_impl_class
@@ -31,15 +30,16 @@
     parser, _, _ = get_parser_and_hprams_data()
 
     parser.add_argument(
         "--load-weights",
         help="Load model weights from previously saved checkpoint.",
     )
     parser.add_argument(
-        "--save-model-to",
+        "-o",
+        "--output",
         help="Location where openvino.zip will be stored.",
     )
 
     return parser.parse_args()
 
 
 def main():
@@ -54,19 +54,16 @@
     # Reads model template file.
     template = config_manager.template
 
     # Get hyper parameters schema.
     hyper_parameters = template.hyper_parameters.data
     assert hyper_parameters
 
-    if not args.load_weights and config_manager.check_workspace():
-        exported_weight_path = config_manager.workspace_root / "models-exported/openvino.xml"
-        if not exported_weight_path.exists():
-            raise RuntimeError("OpenVINO-exported models are supported.")
-        args.load_weights = str(exported_weight_path)
+    if not args.load_weights:
+        raise RuntimeError("No appropriate OpenVINO exported model was found.")
 
     # Get classes for Task, ConfigurableParameters and Dataset.
     if not args.load_weights.endswith(".bin") and not args.load_weights.endswith(".xml"):
         raise RuntimeError("Only OpenVINO-exported models are supported.")
 
     task_class = get_impl_class(template.entrypoints.openvino)
 
@@ -78,19 +75,18 @@
     )
     environment.model = read_model(environment.get_model_configuration(), args.load_weights, None)
 
     task = task_class(task_environment=environment)
 
     deployed_model = ModelEntity(None, environment.get_model_configuration())
 
-    if "save_model_to" not in args or not args.save_model_to:
-        args.save_model_to = str(config_manager.workspace_root / "model-deployed")
-    os.makedirs(args.save_model_to, exist_ok=True)
+    output_path = Path(args.output) if args.output else config_manager.output_path
+    output_path.mkdir(exist_ok=True, parents=True)
     task.deploy(deployed_model)
-    with open(Path(args.save_model_to) / "openvino.zip", "wb") as write_file:
+    with open(output_path / "openvino.zip", "wb") as write_file:
         write_file.write(deployed_model.exportable_code)
 
     return dict(retcode=0, template=template.name)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/eval.py` & `otx-1.2.0rc1/otx/cli/tools/eval.py`

 * *Files 7% similar despite different names*

```diff
@@ -44,21 +44,28 @@
     )
     parser.add_argument(
         "--load-weights",
         help="Load model weights from previously saved checkpoint."
         "It could be a trained/optimized model (POT only) or exported model.",
     )
     parser.add_argument(
-        "--save-performance",
-        help="Path to a json file where computed performance will be stored.",
+        "-o",
+        "--output",
+        help="Location where the intermediate output of the task will be stored.",
     )
     parser.add_argument(
-        "--work-dir",
-        help="Location where the intermediate output of the task will be stored.",
+        "--workspace",
+        help="Path to the workspace where the command will run.",
+        default=None,
+    )
+    parser.add_argument(
+        "--data",
+        type=str,
         default=None,
+        help="The data.yaml path want to use in train task.",
     )
 
     add_hyper_parameters_sub_parser(parser, hyper_parameters, modes=("INFERENCE",))
     override_param = [f"params.{param[2:].split('=')[0]}" for param in params if param.startswith("--")]
 
     return parser.parse_args(), override_param
 
@@ -78,20 +85,23 @@
 
 def main():
     """Main function that is used for model evaluation."""
 
     # Dynamically create an argument parser based on override parameters.
     args, override_param = get_args()
 
-    config_manager = ConfigManager(args, workspace_root=args.work_dir, mode="eval")
+    config_manager = ConfigManager(args, workspace_root=args.workspace, mode="eval")
     # Auto-Configuration for model template
     config_manager.configure_template()
 
     if not args.load_weights and config_manager.check_workspace():
-        args.load_weights = str(config_manager.workspace_root / "models/weights.pth")
+        latest_model_path = (
+            config_manager.workspace_root / "outputs" / "latest_trained_model" / "models" / "weights.pth"
+        )
+        args.load_weights = str(latest_model_path)
 
     # Update Hyper Parameter Configs
     hyper_parameters = config_manager.get_hyparams_config(override_param)
 
     # Get classes for Task, ConfigurableParameters and Dataset.
     template = config_manager.template
     if any(args.load_weights.endswith(x) for x in (".bin", ".xml", ".zip")):
@@ -132,17 +142,16 @@
         ground_truth_dataset=validation_dataset,
         prediction_dataset=predicted_validation_dataset,
     )
     task.evaluate(resultset)
     assert resultset.performance is not None
     print(resultset.performance)
 
-    if not args.save_performance:
-        args.save_performance = str(Path(args.load_weights).parent / "performance.json")
-    with open(args.save_performance, "w", encoding="UTF-8") as write_file:
+    output_path = Path(args.output) if args.output else config_manager.output_path
+    with open(output_path / "performance.json", "w", encoding="UTF-8") as write_file:
         json.dump(
             {resultset.performance.score.name: resultset.performance.score.value},
             write_file,
         )
 
     return dict(retcode=0, template=template.name)
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/export.py` & `otx-1.2.0rc1/otx/cli/tools/export.py`

 * *Files 9% similar despite different names*

```diff
@@ -33,20 +33,21 @@
     parser, _, _ = get_parser_and_hprams_data()
 
     parser.add_argument(
         "--load-weights",
         help="Load model weights from previously saved checkpoint.",
     )
     parser.add_argument(
-        "--save-model-to",
+        "-o",
+        "--output",
         help="Location where exported model will be stored.",
     )
     parser.add_argument(
-        "--work-dir",
-        help="Location where the intermediate output of the export will be stored.",
+        "--workspace",
+        help="Path to the workspace where the command will run.",
         default=None,
     )
     parser.add_argument(
         "--dump-features",
         action="store_true",
         help="Whether to return feature vector and saliency map for explanation purposes.",
     )
@@ -58,24 +59,28 @@
 
     return parser.parse_args()
 
 
 def main():
     """Main function that is used for model exporting."""
     args = get_args()
-    config_manager = ConfigManager(args, mode="eval", workspace_root=args.work_dir)
+    config_manager = ConfigManager(args, mode="export", workspace_root=args.workspace)
     # Auto-Configuration for model template
     config_manager.configure_template()
 
     # Load template.yaml file.
     template = config_manager.template
 
     # Get class for Task.
     if not args.load_weights and config_manager.check_workspace():
-        args.load_weights = str(config_manager.workspace_root / "models/weights.pth")
+        latest_model_path = (
+            config_manager.workspace_root / "outputs" / "latest_trained_model" / "models" / "weights.pth"
+        )
+        args.load_weights = str(latest_model_path)
+
     is_nncf = is_checkpoint_nncf(args.load_weights)
     task_class = get_impl_class(template.entrypoints.nncf if is_nncf else template.entrypoints.base)
 
     # Get hyper parameters schema.
     hyper_parameters = create(template.hyper_parameters.data)
     assert hyper_parameters
 
@@ -91,24 +96,28 @@
         configuration=environment.get_model_configuration(),
         model_adapters=model_adapters,
         train_dataset=None,
         optimization_type=ModelOptimizationType.NNCF if is_nncf else ModelOptimizationType.NONE,
     )
     environment.model = model
 
-    task = task_class(task_environment=environment, output_path=args.work_dir)
+    (config_manager.output_path / "logs").mkdir(exist_ok=True, parents=True)
+    task = task_class(task_environment=environment, output_path=str(config_manager.output_path / "logs"))
 
     exported_model = ModelEntity(None, environment.get_model_configuration())
 
     export_precision = ModelPrecision.FP16 if args.half_precision else ModelPrecision.FP32
     task.export(ExportType.OPENVINO, exported_model, export_precision, args.dump_features)
 
-    if "save_model_to" not in args or not args.save_model_to:
-        args.save_model_to = str(config_manager.workspace_root / "model-exported")
-    Path(args.save_model_to).mkdir(exist_ok=True, parents=True)
-    save_model_data(exported_model, args.save_model_to)
+    if not args.output:
+        output_path = config_manager.output_path
+        output_path = output_path / "openvino"
+    else:
+        output_path = Path(args.output)
+    output_path.mkdir(exist_ok=True, parents=True)
+    save_model_data(exported_model, str(output_path))
 
     return dict(retcode=0, template=template.name)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/find.py` & `otx-1.2.0rc1/otx/cli/tools/find.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/optimize.py` & `otx-1.2.0rc1/otx/cli/tools/optimize.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 import json
+from pathlib import Path
 
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.optimization_parameters import OptimizationParameters
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
@@ -51,23 +52,20 @@
         help="Comma-separated paths to validation data folders.",
     )
     parser.add_argument(
         "--load-weights",
         help="Load weights of trained model",
     )
     parser.add_argument(
-        "--save-model-to",
-        help="Location where trained model will be stored.",
+        "-o",
+        "--output",
+        help="Location where optimized model will be stored.",
     )
     parser.add_argument(
-        "--save-performance",
-        help="Path to a json file where computed performance will be stored.",
-    )
-    parser.add_argument(
-        "--work-dir",
+        "--workspace",
         help="Location where the intermediate output of the task will be stored.",
         default=None,
     )
 
     add_hyper_parameters_sub_parser(parser, hyper_parameters)
     override_param = [f"params.{param[2:].split('=')[0]}" for param in params if param.startswith("--")]
 
@@ -76,21 +74,24 @@
 
 def main():
     """Main function that is used for model training."""
 
     # Dynamically create an argument parser based on override parameters.
     args, override_param = get_args()
 
-    config_manager = ConfigManager(args, workspace_root=args.work_dir, mode="train")
+    config_manager = ConfigManager(args, workspace_root=args.workspace, mode="optimize")
     # Auto-Configuration for model template
     config_manager.configure_template()
 
     # The default in the workspace is the model weight of the OTX train.
     if not args.load_weights and config_manager.check_workspace():
-        args.load_weights = str(config_manager.workspace_root / "models/weights.pth")
+        latest_model_path = (
+            config_manager.workspace_root / "outputs" / "latest_trained_model" / "models" / "weights.pth"
+        )
+        args.load_weights = str(latest_model_path)
 
     is_pot = False
     if args.load_weights.endswith(".bin") or args.load_weights.endswith(".xml"):
         is_pot = True
 
     template = config_manager.template
     if not is_pot and template.entrypoints.nncf is None:
@@ -124,17 +125,22 @@
     task.optimize(
         OptimizationType.POT if is_pot else OptimizationType.NNCF,
         dataset,
         output_model,
         OptimizationParameters(),
     )
 
-    if "save_model_to" not in args or not args.save_model_to:
-        args.save_model_to = str(config_manager.workspace_root / "model-optimized")
-    save_model_data(output_model, args.save_model_to)
+    opt_method = "pot" if is_pot else "nncf"
+    if not args.output:
+        output_path = config_manager.output_path
+        output_path = output_path / opt_method
+    else:
+        output_path = Path(args.output)
+    output_path.mkdir(exist_ok=True, parents=True)
+    save_model_data(output_model, output_path)
 
     validation_dataset = dataset.get_subset(Subset.VALIDATION)
     predicted_validation_dataset = task.infer(
         validation_dataset.with_empty_annotations(),
         InferenceParameters(is_evaluation=True),
     )
 
@@ -143,19 +149,19 @@
         ground_truth_dataset=validation_dataset,
         prediction_dataset=predicted_validation_dataset,
     )
     task.evaluate(resultset)
     assert resultset.performance is not None
     print(resultset.performance)
 
-    if args.save_performance:
-        with open(args.save_performance, "w", encoding="UTF-8") as write_file:
-            json.dump(
-                {resultset.performance.score.name: resultset.performance.score.value},
-                write_file,
-            )
+    performance_file_path = config_manager.output_path / f"{opt_method}_performance.json"
+    with open(performance_file_path, "w", encoding="UTF-8") as write_file:
+        json.dump(
+            {resultset.performance.score.name: resultset.performance.score.value},
+            write_file,
+        )
 
     return dict(retcode=0, template=template.name)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/train.py` & `otx-1.2.0rc1/otx/cli/tools/train.py`

 * *Files 14% similar despite different names*

```diff
@@ -12,15 +12,19 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 # pylint: disable=too-many-locals
 
+import datetime
+import time
+from contextlib import ExitStack
 from pathlib import Path
+from typing import Optional
 
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
@@ -34,14 +38,15 @@
 from otx.cli.utils.io import read_binary, read_label_schema, save_model_data
 from otx.cli.utils.multi_gpu import MultiGPUManager, is_multigpu_child_process
 from otx.cli.utils.parser import (
     MemSizeAction,
     add_hyper_parameters_sub_parser,
     get_parser_and_hprams_data,
 )
+from otx.cli.utils.report import get_otx_report
 from otx.core.data.adapter import get_dataset_adapter
 
 
 def get_args():
     """Parses command line arguments."""
     parser, hyper_parameters, params = get_parser_and_hprams_data()
 
@@ -72,19 +77,20 @@
         help="Load model weights from previously saved checkpoint.",
     )
     parser.add_argument(
         "--resume-from",
         help="Resume training from previously saved checkpoint",
     )
     parser.add_argument(
-        "--save-model-to",
-        help="Location where trained model will be stored.",
+        "-o",
+        "--output",
+        help="Location where outputs (model & logs) will be stored.",
     )
     parser.add_argument(
-        "--work-dir",
+        "--workspace",
         help="Location where the intermediate output of the training will be stored.",
         default=None,
     )
     parser.add_argument(
         "--enable-hpo",
         action="store_true",
         help="Execute hyper parameters optimization (HPO) before training.",
@@ -123,15 +129,15 @@
         "--mem-cache-size",
         action=MemSizeAction,
         dest="params.algo_backend.mem_cache_size",
         type=str,
         required=False,
         help="Size of memory pool for caching decoded data to load data faster. "
         "For example, you can use digits for bytes size (e.g. 1024) or a string with size units "
-        "(e.g. 7KB = 7 * 2^10, 3MB = 3 * 2^20, and 2GB = 2 * 2^30).",
+        "(e.g. 7KiB = 7 * 2^10, 3MB = 3 * 10^6, and 2G = 2 * 2^30).",
     )
     parser.add_argument(
         "--data",
         type=str,
         default=None,
         help="The data.yaml path want to use in train task.",
     )
@@ -149,25 +155,33 @@
                     sub_parser.add_argument(
                         f"{param}",
                         dest=f"params.{param[2:]}",
                     )
     return parser.parse_args(), override_param
 
 
-def main():  # pylint: disable=too-many-branches
-    """Main function that is used for model training."""
+def main():
+    """Main function that invoke train function with ExitStack."""
+    with ExitStack() as exit_stack:
+        return train(exit_stack)
+
+
+def train(exit_stack: Optional[ExitStack] = None):  # pylint: disable=too-many-branches, too-many-statements
+    """Function that is used for model training."""
+    start_time = time.time()
+    mode = "train"
     args, override_param = get_args()
 
-    config_manager = ConfigManager(args, workspace_root=args.work_dir, mode="train")
+    config_manager = ConfigManager(args, workspace_root=args.workspace, mode=mode)
     # Auto-Configuration for model template
     config_manager.configure_template()
 
     # Creates a workspace if it doesn't exist.
     if not config_manager.check_workspace():
-        config_manager.build_workspace(new_workspace_path=args.work_dir)
+        config_manager.build_workspace(new_workspace_path=args.workspace)
 
     # Auto-Configuration for Dataset configuration
     config_manager.configure_data_config(update_data_yaml=config_manager.check_workspace())
     dataset_config = config_manager.get_dataset_config(subsets=["train", "val", "unlabeled"])
     dataset_adapter = get_dataset_adapter(**dataset_config)
     dataset, label_schema = dataset_adapter.get_otx_dataset(), dataset_adapter.get_label_schema()
 
@@ -196,62 +210,95 @@
             model_adapters.update(
                 {"label_schema.json": ModelAdapter(label_schema_to_bytes(read_label_schema(ckpt_path)))}
             )
 
         environment.model = ModelEntity(
             train_dataset=dataset,
             configuration=environment.get_model_configuration(),
-            model_adapters=model_adapters,
+            model_adapters=model_adapters,  # type: ignore
         )
 
-    # FIXME: Need to align output results & Current HPO use save_model_to.parent
-    if "save_model_to" not in args or not args.save_model_to:
-        args.save_model_to = str(config_manager.workspace_root / "models")
     if args.enable_hpo:
-        environment = run_hpo(args, environment, dataset, config_manager.data_config)
+        environment = run_hpo(
+            args.hpo_time_ratio, config_manager.output_path, environment, dataset, config_manager.data_config
+        )
 
-    task = task_class(task_environment=environment, output_path=args.work_dir)
+    (config_manager.output_path / "logs").mkdir(exist_ok=True, parents=True)
 
     if args.gpus:
-        multigpu_manager = MultiGPUManager(main, args.gpus, args.rdzv_endpoint, args.base_rank, args.world_size)
+        multigpu_manager = MultiGPUManager(train, args.gpus, args.rdzv_endpoint, args.base_rank, args.world_size)
         if template.task_type in (TaskType.ACTION_CLASSIFICATION, TaskType.ACTION_DETECTION):
             print("Multi-GPU training for action tasks isn't supported yet. A single GPU will be used for a training.")
         elif (
             multigpu_manager.is_available()
             and not template.task_type.is_anomaly  # anomaly tasks don't use this way for multi-GPU training
         ):
-            multigpu_manager.setup_multi_gpu_train(task.project_path, hyper_parameters if args.enable_hpo else None)
+            multigpu_manager.setup_multi_gpu_train(
+                str(config_manager.output_path), hyper_parameters if args.enable_hpo else None
+            )
+            if exit_stack is not None:
+                exit_stack.callback(multigpu_manager.finalize)
+            else:
+                print(
+                    "Warning: due to abstract of ExitStack context, "
+                    "if main process raises an error, all processes can be stuck."
+                )
+
+    task = task_class(task_environment=environment, output_path=str(config_manager.output_path / "logs"))
 
     output_model = ModelEntity(dataset, environment.get_model_configuration())
 
     task.train(dataset, output_model, train_parameters=TrainParameters())
 
-    save_model_data(output_model, args.save_model_to)
-    print(f"[*] Save Model to: {args.save_model_to}")
+    model_path = config_manager.output_path / "models"
+    save_model_data(output_model, str(model_path))
 
+    performance = None
     if config_manager.data_config["val_subset"]["data_root"]:
         validation_dataset = dataset.get_subset(Subset.VALIDATION)
         predicted_validation_dataset = task.infer(
             validation_dataset.with_empty_annotations(),
             InferenceParameters(is_evaluation=False),
         )
 
         resultset = ResultSetEntity(
             model=output_model,
             ground_truth_dataset=validation_dataset,
             prediction_dataset=predicted_validation_dataset,
         )
         task.evaluate(resultset)
-        assert resultset.performance is not None
-        print(resultset.performance)
-
-    if args.gpus:
-        multigpu_manager.finalize()
+        performance = resultset.performance
+        assert performance is not None
+        print(performance)
+
+    end_time = time.time()
+    sec = end_time - start_time
+    total_time = str(datetime.timedelta(seconds=sec))
+    print("otx train time elapsed: ", total_time)
+    model_results = {"time elapsed": total_time, "score": performance, "model_path": str(model_path.absolute())}
+
+    get_otx_report(
+        model_template=config_manager.template,
+        task_config=task.config,
+        data_config=config_manager.data_config,
+        results=model_results,
+        output_path=config_manager.output_path / "cli_report.log",
+    )
+
+    # Latest model folder symbolic link to models
+    latest_path = config_manager.workspace_root / "outputs" / "latest_trained_model"
+    if latest_path.exists():
+        latest_path.unlink()
+    elif not latest_path.parent.exists():
+        latest_path.parent.mkdir(exist_ok=True, parents=True)
+    latest_path.symlink_to(config_manager.output_path.resolve())
 
     if not is_multigpu_child_process():
         task.cleanup()
+    elif args.gpus and exit_stack is None:
+        multigpu_manager.finalize()
 
     return dict(retcode=0, template=template.name)
 
 
 if __name__ == "__main__":
     main()
```

### Comparing `otx-1.1.2rc1/otx/cli/tools/utils/__init__.py` & `otx-1.2.0rc1/otx/cli/tools/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/utils/demo/__init__.py` & `otx-1.2.0rc1/otx/cli/tools/utils/demo/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/utils/demo/images_capture.py` & `otx-1.2.0rc1/otx/cli/tools/utils/demo/images_capture.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/tools/utils/demo/visualization.py` & `otx-1.2.0rc1/otx/cli/tools/utils/demo/visualization.py`

 * *Files 17% similar despite different names*

```diff
@@ -11,26 +11,30 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 
-from typing import List, Tuple
+from pathlib import Path
+from typing import List, Tuple, Union
 from warnings import warn
 
 import cv2
 import numpy as np
 from cv2 import Mat
 
+from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.annotation import Annotation
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.shapes.polygon import Polygon
 from otx.api.entities.shapes.rectangle import Rectangle
 
+logger = get_logger()
+
 
 def put_text_on_rect_bg(frame: Mat, message: str, position: Tuple[int, int], color=(255, 255, 0)):
     """Puts a text message on a black rectangular aread in specified position of a frame."""
 
     font_face = cv2.FONT_HERSHEY_COMPLEX
     font_scale = 1
     thickness = 1
@@ -157,7 +161,50 @@
     elif task_type in {TaskType.INSTANCE_SEGMENTATION, TaskType.ROTATED_DETECTION}:
         frame = draw_masks(frame, predictions, put_object_count=True)
     elif task_type in {TaskType.SEGMENTATION, TaskType.ANOMALY_SEGMENTATION}:
         frame = draw_masks(frame, predictions, put_object_count=False)
     else:
         raise ValueError(f"Unknown task type: {task_type}")
     return frame
+
+
+def get_input_names_list(input_path: Union[str, int], capture):
+    """Lists the filenames of all inputs for demo."""
+
+    # Web camera input
+    if isinstance(input_path, int):
+        return []
+    if "DIR" in capture.get_type():
+        return [f.name for f in Path(input_path).iterdir() if f.is_file()]
+    else:
+        return [Path(input_path).name]
+
+
+def dump_frames(saved_frames: list, output: str, input_path: Union[str, int], capture):
+    """Saves images/videos with predictions from saved_frames to output folder with proper names."""
+
+    if not saved_frames:
+        return
+
+    output_path = Path(output)
+    if not output_path.exists():
+        output_path.mkdir(parents=True)
+
+    filenames = get_input_names_list(input_path, capture)
+
+    if "VIDEO" in capture.get_type():
+        filename = filenames[0]
+        w, h, _ = saved_frames[0].shape
+        video_path = str(output_path / filename)
+        codec = cv2.VideoWriter_fourcc(*"mp4v")
+        out = cv2.VideoWriter(video_path, codec, capture.fps(), (h, w))
+        for frame in saved_frames:
+            out.write(frame)
+        out.release()
+        logger.info(f"Video was saved to {video_path}")
+    else:
+        if len(filenames) < len(saved_frames):
+            filenames = [f"output_{i}" for i, _ in enumerate(saved_frames)]
+        for filename, frame in zip(filenames, saved_frames):
+            image_path = str(output_path / filename)
+            cv2.imwrite(image_path, frame)
+            logger.info(f"Image was saved to {image_path}")
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/config.py` & `otx-1.2.0rc1/otx/cli/utils/config.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,19 +25,18 @@
     allowed_keys = {"default_value", "value"}
     for k, val in overrides.items():
         if isinstance(val, dict):
             if k in parameters.keys():
                 override_parameters(val, parameters[k])
             else:
                 raise ValueError(f'The "{k}" is not in original parameters.')
+        elif k in allowed_keys:
+            parameters[k] = val
         else:
-            if k in allowed_keys:
-                parameters[k] = val
-            else:
-                raise ValueError(f'The "{k}" is not in allowed_keys: {allowed_keys}')
+            raise ValueError(f'The "{k}" is not in allowed_keys: {allowed_keys}')
 
 
 def configure_dataset(args, data_yaml_path=None):
     """Configure dataset args."""
 
     # Create instances of Task, ConfigurableParameters and Dataset.
     data_subset_format = {"ann-files": None, "data-roots": None}
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/errors.py` & `otx-1.2.0rc1/otx/cli/utils/errors.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/utils/hpo.py` & `otx-1.2.0rc1/otx/cli/utils/hpo.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import json
 import logging
+import os
 import re
 import shutil
 from copy import deepcopy
 from enum import Enum
 from functools import partial
 from inspect import isclass
 from math import floor
@@ -442,20 +443,20 @@
                 logger.info(
                     "Train set size is equal or lower than batch size range. Batch size is fixed to train set size."
                 )
                 del self._hpo_config["hp_space"][batch_size_name]
                 self._fixed_hp[batch_size_name] = self._train_dataset_size
                 self._environment.set_hyper_parameter_using_str_key(self._fixed_hp)
 
-    def run_hpo(self, train_func: Callable, data_roots: Dict[str, str]) -> Dict[str, Any]:
+    def run_hpo(self, train_func: Callable, data_roots: Dict[str, Dict]) -> Dict[str, Any]:
         """Run HPO and provides optimized hyper parameters.
 
         Args:
             train_func (Callable): training model function
-            data_roots (Dict[str, str]): dataset path of each dataset type
+            data_roots (Dict[str, Dict]): dataset path of each dataset type
 
         Returns:
             Dict[str, Any]: optimized hyper parameters
         """
         self._environment.save_initial_weight(self._get_initial_model_weight_path())
         hpo_algo = self._get_hpo_algo()
         resource_type = "gpu" if torch.cuda.is_available() else "cpu"
@@ -532,39 +533,44 @@
         return default_hyper_parameters
 
     def _get_initial_model_weight_path(self):
         return self._hpo_workdir / self._initial_weight_name
 
 
 def run_hpo(
-    args, environment: TaskEnvironment, dataset: DatasetEntity, data_roots: Dict[str, str]
+    hpo_time_ratio: int, output: Path, environment: TaskEnvironment, dataset: DatasetEntity, data_roots: Dict[str, Dict]
 ) -> Optional[TaskEnvironment]:
     """Run HPO and load optimized hyper parameter and best HPO model weight.
 
     Args:
-        args: arguments passed to otx train
+        hpo_time_ratio(int): expected ratio of total time to run HPO to time taken for full fine-tuning
+        output(Path): directory where HPO output is saved
         environment (TaskEnvironment): otx task environment
         dataset (DatasetEntity): dataset to use for training
-        data_roots (Dict[str, str]): dataset path of each dataset type
+        data_roots (Dict[str, Dict]): dataset path of each dataset type
     """
     task_type = environment.model_template.task_type
     if not _check_hpo_enabled_task(task_type):
         logger.warning(
             "Currently supported task types are classification, detection, segmentation and anomaly"
             f"{task_type} is not supported yet."
         )
-        return None
+        return environment
+
+    if "TORCHELASTIC_RUN_ID" in os.environ:
+        logger.warning("OTX is trained by torchrun. HPO isn't available.")
+        return environment
 
-    hpo_save_path = (Path(args.save_model_to).parent / "hpo").absolute()
+    hpo_save_path = (output / "hpo").absolute()
     hpo_runner = HpoRunner(
         environment,
         len(dataset.get_subset(Subset.TRAINING)),
         len(dataset.get_subset(Subset.VALIDATION)),
         hpo_save_path,
-        args.hpo_time_ratio,
+        hpo_time_ratio,
     )
 
     logger.info("started hyper-parameter optimization")
     best_config = hpo_runner.run_hpo(run_trial, data_roots)
     logger.info("completed hyper-parameter optimization")
 
     env_manager = TaskEnvironmentManager(environment)
@@ -622,29 +628,29 @@
 class Trainer:
     """Class which prepares and trains a model given hyper parameters.
 
     Args:
         hp_config (Dict[str, Any]): hyper parameter to use on training
         report_func (Callable): function to report score
         model_template: model template
-        data_roots (Dict[str, str]): dataset path of each dataset type
+        data_roots (Dict[str, Dict]): dataset path of each dataset type
         task_type (TaskType): OTX task type
         hpo_workdir (Union[str, Path]): work directory for HPO
         initial_weight_name (str): initial model weight name for each trials to load
         metric (str): metric name
     """
 
     # pylint: disable=too-many-arguments, too-many-instance-attributes
 
     def __init__(
         self,
         hp_config: Dict[str, Any],
         report_func: Callable,
         model_template,
-        data_roots: Dict[str, str],
+        data_roots: Dict[str, Dict],
         task_type: TaskType,
         hpo_workdir: Union[str, Path],
         initial_weight_name: str,
         metric: str,
     ):
         self._hp_config = hp_config
         self._report_func = report_func
@@ -762,27 +768,27 @@
         return self._hpo_workdir / "weight" / self._hp_config["id"]
 
 
 def run_trial(
     hp_config: Dict[str, Any],
     report_func: Callable,
     model_template,
-    data_roots: Dict[str, str],
+    data_roots: Dict[str, Dict],
     task_type: TaskType,
     hpo_workdir: Union[str, Path],
     initial_weight_name: str,
     metric: str,
 ):
     """Function to train a model given hyper parameters.
 
     Args:
         hp_config (Dict[str, Any]): hyper parameter to use on training
         report_func (Callable): function to report score
         model_template: model template
-        data_roots (Dict[str, str]): dataset path of each dataset type
+        data_roots (Dict[str, Dict]): dataset path of each dataset type
         task_type (TaskType): OTX task type
         hpo_workdir (Union[str, Path]): work directory for HPO
         initial_weight_name (str): initial model weight name for each trials to load
         metric (str): metric name
     """
     # pylint: disable=too-many-arguments
     trainer = Trainer(
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/importing.py` & `otx-1.2.0rc1/otx/cli/utils/importing.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/utils/io.py` & `otx-1.2.0rc1/otx/cli/utils/io.py`

 * *Files 17% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
 
 import json
 import os
+import os.path as osp
 import re
 import struct
 import tempfile
 from pathlib import Path
 from typing import List, Optional, Tuple
 from zipfile import ZipFile
 
@@ -36,139 +37,174 @@
     ModelEntity,
     ModelOptimizationType,
 )
 from otx.api.serialization.label_mapper import LabelSchemaMapper
 from otx.api.usecases.adapters.model_adapter import ModelAdapter
 from otx.cli.utils.nncf import is_checkpoint_nncf
 
+model_adapter_keys = (
+    "confidence_threshold",
+    "image_threshold",
+    "pixel_threshold",
+    "min",
+    "max",
+    "config.json",
+    "tile_classifier.xml",
+    "tile_classifier.bin",
+)
+
 
 def save_model_data(model: ModelEntity, folder: str) -> None:
     """Saves model data to folder. Folder is created if it does not exist.
 
     Args:
         model (ModelEntity): The model to save.
         folder (str): Path to output folder.
     """
 
     os.makedirs(folder, exist_ok=True)
     for filename, model_adapter in model.model_adapters.items():
-        with open(os.path.join(folder, filename), "wb") as write_file:
+        with open(osp.join(folder, filename), "wb") as write_file:
             write_file.write(model_adapter.data)
 
 
 def read_binary(path: str) -> bytes:
     """Loads binary data stored at path.
 
     Args:
         path (str): A path where to load data from.
 
     Returns:
         bytes: Binary data.
     """
-
-    with open(path, "rb") as read_file:
-        return read_file.read()
+    try:
+        with open(path, "rb") as read_file:
+            return read_file.read()
+    except FileNotFoundError:
+        return b""
 
 
 def read_model(model_configuration: ModelConfiguration, path: str, train_dataset: DatasetEntity) -> ModelEntity:
     """Creates ModelEntity based on model_configuration and data stored at path.
 
     Args:
         model_configuration (ModelConfiguration): ModelConfiguration object.
         path (str): Path to the model data.
         train_dataset (DatasetEntity): DatasetEntity object.
 
     Returns:
         ModelEntity: ModelEntity object.
     """
+
+    if path.endswith(".bin") or path.endswith(".xml"):
+        return read_openvino_model(model_configuration, path, train_dataset)
+    if path.endswith(".pth"):
+        return read_pytorch_model(model_configuration, path, train_dataset)
+    if path.endswith(".zip"):
+        return read_deployed_model(model_configuration, path, train_dataset)
+    raise ValueError(f"Unknown file type: {path}")
+
+
+def read_openvino_model(
+    model_configuration: ModelConfiguration, path: str, train_dataset: DatasetEntity
+) -> ModelEntity:
+    """Reads an OpenVINO model from disk and returns a ModelEntity object."""
+
+    model_adapters = {
+        "openvino.xml": ModelAdapter(read_binary(path[:-4] + ".xml")),
+        "openvino.bin": ModelAdapter(read_binary(path[:-4] + ".bin")),
+    }
+    for key in model_adapter_keys:
+        full_path = osp.join(osp.dirname(path), key)
+        model_adapters[key] = ModelAdapter(read_binary(full_path))
+
+    model = ModelEntity(
+        configuration=model_configuration,
+        model_adapters=model_adapters,
+        train_dataset=train_dataset,
+    )
+
+    return model
+
+
+def read_pytorch_model(model_configuration: ModelConfiguration, path: str, train_dataset: DatasetEntity) -> ModelEntity:
+    """Reads a PyTorch model from disk and returns a ModelEntity object."""
     optimization_type = ModelOptimizationType.NONE
 
-    model_adapter_keys = (
-        "confidence_threshold",
-        "image_threshold",
-        "pixel_threshold",
-        "min",
-        "max",
-        "config.json",
+    model_adapters = {"weights.pth": ModelAdapter(read_binary(path))}
+
+    if is_checkpoint_nncf(path):
+        optimization_type = ModelOptimizationType.NNCF
+
+    # Weights of auxiliary models
+    for key in os.listdir(osp.dirname(path)):
+        if re.match(r"aux_model_[0-9]+\.pth", key):
+            full_path = osp.join(osp.dirname(path), key)
+            model_adapters[key] = ModelAdapter(read_binary(full_path))
+
+    model = ModelEntity(
+        configuration=model_configuration,
+        model_adapters=model_adapters,
+        train_dataset=train_dataset,
+        optimization_type=optimization_type,
     )
 
-    if path.endswith(".bin") or path.endswith(".xml"):
-        # Openvino IR.
+    return model
+
+
+def read_deployed_model(
+    model_configuration: ModelConfiguration, path: str, train_dataset: DatasetEntity
+) -> ModelEntity:
+    """Reads a deployed model from disk and returns a ModelEntity object."""
+
+    with tempfile.TemporaryDirectory() as temp_dir:
+        with ZipFile(path) as myzip:
+            myzip.extractall(temp_dir)
+
+        model_path = osp.join(temp_dir, "model")
         model_adapters = {
-            "openvino.xml": ModelAdapter(read_binary(path[:-4] + ".xml")),
-            "openvino.bin": ModelAdapter(read_binary(path[:-4] + ".bin")),
+            "openvino.xml": ModelAdapter(read_binary(osp.join(model_path, "model.xml"))),
+            "openvino.bin": ModelAdapter(read_binary(osp.join(model_path, "model.bin"))),
         }
-        for key in model_adapter_keys:
-            full_path = os.path.join(os.path.dirname(path), key)
-            if os.path.exists(full_path):
-                model_adapters[key] = ModelAdapter(read_binary(full_path))
-            else:
-                model_adapters[key] = ModelAdapter(bytes())
-    elif path.endswith(".pth"):
-        # PyTorch
-        model_adapters = {"weights.pth": ModelAdapter(read_binary(path))}
-
-        if is_checkpoint_nncf(path):
-            optimization_type = ModelOptimizationType.NNCF
-
-        # Weights of auxiliary models
-        for key in os.listdir(os.path.dirname(path)):
-            if re.match(r"aux_model_[0-9]+\.pth", key):
-                full_path = os.path.join(os.path.dirname(path), key)
-                model_adapters[key] = ModelAdapter(read_binary(full_path))
 
-    elif path.endswith(".zip"):
-        # Deployed code.
-        with tempfile.TemporaryDirectory() as temp_dir:
-            with ZipFile(path) as myzip:
-                myzip.extractall(temp_dir)
-
-            model_path = os.path.join(temp_dir, "model", "model")
-            model_adapters = {
-                "openvino.xml": ModelAdapter(read_binary(model_path + ".xml")),
-                "openvino.bin": ModelAdapter(read_binary(model_path + ".bin")),
-            }
-
-            config_path = os.path.join(temp_dir, "model", "config.json")
-            with open(config_path, encoding="UTF-8") as f:
-                model_parameters = json.load(f)["model_parameters"]
-            model_adapters["config.json"] = ModelAdapter(read_binary(config_path))
-
-            for key in model_adapter_keys:
-                if key in model_parameters:
-                    model_adapters[key] = ModelAdapter(struct.pack("f", model_parameters[key]))
-    else:
-        raise ValueError(f"Unknown file type: {path}")
+        config_path = osp.join(model_path, "config.json")
+        with open(config_path, encoding="UTF-8") as f:
+            model_parameters = json.load(f)["model_parameters"]
+        model_adapters["config.json"] = ModelAdapter(read_binary(config_path))
+
+        for key in model_adapter_keys:
+            if key in model_parameters:
+                model_adapters[key] = ModelAdapter(struct.pack("f", model_parameters[key]))
+            if key.endswith(".xml") or key.endswith(".bin"):
+                model_adapters[key] = ModelAdapter(read_binary(osp.join(model_path, key)))
 
     model = ModelEntity(
         configuration=model_configuration,
         model_adapters=model_adapters,
         train_dataset=train_dataset,
-        optimization_type=optimization_type,
     )
-
     return model
 
 
 def read_label_schema(path: str) -> LabelSchemaEntity:
     """Reads serialized LabelSchema and returns deserialized LabelSchema.
 
     Args:
         path (str): Path to model. It assmues that the `label_schema.json` is at the same location as the model.
 
     Returns:
         LabelSchemaEntity: Desetialized LabelSchemaEntity.
     """
 
     if any(path.endswith(extension) for extension in (".xml", ".bin", ".pth")):
-        with open(os.path.join(os.path.dirname(path), "label_schema.json"), encoding="UTF-8") as read_file:
+        with open(osp.join(osp.dirname(path), "label_schema.json"), encoding="UTF-8") as read_file:
             serialized_label_schema = json.load(read_file)
     elif path.endswith(".zip"):
         with ZipFile(path) as read_zip_file:
-            with read_zip_file.open(os.path.join("model", "config.json")) as read_file:
+            with read_zip_file.open(osp.join("model", "config.json")) as read_file:
                 serialized_label_schema = json.load(read_file)["model_parameters"]["labels"]
     return LabelSchemaMapper().backward(serialized_label_schema)
 
 
 def get_image_files(root_dir: str) -> Optional[List[Tuple[str, str]]]:
     """Recursively get all image file paths from given root_dir."""
     img_data_formats = (
@@ -209,27 +245,27 @@
     """Saves processed saliency map (with image overlay) or raw saliency map."""
     if process_saliency_maps:
         # Saves processed saliency map
         overlay = img * weight + saliency_map * (1 - weight)
         overlay[overlay > 255] = 255
         overlay = overlay.astype(np.uint8)
 
-        cv2.imwrite(f"{os.path.join(save_dir, fname)}_saliency_map.png", saliency_map)
-        cv2.imwrite(f"{os.path.join(save_dir, fname)}_overlay_img.png", overlay)
+        cv2.imwrite(f"{osp.join(save_dir, fname)}_saliency_map.png", saliency_map)
+        cv2.imwrite(f"{osp.join(save_dir, fname)}_overlay_img.png", overlay)
     else:
         # Saves raw, low-resolution saliency map
-        cv2.imwrite(f"{os.path.join(save_dir, fname)}_saliency_map.tiff", saliency_map)
+        cv2.imwrite(f"{osp.join(save_dir, fname)}_saliency_map.tiff", saliency_map)
 
 
 def get_explain_dataset_from_filelist(image_files: list):
     """Get explain dataset with empty annotation."""
     empty_annotation = AnnotationSceneEntity(annotations=[], kind=AnnotationSceneKind.PREDICTION)
     items = []
     for root_dir, filename in image_files:
-        frame = cv2.imread(os.path.join(root_dir, filename))
+        frame = cv2.imread(osp.join(root_dir, filename))
         item = DatasetItemEntity(
             media=Image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),
             annotation_scene=empty_annotation,
         )
         items.append(item)
     explain_dataset = DatasetEntity(items=items)
     return explain_dataset
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/multi_gpu.py` & `otx-1.2.0rc1/otx/cli/utils/multi_gpu.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 import os
 import signal
 import socket
 import sys
 import threading
 import time
 from contextlib import closing
-from typing import Callable, List, Optional
+from typing import Callable, List, Optional, Union
 
 import psutil
 import torch
 import torch.distributed as dist
 import torch.multiprocessing as mp
 
 from otx.api.configuration import ConfigurableParameters
@@ -70,37 +70,42 @@
 
     if wrong_gpus:
         logger.warning(f"Wrong gpu indices are excluded. {','.join([str(val) for val in gpu_ids])} GPU will be used.")
 
     return gpu_ids
 
 
-def set_arguments_to_argv(key: str, value: Optional[str] = None, after_params: bool = False):
+def set_arguments_to_argv(keys: Union[str, List[str]], value: Optional[str] = None, after_params: bool = False):
     """Add arguments at proper position in `sys.argv`.
 
     Args:
-        key (str): arguement key.
+        keys (str or List[str]): arguement keys.
         value (str or None): argument value.
         after_params (bool): whether argument should be after `param` or not.
     """
-    if key in sys.argv:
+    if not isinstance(keys, list):
+        keys = [keys]
+    for key in keys:
+        if key in sys.argv:
+            if value is not None:
+                sys.argv[sys.argv.index(key) + 1] = value
+            return
+
+    key = keys[0]
+    if not after_params and "params" in sys.argv:
+        sys.argv.insert(sys.argv.index("params"), key)
         if value is not None:
-            sys.argv[sys.argv.index(key) + 1] = value
+            sys.argv.insert(sys.argv.index("params"), value)
     else:
-        if not after_params and "params" in sys.argv:
-            sys.argv.insert(sys.argv.index("params"), key)
-            if value is not None:
-                sys.argv.insert(sys.argv.index("params"), value)
+        if after_params and "params" not in sys.argv:
+            sys.argv.append("params")
+        if value is not None:
+            sys.argv.extend([key, value])
         else:
-            if after_params and "params" not in sys.argv:
-                sys.argv.append("params")
-            if value is not None:
-                sys.argv.extend([key, value])
-            else:
-                sys.argv.append(key)
+            sys.argv.append(key)
 
 
 def is_multigpu_child_process():
     """Check current process is a child process for multi GPU training."""
     return dist.is_initialized() and os.environ["LOCAL_RANK"] != "0"
 
 
@@ -111,14 +116,16 @@
         train_func (Callable): model training function.
         gpu_ids (str): GPU indices to use. Format should be Comma-separated indices.
         rdzv_endpoint (str): Rendezvous endpoint for multi-node training.
         base_rank (int): Base rank of the worker.
         world_size (int): Total number of workers in a worker group.
     """
 
+    # pylint: disable=too-many-instance-attributes
+
     def __init__(
         self,
         train_func: Callable,
         gpu_ids: str,
         rdzv_endpoint: str = "localhost:0",
         base_rank: int = 0,
         world_size: int = 0,
@@ -135,35 +142,43 @@
         self._gpu_ids = get_gpu_ids(gpu_ids)
         self._rdzv_endpoint = rdzv_endpoint
         self._base_rank = base_rank
         if world_size == 0:
             world_size = len(self._gpu_ids)
         self._world_size = world_size
         self._main_pid = os.getpid()
-        self._processes: Optional[List[mp.Process]] = None
+        self._processes: List[mp.Process] = []
 
     def is_available(self) -> bool:
         """Check multi GPU training is available.
 
         Returns:
             bool:
                 whether multi GPU training is available.
         """
-        return len(self._gpu_ids) > 1
+        return (
+            len(self._gpu_ids) > 1
+            and "TORCHELASTIC_RUN_ID"
+            not in os.environ  # If otx is executed by torchrun, then otx multi gpu interface is disabled.
+        )
 
     def setup_multi_gpu_train(
         self,
         output_path: str,
         optimized_hyper_parameters: Optional[ConfigurableParameters] = None,
     ):
         """Carry out what should be done to run multi GPU training.
 
         Args:
             output_path (str): output path where task output are saved.
             optimized_hyper_parameters (ConfigurableParameters or None): hyper parameters reflecting HPO result.
+
+        Returns:
+            str:
+                If output_path is None, make a temporary directory and return it.
         """
         if optimized_hyper_parameters is not None:  # if HPO is executed, optimized HPs are applied to child processes
             self._set_optimized_hp_for_child_process(optimized_hyper_parameters)
 
         self._processes = self._spawn_multi_gpu_processes(output_path)
 
         signal.signal(signal.SIGINT, self._terminate_signal_handler)
@@ -171,17 +186,17 @@
 
         self.initialize_multigpu_train(self._rdzv_endpoint, self._base_rank, 0, self._gpu_ids, self._world_size)
 
         threading.Thread(target=self._check_child_processes_alive, daemon=True).start()
 
     def finalize(self):
         """Join all child processes."""
-        if self._processes is not None:
-            for p in self._processes:
-                p.join()
+        for p in self._processes:
+            if p.join(10) is None and p.exitcode is None:
+                p.kill()
 
     @staticmethod
     def initialize_multigpu_train(
         rdzv_endpoint: str,
         rank: int,
         local_rank: int,
         gpu_ids: List[int],
@@ -200,17 +215,14 @@
         host, port = rdzv_endpoint.split(":")
         os.environ["MASTER_ADDR"] = host
         os.environ["MASTER_PORT"] = port
         os.environ["LOCAL_WORLD_SIZE"] = str(len(gpu_ids))
         os.environ["WORLD_SIZE"] = str(world_size)
         os.environ["LOCAL_RANK"] = str(local_rank)
         os.environ["RANK"] = str(rank)
-        torch.cuda.set_device(gpu_ids[local_rank])
-        dist.init_process_group(backend="nccl", world_size=world_size, rank=rank)
-        logger.info(f"dist info world_size = {dist.get_world_size()}, rank = {dist.get_rank()}")
 
     @staticmethod
     def run_child_process(
         train_func: Callable,
         output_path: str,
         rdzv_endpoint: str,
         rank: int,
@@ -234,15 +246,15 @@
         mp.set_start_method(method=None, force=True)
 
         gpus_arg_idx = sys.argv.index("--gpus")
         for _ in range(2):
             sys.argv.pop(gpus_arg_idx)
         if "--enable-hpo" in sys.argv:
             sys.argv.remove("--enable-hpo")
-        set_arguments_to_argv("--work-dir", output_path)
+        set_arguments_to_argv(["-o", "--output"], output_path)
         set_arguments_to_argv("--rdzv-endpoint", rdzv_endpoint)
 
         MultiGPUManager.initialize_multigpu_train(rdzv_endpoint, rank, local_rank, gpu_ids, world_size)
 
         threading.Thread(target=MultiGPUManager.check_parent_processes_alive, daemon=True).start()
 
         train_func()
@@ -259,14 +271,23 @@
 
         logger.warning("Parent process is terminated abnormally. Process exits.")
         cur_process.kill()
 
     def _spawn_multi_gpu_processes(self, output_path: str) -> List[mp.Process]:
         processes = []
         ctx = mp.get_context("spawn")
+
+        # set CUDA_VISIBLE_DEVICES to make child process use proper GPU
+        origin_cuda_visible_devices = os.environ.get("CUDA_VISIBLE_DEVICES")
+        if origin_cuda_visible_devices is not None:
+            cuda_visible_devices = origin_cuda_visible_devices.split(",")
+        else:
+            cuda_visible_devices = [str(i) for i in range(torch.cuda.device_count())]
+        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([cuda_visible_devices[gpu_idx] for gpu_idx in self._gpu_ids])
+
         for rank in range(1, len(self._gpu_ids)):
             task_p = ctx.Process(
                 target=MultiGPUManager.run_child_process,
                 args=(
                     self._train_func,
                     output_path,
                     self._rdzv_endpoint,
@@ -275,14 +296,19 @@
                     self._gpu_ids,
                     self._world_size,
                 ),
             )
             task_p.start()
             processes.append(task_p)
 
+        if origin_cuda_visible_devices is None:
+            del os.environ["CUDA_VISIBLE_DEVICES"]
+        else:
+            os.environ["CUDA_VISIBLE_DEVICES"] = origin_cuda_visible_devices
+
         return processes
 
     def _terminate_signal_handler(self, signum, _frame):
         # This code prevents child processses from being killed unintentionally by proccesses forked from main process
         if self._main_pid != os.getpid():
             sys.exit()
 
@@ -290,17 +316,14 @@
 
         singal_name = {2: "SIGINT", 15: "SIGTERM"}
         logger.warning(f"{singal_name[signum]} is sent. process exited.")
 
         sys.exit(1)
 
     def _kill_child_process(self):
-        if self._processes is None:
-            return
-
         for process in self._processes:
             if process.is_alive():
                 logger.warning(f"Kill child process {process.pid}")
                 process.kill()
 
     def _set_optimized_hp_for_child_process(self, hyper_parameters: ConfigurableParameters):
         set_arguments_to_argv(
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/nncf.py` & `otx-1.2.0rc1/otx/cli/utils/nncf.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/cli/utils/parser.py` & `otx-1.2.0rc1/otx/cli/utils/parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -48,20 +48,20 @@
 
         if match is None:
             raise ValueError(f"Cannot parse {mem_size} string.")
 
         units = {
             "": 1,
             "B": 1,
-            "KB": 2**10,
-            "MB": 2**20,
-            "GB": 2**30,
-            "KIB": 10**3,
-            "MIB": 10**6,
-            "GIB": 10**9,
+            "KIB": 2**10,
+            "MIB": 2**20,
+            "GIB": 2**30,
+            "KB": 10**3,
+            "MB": 10**6,
+            "GB": 10**9,
             "K": 2**10,
             "M": 2**20,
             "G": 2**30,
         }
 
         number, unit = int(match.group(1)), match.group(2).upper()
```

### Comparing `otx-1.1.2rc1/otx/cli/utils/telemetry.py` & `otx-1.2.0rc1/otx/cli/utils/telemetry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/__init__.py` & `otx-1.2.0rc1/otx/core/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/__init__.py` & `otx-1.2.0rc1/otx/core/data/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/__init__.py` & `otx-1.2.0rc1/otx/core/data/adapter/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/action_dataset_adapter.py` & `otx-1.2.0rc1/otx/core/data/adapter/action_dataset_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/anomaly_dataset_adapter.py` & `otx-1.2.0rc1/otx/core/data/adapter/anomaly_dataset_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/base_dataset_adapter.py` & `otx-1.2.0rc1/otx/core/data/adapter/base_dataset_adapter.py`

 * *Files identical despite different names*

```diff
@@ -116,17 +116,16 @@
 
             # If validation is manually defined --> set the validation data according to user's input
             if val_data_roots:
                 val_data_candidates = self._detect_dataset_format(path=val_data_roots)
                 val_data_type = self._select_data_type(val_data_candidates)
                 val_dataset = DatumaroDataset.import_from(val_data_roots, format=val_data_type)
                 dataset[Subset.VALIDATION] = self._get_subset_data("val", val_dataset)
-            else:
-                if "val" in train_dataset.subsets():
-                    dataset[Subset.VALIDATION] = self._get_subset_data("val", train_dataset)
+            elif "val" in train_dataset.subsets():
+                dataset[Subset.VALIDATION] = self._get_subset_data("val", train_dataset)
 
         if test_data_roots is not None and train_data_roots is None:
             self.data_type_candidates = self._detect_dataset_format(path=test_data_roots)
             self.data_type = self._select_data_type(self.data_type_candidates)
             test_dataset = DatumaroDataset.import_from(test_data_roots, format=self.data_type)
             dataset[Subset.TESTING] = self._get_subset_data("test", test_dataset)
             self.is_train_phase = False
```

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/classification_dataset_adapter.py` & `otx-1.2.0rc1/otx/core/data/adapter/classification_dataset_adapter.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 
 # pylint: disable=invalid-name, too-many-locals, no-member
 from typing import List, Union
 
 from datumaro.components.annotation import AnnotationType, LabelCategories
 
 from otx.api.entities.annotation import Annotation
-from otx.api.entities.dataset_item import DatasetItemEntity
+from otx.api.entities.dataset_item import DatasetItemEntityWithID
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.image import Image
 from otx.api.entities.label import LabelEntity
 from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.rectangle import Rectangle
 from otx.core.data.adapter.base_dataset_adapter import BaseDatasetAdapter
@@ -34,27 +34,29 @@
         self.category_items = label_information["category_items"]
         self.label_groups = label_information["label_groups"]
         self.label_entities = label_information["label_entities"]
 
         # Generate label schema
         self.label_schema = self._generate_classification_label_schema(self.label_groups, self.label_entities)
 
-        # Set the DatasetItemEntity
-        dataset_items: List[DatasetItemEntity] = []
+        # Set the DatasetItemEntityWithID
+        dataset_items: List[DatasetItemEntityWithID] = []
         for subset, subset_data in self.dataset.items():
             for _, datumaro_items in subset_data.subsets().items():
                 for datumaro_item in datumaro_items:
                     image = Image(file_path=datumaro_item.media.path)
                     datumaro_labels = []
                     for ann in datumaro_item.annotations:
                         if ann.type == AnnotationType.label:
                             datumaro_labels.append(ann.label)
 
                     shapes = self._get_cls_shapes(datumaro_labels)
-                    dataset_item = DatasetItemEntity(image, self._get_ann_scene_entity(shapes), subset=subset)
+                    dataset_item = DatasetItemEntityWithID(
+                        image, self._get_ann_scene_entity(shapes), subset=subset, id_=datumaro_item.id
+                    )
 
                     dataset_items.append(dataset_item)
 
         return DatasetEntity(items=dataset_items)
 
     def _get_cls_shapes(self, datumaro_labels: List[int]) -> List[Annotation]:
         """Converts a list of datumaro labels to Annotation object."""
```

### Comparing `otx-1.1.2rc1/otx/core/data/adapter/detection_dataset_adapter.py` & `otx-1.2.0rc1/otx/core/data/adapter/detection_dataset_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/caching/mem_cache_handler.py` & `otx-1.2.0rc1/otx/core/data/caching/mem_cache_handler.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/caching/mem_cache_hook.py` & `otx-1.2.0rc1/otx/core/data/caching/mem_cache_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/manager/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-"""OTX Core Data Utils."""
-
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
-#
```

### Comparing `otx-1.1.2rc1/otx/core/data/manager/dataset_manager.py` & `otx-1.2.0rc1/otx/core/data/manager/dataset_manager.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/data/pipelines/load_image_from_otx_dataset.py` & `otx-1.2.0rc1/otx/core/data/pipelines/load_image_from_otx_dataset.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 from tempfile import TemporaryDirectory
 from typing import Any, Dict, Tuple
 
 import numpy as np
 
 from otx.algorithms.common.utils.data import get_image
-from otx.api.utils.argument_checks import check_input_parameters_type
 
 from ..caching import MemCacheHandlerError, MemCacheHandlerSingleton
 
 _CACHE_DIR = TemporaryDirectory(prefix="img-cache-")  # pylint: disable=consider-using-with
 
 # TODO: refactoring to common modules
 # TODO: refactoring to Sphinx style.
@@ -26,15 +25,14 @@
         results['dataset_item']: dataset_item from which to load the image
         results['dataset_id']: id of the dataset to which the item belongs
         results['index']: index of the item in the dataset
 
     :param to_float32: optional bool, True to convert images to fp32. defaults to False
     """
 
-    @check_input_parameters_type()
     def __init__(self, to_float32: bool = False):
         self.to_float32 = to_float32
         try:
             self.mem_cache_handler = MemCacheHandlerSingleton.get()
         except MemCacheHandlerError:
             # Create a null handler
             MemCacheHandlerSingleton.create(mode="null", mem_size=0)
@@ -44,15 +42,14 @@
     def _get_unique_key(results: Dict[str, Any]) -> Tuple:
         # TODO: We should improve it by assigning an unique id to DatasetItemEntity.
         # This is because there is a case which
         # d_item.media.path is None, but d_item.media.data is not None
         d_item = results["dataset_item"]
         return d_item.media.path, d_item.roi.id
 
-    @check_input_parameters_type()
     def __call__(self, results: Dict[str, Any]):
         """Callback function of LoadImageFromOTXDataset."""
         key = self._get_unique_key(results)
 
         img = self.mem_cache_handler.get(key)
 
         if img is None:
@@ -81,9 +78,11 @@
         num_channels = 1 if len(shape) < 3 else shape[2]
         results["img_norm_cfg"] = dict(
             mean=np.zeros(num_channels, dtype=np.float32),
             std=np.ones(num_channels, dtype=np.float32),
             to_rgb=False,
         )
         results["img_fields"] = ["img"]
+        results["entity_id"] = results.get("entity_id")
+        results["label_id"] = results.get("label_id")
 
         return results
```

### Comparing `otx-1.1.2rc1/otx/core/ov/graph/graph.py` & `otx-1.2.0rc1/otx/core/ov/graph/graph.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/graph/parsers/cls/cls_base_parser.py` & `otx-1.2.0rc1/otx/core/ov/graph/parsers/cls/cls_base_parser.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/graph/parsers/parser.py` & `otx-1.2.0rc1/otx/core/ov/graph/parsers/parser.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/graph/utils.py` & `otx-1.2.0rc1/otx/core/ov/graph/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/models/mmov_model.py` & `otx-1.2.0rc1/otx/core/ov/models/mmov_model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/models/ov_model.py` & `otx-1.2.0rc1/otx/core/ov/models/ov_model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/models/parser_mixin.py` & `otx-1.2.0rc1/otx/core/ov/models/parser_mixin.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/omz_wrapper.py` & `otx-1.2.0rc1/otx/core/ov/omz_wrapper.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,17 +16,17 @@
 from openvino.model_zoo import _common, _reporting
 from openvino.model_zoo._configuration import load_models
 from openvino.model_zoo.download_engine.downloader import Downloader
 from openvino.model_zoo.download_engine.postprocessing import PostprocUnpackArchive
 from openvino.model_zoo.omz_converter import ModelOptimizerProperties, convert_to_onnx
 from requests.exceptions import HTTPError
 
+from otx.core.file import OTX_CACHE
+
 # pylint: disable=too-many-locals, too-many-branches
-OTX_CACHE = os.path.expanduser(os.getenv("OTX_CACHE", os.path.join(os.getenv("XDG_CACHE_HOME", "~/.cache"), "otx")))
-os.makedirs(OTX_CACHE, exist_ok=True)
 OMZ_CACHE = os.path.join(OTX_CACHE, "omz")
 os.makedirs(OMZ_CACHE, exist_ok=True)
 
 
 OMZ_PUBLIC_MODELS: Dict[str, List[str]] = dict(
     cls=[
         "alexnet",
```

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/__init__.py` & `otx-1.2.0rc1/otx/core/ov/ops/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/activations.py` & `otx-1.2.0rc1/otx/core/ov/ops/activations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/arithmetics.py` & `otx-1.2.0rc1/otx/core/ov/ops/arithmetics.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/builder.py` & `otx-1.2.0rc1/otx/core/ov/ops/builder.py`

 * *Files 0% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
         def wrap(obj):
             layer_name = name
             if layer_name is None:
                 layer_name = obj.__name__
             layer_type = obj.TYPE
             layer_version = obj.VERSION
-            assert layer_type != "" and layer_version >= 0
+            assert layer_type and layer_version >= 0
             if self._add_name_as_attr:
                 setattr(obj, self.REGISTERED_NAME_ATTR, layer_name)
             self._register(obj, layer_name, layer_type, layer_version)
             return obj
 
         return wrap
```

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/convolutions.py` & `otx-1.2.0rc1/otx/core/ov/ops/convolutions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/generation.py` & `otx-1.2.0rc1/otx/core/ov/ops/generation.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/image_processings.py` & `otx-1.2.0rc1/otx/core/ov/ops/image_processings.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/infrastructures.py` & `otx-1.2.0rc1/otx/core/ov/ops/infrastructures.py`

 * *Files 0% similar despite different names*

```diff
@@ -86,15 +86,15 @@
 
     @classmethod
     def from_ov(cls, ov_op):
         """ParameterV0's from_ov function."""
         op_type = ov_op.get_type_name()
         op_version = ov_op.get_version()
         op_name = get_op_name(ov_op)
-        assert cls.TYPE != "" and cls.VERSION >= 0
+        assert cls.TYPE and cls.VERSION >= 0
         assert op_type == cls.TYPE
         assert op_version == cls.VERSION
 
         attrs = ov_op.get_attributes()
         if "shape" not in attrs:
             shapes = []
             for output in ov_op.outputs():
@@ -216,15 +216,15 @@
 
     @classmethod
     def from_ov(cls, ov_op):
         """ConstantV0's from_ov function."""
         op_type = ov_op.get_type_name()
         op_version = ov_op.get_version()
         op_name = get_op_name(ov_op)
-        assert cls.TYPE != "" and cls.VERSION >= 0
+        assert cls.TYPE and cls.VERSION >= 0
         assert op_type == cls.TYPE
         assert op_version == cls.VERSION
 
         attrs = ov_op.get_attributes()
         attrs["shape"] = tuple(attrs["shape"])
 
         data = ov_op.get_data()
```

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/matmuls.py` & `otx-1.2.0rc1/otx/core/ov/ops/matmuls.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/modules/op_module.py` & `otx-1.2.0rc1/otx/core/ov/ops/modules/op_module.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/movements.py` & `otx-1.2.0rc1/otx/core/ov/ops/movements.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/normalizations.py` & `otx-1.2.0rc1/otx/core/ov/ops/normalizations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/object_detections.py` & `otx-1.2.0rc1/otx/core/ov/ops/object_detections.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/op.py` & `otx-1.2.0rc1/otx/core/ov/ops/op.py`

 * *Files 1% similar despite different names*

```diff
@@ -42,15 +42,15 @@
 
     @classmethod
     def from_ov(cls, ov_op):
         """Operation's from_ov function."""
         op_type = ov_op.get_type_name()
         op_version = ov_op.get_version()
         op_name = get_op_name(ov_op)
-        assert cls.TYPE != "" and cls.VERSION >= 0
+        assert cls.TYPE and cls.VERSION >= 0
         assert op_type == cls.TYPE
         assert op_version == cls.VERSION
 
         attrs = ov_op.get_attributes()
         if "shape" not in attrs:
             shapes = []
             for output in ov_op.outputs():
```

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/poolings.py` & `otx-1.2.0rc1/otx/core/ov/ops/poolings.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/reductions.py` & `otx-1.2.0rc1/otx/core/ov/ops/reductions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/shape_manipulations.py` & `otx-1.2.0rc1/otx/core/ov/ops/shape_manipulations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/sorting_maximization.py` & `otx-1.2.0rc1/otx/core/ov/ops/sorting_maximization.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/type_conversions.py` & `otx-1.2.0rc1/otx/core/ov/ops/type_conversions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/ops/utils.py` & `otx-1.2.0rc1/otx/core/ov/ops/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/registry.py` & `otx-1.2.0rc1/otx/core/ov/registry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/ov/utils.py` & `otx-1.2.0rc1/otx/core/ov/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/core/patcher.py` & `otx-1.2.0rc1/otx/core/patcher.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,27 +38,26 @@
         n_args = len(inspect.getfullargspec(obj_cls.__getattribute__)[0])
         if n_args == 1:
             try:
                 fn = obj_cls.__getattribute__(fn_name)
             except AttributeError:
                 return
             self._patch_module_fn(obj_cls, fn_name, fn, wrapper, force)
+        elif inspect.isclass(obj_cls):
+            try:
+                fn = obj_cls.__getattribute__(obj_cls, fn_name)  # type: ignore
+            except AttributeError:
+                return
+            self._patch_class_fn(obj_cls, fn_name, fn, wrapper, force)
         else:
-            if inspect.isclass(obj_cls):
-                try:
-                    fn = obj_cls.__getattribute__(obj_cls, fn_name)  # type: ignore
-                except AttributeError:
-                    return
-                self._patch_class_fn(obj_cls, fn_name, fn, wrapper, force)
-            else:
-                try:
-                    fn = obj_cls.__getattribute__(fn_name)
-                except AttributeError:
-                    return
-                self._patch_instance_fn(obj_cls, fn_name, fn, wrapper, force)
+            try:
+                fn = obj_cls.__getattribute__(fn_name)
+            except AttributeError:
+                return
+            self._patch_instance_fn(obj_cls, fn_name, fn, wrapper, force)
 
     def unpatch(self, obj_cls=None, depth=0):
         """Undo monkey patch."""
 
         def _unpatch(obj, fn_name, key, depth):
             if depth == 0:
                 depth = len(self._patched[key])
@@ -74,20 +73,19 @@
             setattr(obj, fn_name, origin_fn)
 
         if obj_cls is not None:
             obj_cls, fn_name = self.import_obj(obj_cls)
             n_args = len(inspect.getfullargspec(obj_cls.__getattribute__)[0])
             if n_args == 1:
                 key = (obj_cls.__name__, fn_name)
+            elif inspect.isclass(obj_cls):
+                obj_cls_path = obj_cls.__module__ + "." + obj_cls.__name__
+                key = (obj_cls_path, fn_name)
             else:
-                if inspect.isclass(obj_cls):
-                    obj_cls_path = obj_cls.__module__ + "." + obj_cls.__name__
-                    key = (obj_cls_path, fn_name)
-                else:
-                    key = (id(obj_cls), fn_name)
+                key = (id(obj_cls), fn_name)
             _unpatch(obj_cls, fn_name, key, depth)
             return
 
         for key in list(self._patched.keys()):
             obj, fn_name = key
             if isinstance(obj, int):
                 obj = ctypes.cast(obj, ctypes.py_object).value
```

### Comparing `otx-1.1.2rc1/otx/hpo/hpo_base.py` & `otx-1.2.0rc1/otx/hpo/hpo_base.py`

 * *Files 1% similar despite different names*

```diff
@@ -109,15 +109,15 @@
         self.mode = mode
         self.num_trials = num_trials
         self.num_workers = num_workers
         self.num_full_iterations = num_full_iterations
         self.non_pure_train_ratio = non_pure_train_ratio
         self.full_dataset_size = full_dataset_size
         self.expected_time_ratio = expected_time_ratio
-        self.maximum_resource = maximum_resource
+        self.maximum_resource: Optional[Union[int, float]] = maximum_resource
         self.subset_ratio = subset_ratio
         self.min_subset_size = min_subset_size
         self.resume = resume
         self.hpo_status: dict = {}
         self.metric = metric
         self.acceptable_additional_time_ratio = acceptable_additional_time_ratio
         if prior_hyper_parameters is None:
```

### Comparing `otx-1.1.2rc1/otx/hpo/hpo_runner.py` & `otx-1.2.0rc1/otx/hpo/hpo_runner.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/hpo/hyperband.py` & `otx-1.2.0rc1/otx/hpo/hyperband.py`

 * *Files 1% similar despite different names*

```diff
@@ -219,17 +219,16 @@
                         best_score = trial_score
             else:
                 num_promoted_trial += 1
 
         if asynchronous_sha:
             if (num_promoted_trial + num_finished_trial) // self._reduction_factor > num_promoted_trial:
                 return best_trial
-        else:
-            if self.is_done() and self._num_required_trial // self._reduction_factor > num_promoted_trial:
-                return best_trial
+        elif self.is_done() and self._num_required_trial // self._reduction_factor > num_promoted_trial:
+            return best_trial
 
         return None
 
     def get_next_trial(self) -> Optional[AshaTrial]:
         """Get next trial to trian.
 
         Returns:
```

### Comparing `otx-1.1.2rc1/otx/hpo/resource_manager.py` & `otx-1.2.0rc1/otx/hpo/resource_manager.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/hpo/search_space.py` & `otx-1.2.0rc1/otx/hpo/search_space.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/hpo/utils.py` & `otx-1.2.0rc1/otx/hpo/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_inst_seg.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_inst_seg.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_otx.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_otx.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/coco_ubt.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/coco_ubt.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/custom_seg.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/custom_seg.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/data_seg.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/data_seg.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_inst_seg_pipeline.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_inst_seg_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_otx_pipeline.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_otx_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/coco_resize_hflip_pad.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/coco_resize_hflip_pad.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/incr_seg.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/incr_seg.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/twocrop_pipeline.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/twocrop_pipeline.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/pipelines/ubt.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/pipelines/ubt.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/selfsl_cls_data.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/selfsl_cls_data.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/data/selfsl_seg_data.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/data/selfsl_seg_data.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/models/cls_supcon.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/models/cls_supcon.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/encoder_decoder.ote.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/encoder_decoder.ote.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/_base_/models/segmentors/seg_class_incr.py` & `otx-1.2.0rc1/otx/recipes/stages/_base_/models/segmentors/seg_class_incr.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/classification/selfsl.yaml` & `otx-1.2.0rc1/otx/recipes/stages/classification/selfsl.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/detection/incremental.py` & `otx-1.2.0rc1/otx/recipes/stages/detection/incremental.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/detection/semisl.py` & `otx-1.2.0rc1/otx/recipes/stages/detection/semisl.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/detection/train.py` & `otx-1.2.0rc1/otx/recipes/stages/detection/train.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/incremental.py` & `otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/incremental.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/instance-segmentation/train.py` & `otx-1.2.0rc1/otx/recipes/stages/instance-segmentation/train.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/segmentation/incremental.py` & `otx-1.2.0rc1/otx/recipes/stages/segmentation/incremental.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/segmentation/selfsl.py` & `otx-1.2.0rc1/otx/recipes/stages/segmentation/selfsl.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/segmentation/semisl.py` & `otx-1.2.0rc1/otx/recipes/stages/segmentation/semisl.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx/recipes/stages/segmentation/train.py` & `otx-1.2.0rc1/otx/recipes/stages/segmentation/train.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/otx.egg-info/PKG-INFO` & `otx-1.2.0rc1/otx.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 Metadata-Version: 2.1
 Name: otx
-Version: 1.1.2rc1
+Version: 1.2.0rc1
 Summary: OpenVINO Training Extensions: Train, Evaluate, Optimize, Deploy Computer Vision Models via OpenVINO
 Home-page: https://github.com/openvinotoolkit/training_extensions
 Author: OpenVINO Training Extensions Contributors
 License: Apache License 2.0
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Cython
 Description-Content-Type: text/markdown
 Provides-Extra: action
 Provides-Extra: anomaly
 Provides-Extra: classification
 Provides-Extra: detection
 Provides-Extra: segmentation
@@ -23,22 +24,28 @@
 <div align="center">
 
 # OpenVINO Training Extensions
 
 ---
 
 [Key Features](#key-features) 
-[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/index.html) 
-[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/index.html) 
+[Quick Start](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/index.html) 
+[Documentation](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/index.html) 
 [License](#license)
 
 [![PyPI](https://img.shields.io/pypi/v/otx)](https://pypi.org/project/otx)
+
+<!-- markdownlint-disable MD042 -->
+
 [![python](https://img.shields.io/badge/python-3.8%2B-green)]()
 [![pytorch](https://img.shields.io/badge/pytorch-1.13.1%2B-orange)]()
 [![openvino](https://img.shields.io/badge/openvino-2022.3.0-purple)]()
+
+<!-- markdownlint-enable  MD042 -->
+
 [![Codacy Badge](https://app.codacy.com/project/badge/Grade/f9ba89f9ea2a47eeb9d52c2acc311e6c)](https://www.codacy.com/gh/openvinotoolkit/training_extensions/dashboard?utm_source=github.com&utm_medium=referral&utm_content=openvinotoolkit/training_extensions&utm_campaign=Badge_Grade)
 [![Codecov](https://codecov.io/gh/openvinotoolkit/training_extensions/branch/develop/graph/badge.svg?token=9HVFNMPFGD)](https://codecov.io/gh/openvinotoolkit/training_extensions)
 [![Pre-Merge Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/pre_merge.yml)
 [![Nightly Test](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/daily.yml)
 [![Build Docs](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml/badge.svg)](https://github.com/openvinotoolkit/training_extensions/actions/workflows/docs.yml)
 [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
 [![Downloads](https://static.pepy.tech/personalized-badge/otx?period=total&units=international_system&left_color=grey&right_color=green&left_text=PyPI%20Downloads)](https://pepy.tech/project/otx)
@@ -67,69 +74,60 @@
 - **Classification**, including multi-class, multi-label and hierarchical image classification tasks.
 - **Object detection** including rotated bounding box support
 - **Semantic segmentation**
 - **Instance segmentation** including tiling algorithm support
 - **Action recognition** including action classification and detection
 - **Anomaly recognition** tasks including anomaly classification, detection and segmentation
 
-OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/algorithms/index.html):
+OpenVINO Training Extensions supports the [following learning methods](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/algorithms/index.html):
 
 - **Supervised**, incremental training, which includes class incremental scenario and contrastive learning for classification and semantic segmentation tasks
 - **Semi-supervised learning**
 - **Self-supervised learning**
 
 OpenVINO Training Extensions will provide the following features in coming releases:
 
 - **Distributed training** to accelerate the training process when you have multiple GPUs
 - **Half-precision training** to save GPUs memory and use larger batch sizes
-- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
+- Integrated, efficient [hyper-parameter optimization module (HPO)](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/hpo.html). Through dataset proxy and built-in hyper-parameter optimizer, you can get much faster hyper-parameter optimization compared to other off-the-shelf tools. The hyperparameter optimization is dynamically scheduled based on your resource budget.
 - OpenVINO Training Extensions uses [Datumaro](https://openvinotoolkit.github.io/datumaro/docs/) as the backend to hadle datasets. Thanks to that, OpenVINO Training Extensions supports the most common academic field dataset formats for each task. We constantly working to extend supported formats to give more freedom of datasets format choice.
-- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
+- [Auto-configuration functionality](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/explanation/additional_features/auto_configuration.html). OpenVINO Training Extensions analyzes provided dataset and selects the proper task and model template to provide the best accuracy/speed trade-off. It will also make a random auto-split of your dataset if there is no validation set provided.
 
 ---
 
 ## Getting Started
 
 ### Installation
 
-Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/installation.html).
+Please refer to the [installation guide](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/installation.html).
 
 ### OpenVINO Training Extensions CLI Commands
 
 - `otx find` helps you quickly find the best pre-configured models templates as well as a list of supported backbones
 - `otx build` creates the workspace folder with all necessary components to start training. It can help you configure your own model with any supported backbone and even prepare a custom split for your dataset
 - `otx train` actually starts training on your dataset
 - `otx eval` runs evaluation of your trained model in PyTorch or OpenVINO IR format
 - `otx optimize` runs an optimization algorithm to quantize and prune your deep learning model with help of [NNCF](https://github.com/openvinotoolkit/nncf) and [POT](https://docs.openvino.ai/latest/pot_introduction.html) tools.
 - `otx export` starts exporting your model to the OpenVINO IR format
 - `otx deploy` outputs the exported model together with the self-contained python package, a demo application to port and infer it outside of this repository.
 - `otx demo` allows one to apply a trained model on the custom data or the online footage from a web camera and see how it will work in a real-life scenario.
 - `otx explain` runs explain algorithm on the provided data and outputs images with the saliency maps to show how your model makes predictions.
 
-You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.1.2/guide/get_started/quick_start_guide/cli_commands.html).
+You can find more details with examples in the [CLI command intro](https://openvinotoolkit.github.io/training_extensions/releases/1.2.0/guide/get_started/quick_start_guide/cli_commands.html).
 
 ---
 
 ## Updates
 
-### v1.1.0 (1Q23)
-
-- Add FP16 IR export support (<https://github.com/openvinotoolkit/training_extensions/pull/1683>)
-- Add in-memory caching in dataloader (<https://github.com/openvinotoolkit/training_extensions/pull/1694>)
-- Add MoViNet template for action classification (<https://github.com/openvinotoolkit/training_extensions/pull/1742>)
-- Add Semi-SL multilabel classification algorithm (<https://github.com/openvinotoolkit/training_extensions/pull/1805>)
-- Integrate multi-gpu training for semi-supervised learning and self-supervised learning (<https://github.com/openvinotoolkit/training_extensions/pull/1534>)
-- Add train-type parameter to otx train (<https://github.com/openvinotoolkit/training_extensions/pull/1874>)
-- Add embedding of inference configuration to IR for classification (<https://github.com/openvinotoolkit/training_extensions/pull/1842>)
-- Enable VOC dataset in OTX (<https://github.com/openvinotoolkit/training_extensions/pull/1862>)
-- Add mmcls.VisionTransformer backbone support (<https://github.com/openvinotoolkit/training_extensions/pull/1908>)
-
-### v1.2+ (2Q23)
+### v1.2.0 (2Q23)
 
-- In planning
+- Add generating feature cli_report.log in output for otx training (<https://github.com/openvinotoolkit/training_extensions/pull/1959>)
+- Support multiple python versions up to 3.10 (<https://github.com/openvinotoolkit/training_extensions/pull/1978>)
+- Support export of onnx models (<https://github.com/openvinotoolkit/training_extensions/pull/1976>)
+- Add option to save images after inference in OTX CLI demo together with demo in exportable code (<https://github.com/openvinotoolkit/training_extensions/pull/2005>)
 
 ### Release History
 
 Please refer to the [CHANGELOG.md](CHANGELOG.md)
 
 ---
```

### Comparing `otx-1.1.2rc1/otx.egg-info/SOURCES.txt` & `otx-1.2.0rc1/otx.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -8,16 +8,18 @@
 otx.egg-info/SOURCES.txt
 otx.egg-info/dependency_links.txt
 otx.egg-info/entry_points.txt
 otx.egg-info/requires.txt
 otx.egg-info/top_level.txt
 otx/algorithms/__init__.py
 otx/algorithms/action/__init__.py
+otx/algorithms/action/task.py
 otx/algorithms/action/adapters/__init__.py
 otx/algorithms/action/adapters/mmaction/__init__.py
+otx/algorithms/action/adapters/mmaction/task.py
 otx/algorithms/action/adapters/mmaction/data/__init__.py
 otx/algorithms/action/adapters/mmaction/data/cls_dataset.py
 otx/algorithms/action/adapters/mmaction/data/det_dataset.py
 otx/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
 otx/algorithms/action/adapters/mmaction/data/pipelines/loading.py
 otx/algorithms/action/adapters/mmaction/models/__init__.py
 otx/algorithms/action/adapters/mmaction/models/backbones/__init__.py
@@ -26,26 +28,30 @@
 otx/algorithms/action/adapters/mmaction/models/detectors/fast_rcnn.py
 otx/algorithms/action/adapters/mmaction/models/heads/__init__.py
 otx/algorithms/action/adapters/mmaction/models/heads/movinet_head.py
 otx/algorithms/action/adapters/mmaction/models/heads/roi_head.py
 otx/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
 otx/algorithms/action/adapters/mmaction/models/recognizers/movinet_recognizer.py
 otx/algorithms/action/adapters/mmaction/utils/__init__.py
-otx/algorithms/action/adapters/mmaction/utils/config_utils.py
 otx/algorithms/action/adapters/mmaction/utils/det_eval_utils.py
 otx/algorithms/action/adapters/mmaction/utils/export_utils.py
 otx/algorithms/action/adapters/openvino/__init__.py
 otx/algorithms/action/adapters/openvino/dataloader.py
+otx/algorithms/action/adapters/openvino/task.py
 otx/algorithms/action/adapters/openvino/model_wrappers/__init__.py
 otx/algorithms/action/adapters/openvino/model_wrappers/openvino_models.py
 otx/algorithms/action/configs/__init__.py
 otx/algorithms/action/configs/base/__init__.py
 otx/algorithms/action/configs/base/configuration.py
 otx/algorithms/action/configs/classification/__init__.py
 otx/algorithms/action/configs/classification/configuration.yaml
+otx/algorithms/action/configs/classification/base/__init__.py
+otx/algorithms/action/configs/classification/base/base_classification_dynamic.py
+otx/algorithms/action/configs/classification/base/base_classification_static.py
+otx/algorithms/action/configs/classification/base/supervised.py
 otx/algorithms/action/configs/classification/movinet/__init__.py
 otx/algorithms/action/configs/classification/movinet/data_pipeline.py
 otx/algorithms/action/configs/classification/movinet/deployment.py
 otx/algorithms/action/configs/classification/movinet/model.py
 otx/algorithms/action/configs/classification/movinet/template.yaml
 otx/algorithms/action/configs/classification/x3d/__init__.py
 otx/algorithms/action/configs/classification/x3d/data_pipeline.py
@@ -56,23 +62,20 @@
 otx/algorithms/action/configs/detection/configuration.yaml
 otx/algorithms/action/configs/detection/base/__init__.py
 otx/algorithms/action/configs/detection/base/ava_data_pipeline.py
 otx/algorithms/action/configs/detection/base/base_detection_dynamic.py
 otx/algorithms/action/configs/detection/base/base_detection_static.py
 otx/algorithms/action/configs/detection/base/data_pipeline.py
 otx/algorithms/action/configs/detection/base/faster_rcnn_config.py
+otx/algorithms/action/configs/detection/base/supervised.py
 otx/algorithms/action/configs/detection/x3d_fast_rcnn/__init__.py
 otx/algorithms/action/configs/detection/x3d_fast_rcnn/data_pipeline.py
 otx/algorithms/action/configs/detection/x3d_fast_rcnn/deployment.py
 otx/algorithms/action/configs/detection/x3d_fast_rcnn/model.py
 otx/algorithms/action/configs/detection/x3d_fast_rcnn/template.yaml
-otx/algorithms/action/tasks/__init__.py
-otx/algorithms/action/tasks/inference.py
-otx/algorithms/action/tasks/openvino.py
-otx/algorithms/action/tasks/train.py
 otx/algorithms/action/tools/__init__.py
 otx/algorithms/action/tools/sample_classification.py
 otx/algorithms/action/tools/sample_detection.py
 otx/algorithms/action/utils/__init__.py
 otx/algorithms/action/utils/convert_public_data_to_cvat.py
 otx/algorithms/action/utils/data.py
 otx/algorithms/anomaly/__init__.py
@@ -167,32 +170,35 @@
 otx/algorithms/anomaly/tasks/nncf.py
 otx/algorithms/anomaly/tasks/openvino.py
 otx/algorithms/anomaly/tasks/train.py
 otx/algorithms/anomaly/tools/README.md
 otx/algorithms/anomaly/tools/__init__.py
 otx/algorithms/anomaly/tools/sample.py
 otx/algorithms/classification/__init__.py
+otx/algorithms/classification/task.py
 otx/algorithms/classification/adapters/__init__.py
 otx/algorithms/classification/adapters/mmcls/__init__.py
+otx/algorithms/classification/adapters/mmcls/configurer.py
+otx/algorithms/classification/adapters/mmcls/task.py
 otx/algorithms/classification/adapters/mmcls/datasets/__init__.py
 otx/algorithms/classification/adapters/mmcls/datasets/otx_datasets.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/__init__.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/otx_pipelines.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/__init__.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/augmix.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/otx_transforms.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/random_augment.py
 otx/algorithms/classification/adapters/mmcls/datasets/pipelines/transforms/twocrop_transform.py
 otx/algorithms/classification/adapters/mmcls/models/__init__.py
 otx/algorithms/classification/adapters/mmcls/models/backbones/__init__.py
 otx/algorithms/classification/adapters/mmcls/models/backbones/mmov_backbone.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/byol.py
+otx/algorithms/classification/adapters/mmcls/models/classifiers/mixin.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier.py
-otx/algorithms/classification/adapters/mmcls/models/classifiers/sam_classifier_mixin.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_classifier.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/semisl_multilabel_classifier.py
 otx/algorithms/classification/adapters/mmcls/models/classifiers/supcon_classifier.py
 otx/algorithms/classification/adapters/mmcls/models/heads/__init__.py
 otx/algorithms/classification/adapters/mmcls/models/heads/cls_head.py
 otx/algorithms/classification/adapters/mmcls/models/heads/contrastive_head.py
 otx/algorithms/classification/adapters/mmcls/models/heads/conv_head.py
@@ -215,35 +221,23 @@
 otx/algorithms/classification/adapters/mmcls/models/necks/__init__.py
 otx/algorithms/classification/adapters/mmcls/models/necks/mmov_neck.py
 otx/algorithms/classification/adapters/mmcls/models/necks/selfsl_mlp.py
 otx/algorithms/classification/adapters/mmcls/nncf/__init__.py
 otx/algorithms/classification/adapters/mmcls/nncf/builder.py
 otx/algorithms/classification/adapters/mmcls/nncf/patches.py
 otx/algorithms/classification/adapters/mmcls/nncf/registers.py
+otx/algorithms/classification/adapters/mmcls/nncf/task.py
 otx/algorithms/classification/adapters/mmcls/optimizer/__init__.py
 otx/algorithms/classification/adapters/mmcls/optimizer/lars.py
-otx/algorithms/classification/adapters/mmcls/tasks/__init__.py
-otx/algorithms/classification/adapters/mmcls/tasks/evaluator.py
-otx/algorithms/classification/adapters/mmcls/tasks/explainer.py
-otx/algorithms/classification/adapters/mmcls/tasks/exporter.py
-otx/algorithms/classification/adapters/mmcls/tasks/inferrer.py
-otx/algorithms/classification/adapters/mmcls/tasks/stage.py
-otx/algorithms/classification/adapters/mmcls/tasks/trainer.py
-otx/algorithms/classification/adapters/mmcls/tasks/incremental/__init__.py
-otx/algorithms/classification/adapters/mmcls/tasks/incremental/inferrer.py
-otx/algorithms/classification/adapters/mmcls/tasks/incremental/stage.py
-otx/algorithms/classification/adapters/mmcls/tasks/incremental/trainer.py
-otx/algorithms/classification/adapters/mmcls/tasks/semisl/__init__.py
-otx/algorithms/classification/adapters/mmcls/tasks/semisl/inferrer.py
-otx/algorithms/classification/adapters/mmcls/tasks/semisl/stage.py
-otx/algorithms/classification/adapters/mmcls/tasks/semisl/trainer.py
 otx/algorithms/classification/adapters/mmcls/utils/__init__.py
 otx/algorithms/classification/adapters/mmcls/utils/builder.py
 otx/algorithms/classification/adapters/mmcls/utils/config_utils.py
+otx/algorithms/classification/adapters/mmcls/utils/exporter.py
 otx/algorithms/classification/adapters/openvino/__init__.py
+otx/algorithms/classification/adapters/openvino/task.py
 otx/algorithms/classification/adapters/openvino/model_wrappers/__init__.py
 otx/algorithms/classification/adapters/openvino/model_wrappers/openvino_models.py
 otx/algorithms/classification/configs/__init__.py
 otx/algorithms/classification/configs/configuration.yaml
 otx/algorithms/classification/configs/base/__init__.py
 otx/algorithms/classification/configs/base/configuration.py
 otx/algorithms/classification/configs/base/data/__init__.py
@@ -355,19 +349,14 @@
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/data_pipeline.py
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/hparam.yaml
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/selfsl/model.py
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/__init__.py
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/data_pipeline.py
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/hparam.yaml
 otx/algorithms/classification/configs/mobilenet_v3_small_cls_incr/supcon/model.py
-otx/algorithms/classification/tasks/__init__.py
-otx/algorithms/classification/tasks/inference.py
-otx/algorithms/classification/tasks/nncf.py
-otx/algorithms/classification/tasks/openvino.py
-otx/algorithms/classification/tasks/train.py
 otx/algorithms/classification/tools/__init__.py
 otx/algorithms/classification/tools/classification_sample.py
 otx/algorithms/classification/utils/__init__.py
 otx/algorithms/classification/utils/cls_utils.py
 otx/algorithms/classification/utils/convert_coco_to_multilabel.py
 otx/algorithms/common/__init__.py
 otx/algorithms/common/adapters/__init__.py
@@ -391,24 +380,24 @@
 otx/algorithms/common/adapters/mmcv/hooks/dual_model_ema_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/early_stopping_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/eval_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/force_train_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/fp16_sam_optimizer_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/ib_loss_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/logger_hook.py
+otx/algorithms/common/adapters/mmcv/hooks/lr_updater_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/model_ema_v2_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/no_bias_decay_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/progress_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/recording_forward_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/sam_optimizer_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/semisl_cls_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/task_adapt_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/two_crop_transform_hook.py
 otx/algorithms/common/adapters/mmcv/hooks/unbiased_teacher_hook.py
-otx/algorithms/common/adapters/mmcv/hooks/workflow_hook.py
 otx/algorithms/common/adapters/mmcv/models/__init__.py
 otx/algorithms/common/adapters/mmcv/models/builder.py
 otx/algorithms/common/adapters/mmcv/models/backbones/__init__.py
 otx/algorithms/common/adapters/mmcv/models/backbones/efficientnet.py
 otx/algorithms/common/adapters/mmcv/models/backbones/efficientnetv2.py
 otx/algorithms/common/adapters/mmcv/models/backbones/mobilenetv3.py
 otx/algorithms/common/adapters/mmcv/models/backbones/torchvision_backbones.py
@@ -420,20 +409,17 @@
 otx/algorithms/common/adapters/mmcv/pipelines/__init__.py
 otx/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
 otx/algorithms/common/adapters/mmcv/pipelines/transforms/augments.py
 otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/__init__.py
 otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx
 otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx
 otx/algorithms/common/adapters/mmcv/tasks/__init__.py
-otx/algorithms/common/adapters/mmcv/tasks/builder.py
-otx/algorithms/common/adapters/mmcv/tasks/exporter_mixin.py
+otx/algorithms/common/adapters/mmcv/tasks/exporter.py
 otx/algorithms/common/adapters/mmcv/tasks/registry.py
-otx/algorithms/common/adapters/mmcv/tasks/stage.py
 otx/algorithms/common/adapters/mmcv/tasks/version.py
-otx/algorithms/common/adapters/mmcv/tasks/workflow.py
 otx/algorithms/common/adapters/mmcv/utils/__init__.py
 otx/algorithms/common/adapters/mmcv/utils/_builder_build_data_parallel.py
 otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_keys.py
 otx/algorithms/common/adapters/mmcv/utils/_config_utils_get_configs_by_pairs.py
 otx/algorithms/common/adapters/mmcv/utils/builder.py
 otx/algorithms/common/adapters/mmcv/utils/config_utils.py
 otx/algorithms/common/adapters/mmdeploy/__init__.py
@@ -455,53 +441,57 @@
 otx/algorithms/common/adapters/torch/dataloaders/samplers/__init__.py
 otx/algorithms/common/adapters/torch/dataloaders/samplers/balanced_sampler.py
 otx/algorithms/common/adapters/torch/dataloaders/samplers/cls_incr_sampler.py
 otx/algorithms/common/configs/__init__.py
 otx/algorithms/common/configs/configuration_enums.py
 otx/algorithms/common/configs/training_base.py
 otx/algorithms/common/tasks/__init__.py
-otx/algorithms/common/tasks/nncf_base.py
-otx/algorithms/common/tasks/training_base.py
+otx/algorithms/common/tasks/base_task.py
+otx/algorithms/common/tasks/nncf_task.py
 otx/algorithms/common/tools/__init__.py
 otx/algorithms/common/utils/__init__.py
 otx/algorithms/common/utils/callback.py
 otx/algorithms/common/utils/data.py
 otx/algorithms/common/utils/distance_utils.py
 otx/algorithms/common/utils/ext_loader.py
 otx/algorithms/common/utils/ir.py
 otx/algorithms/common/utils/logger.py
 otx/algorithms/common/utils/mask_to_bbox.py
 otx/algorithms/common/utils/mo_wrapper.py
 otx/algorithms/common/utils/task_adapt.py
 otx/algorithms/common/utils/utils.py
 otx/algorithms/detection/__init__.py
+otx/algorithms/detection/task.py
 otx/algorithms/detection/adapters/__init__.py
 otx/algorithms/detection/adapters/mmdet/__init__.py
+otx/algorithms/detection/adapters/mmdet/configurer.py
+otx/algorithms/detection/adapters/mmdet/task.py
 otx/algorithms/detection/adapters/mmdet/datasets/__init__.py
 otx/algorithms/detection/adapters/mmdet/datasets/dataset.py
 otx/algorithms/detection/adapters/mmdet/datasets/task_adapt_dataset.py
 otx/algorithms/detection/adapters/mmdet/datasets/tiling.py
 otx/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
 otx/algorithms/detection/adapters/mmdet/datasets/pipelines/load_pipelines.py
 otx/algorithms/detection/adapters/mmdet/datasets/pipelines/torchvision2mmdet.py
 otx/algorithms/detection/adapters/mmdet/evaluation/__init__.py
 otx/algorithms/detection/adapters/mmdet/evaluation/mean_ap_seg.py
 otx/algorithms/detection/adapters/mmdet/hooks/__init__.py
-otx/algorithms/detection/adapters/mmdet/hooks/det_saliency_map_hook.py
+otx/algorithms/detection/adapters/mmdet/hooks/det_class_probability_map_hook.py
 otx/algorithms/detection/adapters/mmdet/models/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/backbones/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/backbones/imgclsmob.py
 otx/algorithms/detection/adapters/mmdet/models/backbones/mmov_backbone.py
 otx/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_rpn_head.py
 otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_ssd_head.py
 otx/algorithms/detection/adapters/mmdet/models/dense_heads/mmov_yolov3_head.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_atss_detector.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_detector.py
+otx/algorithms/detection/adapters/mmdet/models/detectors/custom_maskrcnn_tile_optimized.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_single_stage_detector.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_two_stage_detector.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_vfnet_detector.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/custom_yolox_detector.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/l2sp_detector_mixin.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/sam_detector_mixin.py
 otx/algorithms/detection/adapters/mmdet/models/detectors/unbiased_teacher.py
@@ -527,33 +517,21 @@
 otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/roi_heads/mask_heads/mmov_mask_head.py
 otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
 otx/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py
 otx/algorithms/detection/adapters/mmdet/nncf/__init__.py
 otx/algorithms/detection/adapters/mmdet/nncf/builder.py
 otx/algorithms/detection/adapters/mmdet/nncf/patches.py
-otx/algorithms/detection/adapters/mmdet/tasks/__init__.py
-otx/algorithms/detection/adapters/mmdet/tasks/explainer.py
-otx/algorithms/detection/adapters/mmdet/tasks/exporter.py
-otx/algorithms/detection/adapters/mmdet/tasks/inferrer.py
-otx/algorithms/detection/adapters/mmdet/tasks/stage.py
-otx/algorithms/detection/adapters/mmdet/tasks/trainer.py
-otx/algorithms/detection/adapters/mmdet/tasks/incremental/__init__.py
-otx/algorithms/detection/adapters/mmdet/tasks/incremental/inferrer.py
-otx/algorithms/detection/adapters/mmdet/tasks/incremental/stage.py
-otx/algorithms/detection/adapters/mmdet/tasks/incremental/trainer.py
-otx/algorithms/detection/adapters/mmdet/tasks/semisl/__init__.py
-otx/algorithms/detection/adapters/mmdet/tasks/semisl/exporter.py
-otx/algorithms/detection/adapters/mmdet/tasks/semisl/inferrer.py
-otx/algorithms/detection/adapters/mmdet/tasks/semisl/stage.py
-otx/algorithms/detection/adapters/mmdet/tasks/semisl/trainer.py
+otx/algorithms/detection/adapters/mmdet/nncf/task.py
 otx/algorithms/detection/adapters/mmdet/utils/__init__.py
 otx/algorithms/detection/adapters/mmdet/utils/builder.py
 otx/algorithms/detection/adapters/mmdet/utils/config_utils.py
+otx/algorithms/detection/adapters/mmdet/utils/exporter.py
 otx/algorithms/detection/adapters/openvino/__init__.py
+otx/algorithms/detection/adapters/openvino/task.py
 otx/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
 otx/algorithms/detection/adapters/openvino/model_wrappers/openvino_models.py
 otx/algorithms/detection/configs/__init__.py
 otx/algorithms/detection/configs/base/__init__.py
 otx/algorithms/detection/configs/base/configuration.py
 otx/algorithms/detection/configs/base/deployments/__init__.py
 otx/algorithms/detection/configs/base/deployments/base_detection_dynamic.py
@@ -614,22 +592,24 @@
 otx/algorithms/detection/configs/detection/resnet50_vfnet/tile_pipeline.py
 otx/algorithms/detection/configs/instance_segmentation/__init__.py
 otx/algorithms/detection/configs/instance_segmentation/configuration.yaml
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/__init__.py
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/compression_config.json
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/data_pipeline.py
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/deployment.py
+otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/deployment_tile_classifier.py
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/hpo_config.yaml
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/template.yaml
 otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/tile_pipeline.py
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/__init__.py
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/compression_config.json
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/data_pipeline.py
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/deployment.py
+otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/deployment_tile_classifier.py
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/hpo_config.yaml
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/model.py
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/template.yaml
 otx/algorithms/detection/configs/instance_segmentation/resnet50_maskrcnn/tile_pipeline.py
 otx/algorithms/detection/configs/rotated_detection/__init__.py
 otx/algorithms/detection/configs/rotated_detection/configuration.yaml
 otx/algorithms/detection/configs/rotated_detection/efficientnetb2b_maskrcnn/__init__.py
@@ -644,41 +624,40 @@
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/compression_config.json
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/data_pipeline.py
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/deployment.py
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/hpo_config.yaml
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/model.py
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/template.yaml
 otx/algorithms/detection/configs/rotated_detection/resnet50_maskrcnn/tile_pipeline.py
-otx/algorithms/detection/tasks/__init__.py
-otx/algorithms/detection/tasks/inference.py
-otx/algorithms/detection/tasks/nncf.py
-otx/algorithms/detection/tasks/openvino.py
-otx/algorithms/detection/tasks/train.py
 otx/algorithms/detection/tools/__init__.py
 otx/algorithms/detection/tools/detection_sample.py
 otx/algorithms/detection/tools/detection_semisl_sample.py
 otx/algorithms/detection/tools/instance_segmentation_sample.py
 otx/algorithms/detection/utils/__init__.py
 otx/algorithms/detection/utils/data.py
 otx/algorithms/detection/utils/utils.py
 otx/algorithms/segmentation/__init__.py
+otx/algorithms/segmentation/task.py
 otx/algorithms/segmentation/adapters/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/__init__.py
+otx/algorithms/segmentation/adapters/mmseg/configurer.py
+otx/algorithms/segmentation/adapters/mmseg/task.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/dataset.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/compose.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/loads.py
 otx/algorithms/segmentation/adapters/mmseg/datasets/pipelines/transforms.py
 otx/algorithms/segmentation/adapters/mmseg/models/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/models/backbones/litehrnet.py
 otx/algorithms/segmentation/adapters/mmseg/models/backbones/mmov_backbone.py
 otx/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/models/heads/custom_fcn_head.py
+otx/algorithms/segmentation/adapters/mmseg/models/heads/detcon_head.py
 otx/algorithms/segmentation/adapters/mmseg/models/heads/mixin.py
 otx/algorithms/segmentation/adapters/mmseg/models/heads/mmov_decode_head.py
 otx/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/models/losses/base_pixel_loss.py
 otx/algorithms/segmentation/adapters/mmseg/models/losses/base_weighted_loss.py
 otx/algorithms/segmentation/adapters/mmseg/models/losses/cross_entropy_loss_with_ignore.py
 otx/algorithms/segmentation/adapters/mmseg/models/losses/detcon_loss.py
@@ -703,35 +682,23 @@
 otx/algorithms/segmentation/adapters/mmseg/models/utils/channel_shuffle.py
 otx/algorithms/segmentation/adapters/mmseg/models/utils/local_attention.py
 otx/algorithms/segmentation/adapters/mmseg/models/utils/loss_equalizer.py
 otx/algorithms/segmentation/adapters/mmseg/models/utils/normalize.py
 otx/algorithms/segmentation/adapters/mmseg/models/utils/psp_layer.py
 otx/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/nncf/builder.py
-otx/algorithms/segmentation/adapters/mmseg/nncf/hooks.py
 otx/algorithms/segmentation/adapters/mmseg/nncf/patches.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/__init__.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/exporter.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/inferrer.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/stage.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/trainer.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/__init__.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/inferrer.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/stage.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/incremental/trainer.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/__init__.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/exporter.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/inferrer.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/stage.py
-otx/algorithms/segmentation/adapters/mmseg/tasks/semisl/trainer.py
+otx/algorithms/segmentation/adapters/mmseg/nncf/task.py
 otx/algorithms/segmentation/adapters/mmseg/utils/__init__.py
 otx/algorithms/segmentation/adapters/mmseg/utils/builder.py
 otx/algorithms/segmentation/adapters/mmseg/utils/config_utils.py
 otx/algorithms/segmentation/adapters/mmseg/utils/data_utils.py
+otx/algorithms/segmentation/adapters/mmseg/utils/exporter.py
 otx/algorithms/segmentation/adapters/openvino/__init__.py
+otx/algorithms/segmentation/adapters/openvino/task.py
 otx/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
 otx/algorithms/segmentation/adapters/openvino/model_wrappers/blur.py
 otx/algorithms/segmentation/configs/__init__.py
 otx/algorithms/segmentation/configs/configuration.yaml
 otx/algorithms/segmentation/configs/base/__init__.py
 otx/algorithms/segmentation/configs/base/configuration.py
 otx/algorithms/segmentation/configs/base/configuration_enums.py
@@ -819,19 +786,14 @@
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/data_pipeline.py
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/hparam.yaml
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/semisl/model.py
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/__init__.py
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/data_pipeline.py
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/hparam.yaml
 otx/algorithms/segmentation/configs/ocr_lite_hrnet_x_mod3/supcon/model.py
-otx/algorithms/segmentation/tasks/__init__.py
-otx/algorithms/segmentation/tasks/inference.py
-otx/algorithms/segmentation/tasks/nncf.py
-otx/algorithms/segmentation/tasks/openvino.py
-otx/algorithms/segmentation/tasks/train.py
 otx/algorithms/segmentation/tools/__init__.py
 otx/algorithms/segmentation/tools/segmentation_sample.py
 otx/algorithms/segmentation/utils/__init__.py
 otx/api/__init__.py
 otx/api/py.typed
 otx/api/configuration/__init__.py
 otx/api/configuration/configurable_parameters.py
@@ -861,14 +823,15 @@
 otx/api/configuration/ui_rules/utils.py
 otx/api/entities/__init__.py
 otx/api/entities/annotation.py
 otx/api/entities/color.py
 otx/api/entities/coordinate.py
 otx/api/entities/dataset_item.py
 otx/api/entities/datasets.py
+otx/api/entities/explain_parameters.py
 otx/api/entities/graph.py
 otx/api/entities/id.py
 otx/api/entities/image.py
 otx/api/entities/inference_parameters.py
 otx/api/entities/label.py
 otx/api/entities/label_schema.py
 otx/api/entities/media.py
@@ -945,14 +908,15 @@
 otx/api/usecases/tasks/interfaces/inference_interface.py
 otx/api/usecases/tasks/interfaces/optimization_interface.py
 otx/api/usecases/tasks/interfaces/training_interface.py
 otx/api/usecases/tasks/interfaces/unload_interface.py
 otx/api/utils/__init__.py
 otx/api/utils/anomaly_utils.py
 otx/api/utils/argument_checks.py
+otx/api/utils/async_pipeline.py
 otx/api/utils/dataset_utils.py
 otx/api/utils/detection_utils.py
 otx/api/utils/importing.py
 otx/api/utils/labels_utils.py
 otx/api/utils/nms.py
 otx/api/utils/segmentation_utils.py
 otx/api/utils/shape_drawer.py
@@ -994,30 +958,35 @@
 otx/cli/utils/errors.py
 otx/cli/utils/hpo.py
 otx/cli/utils/importing.py
 otx/cli/utils/io.py
 otx/cli/utils/multi_gpu.py
 otx/cli/utils/nncf.py
 otx/cli/utils/parser.py
+otx/cli/utils/report.py
 otx/cli/utils/telemetry.py
 otx/core/__init__.py
+otx/core/file.py
 otx/core/patcher.py
 otx/core/data/__init__.py
 otx/core/data/adapter/__init__.py
 otx/core/data/adapter/action_dataset_adapter.py
 otx/core/data/adapter/anomaly_dataset_adapter.py
 otx/core/data/adapter/base_dataset_adapter.py
 otx/core/data/adapter/classification_dataset_adapter.py
 otx/core/data/adapter/detection_dataset_adapter.py
 otx/core/data/adapter/segmentation_dataset_adapter.py
 otx/core/data/caching/__init__.py
 otx/core/data/caching/mem_cache_handler.py
 otx/core/data/caching/mem_cache_hook.py
 otx/core/data/manager/__init__.py
 otx/core/data/manager/dataset_manager.py
+otx/core/data/noisy_label_detection/__init__.py
+otx/core/data/noisy_label_detection/base.py
+otx/core/data/noisy_label_detection/loss_dynamics_tracking_hook.py
 otx/core/data/pipelines/__init__.py
 otx/core/data/pipelines/load_image_from_otx_dataset.py
 otx/core/ov/__init__.py
 otx/core/ov/omz_wrapper.py
 otx/core/ov/registry.py
 otx/core/ov/utils.py
 otx/core/ov/graph/__init__.py
@@ -1204,87 +1173,85 @@
 tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1/instance_002_ADE_train_1.png
 tests/assets/anomaly/classification/test.json
 tests/assets/anomaly/classification/train.json
 tests/assets/anomaly/classification/val.json
 tests/assets/anomaly/detection/test.json
 tests/assets/anomaly/detection/train.json
 tests/assets/anomaly/detection/val.json
+tests/assets/anomaly/hazelnut/ground_truth/colour/00.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/01.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/02.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/03.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/04.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/05.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/06.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/07.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/08.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/09.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/10.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/11.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/12.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/13.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/14.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/15.png
+tests/assets/anomaly/hazelnut/ground_truth/colour/16.png
+tests/assets/anomaly/hazelnut/test/colour/00.jpg
+tests/assets/anomaly/hazelnut/test/colour/01.jpg
+tests/assets/anomaly/hazelnut/test/colour/02.jpg
+tests/assets/anomaly/hazelnut/test/colour/03.jpg
+tests/assets/anomaly/hazelnut/test/colour/04.jpg
+tests/assets/anomaly/hazelnut/test/colour/05.jpg
+tests/assets/anomaly/hazelnut/test/colour/06.jpg
+tests/assets/anomaly/hazelnut/test/colour/07.jpg
+tests/assets/anomaly/hazelnut/test/colour/08.jpg
+tests/assets/anomaly/hazelnut/test/colour/09.jpg
+tests/assets/anomaly/hazelnut/test/colour/10.jpg
+tests/assets/anomaly/hazelnut/test/colour/11.jpg
+tests/assets/anomaly/hazelnut/test/colour/12.jpg
+tests/assets/anomaly/hazelnut/test/colour/13.jpg
+tests/assets/anomaly/hazelnut/test/colour/14.jpg
+tests/assets/anomaly/hazelnut/test/colour/15.jpg
+tests/assets/anomaly/hazelnut/test/colour/16.jpg
+tests/assets/anomaly/hazelnut/test/good/04.jpg
+tests/assets/anomaly/hazelnut/test/good/05.jpg
+tests/assets/anomaly/hazelnut/test/good/13.jpg
+tests/assets/anomaly/hazelnut/test/good/23.jpg
+tests/assets/anomaly/hazelnut/test/good/25.jpg
+tests/assets/anomaly/hazelnut/test/good/28.jpg
+tests/assets/anomaly/hazelnut/train/good/00.jpg
+tests/assets/anomaly/hazelnut/train/good/01.jpg
+tests/assets/anomaly/hazelnut/train/good/02.jpg
+tests/assets/anomaly/hazelnut/train/good/03.jpg
+tests/assets/anomaly/hazelnut/train/good/06.jpg
+tests/assets/anomaly/hazelnut/train/good/07.jpg
+tests/assets/anomaly/hazelnut/train/good/08.jpg
+tests/assets/anomaly/hazelnut/train/good/09.jpg
+tests/assets/anomaly/hazelnut/train/good/10.jpg
+tests/assets/anomaly/hazelnut/train/good/11.jpg
+tests/assets/anomaly/hazelnut/train/good/12.jpg
+tests/assets/anomaly/hazelnut/train/good/14.jpg
+tests/assets/anomaly/hazelnut/train/good/15.jpg
+tests/assets/anomaly/hazelnut/train/good/16.jpg
+tests/assets/anomaly/hazelnut/train/good/17.jpg
+tests/assets/anomaly/hazelnut/train/good/18.jpg
+tests/assets/anomaly/hazelnut/train/good/19.jpg
+tests/assets/anomaly/hazelnut/train/good/20.jpg
+tests/assets/anomaly/hazelnut/train/good/21.jpg
+tests/assets/anomaly/hazelnut/train/good/22.jpg
+tests/assets/anomaly/hazelnut/train/good/24.jpg
+tests/assets/anomaly/hazelnut/train/good/26.jpg
+tests/assets/anomaly/hazelnut/train/good/27.jpg
+tests/assets/anomaly/hazelnut/train/good/29.jpg
+tests/assets/anomaly/hazelnut/train/good/30.jpg
+tests/assets/anomaly/hazelnut/train/good/31.jpg
+tests/assets/anomaly/hazelnut/train/good/32.jpg
+tests/assets/anomaly/hazelnut/train/good/33.jpg
 tests/assets/anomaly/segmentation/test.json
 tests/assets/anomaly/segmentation/train.json
 tests/assets/anomaly/segmentation/val.json
-tests/assets/anomaly/shapes/ground_truth/hexagon/000_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/001_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/002_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/003_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/004_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/005_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/006_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/007_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/008_mask.png
-tests/assets/anomaly/shapes/ground_truth/hexagon/009_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/000_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/001_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/002_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/003_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/004_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/005_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/006_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/007_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/008_mask.png
-tests/assets/anomaly/shapes/ground_truth/star/009_mask.png
-tests/assets/anomaly/shapes/test/good/000.png
-tests/assets/anomaly/shapes/test/good/001.png
-tests/assets/anomaly/shapes/test/good/002.png
-tests/assets/anomaly/shapes/test/good/003.png
-tests/assets/anomaly/shapes/test/good/004.png
-tests/assets/anomaly/shapes/test/good/005.png
-tests/assets/anomaly/shapes/test/good/006.png
-tests/assets/anomaly/shapes/test/good/007.png
-tests/assets/anomaly/shapes/test/good/008.png
-tests/assets/anomaly/shapes/test/good/009.png
-tests/assets/anomaly/shapes/test/hexagon/000.png
-tests/assets/anomaly/shapes/test/hexagon/001.png
-tests/assets/anomaly/shapes/test/hexagon/002.png
-tests/assets/anomaly/shapes/test/hexagon/003.png
-tests/assets/anomaly/shapes/test/hexagon/004.png
-tests/assets/anomaly/shapes/test/hexagon/005.png
-tests/assets/anomaly/shapes/test/hexagon/006.png
-tests/assets/anomaly/shapes/test/hexagon/007.png
-tests/assets/anomaly/shapes/test/hexagon/008.png
-tests/assets/anomaly/shapes/test/hexagon/009.png
-tests/assets/anomaly/shapes/test/star/000.png
-tests/assets/anomaly/shapes/test/star/001.png
-tests/assets/anomaly/shapes/test/star/002.png
-tests/assets/anomaly/shapes/test/star/003.png
-tests/assets/anomaly/shapes/test/star/004.png
-tests/assets/anomaly/shapes/test/star/005.png
-tests/assets/anomaly/shapes/test/star/006.png
-tests/assets/anomaly/shapes/test/star/007.png
-tests/assets/anomaly/shapes/test/star/008.png
-tests/assets/anomaly/shapes/test/star/009.png
-tests/assets/anomaly/shapes/train/good/000.png
-tests/assets/anomaly/shapes/train/good/001.png
-tests/assets/anomaly/shapes/train/good/002.png
-tests/assets/anomaly/shapes/train/good/003.png
-tests/assets/anomaly/shapes/train/good/004.png
-tests/assets/anomaly/shapes/train/good/005.png
-tests/assets/anomaly/shapes/train/good/006.png
-tests/assets/anomaly/shapes/train/good/007.png
-tests/assets/anomaly/shapes/train/good/008.png
-tests/assets/anomaly/shapes/train/good/009.png
-tests/assets/anomaly/shapes/train/good/010.png
-tests/assets/anomaly/shapes/train/good/011.png
-tests/assets/anomaly/shapes/train/good/012.png
-tests/assets/anomaly/shapes/train/good/013.png
-tests/assets/anomaly/shapes/train/good/014.png
-tests/assets/anomaly/shapes/train/good/015.png
-tests/assets/anomaly/shapes/train/good/016.png
-tests/assets/anomaly/shapes/train/good/017.png
-tests/assets/anomaly/shapes/train/good/018.png
-tests/assets/anomaly/shapes/train/good/019.png
 tests/assets/car_tree_bug/annotations/instances_train.json
 tests/assets/car_tree_bug/annotations/instances_val.json
 tests/assets/car_tree_bug/images/train/Slide4.PNG
 tests/assets/car_tree_bug/images/train/Slide5.PNG
 tests/assets/car_tree_bug/images/train/Slide6.PNG
 tests/assets/car_tree_bug/images/train/Slide7.PNG
 tests/assets/car_tree_bug/images/train/Slide8.PNG
@@ -1473,14 +1440,15 @@
 tests/assets/voc_dataset/voc_dataset2/JPEGImages/2007_000001.jpg
 tests/assets/yolo_dataset/obj.data
 tests/assets/yolo_dataset/obj.names
 tests/assets/yolo_dataset/train.txt
 tests/assets/yolo_dataset/obj_train_data/1.jpg
 tests/assets/yolo_dataset/obj_train_data/1.txt
 tests/e2e/__init__.py
+tests/e2e/test_api_xai_sanity.py
 tests/e2e/cli/__init__.py
 tests/e2e/cli/test_cli.py
 tests/e2e/cli/action/__init__.py
 tests/e2e/cli/action/test_action_classification.py
 tests/e2e/cli/action/test_action_detection.py
 tests/e2e/cli/anomaly/__init__.py
 tests/e2e/cli/anomaly/test_anomaly_classification.py
@@ -1501,28 +1469,29 @@
 tests/e2e/cli/classification/__init__.py
 tests/e2e/cli/classification/test_classification.py
 tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficientNet-V2-S/compressed_model.yml
 tests/e2e/cli/classification/reference/Custom_Image_Classification_EfficinetNet-B0/compressed_model.yml
 tests/e2e/cli/classification/reference/Custom_Image_Classification_MobileNet-V3-large-1x/compressed_model.yml
 tests/e2e/cli/detection/__init__.py
 tests/e2e/cli/detection/test_detection.py
-tests/e2e/cli/detection/test_instance_segmentation.py
 tests/e2e/cli/detection/test_tiling_detection.py
-tests/e2e/cli/detection/test_tiling_instseg.py
-tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/compressed_model.yml
-tests/e2e/cli/detection/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/compressed_model.yml
 tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_ATSS/compressed_model.yml
 tests/e2e/cli/detection/reference/Custom_Object_Detection_Gen3_SSD/compressed_model.yml
 tests/e2e/cli/detection/reference/Custom_Object_Detection_YOLOX/compressed_model.yml
-tests/e2e/cli/segmentation/__init__.py
-tests/e2e/cli/segmentation/test_segmentation.py
-tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/compressed_model.yml
-tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/compressed_model.yml
-tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/compressed_model.yml
-tests/e2e/cli/segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/compressed_model.yml
+tests/e2e/cli/instance_segmentation/__init__.py
+tests/e2e/cli/instance_segmentation/test_instance_segmentation.py
+tests/e2e/cli/instance_segmentation/test_tiling_instseg.py
+tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B/compressed_model.yml
+tests/e2e/cli/instance_segmentation/reference/Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50/compressed_model.yml
+tests/e2e/cli/semantic_segmentation/__init__.py
+tests/e2e/cli/semantic_segmentation/test_segmentation.py
+tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR/compressed_model.yml
+tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-18_OCR/compressed_model.yml
+tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR/compressed_model.yml
+tests/e2e/cli/semantic_segmentation/reference/Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR/compressed_model.yml
 tests/fuzzing/__init__.py
 tests/fuzzing/cli_fuzzing.py
 tests/fuzzing/helper.py
 tests/fuzzing/assets/cli/operations.dict
 tests/integration/__init__.py
 tests/integration/api/__init__.py
 tests/integration/api/action/__init__.py
@@ -1531,52 +1500,53 @@
 tests/integration/api/classification/__init__.py
 tests/integration/api/classification/test_api_classification.py
 tests/integration/api/detection/__init__.py
 tests/integration/api/detection/test_api_detection.py
 tests/integration/api/segmentation/__init__.py
 tests/integration/api/segmentation/test_api_segmentation.py
 tests/integration/api/xai/__init__.py
-tests/integration/api/xai/test_api_xai_sanity.py
-tests/integration/api/xai/test_api_xai_validity.py
 tests/integration/cli/__init__.py
 tests/integration/cli/test_cli.py
 tests/integration/cli/action/__init__.py
 tests/integration/cli/action/test_action_classification.py
 tests/integration/cli/action/test_action_detection.py
 tests/integration/cli/anomaly/__init__.py
 tests/integration/cli/anomaly/test_anomaly_classification.py
 tests/integration/cli/anomaly/test_anomaly_detection.py
 tests/integration/cli/anomaly/test_anomaly_segmentation.py
 tests/integration/cli/classification/__init__.py
 tests/integration/cli/classification/test_classification.py
 tests/integration/cli/detection/__init__.py
 tests/integration/cli/detection/test_detection.py
-tests/integration/cli/detection/test_instance_segmentation.py
 tests/integration/cli/detection/test_tiling_detection.py
-tests/integration/cli/detection/test_tiling_instseg.py
-tests/integration/cli/segmentation/__init__.py
-tests/integration/cli/segmentation/test_segmentation.py
+tests/integration/cli/instance_segmentation/__init__.py
+tests/integration/cli/instance_segmentation/test_instance_segmentation.py
+tests/integration/cli/instance_segmentation/test_tiling_instseg.py
+tests/integration/cli/semantic_segmentation/__init__.py
+tests/integration/cli/semantic_segmentation/test_segmentation.py
 tests/regression/__init__.py
+tests/regression/regression_command.py
 tests/regression/regression_config.json
 tests/regression/regression_test_helpers.py
 tests/regression/summarize_test_results.py
 tests/regression/action/test_action_classification.py
 tests/regression/action/test_action_detection.py
 tests/regression/anomaly/test_anomaly_classificaiton.py
 tests/regression/anomaly/test_anomaly_detection.py
 tests/regression/anomaly/test_anomaly_segmentation.py
 tests/regression/classification/__init__.py
 tests/regression/classification/test_classification.py
 tests/regression/detection/__init__.py
 tests/regression/detection/test_detection.py
-tests/regression/detection/test_instnace_segmentation.py
 tests/regression/detection/test_tiling_detection.py
-tests/regression/detection/test_tiling_instnace_segmentation.py
-tests/regression/segmentation/__init__.py
-tests/regression/segmentation/test_segmentation.py
+tests/regression/instance_segmentation/__init__.py
+tests/regression/instance_segmentation/test_instnace_segmentation.py
+tests/regression/instance_segmentation/test_tiling_instnace_segmentation.py
+tests/regression/semantic_segmentation/__init__.py
+tests/regression/semantic_segmentation/test_segmentation.py
 tests/test_suite/ARCHITECTURE.md
 tests/test_suite/QUICK_HOWTO.md
 tests/test_suite/__init__.py
 tests/test_suite/e2e_test_system.py
 tests/test_suite/fixtures.py
 tests/test_suite/logging.py
 tests/test_suite/pytest_insertions.py
@@ -1588,14 +1558,15 @@
 tests/test_suite/training_tests_stage.py
 tests/unit/__init__.py
 tests/unit/algorithms/__init__.py
 tests/unit/algorithms/action/__init__.py
 tests/unit/algorithms/action/test_helpers.py
 tests/unit/algorithms/action/adapters/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/__init__.py
+tests/unit/algorithms/action/adapters/mmaction/test_task.py
 tests/unit/algorithms/action/adapters/mmaction/data/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/data/test_action_cls_dataset.py
 tests/unit/algorithms/action/adapters/mmaction/data/test_action_det_dataset.py
 tests/unit/algorithms/action/adapters/mmaction/data/pipelines/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/data/pipelines/test_action_loading.py
 tests/unit/algorithms/action/adapters/mmaction/models/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/models/backbones/__init__.py
@@ -1605,24 +1576,20 @@
 tests/unit/algorithms/action/adapters/mmaction/models/detectors/test_action_fast_rcnn.py
 tests/unit/algorithms/action/adapters/mmaction/models/heads/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_movinet_head.py
 tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_roi_head.py
 tests/unit/algorithms/action/adapters/mmaction/models/recognizers/__init__.py
 tests/unit/algorithms/action/adapters/mmaction/models/recognizers/test_action_movinet_recognizer.py
 tests/unit/algorithms/action/adapters/mmaction/utils/__init__.py
-tests/unit/algorithms/action/adapters/mmaction/utils/test_action_config_utils.py
 tests/unit/algorithms/action/adapters/mmaction/utils/test_action_det_eval_utils.py
 tests/unit/algorithms/action/adapters/mmaction/utils/test_action_export_utils.py
 tests/unit/algorithms/action/adapters/openvino/__init__.py
 tests/unit/algorithms/action/adapters/openvino/test_action_dataloader.py
 tests/unit/algorithms/action/adapters/openvino/test_action_openvino_models.py
-tests/unit/algorithms/action/tasks/__init__.py
-tests/unit/algorithms/action/tasks/test_action_inference.py
-tests/unit/algorithms/action/tasks/test_action_openvino.py
-tests/unit/algorithms/action/tasks/test_action_train.py
+tests/unit/algorithms/action/adapters/openvino/test_task.py
 tests/unit/algorithms/action/tools/__init__.py
 tests/unit/algorithms/action/tools/test_action_sample_classification.py
 tests/unit/algorithms/action/tools/test_action_sample_detection.py
 tests/unit/algorithms/action/utils/__init__.py
 tests/unit/algorithms/action/utils/test_action_convert_public_data_to_cvat.py
 tests/unit/algorithms/action/utils/test_action_data.py
 tests/unit/algorithms/anomaly/__init__.py
@@ -1641,19 +1608,20 @@
 tests/unit/algorithms/anomaly/helpers/utils.py
 tests/unit/algorithms/anomaly/tasks/__init__.py
 tests/unit/algorithms/anomaly/tasks/test_inference.py
 tests/unit/algorithms/anomaly/tasks/test_nncf.py
 tests/unit/algorithms/anomaly/tasks/test_openvino.py
 tests/unit/algorithms/anomaly/tasks/test_train.py
 tests/unit/algorithms/classification/__init__.py
+tests/unit/algorithms/classification/conftest.py
 tests/unit/algorithms/classification/test_helper.py
+tests/unit/algorithms/classification/test_xai_classification_validity.py
 tests/unit/algorithms/classification/adapters/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/test_cls_config_builder.py
-tests/unit/algorithms/classification/adapters/mmcls/test_mmcls_data_params_validation.py
 tests/unit/algorithms/classification/adapters/mmcls/data/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/data/test_datasets.py
 tests/unit/algorithms/classification/adapters/mmcls/data/test_pipelines.py
 tests/unit/algorithms/classification/adapters/mmcls/models/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_byol.py
 tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_sam_classifier.py
@@ -1674,79 +1642,58 @@
 tests/unit/algorithms/classification/adapters/mmcls/models/necks/test_selfsl_mlp.py
 tests/unit/algorithms/classification/adapters/mmcls/nncf/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_builder.py
 tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_patches.py
 tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_registers.py
 tests/unit/algorithms/classification/adapters/mmcls/optimizer/__init__.py
 tests/unit/algorithms/classification/adapters/mmcls/optimizer/test_lars.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_evaluator.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_explanier.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_exporter.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_inferrer.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_stage.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/test_cls_trainer.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/incremental/test_cls_incremental_stage.py
-tests/unit/algorithms/classification/adapters/mmcls/tasks/semisl/test_cls_semisl_stage.py
 tests/unit/algorithms/classification/adapters/openvino/__init__.py
 tests/unit/algorithms/classification/adapters/openvino/test_openvino_models.py
-tests/unit/algorithms/classification/adapters/openvino/test_openvino_models_params_validation.py
 tests/unit/algorithms/classification/tasks/__init__.py
-tests/unit/algorithms/classification/tasks/test_classification_inference.py
-tests/unit/algorithms/classification/tasks/test_classification_inference_task_params_validation.py
 tests/unit/algorithms/classification/tasks/test_classification_nncf.py
-tests/unit/algorithms/classification/tasks/test_classification_nncf_task_params_validation.py
 tests/unit/algorithms/classification/tasks/test_classification_openvino_task.py
-tests/unit/algorithms/classification/tasks/test_classification_openvino_task_params_validation.py
-tests/unit/algorithms/classification/tasks/test_classification_train_task.py
-tests/unit/algorithms/classification/tasks/test_classification_train_task_params_validation.py
 tests/unit/algorithms/classification/utils/__init__.py
 tests/unit/algorithms/classification/utils/test_utils.py
 tests/unit/algorithms/common/__init__.py
 tests/unit/algorithms/common/adapters/__init__.py
 tests/unit/algorithms/common/adapters/mmcv/__init__.py
 tests/unit/algorithms/common/adapters/mmcv/test_hooks.py
-tests/unit/algorithms/common/adapters/mmcv/test_mmcv_hooks_params_validation.py
-tests/unit/algorithms/common/adapters/mmcv/test_mmcv_runner_params_validation.py
-tests/unit/algorithms/common/adapters/mmcv/test_mmcv_utils_params_validation.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_adaptive_training_hooks.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_cancel_interface_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_checkpoint_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_composed_dataloader_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_early_stopping_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_ema_v2_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_eval_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_fp16_sam_optimizer_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_ib_loss_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_logger_replace_hook.py
+tests/unit/algorithms/common/adapters/mmcv/hooks/test_lr_updater_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_model_ema_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_no_bias_decay_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_recording_forward_hooks.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_save_initial_weight_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_semisl_cls_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_task_adapt_hook.py
 tests/unit/algorithms/common/adapters/mmcv/hooks/test_unbiased_teacher_hook.py
-tests/unit/algorithms/common/adapters/mmcv/hooks/test_workflow_hooks.py
 tests/unit/algorithms/common/adapters/mmcv/nncf/__init__.py
 tests/unit/algorithms/common/adapters/mmcv/nncf/test_helpers.py
 tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_hooks.py
 tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_runners.py
 tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_utils.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/__init__.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/__init__.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augments.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augmix.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_otx_transforms.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_random_augment.py
 tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_twocrop_transform.py
-tests/unit/algorithms/common/adapters/mmcv/tasks/test_builder.py
-tests/unit/algorithms/common/adapters/mmcv/tasks/test_export_mixin.py
+tests/unit/algorithms/common/adapters/mmcv/tasks/test_exporter.py
 tests/unit/algorithms/common/adapters/mmcv/tasks/test_helpers.py
-tests/unit/algorithms/common/adapters/mmcv/tasks/test_stage.py
 tests/unit/algorithms/common/adapters/mmcv/tasks/test_version.py
-tests/unit/algorithms/common/adapters/mmcv/tasks/test_workflow.py
 tests/unit/algorithms/common/adapters/mmdeploy/__init__.py
 tests/unit/algorithms/common/adapters/mmdeploy/test_deploy_apis.py
 tests/unit/algorithms/common/adapters/mmdeploy/test_helpers.py
 tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_mmdeploy.py
 tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_onnx.py
 tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_operations_domain.py
 tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_utils.py
@@ -1755,28 +1702,28 @@
 tests/unit/algorithms/common/adapters/nncf/test_nncf_config.py
 tests/unit/algorithms/common/adapters/nncf/test_nncf_patches.py
 tests/unit/algorithms/common/adapters/nncf/test_nncf_utils.py
 tests/unit/algorithms/common/adapters/torch/dataloaders/__init__.py
 tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_balanced_sampler.py
 tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_cls_incr_sampler.py
 tests/unit/algorithms/common/utils/__init__.py
-tests/unit/algorithms/common/utils/test_common_utils_params_validation.py
 tests/unit/algorithms/detection/__init__.py
 tests/unit/algorithms/detection/conftest.py
 tests/unit/algorithms/detection/test_helpers.py
+tests/unit/algorithms/detection/test_xai_detection_validity.py
 tests/unit/algorithms/detection/adapters/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/__init__.py
-tests/unit/algorithms/detection/adapters/mmdet/test_detection_dataset_params_validation.py
-tests/unit/algorithms/detection/adapters/mmdet/test_detection_pipelines_params_validation.py
+tests/unit/algorithms/detection/adapters/mmdet/test_configurer.py
+tests/unit/algorithms/detection/adapters/mmdet/test_task.py
 tests/unit/algorithms/detection/adapters/mmdet/datasets/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/datasets/test_detection_dataset.py
 tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/test_torchvision2mmdet.py
 tests/unit/algorithms/detection/adapters/mmdet/hooks/__init__.py
-tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_saliency_map_hook.py
+tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_class_probability_map_hook.py
 tests/unit/algorithms/detection/adapters/mmdet/models/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/models/backones/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/models/backones/test_ov_mmdet_mmov_backbone.py
 tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_rpn_head.py
 tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_ssd_head.py
 tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_yolov3_head.py
@@ -1792,103 +1739,72 @@
 tests/unit/algorithms/detection/adapters/mmdet/models/necks/test_ov_mmdet_mmov_ssd_neck.py
 tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/test_ov_mmdet_single_level_roi_extractor.py
 tests/unit/algorithms/detection/adapters/mmdet/nncf/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_builder.py
 tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_patches.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_exporter.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_inferrer.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_stage.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_trainer.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/incremental/test_det_incremental_stage.py
-tests/unit/algorithms/detection/adapters/mmdet/tasks/semisl/test_det_semisl_stage.py
+tests/unit/algorithms/detection/adapters/mmdet/nncf/test_task.py
 tests/unit/algorithms/detection/adapters/mmdet/utils/__init__.py
 tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_builder.py
 tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_config_utils.py
+tests/unit/algorithms/detection/adapters/mmdet/utils/test_exporter.py
 tests/unit/algorithms/detection/adapters/openvino/__init__.py
+tests/unit/algorithms/detection/adapters/openvino/test_task.py
 tests/unit/algorithms/detection/adapters/openvino/model_wrappers/__init__.py
 tests/unit/algorithms/detection/adapters/openvino/model_wrappers/test_detection_openvino_models.py
-tests/unit/algorithms/detection/tasks/__init__.py
-tests/unit/algorithms/detection/tasks/test_detection_inference.py
-tests/unit/algorithms/detection/tasks/test_detection_inference_task_params_validation.py
-tests/unit/algorithms/detection/tasks/test_detection_nncf.py
-tests/unit/algorithms/detection/tasks/test_detection_nncf_task_params_validation.py
-tests/unit/algorithms/detection/tasks/test_detection_openvino.py
-tests/unit/algorithms/detection/tasks/test_detection_openvino_task_params_validation.py
-tests/unit/algorithms/detection/tasks/test_detection_train.py
-tests/unit/algorithms/detection/tasks/test_detection_train_task_params_validation.py
 tests/unit/algorithms/detection/tiling/__init__.py
-tests/unit/algorithms/detection/tiling/test_tiling_detection_unittest.py
+tests/unit/algorithms/detection/tiling/test_tiling_detection.py
+tests/unit/algorithms/detection/tiling/test_tiling_tile_classifier.py
 tests/unit/algorithms/detection/utils/__init__.py
-tests/unit/algorithms/detection/utils/test_detection_config_utils_params_validation.py
 tests/unit/algorithms/detection/utils/test_detection_data.py
-tests/unit/algorithms/detection/utils/test_detection_data_utils_params_validation.py
 tests/unit/algorithms/detection/utils/test_detection_mask_to_bbox.py
 tests/unit/algorithms/detection/utils/test_detection_utils.py
 tests/unit/algorithms/segmentation/__init__.py
 tests/unit/algorithms/segmentation/conftest.py
 tests/unit/algorithms/segmentation/test_helpers.py
+tests/unit/algorithms/segmentation/test_task.py
 tests/unit/algorithms/segmentation/adapters/__init__.py
+tests/unit/algorithms/segmentation/adapters/test_otx_segmentation_task.py
 tests/unit/algorithms/segmentation/adapters/mmseg/__init__.py
+tests/unit/algorithms/segmentation/adapters/mmseg/test_mmseg_configurer.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset.py
-tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset_params_validation.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_compose.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_loads.py
-tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_pipelines_params_validation.py
 tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_transforms.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_litehrnet.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_mmseg_mmov_backbone.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/__init__.py
+tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_detcon_head.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_mmseg_mmov_decode_head.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/test_detcon_loss.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/test_selfsl_mlp.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/test_schedulers.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/test_detcon.py
 tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/test_utils.py
 tests/unit/algorithms/segmentation/adapters/mmseg/nncf/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_builder.py
-tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_hooks.py
 tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_patches.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/__init__.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_exporter.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_inferrer.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_stage.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_trainer.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/incremental/__init__.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/incremental/test_seg_incremental_stage.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/__init__.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/test_seg_semisl_inferrer.py
-tests/unit/algorithms/segmentation/adapters/mmseg/tasks/semisl/test_seg_semisl_stage.py
+tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_task.py
 tests/unit/algorithms/segmentation/adapters/mmseg/utils/__init__.py
 tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils.py
-tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils_params_validation.py
 tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils.py
-tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils_params_validation.py
+tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_exporter.py
 tests/unit/algorithms/segmentation/adapters/openvino/__init__.py
-tests/unit/algorithms/segmentation/adapters/openvino/test_blur_params_validation.py
+tests/unit/algorithms/segmentation/adapters/openvino/test_openvino_task.py
 tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/__init__.py
 tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/test_blur.py
-tests/unit/algorithms/segmentation/tasks/__init__.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_inference.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_inference_task_params_validation.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_nncf.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_nncf_task_params_validation.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_openvino.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_openvino_task_params_validation.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_train.py
-tests/unit/algorithms/segmentation/tasks/test_segmentation_train_task_params_validation.py
 tests/unit/api/__init__.py
 tests/unit/api/configuration/__init__.py
 tests/unit/api/configuration/dummy_broken_config.yaml
 tests/unit/api/configuration/dummy_config.py
 tests/unit/api/configuration/dummy_config.yaml
 tests/unit/api/configuration/test_configurable_parameters.py
 tests/unit/api/configuration/test_configuration_helper.py
@@ -1973,14 +1889,15 @@
 tests/unit/cli/utils/test_config.py
 tests/unit/cli/utils/test_hpo.py
 tests/unit/cli/utils/test_importing.py
 tests/unit/cli/utils/test_io.py
 tests/unit/cli/utils/test_multi_gpu.py
 tests/unit/cli/utils/test_nncf.py
 tests/unit/cli/utils/test_parser.py
+tests/unit/cli/utils/test_report.py
 tests/unit/cli/utils/test_telemetry.py
 tests/unit/core/__init__.py
 tests/unit/core/test_core_patcher.py
 tests/unit/core/data/__init__.py
 tests/unit/core/data/test_caching.py
 tests/unit/core/data/test_helpers.py
 tests/unit/core/data/adapter/test_action_adapter.py
```

### Comparing `otx-1.1.2rc1/otx.egg-info/requires.txt` & `otx-1.2.0rc1/otx.egg-info/requires.txt`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/setup.py` & `otx-1.2.0rc1/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,21 @@
 """Setup file for OTX."""
 
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
+# ruff: noqa
+
 import os
 import platform
-import subprocess
-import sys
-import warnings
 from collections import defaultdict
-from glob import glob
 from importlib.util import module_from_spec, spec_from_file_location
 from pathlib import Path
-from typing import List, Optional, Union
+from typing import List, Union
 
-import Cython
 import numpy
 from Cython.Build import cythonize
 from pkg_resources import Requirement
 from setuptools import Extension, find_packages, setup
 
 try:
     from torch.utils.cpp_extension import BuildExtension
@@ -90,27 +87,25 @@
 
     requirements: List[str] = []
     for requirement_file in requirement_files:
         with open(f"requirements/{requirement_file}.txt", "r", encoding="UTF-8") as file:
             for line in file:
                 package = line.strip()
                 if package and not package.startswith(("#", "-f")):
-                    requirement = Requirement.parse(package)
+                    Requirement.parse(package)
                     requirements.append(package)
 
     return requirements
 
 
 def get_extensions():
     if platform.system() == "Windows":
         return []
 
     def _cython_modules():
-        package_root = os.path.dirname(__file__)
-
         cython_files = [
             "otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/pil_augment.pyx",
             "otx/algorithms/common/adapters/mmcv/pipelines/transforms/cython_augments/cv_augment.pyx"
         ]
 
         ext_modules = [
             Extension(
@@ -192,14 +187,15 @@
     url="https://github.com/openvinotoolkit/training_extensions",
     classifiers=[
         "Development Status :: 5 - Production/Stable",
         "License :: OSI Approved :: Apache Software License",
         "Programming Language :: Python :: 3",
         "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
         "Programming Language :: Cython",
     ],
     license="Apache License 2.0",
     packages=find_packages(exclude=("tests",)),
     package_data=package_data,
     ext_modules=get_extensions(),
     cmdclass=cmd_class,
```

### Comparing `otx-1.1.2rc1/tests/.pytest_cache/v/cache/nodeids` & `otx-1.2.0rc1/tests/.pytest_cache/v/cache/nodeids`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,17 +1,13 @@
-# Copyright (C) 2022-2023 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 # http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions
 # and limitations under the License.
-
-import os
-
-os.environ["FEATURE_FLAGS_OTX_ACTION_TASKS"] = "1"
```

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/training/street/1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset/validation/2.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset/validation/2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2017_dataset/dataset_with_meta_file/training/street/1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.json` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/training/street/1.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.json` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset/validation/2.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.jpg` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.json` & `otx-1.2.0rc1/tests/assets/ade20k2020_dataset/dataset_with_meta_file/training/street/1.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/anomaly/classification/train.json` & `otx-1.2.0rc1/tests/assets/anomaly/detection/train.json`

 * *Files 16% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.511904761904762%*

 * *Differences: {"'bboxes'": 'OrderedDict()',*

 * * "'image_path'": "{'0': 'train/good/06.jpg', '1': 'train/good/32.jpg', '2': 'train/good/00.jpg', "*

 * *                 "'3': 'train/good/33.jpg', '4': 'train/good/21.jpg', '5': 'train/good/03.jpg', "*

 * *                 "'6': 'train/good/07.jpg', '7': 'train/good/14.jpg', '8': 'train/good/17.jpg', "*

 * *                 "'9': 'train/good/02.jpg', '10': 'train/good/30.jpg', '11': 'train/good/26.jpg', "*

 * *                 "'12': 'train/good/19.jpg', '13': 'train/good/16.jpg', '14': 'train/go []*

```diff
@@ -1,29 +1,38 @@
 {
+    "bboxes": {},
     "image_path": {
-        "0": "train/good/000.png",
-        "1": "train/good/001.png",
-        "10": "train/good/010.png",
-        "11": "train/good/011.png",
-        "12": "train/good/012.png",
-        "13": "train/good/013.png",
-        "14": "train/good/014.png",
-        "15": "train/good/015.png",
-        "16": "train/good/016.png",
-        "17": "train/good/017.png",
-        "18": "train/good/018.png",
-        "19": "train/good/019.png",
-        "2": "train/good/002.png",
-        "3": "train/good/003.png",
-        "4": "train/good/004.png",
-        "5": "train/good/005.png",
-        "6": "train/good/006.png",
-        "7": "train/good/007.png",
-        "8": "train/good/008.png",
-        "9": "train/good/009.png"
+        "0": "train/good/06.jpg",
+        "1": "train/good/32.jpg",
+        "10": "train/good/30.jpg",
+        "11": "train/good/26.jpg",
+        "12": "train/good/19.jpg",
+        "13": "train/good/16.jpg",
+        "14": "train/good/01.jpg",
+        "15": "train/good/15.jpg",
+        "16": "train/good/31.jpg",
+        "17": "train/good/27.jpg",
+        "18": "train/good/29.jpg",
+        "19": "train/good/10.jpg",
+        "2": "train/good/00.jpg",
+        "20": "train/good/20.jpg",
+        "21": "train/good/12.jpg",
+        "22": "train/good/11.jpg",
+        "23": "train/good/24.jpg",
+        "24": "train/good/09.jpg",
+        "25": "train/good/08.jpg",
+        "26": "train/good/22.jpg",
+        "27": "train/good/18.jpg",
+        "3": "train/good/33.jpg",
+        "4": "train/good/21.jpg",
+        "5": "train/good/03.jpg",
+        "6": "train/good/07.jpg",
+        "7": "train/good/14.jpg",
+        "8": "train/good/17.jpg",
+        "9": "train/good/02.jpg"
     },
     "label": {
         "0": "good",
         "1": "good",
         "10": "good",
         "11": "good",
         "12": "good",
@@ -31,14 +40,22 @@
         "14": "good",
         "15": "good",
         "16": "good",
         "17": "good",
         "18": "good",
         "19": "good",
         "2": "good",
+        "20": "good",
+        "21": "good",
+        "22": "good",
+        "23": "good",
+        "24": "good",
+        "25": "good",
+        "26": "good",
+        "27": "good",
         "3": "good",
         "4": "good",
         "5": "good",
         "6": "good",
         "7": "good",
         "8": "good",
         "9": "good"
```

### Comparing `otx-1.1.2rc1/tests/assets/anomaly/detection/test.json` & `otx-1.2.0rc1/tests/assets/anomaly/detection/val.json`

 * *Files 24% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.6174733709273182%*

 * *Differences: {"'bboxes'": "{'7': [[0.421875, 0.427734375, 0.580078125, 0.525390625], [0.623046875, 0.453125, "*

 * *             "0.67578125, 0.513671875]], '8': {0: {insert: [(0, 0.5859375), (2, 0.751953125), (3, "*

 * *             '0.58203125)], delete: [3, 2, 1]}, insert: [(1, [0.513671875, 0.39453125, 0.62890625, '*

 * *             '0.501953125]), (2, [0.337890625, 0.45703125, 0.47265625, 0.515625]), (3, '*

 * *             "[0.626953125, 0.607421875, 0.642578125, 0.626953125])], delete: [0]}, '9': "*

 * *             '[[0.361328125, 0.28 []*

```diff
@@ -1,188 +1,262 @@
 {
     "bboxes": {
         "10": [
             [
-                0.015625,
-                0.15625,
-                0.9609375,
-                0.9765625
-            ]
-        ],
-        "11": [
+                0.396484375,
+                0.41015625,
+                0.427734375,
+                0.4375
+            ],
             [
-                0.0625,
-                0.0546875,
-                0.953125,
-                0.9609375
-            ]
-        ],
-        "12": [
+                0.51953125,
+                0.482421875,
+                0.576171875,
+                0.6328125
+            ],
             [
+                0.357421875,
+                0.484375,
+                0.462890625,
+                0.64453125
+            ],
+            [
+                0.541015625,
+                0.5078125,
                 0.6953125,
-                0.71875,
-                0.9765625,
-                0.9765625
+                0.693359375
             ],
             [
-                0.203125,
-                0.4375,
-                0.421875,
-                0.6328125
+                0.263671875,
+                0.51953125,
+                0.3125,
+                0.57421875
             ],
             [
-                0.109375,
-                0.09375,
-                0.40625,
-                0.375
+                0.43359375,
+                0.708984375,
+                0.46484375,
+                0.728515625
             ]
         ],
-        "13": [
+        "3": [
+            [
+                0.560546875,
+                0.384765625,
+                0.619140625,
+                0.4609375
+            ],
             [
-                0.2890625,
-                0.6640625,
-                0.6015625,
-                0.921875
+                0.41796875,
+                0.458984375,
+                0.630859375,
+                0.640625
             ],
             [
-                0.0078125,
-                0.15625,
-                0.1171875,
-                0.25
+                0.423828125,
+                0.701171875,
+                0.484375,
+                0.734375
             ],
             [
-                0.59375,
-                0.046875,
-                0.6875,
-                0.1171875
+                0.400390625,
+                0.7578125,
+                0.455078125,
+                0.794921875
             ]
         ],
-        "14": [
+        "4": [
+            [
+                0.466796875,
+                0.443359375,
+                0.705078125,
+                0.603515625
+            ],
             [
-                0.0078125,
-                0.0,
-                0.9296875,
-                0.796875
-            ]
-        ],
-        "15": [
+                0.48828125,
+                0.451171875,
+                0.517578125,
+                0.470703125
+            ],
             [
-                0.359375,
-                0.53125,
-                0.796875,
-                0.8984375
+                0.388671875,
+                0.521484375,
+                0.453125,
+                0.552734375
             ],
             [
-                0.65625,
-                0.0,
-                0.984375,
-                0.2890625
-            ]
-        ],
-        "16": [
+                0.39453125,
+                0.599609375,
+                0.474609375,
+                0.65625
+            ],
             [
-                0.0078125,
-                0.0,
-                0.984375,
-                0.8828125
+                0.35546875,
+                0.62109375,
+                0.390625,
+                0.640625
             ]
         ],
-        "17": [
+        "5": [
+            [
+                0.591796875,
+                0.412109375,
+                0.712890625,
+                0.595703125
+            ],
             [
-                0.203125,
-                0.0,
-                0.984375,
-                0.859375
+                0.21484375,
+                0.447265625,
+                0.2421875,
+                0.548828125
+            ],
+            [
+                0.25,
+                0.447265625,
+                0.337890625,
+                0.552734375
             ]
         ],
-        "18": [
+        "6": [
             [
-                0.421875,
-                0.1328125,
-                0.796875,
-                0.4453125
+                0.349609375,
+                0.23828125,
+                0.583984375,
+                0.314453125
+            ],
+            [
+                0.265625,
+                0.384765625,
+                0.37890625,
+                0.568359375
             ],
             [
-                0.03125,
-                0.0,
-                0.40625,
-                0.3125
+                0.369140625,
+                0.478515625,
+                0.50390625,
+                0.603515625
+            ],
+            [
+                0.234375,
+                0.482421875,
+                0.263671875,
+                0.5390625
+            ],
+            [
+                0.298828125,
+                0.580078125,
+                0.357421875,
+                0.626953125
+            ],
+            [
+                0.328125,
+                0.72265625,
+                0.380859375,
+                0.767578125
             ]
         ],
         "7": [
             [
-                0.03125,
-                0.1953125,
-                0.84375,
-                0.9765625
+                0.421875,
+                0.427734375,
+                0.580078125,
+                0.525390625
+            ],
+            [
+                0.623046875,
+                0.453125,
+                0.67578125,
+                0.513671875
             ]
         ],
         "8": [
             [
-                0.03125,
-                0.0703125,
-                0.9609375,
-                0.9765625
+                0.5859375,
+                0.375,
+                0.751953125,
+                0.58203125
             ],
             [
-                0.375,
-                0.4296875,
-                0.484375,
-                0.5390625
+                0.513671875,
+                0.39453125,
+                0.62890625,
+                0.501953125
+            ],
+            [
+                0.337890625,
+                0.45703125,
+                0.47265625,
+                0.515625
+            ],
+            [
+                0.626953125,
+                0.607421875,
+                0.642578125,
+                0.626953125
             ]
         ],
         "9": [
             [
-                0.25,
-                0.8671875,
-                0.265625,
-                0.9140625
+                0.361328125,
+                0.287109375,
+                0.396484375,
+                0.33203125
+            ],
+            [
+                0.25390625,
+                0.392578125,
+                0.28125,
+                0.4375
+            ],
+            [
+                0.447265625,
+                0.40234375,
+                0.74609375,
+                0.6328125
+            ],
+            [
+                0.396484375,
+                0.474609375,
+                0.431640625,
+                0.505859375
+            ],
+            [
+                0.4921875,
+                0.650390625,
+                0.513671875,
+                0.66796875
             ],
             [
-                0.0390625,
-                0.09375,
-                0.8359375,
-                0.84375
+                0.533203125,
+                0.669921875,
+                0.56640625,
+                0.693359375
             ]
         ]
     },
     "image_path": {
-        "1": "test/good/004.png",
-        "10": "test/star/007.png",
-        "11": "test/star/008.png",
-        "12": "test/star/009.png",
-        "13": "test/hexagon/004.png",
-        "14": "test/hexagon/005.png",
-        "15": "test/hexagon/006.png",
-        "16": "test/hexagon/007.png",
-        "17": "test/hexagon/008.png",
-        "18": "test/hexagon/009.png",
-        "2": "test/good/005.png",
-        "3": "test/good/006.png",
-        "4": "test/good/007.png",
-        "5": "test/good/008.png",
-        "6": "test/good/009.png",
-        "7": "test/star/004.png",
-        "8": "test/star/005.png",
-        "9": "test/star/006.png"
+        "0": "test/good/13.jpg",
+        "1": "test/good/23.jpg",
+        "10": "test/colour/04.jpg",
+        "2": "test/good/04.jpg",
+        "3": "test/colour/13.jpg",
+        "4": "test/colour/00.jpg",
+        "5": "test/colour/05.jpg",
+        "6": "test/colour/02.jpg",
+        "7": "test/colour/16.jpg",
+        "8": "test/colour/15.jpg",
+        "9": "test/colour/10.jpg"
     },
     "label": {
+        "0": "good",
         "1": "good",
-        "10": "star",
-        "11": "star",
-        "12": "star",
-        "13": "hexagon",
-        "14": "hexagon",
-        "15": "hexagon",
-        "16": "hexagon",
-        "17": "hexagon",
-        "18": "hexagon",
+        "10": "abnormal",
         "2": "good",
-        "3": "good",
-        "4": "good",
-        "5": "good",
-        "6": "good",
-        "7": "star",
-        "8": "star",
-        "9": "star"
+        "3": "abnormal",
+        "4": "abnormal",
+        "5": "abnormal",
+        "6": "abnormal",
+        "7": "abnormal",
+        "8": "abnormal",
+        "9": "abnormal"
     }
 }
```

### Comparing `otx-1.1.2rc1/tests/assets/anomaly/detection/train.json` & `otx-1.2.0rc1/tests/assets/anomaly/classification/train.json`

 * *Files 13% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.38392857142857145%*

 * *Differences: {"'image_path'": "{'0': 'train/good/06.jpg', '1': 'train/good/32.jpg', '2': 'train/good/00.jpg', "*

 * *                 "'3': 'train/good/33.jpg', '4': 'train/good/21.jpg', '5': 'train/good/03.jpg', "*

 * *                 "'6': 'train/good/07.jpg', '7': 'train/good/14.jpg', '8': 'train/good/17.jpg', "*

 * *                 "'9': 'train/good/02.jpg', '10': 'train/good/30.jpg', '11': 'train/good/26.jpg', "*

 * *                 "'12': 'train/good/19.jpg', '13': 'train/good/16.jpg', '14': 'train/good/01.jpg', "*

 * *                 []*

```diff
@@ -1,30 +1,37 @@
 {
-    "bboxes": {},
     "image_path": {
-        "0": "train/good/000.png",
-        "1": "train/good/001.png",
-        "10": "train/good/010.png",
-        "11": "train/good/011.png",
-        "12": "train/good/012.png",
-        "13": "train/good/013.png",
-        "14": "train/good/014.png",
-        "15": "train/good/015.png",
-        "16": "train/good/016.png",
-        "17": "train/good/017.png",
-        "18": "train/good/018.png",
-        "19": "train/good/019.png",
-        "2": "train/good/002.png",
-        "3": "train/good/003.png",
-        "4": "train/good/004.png",
-        "5": "train/good/005.png",
-        "6": "train/good/006.png",
-        "7": "train/good/007.png",
-        "8": "train/good/008.png",
-        "9": "train/good/009.png"
+        "0": "train/good/06.jpg",
+        "1": "train/good/32.jpg",
+        "10": "train/good/30.jpg",
+        "11": "train/good/26.jpg",
+        "12": "train/good/19.jpg",
+        "13": "train/good/16.jpg",
+        "14": "train/good/01.jpg",
+        "15": "train/good/15.jpg",
+        "16": "train/good/31.jpg",
+        "17": "train/good/27.jpg",
+        "18": "train/good/29.jpg",
+        "19": "train/good/10.jpg",
+        "2": "train/good/00.jpg",
+        "20": "train/good/20.jpg",
+        "21": "train/good/12.jpg",
+        "22": "train/good/11.jpg",
+        "23": "train/good/24.jpg",
+        "24": "train/good/09.jpg",
+        "25": "train/good/08.jpg",
+        "26": "train/good/22.jpg",
+        "27": "train/good/18.jpg",
+        "3": "train/good/33.jpg",
+        "4": "train/good/21.jpg",
+        "5": "train/good/03.jpg",
+        "6": "train/good/07.jpg",
+        "7": "train/good/14.jpg",
+        "8": "train/good/17.jpg",
+        "9": "train/good/02.jpg"
     },
     "label": {
         "0": "good",
         "1": "good",
         "10": "good",
         "11": "good",
         "12": "good",
@@ -32,16 +39,25 @@
         "14": "good",
         "15": "good",
         "16": "good",
         "17": "good",
         "18": "good",
         "19": "good",
         "2": "good",
+        "20": "good",
+        "21": "good",
+        "22": "good",
+        "23": "good",
+        "24": "good",
+        "25": "good",
+        "26": "good",
+        "27": "good",
         "3": "good",
         "4": "good",
         "5": "good",
         "6": "good",
         "7": "good",
         "8": "good",
         "9": "good"
-    }
+    },
+    "masks": {}
 }
```

### Comparing `otx-1.1.2rc1/tests/assets/anomaly/segmentation/train.json` & `otx-1.2.0rc1/tests/assets/anomaly/segmentation/train.json`

 * *Files 14% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.8452380952380952%*

 * *Differences: {"'image_path'": "{'0': 'train/good/06.jpg', '1': 'train/good/32.jpg', '2': 'train/good/00.jpg', "*

 * *                 "'3': 'train/good/33.jpg', '4': 'train/good/21.jpg', '5': 'train/good/03.jpg', "*

 * *                 "'6': 'train/good/07.jpg', '7': 'train/good/14.jpg', '8': 'train/good/17.jpg', "*

 * *                 "'9': 'train/good/02.jpg', '10': 'train/good/30.jpg', '11': 'train/good/26.jpg', "*

 * *                 "'12': 'train/good/19.jpg', '13': 'train/good/16.jpg', '14': 'train/good/01.jpg', "*

 * *                 []*

```diff
@@ -1,29 +1,37 @@
 {
     "image_path": {
-        "0": "train/good/000.png",
-        "1": "train/good/001.png",
-        "10": "train/good/010.png",
-        "11": "train/good/011.png",
-        "12": "train/good/012.png",
-        "13": "train/good/013.png",
-        "14": "train/good/014.png",
-        "15": "train/good/015.png",
-        "16": "train/good/016.png",
-        "17": "train/good/017.png",
-        "18": "train/good/018.png",
-        "19": "train/good/019.png",
-        "2": "train/good/002.png",
-        "3": "train/good/003.png",
-        "4": "train/good/004.png",
-        "5": "train/good/005.png",
-        "6": "train/good/006.png",
-        "7": "train/good/007.png",
-        "8": "train/good/008.png",
-        "9": "train/good/009.png"
+        "0": "train/good/06.jpg",
+        "1": "train/good/32.jpg",
+        "10": "train/good/30.jpg",
+        "11": "train/good/26.jpg",
+        "12": "train/good/19.jpg",
+        "13": "train/good/16.jpg",
+        "14": "train/good/01.jpg",
+        "15": "train/good/15.jpg",
+        "16": "train/good/31.jpg",
+        "17": "train/good/27.jpg",
+        "18": "train/good/29.jpg",
+        "19": "train/good/10.jpg",
+        "2": "train/good/00.jpg",
+        "20": "train/good/20.jpg",
+        "21": "train/good/12.jpg",
+        "22": "train/good/11.jpg",
+        "23": "train/good/24.jpg",
+        "24": "train/good/09.jpg",
+        "25": "train/good/08.jpg",
+        "26": "train/good/22.jpg",
+        "27": "train/good/18.jpg",
+        "3": "train/good/33.jpg",
+        "4": "train/good/21.jpg",
+        "5": "train/good/03.jpg",
+        "6": "train/good/07.jpg",
+        "7": "train/good/14.jpg",
+        "8": "train/good/17.jpg",
+        "9": "train/good/02.jpg"
     },
     "label": {
         "0": "good",
         "1": "good",
         "10": "good",
         "11": "good",
         "12": "good",
@@ -31,14 +39,22 @@
         "14": "good",
         "15": "good",
         "16": "good",
         "17": "good",
         "18": "good",
         "19": "good",
         "2": "good",
+        "20": "good",
+        "21": "good",
+        "22": "good",
+        "23": "good",
+        "24": "good",
+        "25": "good",
+        "26": "good",
+        "27": "good",
         "3": "good",
         "4": "good",
         "5": "good",
         "6": "good",
         "7": "good",
         "8": "good",
         "9": "good"
```

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/annotations/instances_train.json` & `otx-1.2.0rc1/tests/assets/car_tree_bug/annotations/instances_train.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/annotations/instances_val.json` & `otx-1.2.0rc1/tests/assets/car_tree_bug/annotations/instances_val.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide4.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide4.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide5.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide5.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide6.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide6.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide7.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide7.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide8.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide8.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/train/Slide9.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/train/Slide9.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide3.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide3.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide4.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide4.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/car_tree_bug/images/val/Slide5.PNG` & `otx-1.2.0rc1/tests/assets/car_tree_bug/images/val/Slide5.PNG`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0002.png` & `otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/train/masks/0002.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0002.png` & `otx-1.2.0rc1/tests/assets/common_semantic_segmentation_dataset/val/masks/0002.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00020.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00020.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00021.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00021.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00022.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00022.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00023.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00023.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00024.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00024.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00025.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00025.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00026.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00026.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00027.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00027.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00028.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00028.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00029.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/0/images/00029.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00020.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00020.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00021.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00021.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00022.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00022.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00023.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00023.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00024.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00024.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00025.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00025.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00026.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00026.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00027.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00027.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00028.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00028.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00029.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/1/images/00029.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00020.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00020.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00021.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00021.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00022.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00022.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00023.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00023.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00024.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00024.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00025.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00025.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00026.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00026.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00027.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00027.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00028.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00028.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00029.jpg` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_classification/train/2/images/00029.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000020.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000020.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000021.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000021.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000022.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000022.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000023.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000023.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000024.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000024.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000025.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000025.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000026.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000026.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000027.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000027.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000028.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000028.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000029.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/0/images/frame_000029.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000020.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000020.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000021.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000021.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000022.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000022.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000023.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000023.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000024.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000024.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000025.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000025.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000026.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000026.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000027.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000027.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000028.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000028.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000029.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/1/images/frame_000029.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/annotations.xml` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/annotations.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000020.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000020.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000021.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000021.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000022.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000022.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000023.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000023.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000024.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000024.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000025.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000025.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000026.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000026.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000027.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000027.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000028.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000028.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000029.png` & `otx-1.2.0rc1/tests/assets/cvat_dataset/action_detection/train/2/images/frame_000029.png`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_h-label/annotations/train.json` & `otx-1.2.0rc1/tests/assets/datumaro_h-label/annotations/train.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_h-label/annotations/validation.json` & `otx-1.2.0rc1/tests/assets/datumaro_h-label/annotations/validation.json`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_h-label/images/train/a.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_h-label/images/train/a.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_h-label/images/train/b.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_h-label/images/train/b.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_h-label/images/validation/d.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_h-label/images/validation/d.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_multilabel/annotations/train.json` & `otx-1.2.0rc1/tests/assets/datumaro_multilabel/annotations/validation.json`

 * *Files 7% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.8958333333333334%*

 * *Differences: {"'items'": "{0: {'id': 'd', 'image': {'path': 'd.jpg'}}, delete: [1]}"}*

```diff
@@ -45,28 +45,14 @@
                 {
                     "group": 0,
                     "id": 1,
                     "label_id": 1,
                     "type": "label"
                 }
             ],
-            "id": "a",
+            "id": "d",
             "image": {
-                "path": "a.jpg"
-            }
-        },
-        {
-            "annotations": [
-                {
-                    "group": 0,
-                    "id": 0,
-                    "label_id": 0,
-                    "type": "label"
-                }
-            ],
-            "id": "b",
-            "image": {
-                "path": "b.jpg"
+                "path": "d.jpg"
             }
         }
     ]
 }
```

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/train/a.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/train/a.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/train/b.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/train/b.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/datumaro_multilabel/images/validation/d.jpg` & `otx-1.2.0rc1/tests/assets/datumaro_multilabel/images/validation/d.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_1.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_2.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_0/label_0_3.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_0/label_0_3.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_1.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_2.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset/label_1/label_1_3.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset/label_1/label_1_3.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_1.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_2.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_3.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_3.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_4.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_0/label_0_4.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_1.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_2.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_3.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_3.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_4.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_1/label_1_4.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_1.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_2.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_2.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_3.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_3.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_4.jpg` & `otx-1.2.0rc1/tests/assets/imagenet_dataset_class_incremental/label_2/label_2_4.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/2007_000001.xml` & `otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/Annotations/2007_000001.xml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000001.jpg` & `otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000001.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000002.jpg` & `otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset1/JPEGImages/2007_000002.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/2007_000001.jpg` & `otx-1.2.0rc1/tests/assets/voc_dataset/voc_dataset2/JPEGImages/2007_000001.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/assets/yolo_dataset/obj_train_data/1.jpg` & `otx-1.2.0rc1/tests/assets/yolo_dataset/obj_train_data/1.jpg`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/conftest.py` & `otx-1.2.0rc1/tests/conftest.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 
 def pytest_addoption(parser):
     otx_pytest_addoption_insertion(parser)  # noqa: F405
 
 
 @pytest.fixture(scope="session")
 def tmp_dir_path(request) -> Generator[Path, None, None]:
-    prefix = request.config.getoption("--test-work-dir")
+    prefix = request.config.getoption("--test-workspace")
     with TemporaryDirectory(prefix=prefix) as tmp_dir:
         yield Path(tmp_dir)
 
 
 @pytest.fixture(autouse=True)
 def set_default_tmp_path(tmp_dir_path: Path) -> Generator[None, None, None]:
     origin_tmp_dir = os.environ.get("TMPDIR", None)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/action/test_action_classification.py` & `otx-1.2.0rc1/tests/e2e/cli/action/test_action_classification.py`

 * *Files 0% similar despite different names*

```diff
@@ -64,15 +64,15 @@
         otx_export_testing(template, tmp_dir_path)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval_openvino(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "action_cls"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize(self, template, tmp_dir_path):
         if template.name == "MoViNet":
             pytest.skip(reason="[CVS-106020] MoViNet fails with POT")
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/action/test_action_detection.py` & `otx-1.2.0rc1/tests/e2e/cli/action/test_action_detection.py`

 * *Files 0% similar despite different names*

```diff
@@ -66,15 +66,15 @@
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skip(reason="CVS-102941 ONNX export of action detection model keeps failed")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval_openvino(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "action_det"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skip(reason="CVS-102941 ONNX export of action detection model keeps failed")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "action_det"
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_padim/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_classification_stfpm/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_padim/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_detection_stfpm/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_padim/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/nncf_quantization.dot` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/reference/ote_anomaly_segmentation_stfpm/nncf/nncf_quantization.dot`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_classification.py` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_detection.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for anomaly classification with OTX CLI"""
+"""Tests for anomaly detection with OTX CLI."""
 
 # Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -37,28 +37,28 @@
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
-templates = Registry("otx/algorithms").filter(task_type="ANOMALY_CLASSIFICATION").templates
+templates = Registry("otx/algorithms").filter(task_type="ANOMALY_DETECTION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsAnomalyClassification:
+class TestToolsAnomalyDetection:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_detection.py` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_segmentation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for anomaly detection with OTX CLI."""
+"""Tests for anomaly segmentation with OTX CLI"""
 
 # Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -37,28 +37,28 @@
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
-templates = Registry("otx/algorithms").filter(task_type="ANOMALY_DETECTION").templates
+templates = Registry("otx/algorithms").filter(task_type="ANOMALY_SEGMENTATION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsAnomalyDetection:
+class TestToolsAnomalySegmentation:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/anomaly/test_anomaly_segmentation.py` & `otx-1.2.0rc1/tests/e2e/cli/anomaly/test_anomaly_classification.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for anomaly segmentation with OTX CLI"""
+"""Tests for anomaly classification with OTX CLI"""
 
 # Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -37,28 +37,28 @@
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
-templates = Registry("otx/algorithms").filter(task_type="ANOMALY_SEGMENTATION").templates
+templates = Registry("otx/algorithms").filter(task_type="ANOMALY_CLASSIFICATION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsAnomalySegmentation:
+class TestToolsAnomalyClassification:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/classification/test_classification.py` & `otx-1.2.0rc1/tests/e2e/cli/classification/test_classification.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,15 +25,14 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
@@ -110,42 +109,45 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         otx_train_testing(template, tmp_dir_path, otx_dir, args0)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args0)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args0)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_export_testing(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    def test_otx_export_fp16(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
@@ -163,17 +165,18 @@
     def test_otx_explain_openvino(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         otx_demo_testing(template, tmp_dir_path, otx_dir, args)
@@ -281,15 +284,14 @@
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu"
         args1 = copy.deepcopy(args)
         args1["--gpus"] = "0,1"
@@ -310,15 +312,14 @@
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_semisl"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args0)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu_semisl"
         args_semisl_multigpu = copy.deepcopy(args0)
         args_semisl_multigpu["--unlabeled-data-roots"] = args["--train-data-roots"]
@@ -363,42 +364,38 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         otx_train_testing(template, tmp_dir_path, otx_dir, args0_m)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args_m)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_label_cls/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args0_m)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args0_m)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_export_testing(template, tmp_dir_path)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args_m)
@@ -530,15 +527,14 @@
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args_m)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_label_cls/test_multi_gpu"
         args0 = copy.deepcopy(args_m)
         args0["--gpus"] = "0,1"
@@ -564,41 +560,38 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         otx_train_testing(template, tmp_dir_path, otx_dir, args_h)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args_h)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "h_label_cls/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args_h)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args_h)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_export_testing(template, tmp_dir_path)
-
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args_h)
@@ -723,15 +716,14 @@
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args_h)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_validate_fq(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "classification", type(self).__name__)
 
     @e2e_pytest_component
@@ -766,27 +758,26 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_selfsl_train(self, template, tmp_dir_path):
         tmp_dir_path_1 = tmp_dir_path / "multi_class_cls/test_selfsl"
         otx_train_testing(template, tmp_dir_path_1, otx_dir, args_selfsl)
         template_work_dir = get_template_dir(template, tmp_dir_path_1)
         args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         tmp_dir_path_2 = tmp_dir_path / "multi_class_cls/test_selfsl_sl"
         otx_train_testing(template, tmp_dir_path_2, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_selfsl_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_selfsl_sl"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_selfsl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu_selfsl"
         args_selfsl_multigpu = copy.deepcopy(args_selfsl)
         args_selfsl_multigpu["--gpus"] = "0,1"
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/detection/test_detection.py` & `otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/test_instance_segmentation.py`

 * *Files 6% similar despite different names*

```diff
@@ -24,56 +24,38 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
 
-# Pre-train w/ 'person' class ##TODO: Currently, it is closed to sample test. need to change other sample
+# Pre-train w/ 'car & tree' class
 args0 = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "4", "--learning_parameters.batch_size", "4"],
+    "train_params": ["params", "--learning_parameters.num_iters", "4", "--learning_parameters.batch_size", "2"],
 }
 
-# Class-Incremental learning w/ 'vehicle', 'person', 'non-vehicle' classes
+# Class-Incremental learning w/ 'car', 'tree', 'bug' classes ## TODO: add class incr sample
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "2", "--learning_parameters.batch_size", "4"],
-}
-
-args_semisl = {
-    "--train-data-roots": "tests/assets/car_tree_bug",
-    "--val-data-roots": "tests/assets/car_tree_bug",
-    "--test-data-roots": "tests/assets/car_tree_bug",
-    "--unlabeled-data-roots": "tests/assets/car_tree_bug",
-    "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": [
-        "params",
-        "--learning_parameters.num_iters",
-        "2",
-        "--learning_parameters.batch_size",
-        "4",
-        "--algo_backend.train_type",
-        "Semisupervised",
-    ],
+    "train_params": ["params", "--learning_parameters.num_iters", "4", "--learning_parameters.batch_size", "2"],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
     "8",
@@ -83,230 +65,214 @@
 
 otx_dir = os.getcwd()
 
 MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
 TT_STABILITY_TESTS = os.environ.get("TT_STABILITY_TESTS", False)
 if TT_STABILITY_TESTS:
     default_template = parse_model_template(
-        os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
+        os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
     )
     templates = [default_template] * 100
     templates_ids = [template.model_template_id + f"-{i+1}" for i, template in enumerate(templates)]
 else:
-    templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
+    templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
     templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsMPADetection:
+class TestToolsMPAInstanceSegmentation:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_train_testing(template, tmp_dir_path, otx_dir, args0)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_resume"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args0)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args0)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
+    @pytest.mark.skip(reason="CVS-104657")
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_demo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_demo_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_demo_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_demo_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_demo_deployment_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_hpo"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_export_testing(template, tmp_dir_path)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_testing(template, tmp_dir_path, otx_dir, args, threshold=0.001)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-104657")
     def test_nncf_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         pot_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_multi_gpu"
         args1 = copy.deepcopy(args)
         args1["--gpus"] = "0,1"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
-
-
-class TestToolsMPASemiSLDetection:
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
-        otx_eval_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu_semisl"
-        args_semisl_multigpu = copy.deepcopy(args_semisl)
-        args_semisl_multigpu["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/detection/test_instance_segmentation.py` & `otx-1.2.0rc1/tests/e2e/cli/detection/test_tiling_detection.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-"""Tests for Class-Incremental Learning for object detection with OTX CLI"""
+"""Tests for MPA Class-Incremental Learning for object detection with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import copy
 import os
 
 import pytest
-import torch
 
 from otx.api.entities.model_template import parse_model_template
 from otx.cli.registry import Registry
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
     nncf_eval_openvino_testing,
@@ -24,253 +23,242 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
 
-# Pre-train w/ 'car & tree' class
-args0 = {
-    "--train-data-roots": "tests/assets/car_tree_bug",
-    "--val-data-roots": "tests/assets/car_tree_bug",
-    "--test-data-roots": "tests/assets/car_tree_bug",
-    "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "4", "--learning_parameters.batch_size", "2"],
-}
-
-# Class-Incremental learning w/ 'car', 'tree', 'bug' classes ## TODO: add class incr sample
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "4", "--learning_parameters.batch_size", "2"],
+    "train_params": [
+        "params",
+        "--learning_parameters.num_iters",
+        "10",
+        "--learning_parameters.batch_size",
+        "4",
+        "--tiling_parameters.enable_tiling",
+        "1",
+        "--tiling_parameters.enable_adaptive_params",
+        "1",
+    ],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
-    "8",
+    "15",
     "--learning_parameters.batch_size",
     "4",
 ]
 
 otx_dir = os.getcwd()
 
-MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
 TT_STABILITY_TESTS = os.environ.get("TT_STABILITY_TESTS", False)
 if TT_STABILITY_TESTS:
     default_template = parse_model_template(
-        os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
+        os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
     )
     templates = [default_template] * 100
     templates_ids = [template.model_template_id + f"-{i+1}" for i, template in enumerate(templates)]
 else:
-    templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
+    templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
     templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsMPAInstanceSegmentation:
+class TestToolsTilingDetection:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args0)
-        template_work_dir = get_template_dir(template, tmp_dir_path)
-        args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
+        tmp_dir_path = tmp_dir_path / "tiling_det"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_resume"
-        otx_resume_testing(template, tmp_dir_path, otx_dir, args0)
+        tmp_dir_path = tmp_dir_path / "tiling_det/test_resume"
+        otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
-        args1 = copy.deepcopy(args0)
+        args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "tiling_det"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "tiling_det"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        if template.name in ["SSD", "ATSS"]:
+            pytest.skip(reason="[CVS-108291] Tiling ATSS, SSD show performance drop")
+        tmp_dir_path = tmp_dir_path / "tiling_det"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_demo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_demo_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_demo_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        if template.name in ["ATSS", "SSD"]:
+            pytest.skip(reason="[CVS-108291] Tiling ATSS, SSD show performance drop")
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
     def test_otx_demo_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_demo_deployment_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_hpo"
+        tmp_dir_path = tmp_dir_path / "tiling_det/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_export_testing(template, tmp_dir_path)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_testing(template, tmp_dir_path, otx_dir, args, threshold=0.001)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-104657")
+    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         pot_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_det"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_multi_gpu_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_multi_gpu"
-        args1 = copy.deepcopy(args)
-        args1["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/detection/test_tiling_detection.py` & `otx-1.2.0rc1/tests/e2e/cli/instance_segmentation/test_tiling_instseg.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for MPA Class-Incremental Learning for object detection with OTX CLI"""
+"""Tests for MPA Class-Incremental Learning for instance segmentation with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import copy
 import os
 
 import pytest
@@ -23,15 +23,14 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
@@ -64,194 +63,198 @@
 ]
 
 otx_dir = os.getcwd()
 
 TT_STABILITY_TESTS = os.environ.get("TT_STABILITY_TESTS", False)
 if TT_STABILITY_TESTS:
     default_template = parse_model_template(
-        os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
+        os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
     )
     templates = [default_template] * 100
     templates_ids = [template.model_template_id + f"-{i+1}" for i, template in enumerate(templates)]
 else:
-    templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
+    templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
     templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsTilingDetection:
+class TestToolsTilingInstanceSegmentation:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det/test_resume"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_demo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_demo_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_demo_deployment_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det/test_hpo"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_export_testing(template, tmp_dir_path)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_testing(template, tmp_dir_path, otx_dir, args, threshold=0.001)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_eval_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         pot_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_det"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         pot_eval_testing(template, tmp_dir_path, otx_dir, args)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/detection/test_tiling_instseg.py` & `otx-1.2.0rc1/tests/integration/cli/detection/test_detection.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,257 +1,211 @@
-"""Tests for MPA Class-Incremental Learning for instance segmentation with OTX CLI"""
+"""Tests for Class-Incremental Learning for object detection with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import copy
 import os
 
 import pytest
+import torch
 
 from otx.api.entities.model_template import parse_model_template
 from otx.cli.registry import Registry
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
-    nncf_eval_openvino_testing,
-    nncf_eval_testing,
-    nncf_export_testing,
     nncf_optimize_testing,
-    nncf_validate_fq_testing,
-    otx_demo_deployment_testing,
-    otx_demo_openvino_testing,
-    otx_demo_testing,
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
+    otx_explain_all_classes_openvino_testing,
     otx_explain_openvino_testing,
+    otx_explain_process_saliency_maps_openvino_testing,
     otx_explain_testing,
+    otx_explain_testing_all_classes,
+    otx_explain_testing_process_saliency_maps,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
-    pot_eval_testing,
-    pot_optimize_testing,
-    pot_validate_fq_testing,
 )
 
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
+    "train_params": ["params", "--learning_parameters.num_iters", "1", "--learning_parameters.batch_size", "4"],
+}
+
+args_semisl = {
+    "--train-data-roots": "tests/assets/car_tree_bug",
+    "--val-data-roots": "tests/assets/car_tree_bug",
+    "--test-data-roots": "tests/assets/car_tree_bug",
+    "--unlabeled-data-roots": "tests/assets/car_tree_bug",
+    "--input": "tests/assets/car_tree_bug/images/train",
     "train_params": [
         "params",
         "--learning_parameters.num_iters",
-        "2",
+        "1",
         "--learning_parameters.batch_size",
         "4",
-        "--tiling_parameters.enable_tiling",
-        "1",
-        "--tiling_parameters.enable_adaptive_params",
-        "1",
+        "--algo_backend.train_type",
+        "Semisupervised",
     ],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
-    "4",
+    "2",
     "--learning_parameters.batch_size",
     "4",
 ]
 
 otx_dir = os.getcwd()
 
-TT_STABILITY_TESTS = os.environ.get("TT_STABILITY_TESTS", False)
-if TT_STABILITY_TESTS:
-    default_template = parse_model_template(
-        os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
-    )
-    templates = [default_template] * 100
-    templates_ids = [template.model_template_id + f"-{i+1}" for i, template in enumerate(templates)]
-else:
-    templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
-    templates_ids = [template.model_template_id for template in templates]
+MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
+default_template = parse_model_template(
+    os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
+)
+default_templates = [default_template]
+default_templates_ids = [default_template.model_template_id]
 
+templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
+templates_ids = [template.model_template_id for template in templates]
 
-class TestToolsTilingInstanceSegmentation:
+
+class TestDetectionCLI:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_resume"
+        tmp_dir_path = tmp_dir_path / "detection/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0, half_precision=half_precision)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_all_classes(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_testing_all_classes(template, tmp_dir_path, otx_dir, args)
+
+    @e2e_pytest_component
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_process_saliency_maps(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_testing_process_saliency_maps(template, tmp_dir_path, otx_dir, args)
+
+    @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_demo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_demo_testing(template, tmp_dir_path, otx_dir, args)
+    def test_otx_explain_all_classes_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_all_classes_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_demo_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_demo_openvino_testing(template, tmp_dir_path, otx_dir, args)
+    def test_otx_explain_process_saliency_maps_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_process_saliency_maps_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_demo_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        otx_demo_deployment_testing(template, tmp_dir_path, otx_dir, args)
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_hpo"
+        tmp_dir_path = tmp_dir_path / "detection/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        tmp_dir_path = tmp_dir_path / "detection"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-98026")
-    def test_nncf_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_export_testing(template, tmp_dir_path)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-98026")
-    def test_nncf_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-98026")
-    def test_nncf_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_eval_testing(template, tmp_dir_path, otx_dir, args, threshold=0.001)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    @pytest.mark.skip(reason="CVS-98026")
-    def test_nncf_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_eval_openvino_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_pot_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        pot_optimize_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_pot_validate_fq(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
+    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    def test_otx_multi_gpu_train(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu"
+        args1 = copy.deepcopy(args)
+        args1["--gpus"] = "0,1"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
-    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
-    @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_pot_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
-        pot_eval_testing(template, tmp_dir_path, otx_dir, args)
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    def test_otx_train_semisl(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
+
+    @e2e_pytest_component
+    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
+    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu_semisl"
+        args_semisl_multigpu = copy.deepcopy(args_semisl)
+        args_semisl_multigpu["--gpus"] = "0,1"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/segmentation/test_segmentation.py` & `otx-1.2.0rc1/tests/e2e/cli/semantic_segmentation/test_segmentation.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,14 @@
     otx_demo_openvino_testing,
     otx_demo_testing,
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
     pot_eval_testing,
     pot_optimize_testing,
     pot_validate_fq_testing,
 )
@@ -83,56 +82,60 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_export_testing(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    def test_otx_export_fp16(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.1)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.1, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_demo(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         otx_demo_testing(template, tmp_dir_path, otx_dir, args)
@@ -249,15 +252,14 @@
     def test_pot_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         if template.model_template_id.startswith("ClassIncremental_Semantic_Segmentation_Lite-HRNet-"):
             pytest.skip("CVS-82482")
         pot_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu"
         args1 = copy.deepcopy(args)
         args1["--gpus"] = "0,1"
@@ -292,15 +294,14 @@
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_semisl"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args_semisl)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu_semisl"
         args_semisl_multigpu = copy.deepcopy(args_semisl)
         args_semisl_multigpu["--gpus"] = "0,1"
@@ -326,27 +327,26 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path_1 = tmp_dir_path / "segmentation/test_selfsl"
         otx_train_testing(template, tmp_dir_path_1, otx_dir, args_selfsl)
         template_work_dir = get_template_dir(template, tmp_dir_path_1)
         args1 = copy.deepcopy(args)
-        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         tmp_dir_path_2 = tmp_dir_path / "segmentation/test_selfsl_sl"
         otx_train_testing(template, tmp_dir_path_2, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_selfsl_sl"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_selfsl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu_selfsl"
         args_selfsl_multigpu = copy.deepcopy(args_selfsl)
         args_selfsl_multigpu["--gpus"] = "0,1"
```

### Comparing `otx-1.1.2rc1/tests/e2e/cli/test_cli.py` & `otx-1.2.0rc1/tests/e2e/cli/test_cli.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/fuzzing/cli_fuzzing.py` & `otx-1.2.0rc1/tests/fuzzing/cli_fuzzing.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/integration/api/action/test_api_action_classification.py` & `otx-1.2.0rc1/tests/integration/api/action/test_api_action_classification.py`

 * *Files 2% similar despite different names*

```diff
@@ -54,16 +54,19 @@
         model_templates = ["x3d"]
         for model_template in model_templates:
             parse_model_template(
                 osp.join("otx/algorithms/action/configs", "classification", model_template, "template.yaml")
             )
 
     def init_environment(self, params, model_template):
+        algo_backend = model_template.hyper_parameters.parameter_overrides["algo_backend"]
+        train_type = algo_backend["train_type"]["default_value"]
         dataset_adapter = get_dataset_adapter(
             model_template.task_type,
+            train_type,
             train_data_roots=self.train_data_roots,
             val_data_roots=self.val_data_roots,
         )
         dataset = dataset_adapter.get_otx_dataset()
         label_schema = dataset_adapter.get_label_schema()
         environment = TaskEnvironment(
             model=None,
```

### Comparing `otx-1.1.2rc1/tests/integration/api/action/test_api_action_detection.py` & `otx-1.2.0rc1/tests/integration/api/action/test_api_action_detection.py`

 * *Files 3% similar despite different names*

```diff
@@ -53,16 +53,19 @@
         model_templates = ["x3d_fast_rcnn"]
         for model_template in model_templates:
             parse_model_template(
                 osp.join("otx/algorithms/action/configs", "detection", model_template, "template.yaml")
             )
 
     def init_environment(self, params, model_template):
+        algo_backend = model_template.hyper_parameters.parameter_overrides["algo_backend"]
+        train_type = algo_backend["train_type"]["default_value"]
         dataset_adapter = get_dataset_adapter(
             model_template.task_type,
+            train_type,
             train_data_roots=self.train_data_roots,
             val_data_roots=self.val_data_roots,
         )
         dataset = dataset_adapter.get_otx_dataset()
         label_schema = dataset_adapter.get_label_schema()
         environment = TaskEnvironment(
             model=None,
```

### Comparing `otx-1.1.2rc1/tests/integration/api/classification/test_api_classification.py` & `otx-1.2.0rc1/tests/integration/api/classification/test_api_classification.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,19 +8,16 @@
 from typing import Optional
 
 import cv2 as cv
 import numpy as np
 import pytest
 from bson import ObjectId
 
-from otx.algorithms.classification.tasks import (
-    ClassificationInferenceTask,
-    ClassificationTrainTask,
-)
-from otx.algorithms.common.tasks.training_base import BaseTask
+from otx.algorithms.classification.adapters.mmcls.task import MMClassificationTask
+from otx.algorithms.common.tasks.base_task import OTXTask
 from otx.api.configuration.helper import create
 from otx.api.entities.annotation import (
     Annotation,
     AnnotationSceneEntity,
     AnnotationSceneKind,
 )
 from otx.api.entities.dataset_item import DatasetItemEntity
@@ -41,15 +38,15 @@
 from otx.api.entities.train_parameters import TrainParameters
 from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from tests.test_suite.e2e_test_system import e2e_pytest_api
 
 DEFAULT_CLS_TEMPLATE_DIR = osp.join("otx/algorithms/classification", "configs", "efficientnet_b0_cls_incr")
 
 
-def task_eval(task: BaseTask, model: ModelEntity, dataset: DatasetEntity) -> Performance:
+def task_eval(task: OTXTask, model: ModelEntity, dataset: DatasetEntity) -> Performance:
     start_time = time.time()
     result_dataset = task.infer(dataset.with_empty_annotations())
     end_time = time.time()
     print(f"{len(dataset)} analysed in {end_time - start_time} seconds")
     result_set = ResultSetEntity(model=model, ground_truth_dataset=dataset, prediction_dataset=result_dataset)
     task.evaluate(result_set)
     assert result_set.performance is not None
@@ -199,15 +196,15 @@
         ids=["multiclass", "multilabel", "hierarchical"],
     )
     def test_training_progress_tracking(self, multilabel, hierarchical):
         hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_CLS_TEMPLATE_DIR, num_iters=10)
         task_environment, dataset = self.init_environment(
             hyper_parameters, model_template, multilabel, hierarchical, 20
         )
-        task = ClassificationTrainTask(task_environment=task_environment)
+        task = MMClassificationTask(task_environment=task_environment)
         print("Task initialized, model training starts.")
 
         training_progress_curve = []
 
         def progress_callback(progress: float, score: Optional[float] = None):
             training_progress_curve.append(progress)
 
@@ -229,15 +226,15 @@
         ids=["multiclass", "multilabel", "hierarchical"],
     )
     def test_inference_progress_tracking(self, multilabel, hierarchical):
         hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_CLS_TEMPLATE_DIR, num_iters=5)
         task_environment, dataset = self.init_environment(
             hyper_parameters, model_template, multilabel, hierarchical, 20
         )
-        task = ClassificationInferenceTask(task_environment=task_environment)
+        task = MMClassificationTask(task_environment=task_environment)
         print("Task initialized, model inference starts.")
 
         inference_progress_curve = []
 
         def progress_callback(progress: int):
             inference_progress_curve.append(progress)
 
@@ -258,15 +255,15 @@
         # Prepare pretrained weights
         hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_CLS_TEMPLATE_DIR, num_iters=2)
         classification_environment, dataset = self.init_environment(
             hyper_parameters, model_template, multilabel, hierarchical, 50
         )
         val_dataset = dataset.get_subset(Subset.VALIDATION)
 
-        train_task = ClassificationTrainTask(task_environment=classification_environment)
+        train_task = MMClassificationTask(task_environment=classification_environment)
 
         training_progress_curve = []
 
         def progress_callback(progress: float, score: Optional[float] = None):
             training_progress_curve.append(progress)
 
         train_parameters = TrainParameters()
@@ -276,15 +273,15 @@
             classification_environment.get_model_configuration(),
         )
         train_task.train(dataset, trained_model, train_parameters)
         performance_after_train = task_eval(train_task, trained_model, val_dataset)
 
         # Create InferenceTask
         classification_environment.model = trained_model
-        inference_task = ClassificationInferenceTask(task_environment=classification_environment)
+        inference_task = MMClassificationTask(task_environment=classification_environment)
 
         performance_after_load = task_eval(inference_task, trained_model, val_dataset)
 
         assert performance_after_train == performance_after_load
 
         # Export
         exported_model = ModelEntity(
```

### Comparing `otx-1.1.2rc1/tests/integration/api/detection/test_api_detection.py` & `otx-1.2.0rc1/tests/integration/api/detection/test_api_detection.py`

 * *Files 0% similar despite different names*

```diff
@@ -121,15 +121,15 @@
         hyper_parameters.postprocessing.result_based_confidence_threshold = False
         hyper_parameters.postprocessing.confidence_threshold = 0.1
         return hyper_parameters, model_template
 
 
 class TestDetectionTaskAPI(DetectionTaskAPIBase):
     """
-    Collection of tests for OTE API and OTE Model Templates
+    Collection of tests for OTX API and OTX Model Templates
     """
 
     @e2e_pytest_api
     def test_reading_detection_model_template(self):
         detection_template = ["mobilenetv2_atss"]
         for model_template in detection_template:
             parse_model_template(
```

### Comparing `otx-1.1.2rc1/tests/integration/api/segmentation/test_api_segmentation.py` & `otx-1.2.0rc1/otx/algorithms/common/tasks/base_task.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,309 +1,310 @@
-"""API Tests for segmentation training"""
-# Copyright (C) 2022 Intel Corporation
-# SPDX-License-Identifier: Apache-2.0
-#
+"""Base task of OTX."""
 
-import os.path as osp
-import random
-import time
-import warnings
-from concurrent.futures import ThreadPoolExecutor
-from typing import Optional
-
-import numpy as np
-from bson import ObjectId
-
-from otx.algorithms.common.tasks.training_base import BaseTask
-from otx.algorithms.segmentation.tasks import (
-    SegmentationInferenceTask,
-    SegmentationTrainTask,
-)
-from otx.api.configuration.helper import create
-from otx.api.entities.annotation import (
-    Annotation,
-    AnnotationSceneEntity,
-    AnnotationSceneKind,
-)
-from otx.api.entities.color import Color
-from otx.api.entities.dataset_item import DatasetItemEntity
+# Copyright (C) 2023 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions
+# and limitations under the License.
+
+import io
+import os
+import shutil
+import tempfile
+from abc import ABC, abstractmethod
+from datetime import timedelta
+from typing import Any, Dict, Iterable, List, Optional
+
+import torch
+from torch import distributed as dist
+
+from otx.algorithms.common.adapters.mmcv.hooks import OTXLoggerHook
+from otx.algorithms.common.adapters.mmcv.hooks.cancel_hook import CancelInterfaceHook
+from otx.algorithms.common.configs.training_base import TrainType
+from otx.algorithms.common.utils import UncopiableDefaultDict
+from otx.algorithms.common.utils.logger import get_logger
 from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.image import Image
+from otx.api.entities.explain_parameters import ExplainParameters
 from otx.api.entities.inference_parameters import InferenceParameters
-from otx.api.entities.label import Domain, LabelEntity
-from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
-from otx.api.entities.metrics import Performance
-from otx.api.entities.model import ModelEntity
-from otx.api.entities.model_template import parse_model_template
+from otx.api.entities.label import LabelEntity
+from otx.api.entities.metrics import MetricsGroup
+from otx.api.entities.model import ModelEntity, ModelPrecision, OptimizationMethod
 from otx.api.entities.resultset import ResultSetEntity
-from otx.api.entities.shapes.ellipse import Ellipse
-from otx.api.entities.shapes.polygon import Point, Polygon
-from otx.api.entities.shapes.rectangle import Rectangle
-from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.entities.train_parameters import TrainParameters
-from otx.api.usecases.tasks.interfaces.export_interface import ExportType
-from tests.test_helpers import generate_random_annotated_image
-from tests.test_suite.e2e_test_system import e2e_pytest_api
-
-DEFAULT_SEG_TEMPLATE_DIR = osp.join("otx/algorithms/segmentation/configs", "ocr_lite_hrnet_18_mod2")
-
-
-def task_eval(task: BaseTask, model: ModelEntity, dataset: DatasetEntity) -> Performance:
-    start_time = time.time()
-    result_dataset = task.infer(dataset.with_empty_annotations())
-    end_time = time.time()
-    print(f"{len(dataset)} analysed in {end_time - start_time} seconds")
-    result_set = ResultSetEntity(model=model, ground_truth_dataset=dataset, prediction_dataset=result_dataset)
-    task.evaluate(result_set)
-    assert result_set.performance is not None
-    return result_set.performance
-
-
-class TestMPASegAPI:
-    """
-    Collection of tests for OTE API and OTE Model Templates
-    """
-
-    @e2e_pytest_api
-    def test_reading_segmentation_cls_incr_model_template(self):
-        segmentation_template = [
-            "ocr_lite_hrnet_18_mod2",
-            "ocr_lite_hrnet_s_mod2",
-            "ocr_lite_hrnet_x_mod3",
-        ]
-        for model_template in segmentation_template:
-            parse_model_template(osp.join("otx/algorithms/segmentation/configs", model_template, "template.yaml"))
+from otx.api.serialization.label_mapper import LabelSchemaMapper
+from otx.api.usecases.reporting.time_monitor_callback import TimeMonitorCallback
+from otx.api.usecases.tasks.interfaces.evaluate_interface import IEvaluationTask
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType, IExportTask
+from otx.api.usecases.tasks.interfaces.inference_interface import IInferenceTask
+from otx.api.usecases.tasks.interfaces.unload_interface import IUnload
+
+TRAIN_TYPE_DIR_PATH = {
+    TrainType.Incremental.name: ".",
+    TrainType.Selfsupervised.name: "selfsl",
+    TrainType.Semisupervised.name: "semisl",
+}
+
+logger = get_logger()
+
+
+class OnHookInitialized:
+    """OnHookInitialized class."""
+
+    def __init__(self, task_instance):
+        self.task_instance = task_instance
+        self.__findable = False  # a barrier to block segmentation fault
+
+    def __call__(self, cancel_interface):
+        """Function call in OnHookInitialized."""
+        if isinstance(self.task_instance, int) and self.__findable:
+            import ctypes
+
+            # NOTE: BE AWARE OF SEGMENTATION FAULT
+            self.task_instance = ctypes.cast(self.task_instance, ctypes.py_object).value
+        self.task_instance.cancel_hook_initialized(cancel_interface)
+
+    def __repr__(self):
+        """Function repr in OnHookInitialized."""
+        return f"'{__name__}.OnHookInitialized'"
+
+    def __deepcopy__(self, memo):
+        """Function deepcopy in OnHookInitialized."""
+        cls = self.__class__
+        result = cls.__new__(cls)
+        memo[id(self)] = result
+        result.task_instance = self.task_instance
+        result.__findable = True  # pylint: disable=unused-private-member, protected-access
+        return result
+
+    def __reduce__(self):
+        """Function reduce in OnHookInitialized."""
+        return (self.__class__, (id(self.task_instance),))
+
+
+# pylint: disable=too-many-instance-attributes
+class OTXTask(IInferenceTask, IExportTask, IEvaluationTask, IUnload, ABC):
+    """Base task of OTX."""
+
+    def __init__(self, task_environment: TaskEnvironment, output_path: Optional[str] = None):
+        self._config: Dict[Any, Any] = {}
+        self._task_environment = task_environment
+        self._task_type = task_environment.model_template.task_type
+        self._labels = task_environment.get_labels(include_empty=False)
+        self._work_dir_is_temp = False
+        self._output_path = output_path
+        self._output_path = output_path if output_path is not None else self._get_tmp_dir()
+        self._time_monitor: Optional[TimeMonitorCallback] = None
+        self.on_hook_initialized = OnHookInitialized(self)
+        self._learning_curves = UncopiableDefaultDict(OTXLoggerHook.Curve)
+        self._model_label_schema: List[LabelEntity] = []
+        self._resume = False
+        self._should_stop = False
+        self.cancel_interface: Optional[CancelInterfaceHook] = None
+        self.reserved_cancel = False
+        self._model_ckpt = None
+        self._precision = [ModelPrecision.FP32]
+        self._optimization_methods: List[OptimizationMethod] = []
+        self._is_training = False
 
-    @staticmethod
-    def generate_label_schema(label_names):
-        label_domain = Domain.SEGMENTATION
-        rgb = [int(i) for i in np.random.randint(0, 256, 3)]
-        colors = [Color(*rgb) for _ in range(len(label_names))]
-        not_empty_labels = [
-            LabelEntity(name=name, color=colors[i], domain=label_domain, id=i) for i, name in enumerate(label_names)
-        ]
-        empty_label = LabelEntity(
-            name="Empty label",
-            color=Color(42, 43, 46),
-            is_empty=True,
-            domain=label_domain,
-            id=len(not_empty_labels),
-        )
-
-        label_schema = LabelSchemaEntity()
-        exclusive_group = LabelGroup(name="labels", labels=not_empty_labels, group_type=LabelGroupType.EXCLUSIVE)
-        empty_group = LabelGroup(name="empty", labels=[empty_label], group_type=LabelGroupType.EMPTY_LABEL)
-        label_schema.add_group(exclusive_group)
-        label_schema.add_group(empty_group)
-        return label_schema
-
-    def init_environment(self, params, model_template, number_of_images=10):
-        labels_names = ("rectangle", "ellipse", "triangle")
-        labels_schema = self.generate_label_schema(labels_names)
-        labels_list = labels_schema.get_labels(False)
-        environment = TaskEnvironment(
-            model=None,
-            hyper_parameters=params,
-            label_schema=labels_schema,
-            model_template=model_template,
-        )
-
-        warnings.filterwarnings("ignore", message=".* coordinates .* are out of bounds.*")
-        items = []
-        for i in range(0, number_of_images):
-            image_numpy, shapes = generate_random_annotated_image(
-                image_width=640,
-                image_height=480,
-                labels=labels_list,
-                max_shapes=20,
-                min_size=50,
-                max_size=100,
-                random_seed=None,
-            )
-            # Convert all shapes to polygons
-            out_shapes = []
-            for shape in shapes:
-                shape_labels = shape.get_labels(include_empty=True)
-
-                in_shape = shape.shape
-                if isinstance(in_shape, Rectangle):
-                    points = [
-                        Point(in_shape.x1, in_shape.y1),
-                        Point(in_shape.x2, in_shape.y1),
-                        Point(in_shape.x2, in_shape.y2),
-                        Point(in_shape.x1, in_shape.y2),
-                    ]
-                elif isinstance(in_shape, Ellipse):
-                    points = [Point(x, y) for x, y in in_shape.get_evenly_distributed_ellipse_coordinates()]
-                elif isinstance(in_shape, Polygon):
-                    points = in_shape.points
-
-                out_shapes.append(Annotation(Polygon(points=points), labels=shape_labels))
-
-            image = Image(data=image_numpy)
-            annotation = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=out_shapes)
-            items.append(DatasetItemEntity(media=image, annotation_scene=annotation))
-        warnings.resetwarnings()
-
-        rng = random.Random()
-        rng.shuffle(items)
-        for i, _ in enumerate(items):
-            subset_region = i / number_of_images
-            if subset_region >= 0.8:
-                subset = Subset.TESTING
-            elif subset_region >= 0.6:
-                subset = Subset.VALIDATION
-            else:
-                subset = Subset.TRAINING
+        self.override_configs: Dict[str, str] = {}
 
-            items[i].subset = subset
+        # This is for hpo, and this should be removed
+        self.project_path = self._output_path
 
-        dataset = DatasetEntity(items)
-
-        return environment, dataset
+        if self._is_multi_gpu_training():
+            self._setup_multigpu_training()
 
     @staticmethod
-    def setup_configurable_parameters(template_dir, num_iters=10):
-        model_template = parse_model_template(osp.join(template_dir, "template.yaml"))
-
-        hyper_parameters = create(model_template.hyper_parameters.data)
-        hyper_parameters.learning_parameters.learning_rate_fixed_iters = 0
-        hyper_parameters.learning_parameters.learning_rate_warmup_iters = 1
-        hyper_parameters.learning_parameters.num_iters = num_iters
-        hyper_parameters.learning_parameters.num_checkpoints = 1
+    def _is_multi_gpu_training():
+        multi_gpu_env = ["MASTER_ADDR", "MASTER_PORT", "LOCAL_WORLD_SIZE", "WORLD_SIZE", "LOCAL_RANK", "RANK"]
+        for env in multi_gpu_env:
+            if env not in os.environ:
+                return False
 
-        return hyper_parameters, model_template
+        return torch.cuda.is_available()
 
-    @e2e_pytest_api
-    def test_cancel_training_segmentation(self):
-        """
-        Tests starting and cancelling training.
+    @staticmethod
+    def _setup_multigpu_training():
+        if not dist.is_initialized():
+            torch.cuda.set_device(int(os.environ["LOCAL_RANK"]))
+            dist.init_process_group(backend="nccl", init_method="env://", timeout=timedelta(seconds=30))
+            logger.info(f"Dist info: rank {dist.get_rank()} / {dist.get_world_size()} world_size")
+
+    def _get_tmp_dir(self):
+        self._work_dir_is_temp = True
+        # If training is excuted with torchrun, set all trainings' output directory same
+        if "TORCHELASTIC_RUN_ID" in os.environ:
+            return os.path.join(tempfile.gettempdir(), f"OTX-task-torchelastic-{os.environ['TORCHELASTIC_RUN_ID']}")
+        return tempfile.mkdtemp(prefix="OTX-task-")
+
+    def _load_model(self):
+        """Loading model from checkpoint."""
+
+        def _load_model_label_schema(model: Optional[ModelEntity]):
+            # If a model has been trained and saved for the task already, create empty model and load weights here
+            if model and "label_schema.json" in model.model_adapters:
+                import json
+
+                buffer = json.loads(model.get_data("label_schema.json").decode("utf-8"))
+                model_label_schema = LabelSchemaMapper().backward(buffer)
+                return model_label_schema.get_labels(include_empty=False)
+            return self._labels
+
+        logger.info("loading the model from the task env.")
+        model = self._task_environment.model
+        state_dict = self._load_model_ckpt(model)
+        if state_dict:
+            self._model_ckpt = os.path.join(self._output_path, "env_model_ckpt.pth")
+            if os.path.exists(self._model_ckpt):
+                os.remove(self._model_ckpt)
+            torch.save(state_dict, self._model_ckpt)
+            self._model_label_schema = _load_model_label_schema(model)
+            if model is not None:
+                self._resume = model.model_adapters.get("resume", False)
+
+    def _load_model_ckpt(self, model: Optional[ModelEntity]):
+        if model and "weights.pth" in model.model_adapters:
+            # If a model has been trained and saved for the task already, create empty model and load weights here
+            buffer = io.BytesIO(model.get_data("weights.pth"))
+            model_data = torch.load(buffer, map_location=torch.device("cpu"))
+            return model_data
+        return None
+
+    @abstractmethod
+    def train(
+        self, dataset: DatasetEntity, output_model: ModelEntity, train_parameters: Optional[TrainParameters] = None
+    ):
+        """Train function for OTX task."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def infer(
+        self,
+        dataset: DatasetEntity,
+        inference_parameters: Optional[InferenceParameters] = None,
+    ) -> DatasetEntity:
+        """Main infer function."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def export(
+        self,
+        export_type: ExportType,
+        output_model: ModelEntity,
+        precision: ModelPrecision = ModelPrecision.FP32,
+        dump_features: bool = True,
+    ):
+        """Export function of OTX Task."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def explain(
+        self,
+        dataset: DatasetEntity,
+        explain_parameters: Optional[ExplainParameters] = None,
+    ) -> DatasetEntity:
+        """Main explain function of OTX Task."""
+        raise NotImplementedError
+
+    @abstractmethod
+    def evaluate(
+        self,
+        output_resultset: ResultSetEntity,
+        evaluation_metric: Optional[str] = None,
+    ):
+        """Evaluate function of OTX Task."""
+        raise NotImplementedError
 
-        Flow of the test:
-        - Creates a randomly annotated project with a small dataset.
-        - Start training and give cancel training signal after 10 seconds. Assert that training
-            stops within 35 seconds after that
-        - Start training and give cancel signal immediately. Assert that training stops within 25 seconds.
+    @staticmethod
+    @abstractmethod
+    def _generate_training_metrics(learning_curves, scores) -> Iterable[MetricsGroup[Any, Any]]:
+        """Get Training metrics (epochs & scores).
 
-        This test should be finished in under one minute on a workstation.
+        Parses the training logs to get metrics from the latest training run
+        :return output List[MetricsGroup]
         """
-        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=200)
-        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 64)
-
-        segmentation_task = SegmentationTrainTask(task_environment=segmentation_environment)
-
-        executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="train_thread")
-
-        output_model = ModelEntity(
-            dataset,
-            segmentation_environment.get_model_configuration(),
-        )
-
-        training_progress_curve = []
-
-        def progress_callback(progress: float, score: Optional[float] = None):
-            training_progress_curve.append(progress)
-
-        train_parameters = TrainParameters()
-        train_parameters.update_progress = progress_callback
-
-        # Test stopping after some time
-        start_time = time.time()
-        train_future = executor.submit(segmentation_task.train, dataset, output_model, train_parameters)
-        # give train_thread some time to initialize the model
-        while not segmentation_task._is_training:
-            time.sleep(10)
-        segmentation_task.cancel_training()
-
-        # stopping process has to happen in less than 35 seconds
-        train_future.result()
-        assert training_progress_curve[-1] == 100
-        assert time.time() - start_time < 100, "Expected to stop within 100 seconds."
-
-        # Test stopping immediately
-        start_time = time.time()
-        train_future = executor.submit(segmentation_task.train, dataset, output_model)
-        segmentation_task.cancel_training()
-
-        train_future.result()
-        assert time.time() - start_time < 25  # stopping process has to happen in less than 25 seconds
-
-    @e2e_pytest_api
-    def test_training_progress_tracking(self):
-        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=5)
-        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 12)
+        raise NotImplementedError
 
-        task = SegmentationTrainTask(task_environment=segmentation_environment)
-        print("Task initialized, model training starts.")
-
-        training_progress_curve = []
-
-        def progress_callback(progress: float, score: Optional[float] = None):
-            training_progress_curve.append(progress)
-
-        train_parameters = TrainParameters()
-        train_parameters.update_progress = progress_callback
-        output_model = ModelEntity(
-            dataset,
-            segmentation_environment.get_model_configuration(),
-        )
-        task.train(dataset, output_model, train_parameters)
-
-        assert len(training_progress_curve) > 0
-        assert np.all(training_progress_curve[1:] >= training_progress_curve[:-1])
-
-    @e2e_pytest_api
-    def test_inference_progress_tracking(self):
-        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=10)
-        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 12)
-
-        task = SegmentationInferenceTask(task_environment=segmentation_environment)
-        print("Task initialized, model inference starts.")
-
-        inference_progress_curve = []
-
-        def progress_callback(progress: int):
-            assert isinstance(progress, int)
-            inference_progress_curve.append(progress)
-
-        inference_parameters = InferenceParameters()
-        inference_parameters.update_progress = progress_callback
-        task.infer(dataset.with_empty_annotations(), inference_parameters)
-
-        assert len(inference_progress_curve) > 0
-        assert np.all(inference_progress_curve[1:] >= inference_progress_curve[:-1])
-
-    @e2e_pytest_api
-    def test_inference_task(self):
-        # Prepare pretrained weights
-        hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_SEG_TEMPLATE_DIR, num_iters=2)
-        segmentation_environment, dataset = self.init_environment(hyper_parameters, model_template, 30)
-        val_dataset = dataset.get_subset(Subset.VALIDATION)
-
-        train_task = SegmentationTrainTask(task_environment=segmentation_environment)
-
-        training_progress_curve = []
-
-        def progress_callback(progress: float, score: Optional[float] = None):
-            training_progress_curve.append(progress)
-
-        train_parameters = TrainParameters()
-        train_parameters.update_progress = progress_callback
-        trained_model = ModelEntity(
-            dataset,
-            segmentation_environment.get_model_configuration(),
-        )
-        train_task.train(dataset, trained_model, train_parameters)
-        performance_after_train = task_eval(train_task, trained_model, val_dataset)
-
-        # Create InferenceTask
-        segmentation_environment.model = trained_model
-        inference_task = SegmentationInferenceTask(task_environment=segmentation_environment)
-
-        performance_after_load = task_eval(inference_task, trained_model, val_dataset)
+    @abstractmethod
+    def save_model(self, output_model: ModelEntity):
+        """Save best model weights in trining task."""
+        raise NotImplementedError
+
+    def cancel_training(self):
+        """Cancel training function in trining task.
+
+        Sends a cancel training signal to gracefully stop the optimizer. The signal consists of creating a
+        '.stop_training' file in the current work_dir. The runner checks for this file periodically.
+        The stopping mechanism allows stopping after each iteration, but validation will still be carried out. Stopping
+        will therefore take some time.
+        """
+        logger.info("Cancel training requested.")
+        self._should_stop = True
+        if self.cancel_interface is not None:
+            self.cancel_interface.cancel()
+        else:
+            logger.info("but training was not started yet. reserved it to cancel")
+            self.reserved_cancel = True
+
+    def cancel_hook_initialized(self, cancel_interface: CancelInterfaceHook):
+        """Initialization of cancel_interface hook."""
+        logger.info("cancel hook is initialized")
+        self.cancel_interface = cancel_interface
+        if self.reserved_cancel and self.cancel_interface:
+            self.cancel_interface.cancel()
+
+    def cleanup(self):
+        """Clean up work directory if user specified it."""
+        if self._work_dir_is_temp:
+            self._delete_scratch_space()
+
+    def _delete_scratch_space(self):
+        """Remove model checkpoints and otx logs."""
+        if os.path.exists(self._output_path):
+            shutil.rmtree(self._output_path, ignore_errors=False)
+
+    def unload(self):
+        """Unload the task."""
+        self.cleanup()
+        if self._is_docker():
+            logger.warning("Got unload request. Unloading models. Throwing Segmentation Fault on purpose")
+            import ctypes
+
+            ctypes.string_at(0)
+        else:
+            logger.warning("Got unload request, but not on Docker. Only clearing CUDA cache")
+            torch.cuda.empty_cache()
+            logger.warning(
+                f"Done unloading. " f"Torch is still occupying {torch.cuda.memory_allocated()} bytes of GPU memory"
+            )
 
-        assert performance_after_train == performance_after_load
+    @staticmethod
+    def _is_docker():
+        """Checks whether the task runs in docker container.
 
-        # Export
-        exported_model = ModelEntity(dataset, segmentation_environment.get_model_configuration(), _id=ObjectId())
-        inference_task.export(ExportType.OPENVINO, exported_model)
+        :return bool: True if task runs in docker
+        """
+        path = "/proc/self/cgroup"
+        is_in_docker = False
+        if os.path.isfile(path):
+            with open(path, encoding="UTF-8") as f:
+                is_in_docker = is_in_docker or any("docker" in line for line in f)
+        is_in_docker = is_in_docker or os.path.exists("/.dockerenv")
+        return is_in_docker
+
+    @property
+    def config(self):
+        """Config of OTX task."""
+        return self._config
+
+    @config.setter
+    def config(self, config: Dict[Any, Any]):
+        self._config = config
```

### Comparing `otx-1.1.2rc1/tests/integration/api/xai/test_api_xai_sanity.py` & `otx-1.2.0rc1/tests/e2e/test_api_xai_sanity.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,41 +1,41 @@
-# Copyright (C) 2022 Intel Corporation
+# Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import os
 import os.path as osp
 import tempfile
 
 import pytest
 import torch
 
-from otx.algorithms.classification.tasks import (  # ClassificationOpenVINOTask,
-    ClassificationInferenceTask,
-    ClassificationTrainTask,
-)
-from otx.algorithms.detection.tasks import (
-    DetectionInferenceTask,
-    DetectionTrainTask,
-    OpenVINODetectionTask,
-)
+from otx.algorithms.classification.adapters.mmcls.task import MMClassificationTask
+from otx.algorithms.classification.adapters.openvino.task import ClassificationOpenVINOTask
+
+# from otx.algorithms.detection.tasks import (
+#     DetectionInferenceTask,
+#     DetectionTrainTask,
+#     OpenVINODetectionTask,
+# )
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.result_media import ResultMediaEntity
 from otx.api.entities.train_parameters import TrainParameters
 from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from otx.cli.utils.io import read_model, save_model_data
 from tests.integration.api.classification.test_api_classification import (
     DEFAULT_CLS_TEMPLATE_DIR,
     ClassificationTaskAPIBase,
 )
-from tests.integration.api.detection.test_api_detection import (
-    DEFAULT_DET_TEMPLATE_DIR,
-    DetectionTaskAPIBase,
-)
+
+# from tests.integration.api.detection.test_api_detection import (
+#     DEFAULT_DET_TEMPLATE_DIR,
+#     DetectionTaskAPIBase,
+# )
 from tests.test_suite.e2e_test_system import e2e_pytest_api
 
 torch.manual_seed(0)
 
 assert_text_explain_all = "The number of saliency maps should be equal to the number of all classes."
 assert_text_explain_predicted = "The number of saliency maps should be equal to the number of predicted classes."
 
@@ -77,30 +77,30 @@
         with tempfile.TemporaryDirectory() as temp_dir:
             hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_CLS_TEMPLATE_DIR, num_iters=1)
             task_environment, dataset = self.init_environment(
                 hyper_parameters, model_template, multilabel, hierarchical, 20
             )
 
             # Train and save a model
-            task = ClassificationTrainTask(task_environment=task_environment)
+            task = MMClassificationTask(task_environment=task_environment)
             train_parameters = TrainParameters()
             output_model = ModelEntity(
                 dataset,
                 task_environment.get_model_configuration(),
             )
             task.train(dataset, output_model, train_parameters)
             save_model_data(output_model, temp_dir)
 
             for processed_saliency_maps, only_predicted in [[True, False], [False, True]]:
                 task_environment, dataset = self.init_environment(
                     hyper_parameters, model_template, multilabel, hierarchical, 20
                 )
 
                 # Infer torch model
-                task = ClassificationInferenceTask(task_environment=task_environment)
+                task = MMClassificationTask(task_environment=task_environment)
                 inference_parameters = InferenceParameters(
                     is_evaluation=False,
                     process_saliency_maps=processed_saliency_maps,
                     explain_predicted_classes=only_predicted,
                 )
                 predicted_dataset = task.infer(dataset.with_empty_annotations(), inference_parameters)
 
@@ -110,78 +110,105 @@
                     predicted_dataset,
                     task_labels,
                     self.ref_raw_saliency_shapes[model_template.name],
                     processed_saliency_maps=processed_saliency_maps,
                     only_predicted=only_predicted,
                 )
 
-            # # TODO(negvet): get it back (IR infer does not work)
-            # # Save OV IR model
-            # task._model_ckpt = osp.join(temp_dir, "weights.pth")
-            # exported_model = ModelEntity(None, task_environment.get_model_configuration())
-            # task.export(ExportType.OPENVINO, exported_model)
-            # os.makedirs(temp_dir, exist_ok=True)
-            # save_model_data(exported_model, temp_dir)
-            #
-            # # Infer OV IR model
-            # load_weights_ov = osp.join(temp_dir, "openvino.xml")
-            # task_environment.model = read_model(task_environment.get_model_configuration(), load_weights_ov, None)
-            # task = ClassificationOpenVINOTask(task_environment=task_environment)
-            # predicted_dataset_ov = task.infer(
-            #     dataset.with_empty_annotations(),
-            #     InferenceParameters(is_evaluation=False),
-            # )
-            #
-            # # Check saliency maps OV task
-            # saliency_maps_check(predicted_dataset_ov, task_labels, self.ref_raw_saliency_shapes[model_template.name])
-
-
-class TestOVDetXAIAPI(DetectionTaskAPIBase):
-    ref_raw_saliency_shapes = {
-        "ATSS": (4, 4),
-        "SSD": (13, 13),
-        "YOLOX": (13, 13),
-    }
-
-    @e2e_pytest_api
-    def test_inference_xai(self):
-        with tempfile.TemporaryDirectory() as temp_dir:
-            hyper_parameters, model_template = self.setup_configurable_parameters(DEFAULT_DET_TEMPLATE_DIR, num_iters=2)
-            detection_environment, dataset = self.init_environment(hyper_parameters, model_template, 10)
+                # Save OV IR model
+                task._model_ckpt = osp.join(temp_dir, "weights.pth")
+                exported_model = ModelEntity(None, task_environment.get_model_configuration())
+                task.export(ExportType.OPENVINO, exported_model, dump_features=True)
+                os.makedirs(temp_dir, exist_ok=True)
+                save_model_data(exported_model, temp_dir)
+
+                # Infer OV IR model
+                load_weights_ov = osp.join(temp_dir, "openvino.xml")
+                task_environment.model = read_model(task_environment.get_model_configuration(), load_weights_ov, None)
+                task = ClassificationOpenVINOTask(task_environment=task_environment)
+                _, dataset = self.init_environment(hyper_parameters, model_template, multilabel, hierarchical, 20)
+                predicted_dataset_ov = task.infer(dataset.with_empty_annotations(), inference_parameters)
 
-            train_task = DetectionTrainTask(task_environment=detection_environment)
-            trained_model = ModelEntity(
-                dataset,
-                detection_environment.get_model_configuration(),
-            )
-            train_task.train(dataset, trained_model, TrainParameters())
-            save_model_data(trained_model, temp_dir)
+                # Check saliency maps OV task
+                saliency_maps_check(
+                    predicted_dataset_ov,
+                    task_labels,
+                    self.ref_raw_saliency_shapes[model_template.name],
+                    processed_saliency_maps=processed_saliency_maps,
+                    only_predicted=only_predicted,
+                )
 
-            # Infer torch model
-            detection_environment.model = trained_model
-            inference_task = DetectionInferenceTask(task_environment=detection_environment)
-            predicted_dataset = inference_task.infer(dataset.with_empty_annotations())
-
-            # Check saliency maps torch task
-            task_labels = trained_model.configuration.get_label_schema().get_labels(include_empty=False)
-            saliency_maps_check(predicted_dataset, task_labels, self.ref_raw_saliency_shapes[model_template.name])
-
-            # Save OV IR model
-            inference_task._model_ckpt = osp.join(temp_dir, "weights.pth")
-            exported_model = ModelEntity(None, detection_environment.get_model_configuration())
-            inference_task.export(ExportType.OPENVINO, exported_model)
-            os.makedirs(temp_dir, exist_ok=True)
-            save_model_data(exported_model, temp_dir)
-
-            # Infer OV IR model
-            load_weights_ov = osp.join(temp_dir, "openvino.xml")
-            detection_environment.model = read_model(
-                detection_environment.get_model_configuration(), load_weights_ov, None
-            )
-            task = OpenVINODetectionTask(task_environment=detection_environment)
-            predicted_dataset_ov = task.infer(
-                dataset.with_empty_annotations(),
-                InferenceParameters(is_evaluation=False),
-            )
 
-            # Check saliency maps OV task
-            saliency_maps_check(predicted_dataset_ov, task_labels, self.ref_raw_saliency_shapes[model_template.name])
+# class TestOVDetXAIAPI(DetectionTaskAPIBase):
+#     ref_raw_saliency_shapes = {
+#         "ATSS": (6, 8),
+#         "SSD": (13, 13),
+#         "YOLOX": (13, 13),
+#     }
+#
+#     @e2e_pytest_api
+#     @pytest.mark.skip(reason="Detection task refactored.")
+#     def test_inference_xai(self):
+#         with tempfile.TemporaryDirectory() as temp_dir:
+#             hyper_parameters, model_template = self.setup_configurable_parameters(
+#                 DEFAULT_DET_TEMPLATE_DIR, num_iters=15
+#             )
+#             detection_environment, dataset = self.init_environment(hyper_parameters, model_template, 10)
+#
+#             train_task = DetectionTrainTask(task_environment=detection_environment)
+#             trained_model = ModelEntity(
+#                 dataset,
+#                 detection_environment.get_model_configuration(),
+#             )
+#             train_task.train(dataset, trained_model, TrainParameters())
+#             save_model_data(trained_model, temp_dir)
+#
+#             from otx.api.entities.subset import Subset
+#
+#             for processed_saliency_maps, only_predicted in [[True, False], [False, True]]:
+#                 detection_environment, dataset = self.init_environment(hyper_parameters, model_template, 10)
+#                 inference_parameters = InferenceParameters(
+#                     is_evaluation=False,
+#                     process_saliency_maps=processed_saliency_maps,
+#                     explain_predicted_classes=only_predicted,
+#                 )
+#
+#                 # Infer torch model
+#                 detection_environment.model = trained_model
+#                 inference_task = DetectionInferenceTask(task_environment=detection_environment)
+#                 val_dataset = dataset.get_subset(Subset.VALIDATION)
+#                 predicted_dataset = inference_task.infer(val_dataset.with_empty_annotations(), inference_parameters)
+#
+#                 # Check saliency maps torch task
+#                 task_labels = trained_model.configuration.get_label_schema().get_labels(include_empty=False)
+#                 saliency_maps_check(
+#                     predicted_dataset,
+#                     task_labels,
+#                     self.ref_raw_saliency_shapes[model_template.name],
+#                     processed_saliency_maps=processed_saliency_maps,
+#                     only_predicted=only_predicted,
+#                 )
+#
+#                 # Save OV IR model
+#                 inference_task._model_ckpt = osp.join(temp_dir, "weights.pth")
+#                 exported_model = ModelEntity(None, detection_environment.get_model_configuration())
+#                 inference_task.export(ExportType.OPENVINO, exported_model, dump_features=True)
+#                 os.makedirs(temp_dir, exist_ok=True)
+#                 save_model_data(exported_model, temp_dir)
+#
+#                 # Infer OV IR model
+#                 load_weights_ov = osp.join(temp_dir, "openvino.xml")
+#                 detection_environment.model = read_model(
+#                     detection_environment.get_model_configuration(), load_weights_ov, None
+#                 )
+#                 task = OpenVINODetectionTask(task_environment=detection_environment)
+#                 _, dataset = self.init_environment(hyper_parameters, model_template, 10)
+#                 predicted_dataset_ov = task.infer(dataset.with_empty_annotations(), inference_parameters)
+#
+#                 # Check saliency maps OV task
+#                 saliency_maps_check(
+#                     predicted_dataset_ov,
+#                     task_labels,
+#                     self.ref_raw_saliency_shapes[model_template.name],
+#                     processed_saliency_maps=processed_saliency_maps,
+#                     only_predicted=only_predicted,
+#                 )
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/action/test_action_classification.py` & `otx-1.2.0rc1/tests/integration/cli/action/test_action_classification.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/integration/cli/action/test_action_detection.py` & `otx-1.2.0rc1/tests/integration/cli/action/test_action_detection.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_classification.py` & `otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_detection.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for anomaly classification with OTX CLI"""
+"""Tests for anomaly detection with OTX CLI."""
 
 # Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -27,28 +27,28 @@
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_export_testing,
     otx_train_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
-templates = Registry("otx/algorithms").filter(task_type="ANOMALY_CLASSIFICATION").templates
+templates = Registry("otx/algorithms").filter(task_type="ANOMALY_DETECTION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsAnomalyClassification:
+class TestToolsAnomalyDetection:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_detection.py` & `otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for anomaly detection with OTX CLI."""
+"""Tests for anomaly classification with OTX CLI"""
 
 # Copyright (C) 2021 Intel Corporation
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -27,28 +27,28 @@
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_export_testing,
     otx_train_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
-templates = Registry("otx/algorithms").filter(task_type="ANOMALY_DETECTION").templates
+templates = Registry("otx/algorithms").filter(task_type="ANOMALY_CLASSIFICATION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestToolsAnomalyDetection:
+class TestToolsAnomalyClassification:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/anomaly/test_anomaly_segmentation.py` & `otx-1.2.0rc1/tests/integration/cli/anomaly/test_anomaly_segmentation.py`

 * *Files 3% similar despite different names*

```diff
@@ -27,18 +27,18 @@
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_export_testing,
     otx_train_testing,
 )
 
 args = {
-    "--train-data-roots": "tests/assets/anomaly/shapes/train",
-    "--val-data-roots": "tests/assets/anomaly/shapes/test",
-    "--test-data-roots": "tests/assets/anomaly/shapes/test",
-    "--input": "tests/assets/anomaly/shapes/test/hexagon",
+    "--train-data-roots": "tests/assets/anomaly/hazelnut/train",
+    "--val-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--test-data-roots": "tests/assets/anomaly/hazelnut/test",
+    "--input": "tests/assets/anomaly/hazelnut/test/colour",
     "train_params": [],
 }
 
 otx_dir = os.getcwd()
 
 templates = Registry("otx/algorithms").filter(task_type="ANOMALY_SEGMENTATION").templates
 templates_ids = [template.model_template_id for template in templates]
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/classification/test_classification.py` & `otx-1.2.0rc1/tests/e2e/cli/detection/test_detection.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,392 +1,345 @@
-"""Tests for Classification with OTX CLI"""
+"""Tests for Class-Incremental Learning for object detection with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
-
 import copy
 import os
 
 import pytest
 import torch
 
 from otx.api.entities.model_template import parse_model_template
 from otx.cli.registry import Registry
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
+    nncf_eval_openvino_testing,
+    nncf_eval_testing,
+    nncf_export_testing,
     nncf_optimize_testing,
+    nncf_validate_fq_testing,
+    otx_demo_deployment_testing,
+    otx_demo_openvino_testing,
+    otx_demo_testing,
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
+    otx_explain_all_classes_openvino_testing,
     otx_explain_openvino_testing,
+    otx_explain_process_saliency_maps_openvino_testing,
     otx_explain_testing,
+    otx_explain_testing_all_classes,
+    otx_explain_testing_process_saliency_maps,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
+    pot_eval_testing,
+    pot_optimize_testing,
+    pot_validate_fq_testing,
 )
 
-# Pre-train w/ 'label_0', 'label_1', 'label_2' classes
+# Pre-train w/ 'person' class ##TODO: Currently, it is closed to sample test. need to change other sample
+args0 = {
+    "--train-data-roots": "tests/assets/car_tree_bug",
+    "--val-data-roots": "tests/assets/car_tree_bug",
+    "--test-data-roots": "tests/assets/car_tree_bug",
+    "--input": "tests/assets/car_tree_bug/images/train",
+    "train_params": ["params", "--learning_parameters.num_iters", "10", "--learning_parameters.batch_size", "4"],
+}
+
+# Class-Incremental learning w/ 'vehicle', 'person', 'non-vehicle' classes
 args = {
-    "--train-data-roots": "tests/assets/imagenet_dataset_class_incremental",
-    "--val-data-roots": "tests/assets/imagenet_dataset_class_incremental",
-    "--test-data-roots": "tests/assets/imagenet_dataset_class_incremental",
-    "--input": "tests/assets/imagenet_dataset/label_0",
-    "train_params": [
-        "params",
-        "--learning_parameters.num_iters",
-        "1",
-        "--learning_parameters.batch_size",
-        "4",
-    ],
+    "--train-data-roots": "tests/assets/car_tree_bug",
+    "--val-data-roots": "tests/assets/car_tree_bug",
+    "--test-data-roots": "tests/assets/car_tree_bug",
+    "--input": "tests/assets/car_tree_bug/images/train",
+    "train_params": ["params", "--learning_parameters.num_iters", "5", "--learning_parameters.batch_size", "4"],
 }
 
-# Warmstart using data w/ 'intel', 'openvino', 'opencv' classes
-args_selfsl = {
-    "--train-data-roots": "tests/assets/imagenet_dataset",
+args_semisl = {
+    "--train-data-roots": "tests/assets/car_tree_bug",
+    "--val-data-roots": "tests/assets/car_tree_bug",
+    "--test-data-roots": "tests/assets/car_tree_bug",
+    "--unlabeled-data-roots": "tests/assets/car_tree_bug",
+    "--input": "tests/assets/car_tree_bug/images/train",
     "train_params": [
         "params",
         "--learning_parameters.num_iters",
-        "1",
+        "2",
         "--learning_parameters.batch_size",
         "4",
         "--algo_backend.train_type",
-        "Selfsupervised",
+        "Semisupervised",
     ],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
-    "2",
+    "8",
     "--learning_parameters.batch_size",
     "4",
 ]
 
 otx_dir = os.getcwd()
 
-
 MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
-default_template = parse_model_template(
-    os.path.join(
-        "otx/algorithms/classification",
-        "configs",
-        "efficientnet_b0_cls_incr",
-        "template.yaml",
+TT_STABILITY_TESTS = os.environ.get("TT_STABILITY_TESTS", False)
+if TT_STABILITY_TESTS:
+    default_template = parse_model_template(
+        os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
     )
-)
-default_templates = [default_template]
-default_templates_ids = [default_template.model_template_id]
-
-templates = Registry("otx/algorithms/classification").filter(task_type="CLASSIFICATION").templates
-templates_ids = [template.model_template_id for template in templates]
+    templates = [default_template] * 100
+    templates_ids = [template.model_template_id + f"-{i+1}" for i, template in enumerate(templates)]
+else:
+    templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
+    templates_ids = [template.model_template_id for template in templates]
 
 
-class TestMultiClassClassificationCLI:
+class TestToolsMPADetection:
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train_supcon(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_supcon"
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_train(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args0)
+        template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
-        args1["train_params"].extend(["--learning_parameters.enable_supcon", "True"])
+        args1["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_resume"
-        otx_resume_testing(template, tmp_dir_path, otx_dir, args)
+        tmp_dir_path = tmp_dir_path / "detection/test_resume"
+        otx_resume_testing(template, tmp_dir_path, otx_dir, args0)
         template_work_dir = get_template_dir(template, tmp_dir_path)
-        args1 = copy.deepcopy(args)
+        args1 = copy.deepcopy(args0)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
+        tmp_dir_path = tmp_dir_path / "detection"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_explain_testing(template, tmp_dir_path, otx_dir, args)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=0.2, half_precision=half_precision)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_hpo"
-        otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
+    def test_otx_explain(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_testing(template, tmp_dir_path, otx_dir, args, trained=True)
 
     @e2e_pytest_component
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
+    def test_otx_explain_all_classes(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_testing_all_classes(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_multi_gpu_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu"
-        args1 = copy.deepcopy(args)
-        args1["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_process_saliency_maps(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_testing_process_saliency_maps(template, tmp_dir_path, otx_dir, args, trained=True)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_semisl"
-        args_semisl = copy.deepcopy(args)
-        args_semisl["--unlabeled-data-roots"] = args["--train-data-roots"]
-        args_semisl["train_params"].extend(["--algo_backend.train_type", "Semisupervised"])
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args, trained=True)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu_semisl"
-        args_semisl_multigpu = copy.deepcopy(args)
-        args_semisl_multigpu["--unlabeled-data-roots"] = args["--train-data-roots"]
-        args_semisl_multigpu["train_params"].extend(["--algo_backend.train_type", "Semisupervised"])
-        args_semisl_multigpu["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_all_classes_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_all_classes_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train_selfsl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_selfsl"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_selfsl)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_explain_process_saliency_maps_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_explain_process_saliency_maps_openvino_testing(template, tmp_dir_path, otx_dir, args, trained=True)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_multi_gpu_train_selfsl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_class_cls/test_multi_gpu_selfsl"
-        args_selfsl_multigpu = copy.deepcopy(args_selfsl)
-        args_selfsl_multigpu["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_selfsl_multigpu)
-
-
-# Multi-label training w/ 'car', 'tree', 'bug' classes
-args_m = {
-    "--train-data-roots": "tests/assets/datumaro_multilabel",
-    "--val-data-roots": "tests/assets/datumaro_multilabel",
-    "--test-data-roots": "tests/assets/datumaro_multilabel",
-    "--input": "tests/assets/datumaro_multilabel/images/train",
-    "train_params": [
-        "params",
-        "--learning_parameters.num_iters",
-        "1",
-        "--learning_parameters.batch_size",
-        "4",
-    ],
-}
-
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_demo(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_demo_testing(template, tmp_dir_path, otx_dir, args)
 
-class TestMultilabelClassificationCLI:
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_m)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_demo_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_demo_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_deploy_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_eval_deployment(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=0.0)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_eval_testing(template, tmp_dir_path, otx_dir, args_m)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_demo_deployment(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        otx_demo_deployment_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_explain_testing(template, tmp_dir_path, otx_dir, args_m)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_hpo(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_hpo"
+        otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args_m)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_nncf_optimize(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        if template.entrypoints.nncf is None:
+            pytest.skip("nncf entrypoint is none")
 
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args_m, threshold=1.0)
+        nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args_m)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_nncf_export(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        if template.entrypoints.nncf is None:
+            pytest.skip("nncf entrypoint is none")
 
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
-        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args_m, threshold=1.0)
+        nncf_export_testing(template, tmp_dir_path)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls"
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_nncf_validate_fq(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
-        nncf_optimize_testing(template, tmp_dir_path, otx_dir, args_m)
+        nncf_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "multi_label_cls" / "test_semisl"
-        args_semisl = copy.deepcopy(args_m)
-        args_semisl["--unlabeled-data-roots"] = args_m["--train-data-roots"]
-        args_semisl["train_params"].extend(["--algo_backend.train_type", "Semisupervised"])
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
-
-
-args_h = {
-    "--train-data-roots": "tests/assets/datumaro_h-label",
-    "--val-data-roots": "tests/assets/datumaro_h-label",
-    "--test-data-roots": "tests/assets/datumaro_h-label",
-    "--input": "tests/assets/datumaro_h-label/images/train",
-    "train_params": [
-        "params",
-        "--learning_parameters.num_iters",
-        "1",
-        "--learning_parameters.batch_size",
-        "4",
-    ],
-}
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_nncf_eval(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        if template.entrypoints.nncf is None:
+            pytest.skip("nncf entrypoint is none")
 
+        nncf_eval_testing(template, tmp_dir_path, otx_dir, args, threshold=0.001)
 
-class TestHierarchicalClassificationCLI:
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_nncf_eval_openvino(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        if template.entrypoints.nncf is None:
+            pytest.skip("nncf entrypoint is none")
 
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_export_testing(template, tmp_dir_path)
+        nncf_eval_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_pot_optimize(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        pot_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_eval_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_pot_validate_fq(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        pot_validate_fq_testing(template, tmp_dir_path, otx_dir, "detection", type(self).__name__)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_explain_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_pot_eval(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection"
+        pot_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_multi_gpu_train(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu"
+        args1 = copy.deepcopy(args)
+        args1["--gpus"] = "0,1"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
 
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args_h, threshold=1.0)
 
+class TestToolsMPASemiSLDetection:
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_train(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args_h, threshold=1.0)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_eval(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
+        otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "h_label_cls"
-        if template.entrypoints.nncf is None:
-            pytest.skip("nncf entrypoint is none")
-
-        nncf_optimize_testing(template, tmp_dir_path, otx_dir, args_h)
+    @pytest.mark.skipif(TT_STABILITY_TESTS, reason="This is TT_STABILITY_TESTS")
+    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu_semisl"
+        args_semisl_multigpu = copy.deepcopy(args_semisl)
+        args_semisl_multigpu["--gpus"] = "0,1"
+        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/detection/test_detection.py` & `otx-1.2.0rc1/tests/integration/cli/instance_segmentation/test_instance_segmentation.py`

 * *Files 16% similar despite different names*

```diff
@@ -17,166 +17,136 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
 )
 
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "1", "--learning_parameters.batch_size", "4"],
-}
-
-args_semisl = {
-    "--train-data-roots": "tests/assets/car_tree_bug",
-    "--val-data-roots": "tests/assets/car_tree_bug",
-    "--test-data-roots": "tests/assets/car_tree_bug",
-    "--unlabeled-data-roots": "tests/assets/car_tree_bug",
-    "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": [
-        "params",
-        "--learning_parameters.num_iters",
-        "1",
-        "--learning_parameters.batch_size",
-        "4",
-        "--algo_backend.train_type",
-        "Semisupervised",
-    ],
+    "train_params": ["params", "--learning_parameters.num_iters", "1", "--learning_parameters.batch_size", "2"],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
     "2",
     "--learning_parameters.batch_size",
     "4",
 ]
 
 otx_dir = os.getcwd()
 
+
 MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
 default_template = parse_model_template(
-    os.path.join("otx/algorithms/detection/configs", "detection", "mobilenetv2_atss", "template.yaml")
+    os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
 )
 default_templates = [default_template]
 default_templates_ids = [default_template.model_template_id]
 
-templates = Registry("otx/algorithms/detection").filter(task_type="DETECTION").templates
+templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
 templates_ids = [template.model_template_id for template in templates]
 
 
-class TestDetectionCLI:
+class TestInstanceSegmentationCLI:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_resume"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "ins_seg"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_hpo"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection"
+        tmp_dir_path = tmp_dir_path / "ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu"
+        tmp_dir_path = tmp_dir_path / "ins_seg/test_multi_gpu"
         args1 = copy.deepcopy(args)
         args1["--gpus"] = "0,1"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
-
-    @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_semisl"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
-
-    @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "detection/test_multi_gpu_semisl"
-        args_semisl_multigpu = copy.deepcopy(args_semisl)
-        args_semisl_multigpu["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/detection/test_instance_segmentation.py` & `otx-1.2.0rc1/tests/integration/cli/instance_segmentation/test_tiling_instseg.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,150 +1,156 @@
-"""Tests for Class-Incremental Learning for object detection with OTX CLI"""
+"""Tests for MPA Class-Incremental Learning for instance segmentation with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import copy
 import os
 
 import pytest
-import torch
 
 from otx.api.entities.model_template import parse_model_template
-from otx.cli.registry import Registry
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
-    otx_resume_testing,
     otx_train_testing,
+    otx_resume_testing,
 )
 
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
     "--test-data-roots": "tests/assets/car_tree_bug",
     "--input": "tests/assets/car_tree_bug/images/train",
-    "train_params": ["params", "--learning_parameters.num_iters", "1", "--learning_parameters.batch_size", "2"],
+    "train_params": [
+        "params",
+        "--learning_parameters.num_iters",
+        "1",
+        "--learning_parameters.batch_size",
+        "4",
+        "--tiling_parameters.enable_tiling",
+        "1",
+        "--tiling_parameters.enable_tile_classifier",
+        "1",
+        "--tiling_parameters.enable_adaptive_params",
+        "1",
+    ],
 }
 
 # Training params for resume, num_iters*2
 resume_params = [
     "params",
     "--learning_parameters.num_iters",
     "2",
     "--learning_parameters.batch_size",
     "4",
+    "--tiling_parameters.enable_tiling",
+    "1",
+    "--tiling_parameters.enable_tile_classifier",
+    "1",
+    "--tiling_parameters.enable_adaptive_params",
+    "1",
 ]
 
 otx_dir = os.getcwd()
 
-
-MULTI_GPU_UNAVAILABLE = torch.cuda.device_count() <= 1
 default_template = parse_model_template(
     os.path.join("otx/algorithms/detection/configs", "instance_segmentation", "resnet50_maskrcnn", "template.yaml")
 )
-default_templates = [default_template]
-default_templates_ids = [default_template.model_template_id]
+templates = [default_template]
+templates_ids = [default_template.model_template_id]
 
-templates = Registry("otx/algorithms/detection").filter(task_type="INSTANCE_SEGMENTATION").templates
-templates_ids = [template.model_template_id for template in templates]
 
-
-class TestInstanceSegmentationCLI:
+class TestTilingInstanceSegmentationCLI:
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_resume"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_export_testing(template, tmp_dir_path)
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_export_testing_w_features(template, tmp_dir_path)
+    def test_otx_export_fp16(self, template, tmp_dir_path):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_explain_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval_deployment(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         otx_eval_deployment_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
 
     @e2e_pytest_component
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
+    @pytest.mark.skip(reason="CVS-107743")
+    @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_hpo(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_hpo"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg/test_hpo"
         otx_hpo_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
+    @pytest.mark.skip(reason="CVS-98026")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg"
+        tmp_dir_path = tmp_dir_path / "tiling_ins_seg"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
-
-    @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
-    @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
-    @pytest.mark.parametrize("template", default_templates, ids=default_templates_ids)
-    def test_otx_multi_gpu_train(self, template, tmp_dir_path):
-        tmp_dir_path = tmp_dir_path / "ins_seg/test_multi_gpu"
-        args1 = copy.deepcopy(args)
-        args1["--gpus"] = "0,1"
-        otx_train_testing(template, tmp_dir_path, otx_dir, args1)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/detection/test_tiling_detection.py` & `otx-1.2.0rc1/tests/integration/cli/detection/test_tiling_detection.py`

 * *Files 10% similar despite different names*

```diff
@@ -13,15 +13,14 @@
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_explain_openvino_testing,
     otx_explain_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_train_testing,
 )
 
 args = {
     "--train-data-roots": "tests/assets/car_tree_bug",
     "--val-data-roots": "tests/assets/car_tree_bug",
@@ -54,35 +53,37 @@
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_train_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_export_testing(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    def test_otx_export_fp16(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
         tmp_dir_path = tmp_dir_path / "tiling_det"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_explain(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "tiling_det"
         otx_explain_testing(template, tmp_dir_path, otx_dir, args)
```

### Comparing `otx-1.1.2rc1/tests/integration/cli/segmentation/test_segmentation.py` & `otx-1.2.0rc1/tests/integration/cli/semantic_segmentation/test_segmentation.py`

 * *Files 4% similar despite different names*

```diff
@@ -14,15 +14,14 @@
     get_template_dir,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
     otx_eval_deployment_testing,
     otx_eval_openvino_testing,
     otx_eval_testing,
     otx_export_testing,
-    otx_export_testing_w_features,
     otx_hpo_testing,
     otx_resume_testing,
     otx_train_testing,
 )
 
 args = {
     "--train-data-roots": "tests/assets/common_semantic_segmentation_dataset/train",
@@ -109,40 +108,44 @@
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_resume(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_resume"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args)
         template_work_dir = get_template_dir(template, tmp_dir_path)
         args1 = copy.deepcopy(args)
         args1["train_params"] = resume_params
-        args1["--resume-from"] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth"
+        args1[
+            "--resume-from"
+        ] = f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth"
         otx_resume_testing(template, tmp_dir_path, otx_dir, args1)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("dump_features", [True, False])
+    def test_otx_export(self, template, tmp_dir_path, dump_features):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_export_testing(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, dump_features)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_export_w_features(self, template, tmp_dir_path):
+    def test_otx_export_fp16(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_export_testing_w_features(template, tmp_dir_path)
+        otx_export_testing(template, tmp_dir_path, half_precision=True)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_eval(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         otx_eval_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
-    def test_otx_eval_openvino(self, template, tmp_dir_path):
+    @pytest.mark.parametrize("half_precision", [True, False])
+    def test_otx_eval_openvino(self, template, tmp_dir_path, half_precision):
         tmp_dir_path = tmp_dir_path / "segmentation"
-        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0)
+        otx_eval_openvino_testing(template, tmp_dir_path, otx_dir, args, threshold=1.0, half_precision=half_precision)
 
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_openvino(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation"
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, args)
 
@@ -164,15 +167,14 @@
         tmp_dir_path = tmp_dir_path / "segmentation"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, args)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu"
         args1 = copy.deepcopy(args)
         args1["--gpus"] = "0,1"
         otx_train_testing(template, tmp_dir_path, otx_dir, args1)
@@ -180,15 +182,14 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_semisl"
         otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_semisl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu_semisl"
         args_semisl_multigpu = copy.deepcopy(args_semisl)
         args_semisl_multigpu["--gpus"] = "0,1"
         otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl_multigpu)
@@ -196,15 +197,14 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_selfsl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_selfsl"
         otx_train_testing(template, tmp_dir_path, otx_dir, args_selfsl)
 
     @e2e_pytest_component
-    @pytest.mark.skip(reason="CVS-101246 Multi-GPU tests are stuck while CI is running")
     @pytest.mark.skipif(MULTI_GPU_UNAVAILABLE, reason="The number of gpu is insufficient")
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_multi_gpu_train_selfsl(self, template, tmp_dir_path):
         tmp_dir_path = tmp_dir_path / "segmentation/test_multi_gpu_selfsl"
         args_selfsl_multigpu = copy.deepcopy(args_selfsl)
         args_selfsl_multigpu["--gpus"] = "0,1"
         otx_train_testing(template, tmp_dir_path, otx_dir, args_selfsl_multigpu)
```

### Comparing `otx-1.1.2rc1/tests/regression/action/test_action_classification.py` & `otx-1.2.0rc1/tests/regression/action/test_action_classification.py`

 * *Files 10% similar despite different names*

```diff
@@ -15,24 +15,29 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    otx_eval_compare,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "action_classification"
 TRAIN_TYPE = "supervised"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/action").filter(task_type=TASK_TYPE.upper()).templates
@@ -64,91 +69,102 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, action_cls_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             action_cls_data_args,
             action_cls_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=action_cls_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=action_cls_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
+        if template.name == "MoViNet":
+            pytest.skip(reason="[CVS-106939] MoViNet export --> eval issue.")
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             action_cls_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=action_cls_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, action_cls_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             action_cls_data_args,
             criteria=action_cls_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/action/test_action_detection.py` & `otx-1.2.0rc1/tests/regression/action/test_action_detection.py`

 * *Files 20% similar despite different names*

```diff
@@ -15,20 +15,27 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    otx_eval_compare,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
     otx_train_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "action_detection"
 TRAIN_TYPE = "supervised"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/action").filter(task_type=TASK_TYPE.upper()).templates
@@ -60,38 +67,43 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, action_det_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             action_det_data_args,
             action_det_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=action_det_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=action_det_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
+
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_classificaiton.py` & `otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_classificaiton.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,28 +16,31 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "anomaly_classification"
 SAMPLED_ANOMALY_DATASET_CATEGORIES = random.sample(ANOMALY_DATASET_CATEGORIES, 15)
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/anomaly").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
@@ -78,112 +81,121 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, category_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             anomaly_classification_regression_config["regression_criteria"]["train"][category],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE]["train"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_train_kpi_test(self, template, category):
         """KPI tests: measure the train+val time and evaluation time and compare with criteria."""
         results = result_dict[TASK_TYPE]["train"][category]
         performance = get_template_performance(results, template)
 
         # Compare train+val time with the KPI criteria.
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=anomaly_classification_regression_config["kpi_e2e_train_time_criteria"]["train"][
                 category
             ],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
         # Compare evaluation time with the KPI criteria.
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=anomaly_classification_regression_config["kpi_e2e_eval_time_criteria"]["train"][
                 category
             ],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_classification_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_classification_regression_config["regression_criteria"]["export"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["export"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_classification_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, category_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_classification_regression_config["regression_criteria"]["deploy"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["deploy"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_nncf_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_classification_data_args, category)
 
@@ -192,50 +204,54 @@
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=anomaly_classification_regression_config["regression_criteria"]["nncf"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["nncf"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_pot_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_classification_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             criteria=anomaly_classification_regression_config["regression_criteria"]["pot"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["pot"][category].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_detection.py` & `otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_detection.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,28 +16,31 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "anomaly_detection"
 SAMPLED_ANOMALY_DATASET_CATEGORIES = random.sample(ANOMALY_DATASET_CATEGORIES, 15)
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/anomaly").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
@@ -78,108 +81,117 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, category_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             anomaly_detection_regression_config["regression_criteria"]["train"][category],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE]["train"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_train_kpi_test(self, template, category):
         """KPI tests: measure the train+val time and evaluation time and compare with criteria."""
         results = result_dict[TASK_TYPE]["train"][category]
         performance = get_template_performance(results, template)
 
         # Compare train+val time with the KPI criteria.
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=anomaly_detection_regression_config["kpi_e2e_train_time_criteria"]["train"][category],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
         # Compare evaluation time with the KPI criteria.
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=anomaly_detection_regression_config["kpi_e2e_eval_time_criteria"]["train"][category],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_detection_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_detection_regression_config["regression_criteria"]["export"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["export"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_detection_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, category_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_detection_regression_config["regression_criteria"]["deploy"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["deploy"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_nncf_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_detection_data_args, category)
 
@@ -188,50 +200,54 @@
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=anomaly_detection_regression_config["regression_criteria"]["nncf"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["nncf"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_pot_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_detection_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             criteria=anomaly_detection_regression_config["regression_criteria"]["pot"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["pot"][category].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/anomaly/test_anomaly_segmentation.py` & `otx-1.2.0rc1/tests/regression/anomaly/test_anomaly_segmentation.py`

 * *Files 7% similar despite different names*

```diff
@@ -16,28 +16,31 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "anomaly_segmentation"
 SAMPLED_ANOMALY_DATASET_CATEGORIES = random.sample(ANOMALY_DATASET_CATEGORIES, 15)
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/anomaly").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
@@ -78,110 +81,119 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, category_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             anomaly_segmentation_regression_config["regression_criteria"]["train"][category],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE]["train"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_train_kpi_test(self, template, category):
         """KPI tests: measure the train+val time and evaluation time and compare with criteria."""
         results = result_dict[TASK_TYPE]["train"][category]
         performance = get_template_performance(results, template)
 
         # Compare train+val time with the KPI criteria.
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=anomaly_segmentation_regression_config["kpi_e2e_train_time_criteria"]["train"][
                 category
             ],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
         # Compare evaluation time with the KPI criteria.
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=anomaly_segmentation_regression_config["kpi_e2e_eval_time_criteria"]["train"][category],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_segmentation_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_segmentation_regression_config["regression_criteria"]["export"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["export"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_segmentation_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, category_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=anomaly_segmentation_regression_config["regression_criteria"]["deploy"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["deploy"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_nncf_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_segmentation_data_args, category)
 
@@ -190,50 +202,54 @@
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=anomaly_segmentation_regression_config["regression_criteria"]["nncf"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["nncf"][category].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.parametrize("category", SAMPLED_ANOMALY_DATASET_CATEGORIES)
     def test_pot_optimize_eval(self, template, tmp_dir_path, category):
         self.performance[template.name] = {}
         category_data_args = self._apply_category(anomaly_segmentation_data_args, category)
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, category_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             category_data_args,
             criteria=anomaly_segmentation_regression_config["regression_criteria"]["pot"][category],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE]["pot"][category].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/classification/test_classification.py` & `otx-1.2.0rc1/tests/regression/classification/test_classification.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,28 +17,31 @@
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "classification"
 TRAIN_TYPE = "supervised"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/classification").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
@@ -68,98 +71,110 @@
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, multi_class_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_class_data_args,
             multi_class_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=multi_class_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=multi_class_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         sl_template_work_dir = get_template_dir(template, tmp_dir_path / "multi_class_cls")
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls_incr"
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         args_cls_incr = config_cls_incr["data_path"]
-        args_cls_incr["--load-weights"] = f"{sl_template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_cls_incr[
+            "--load-weights"
+        ] = f"{sl_template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         args_cls_incr["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_cls_incr)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_cls_incr,
             config_cls_incr["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["class_incr"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr_kpi_test(self, template):
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
 
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_cls_incr["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_cls_incr["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_semisl"
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", self.label_type)
@@ -173,48 +188,53 @@
             "Semisupervised",
         ]
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_semisl,
             config_semisl["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["semi_supervised"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl_kpi_test(self, template):
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", self.label_type)
 
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_semisl["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_semisl["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_selfsl(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls/test_selfsl"
         config_selfsl = load_regression_configuration(otx_dir, TASK_TYPE, "self_supervised", self.label_type)
@@ -238,164 +258,177 @@
 
         # Supervised Training
         template_work_dir = get_template_dir(template, tmp_dir_path)
         new_tmp_dir_path = tmp_dir_path / "test_supervised"
         args_selfsl["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
         args_selfsl["--val-data-roots"] = multi_class_data_args["--val-data-roots"]
         args_selfsl["--test-data-roots"] = multi_class_data_args["--test-data-roots"]
-        args_selfsl["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_selfsl["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, new_tmp_dir_path, otx_dir, args_selfsl)
 
         # Evaluation with self + supervised training model
         args_selfsl.pop("--load-weights")
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             new_tmp_dir_path,
             otx_dir,
             args_selfsl,
             config_selfsl["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["self_supervised"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_selfsl_kpi_test(self, template):
         config_selfsl = load_regression_configuration(otx_dir, TASK_TYPE, "self_supervised", self.label_type)
 
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_selfsl["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_selfsl["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_class_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=multi_class_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, multi_class_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_class_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=multi_class_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, multi_class_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_class_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=multi_class_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_class_cls"
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, multi_class_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_class_data_args,
             criteria=multi_class_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
 
 multi_label_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, "multi_label")
 multi_label_data_args = multi_label_regression_config["data_path"]
 multi_label_data_args["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
 
 class TestRegressionMultiLabelClassification:
@@ -414,208 +447,228 @@
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, multi_label_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_label_data_args,
             multi_label_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=multi_label_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=multi_label_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         sl_template_work_dir = get_template_dir(template, tmp_dir_path / "multi_label_cls")
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls_incr"
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         args_cls_incr = config_cls_incr["data_path"]
-        args_cls_incr["--load-weights"] = f"{sl_template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_cls_incr[
+            "--load-weights"
+        ] = f"{sl_template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         args_cls_incr["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_cls_incr)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_cls_incr,
             config_cls_incr["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["class_incr"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr_kpi_test(self, template):
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
 
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_cls_incr["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_cls_incr["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_label_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=multi_label_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, multi_label_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_label_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=multi_label_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, multi_label_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_label_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=multi_label_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "multi_label_cls"
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, multi_label_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             multi_label_data_args,
             criteria=multi_label_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
 
 h_label_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, "h_label")
 h_label_data_args = h_label_regression_config["data_path"]
 h_label_data_args["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
 
 class TestRegressionHierarchicalLabelClassification:
@@ -634,156 +687,169 @@
 
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, h_label_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             h_label_data_args,
             h_label_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=h_label_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=h_label_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             h_label_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=h_label_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, h_label_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             h_label_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=h_label_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, h_label_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             h_label_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=h_label_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / "h_label_cls"
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, h_label_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             h_label_data_args,
             criteria=h_label_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
 
 class TestRegressionSupconClassification:
     def setup_method(self):
         self.label_type = "supcon"
         self.performance = {}
 
     def teardown_method(self):
@@ -809,39 +875,44 @@
         # Supcon
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_supcon)
         train_elapsed_time = timer() - train_start_time
 
         # Evaluation with supcon + supervised training
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_supcon,
             config_supcon["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         config_supcon = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, self.label_type)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_supcon["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_supcon["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
+
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/detection/test_detection.py` & `otx-1.2.0rc1/tests/regression/detection/test_detection.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,28 +16,31 @@
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "detection"
 TRAIN_TYPE = "supervised"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/detection").filter(task_type=TASK_TYPE.upper()).templates
@@ -68,97 +71,109 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, detection_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             detection_data_args,
             detection_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=detection_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=detection_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         sl_template_work_dir = get_template_dir(template, tmp_dir_path / TASK_TYPE)
 
         tmp_dir_path = tmp_dir_path / "det_incr"
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         args_cls_incr = config_cls_incr["data_path"]
-        args_cls_incr["--load-weights"] = f"{sl_template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_cls_incr[
+            "--load-weights"
+        ] = f"{sl_template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         args_cls_incr["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_cls_incr)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_cls_incr,
             config_cls_incr["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["class_incr"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr_kpi_test(self, template):
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_cls_incr["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_cls_incr["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / f"{TASK_TYPE}/test_semisl"
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", LABEL_TYPE)
@@ -173,149 +188,162 @@
         ]
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
         train_elapsed_time = timer() - train_start_time
 
         args_semisl.pop("train_params")
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_semisl,
             config_semisl["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE]["semi_supervised"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl_kpi_test(self, template):
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", LABEL_TYPE)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_semisl["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_semisl["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             detection_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=detection_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, detection_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             detection_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=detection_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, detection_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             detection_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=detection_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, detection_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             detection_data_args,
             criteria=detection_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/detection/test_instnace_segmentation.py` & `otx-1.2.0rc1/tests/regression/instance_segmentation/test_instnace_segmentation.py`

 * *Files 22% similar despite different names*

```diff
@@ -16,28 +16,31 @@
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "instance_segmentation"
 TRAIN_TYPE = "supervised"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/detection").filter(task_type=TASK_TYPE.upper()).templates
@@ -68,199 +71,219 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, inst_seg_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             inst_seg_data_args,
             inst_seg_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=inst_seg_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=inst_seg_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         sl_template_work_dir = get_template_dir(template, tmp_dir_path / TASK_TYPE)
 
         tmp_dir_path = tmp_dir_path / "inst_seg_incr"
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         args_cls_incr = config_cls_incr["data_path"]
-        args_cls_incr["--load-weights"] = f"{sl_template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_cls_incr[
+            "--load-weights"
+        ] = f"{sl_template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         args_cls_incr["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_cls_incr)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_cls_incr,
             config_cls_incr["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["class_incr"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr_kpi_test(self, template):
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_cls_incr["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_cls_incr["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             inst_seg_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=inst_seg_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, inst_seg_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             inst_seg_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=inst_seg_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, inst_seg_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             inst_seg_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=inst_seg_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, inst_seg_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             inst_seg_data_args,
             criteria=inst_seg_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/detection/test_tiling_detection.py` & `otx-1.2.0rc1/tests/regression/instance_segmentation/test_tiling_instnace_segmentation.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for Tiling Detection with OTX CLI"""
+"""Tests for Tiling Instance Segmentation with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import json
 import os
 from pathlib import Path
 from timeit import default_timer as timer
@@ -15,55 +15,58 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
-TASK_TYPE = "detection"
+TASK_TYPE = "instance_segmentation"
 TRAIN_TYPE = "tiling"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/detection").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
 
 result_dict = get_result_dict(TASK_TYPE)
 result_dir = f"/tmp/regression_test_results/tiling_{TASK_TYPE}"
 Path(result_dir).mkdir(parents=True, exist_ok=True)
 
-tiling_detection_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, LABEL_TYPE)
-tiling_detection_data_args = tiling_detection_regression_config["data_path"]
-tiling_detection_data_args["train_params"] = [
+tiling_inst_seg_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, LABEL_TYPE)
+tiling_inst_seg_data_args = tiling_inst_seg_regression_config["data_path"]
+tiling_inst_seg_data_args["train_params"] = [
     "params",
     "--learning_parameters.num_iters",
     REGRESSION_TEST_EPOCHS,
     "--tiling_parameters.enable_tiling",
     "1",
     "--tiling_parameters.enable_adaptive_params",
     "1",
 ]
 
 
-class TestRegressionTilingDetection:
+class TestRegressionTilingInstanceSegmentation:
     def setup_method(self):
         self.label_type = LABEL_TYPE
         self.performance = {}
 
     def teardown_method(self):
         with open(f"{result_dir}/result.json", "w") as result_file:
             json.dump(result_dict, result_file, indent=4)
@@ -71,153 +74,166 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
-        otx_train_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
+        otx_train_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_detection_data_args,
-            tiling_detection_regression_config["regression_criteria"]["train"],
+            tiling_inst_seg_data_args,
+            tiling_inst_seg_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
-            train_time_criteria=tiling_detection_regression_config["kpi_e2e_train_time_criteria"]["train"],
+        kpi_train_result = regression_train_time_testing(
+            train_time_criteria=tiling_inst_seg_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
-            eval_time_criteria=tiling_detection_regression_config["kpi_e2e_eval_time_criteria"]["train"],
+        kpi_eval_result = regression_eval_time_testing(
+            eval_time_criteria=tiling_inst_seg_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_detection_data_args,
-            threshold=1.0,
-            criteria=tiling_detection_regression_config["regression_criteria"]["export"],
+            tiling_inst_seg_data_args,
+            threshold=0.02,
+            criteria=tiling_inst_seg_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
-        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
+        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_detection_data_args,
-            threshold=1.0,
-            criteria=tiling_detection_regression_config["regression_criteria"]["deploy"],
+            tiling_inst_seg_data_args,
+            threshold=0.02,
+            criteria=tiling_inst_seg_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
-        nncf_optimize_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
+        nncf_optimize_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_detection_data_args,
-            threshold=1.0,
-            criteria=tiling_detection_regression_config["regression_criteria"]["nncf"],
+            tiling_inst_seg_data_args,
+            threshold=0.001,
+            criteria=tiling_inst_seg_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
-        pot_optimize_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
+        pot_optimize_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_detection_data_args,
-            criteria=tiling_detection_regression_config["regression_criteria"]["pot"],
+            tiling_inst_seg_data_args,
+            criteria=tiling_inst_seg_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/detection/test_tiling_instnace_segmentation.py` & `otx-1.2.0rc1/tests/regression/detection/test_tiling_detection.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Tests for Tiling Instance Segmentation with OTX CLI"""
+"""Tests for Tiling Detection with OTX CLI"""
 # Copyright (C) 2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import json
 import os
 from pathlib import Path
 from timeit import default_timer as timer
@@ -15,55 +15,58 @@
     TIME_LOG,
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
-TASK_TYPE = "instance_segmentation"
+TASK_TYPE = "detection"
 TRAIN_TYPE = "tiling"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry("otx/algorithms/detection").filter(task_type=TASK_TYPE.upper()).templates
 templates_ids = [template.model_template_id for template in templates]
 
 result_dict = get_result_dict(TASK_TYPE)
 result_dir = f"/tmp/regression_test_results/tiling_{TASK_TYPE}"
 Path(result_dir).mkdir(parents=True, exist_ok=True)
 
-tiling_inst_seg_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, LABEL_TYPE)
-tiling_inst_seg_data_args = tiling_inst_seg_regression_config["data_path"]
-tiling_inst_seg_data_args["train_params"] = [
+tiling_detection_regression_config = load_regression_configuration(otx_dir, TASK_TYPE, TRAIN_TYPE, LABEL_TYPE)
+tiling_detection_data_args = tiling_detection_regression_config["data_path"]
+tiling_detection_data_args["train_params"] = [
     "params",
     "--learning_parameters.num_iters",
     REGRESSION_TEST_EPOCHS,
     "--tiling_parameters.enable_tiling",
     "1",
     "--tiling_parameters.enable_adaptive_params",
     "1",
 ]
 
 
-class TestRegressionTilingInstanceSegmentation:
+class TestRegressionTilingDetection:
     def setup_method(self):
         self.label_type = LABEL_TYPE
         self.performance = {}
 
     def teardown_method(self):
         with open(f"{result_dir}/result.json", "w") as result_file:
             json.dump(result_dict, result_file, indent=4)
@@ -71,153 +74,166 @@
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
-        otx_train_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
+        otx_train_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_inst_seg_data_args,
-            tiling_inst_seg_regression_config["regression_criteria"]["train"],
+            tiling_detection_data_args,
+            tiling_detection_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
-            train_time_criteria=tiling_inst_seg_regression_config["kpi_e2e_train_time_criteria"]["train"],
+        kpi_train_result = regression_train_time_testing(
+            train_time_criteria=tiling_detection_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
-            eval_time_criteria=tiling_inst_seg_regression_config["kpi_e2e_eval_time_criteria"]["train"],
+        kpi_eval_result = regression_eval_time_testing(
+            eval_time_criteria=tiling_detection_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_inst_seg_data_args,
-            threshold=1.0,
-            criteria=tiling_inst_seg_regression_config["regression_criteria"]["export"],
+            tiling_detection_data_args,
+            threshold=0.02,
+            criteria=tiling_detection_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
-        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
+        otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_inst_seg_data_args,
-            threshold=1.0,
-            criteria=tiling_inst_seg_regression_config["regression_criteria"]["deploy"],
+            tiling_detection_data_args,
+            threshold=0.02,
+            criteria=tiling_detection_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     @pytest.mark.skip(reason="CVS-98026")
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
-        nncf_optimize_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
+        nncf_optimize_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_inst_seg_data_args,
-            threshold=1.0,
-            criteria=tiling_inst_seg_regression_config["regression_criteria"]["nncf"],
+            tiling_detection_data_args,
+            threshold=0.001,
+            criteria=tiling_detection_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
-        pot_optimize_testing(template, tmp_dir_path, otx_dir, tiling_inst_seg_data_args)
+        pot_optimize_testing(template, tmp_dir_path, otx_dir, tiling_detection_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
-            tiling_inst_seg_data_args,
-            criteria=tiling_inst_seg_regression_config["regression_criteria"]["pot"],
+            tiling_detection_data_args,
+            criteria=tiling_detection_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/regression_config.json` & `otx-1.2.0rc1/tests/regression/regression_config.json`

 * *Files 23% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9561284722222222%*

 * *Differences: {"'data_path'": "{'classification': {'supervised': {'multi_class': {'--train-data-roots': "*

 * *                "'/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/train', "*

 * *                "'--val-data-roots': "*

 * *                "'/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test', "*

 * *                "'--test-data-roots': "*

 * *                "'/storageserver/pvd_data/otx_data_archive/regression_datasets/classif []*

```diff
@@ -1,2917 +1,2178 @@
 {
     "data_path": {
         "action_classification": {
             "supervised": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/action/classification/HMDB51_30percent/val",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/action/classification/HMDB51_30percent/train",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/action/classification/HMDB51_30percent/val"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/classification/HMDB51_30percent/val",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/classification/HMDB51_30percent/train",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/classification/HMDB51_30percent/val"
                 }
             }
         },
         "action_detection": {
             "supervised": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/action/detection/JHMDB_5percent/test",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/action/detection/JHMDB_5percent/train",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/action/detection/JHMDB_5percent/test"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/detection/JHMDB_5percent/test",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/detection/JHMDB_5percent/train",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/action/detection/JHMDB_5percent/test"
                 }
             }
         },
         "anomaly_classification": {
-            "--input": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec/bottle/test/contamination",
-            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
+            "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec/bottle/test/contamination",
+            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
             "train_params": []
         },
         "anomaly_detection": {
-            "--input": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec/bottle/test/contamination",
-            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
+            "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec/bottle/test/contamination",
+            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
             "train_params": []
         },
         "anomaly_segmentation": {
-            "--input": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec/bottle/test/contamination",
-            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
-            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/anomaly/mvtec",
+            "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec/bottle/test/contamination",
+            "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
+            "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/anomaly/mvtec",
             "train_params": []
         },
         "classification": {
             "class_incr": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset/test",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset/train",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset/test"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset/test",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset/train",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset/test"
                 },
                 "multi_label": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset"
                 }
             },
             "self_supervised": {
                 "multi_class": {
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/train"
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/train"
                 }
             },
             "semi_supervised": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/train",
-                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_unlabeled",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/train",
+                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_unlabeled",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test"
                 }
             },
             "supervised": {
                 "h_label": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/classification/hierarhical_classification/h_label_cifar10_subset/images/test/airplane",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/hierarhical_classification/h_label_cifar10_subset",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/hierarhical_classification/h_label_cifar10_subset",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/hierarhical_classification/h_label_cifar10_subset"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/h_label_cifar10_subset/images/test/airplane",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/h_label_cifar10_subset",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/h_label_cifar10_subset",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/h_label_cifar10_subset"
                 },
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset/test/airplane",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/train",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset/test/airplane",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/train",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test"
                 },
                 "multi_label": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset/images/test",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/multi_label_classification/multi_label_coco_subset_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset/images/test",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/multi_label_coco_subset_cls_decr"
                 },
                 "supcon": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/train",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/classification/cifar10_subset_cls_decr/test"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/train",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/classification/cifar10_subset_cls_decr/test"
                 }
             }
         },
         "detection": {
             "class_incr": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset"
                 }
             },
             "semi_supervised": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset/images/unlabeled",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset/images/unlabeled",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr"
                 }
             },
             "supervised": {
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr/images/test",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr/images/test",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr"
                 }
             },
             "tiling": {
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset/images/test",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset/images/test",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr"
                 }
             }
         },
         "instance_segmentation": {
             "class_incr": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset"
                 }
             },
             "supervised": {
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr/images/test",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr/images/test",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr"
                 }
             },
             "tiling": {
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset/images/test",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/detection/coco_subset_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset/images/test",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/detection/coco_subset_cls_decr"
                 }
             }
         },
         "segmentation": {
             "class_incr": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_sl",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_sl",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_sl"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_sl",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_sl",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_sl"
                 }
             },
             "self_supervised": {
                 "multi_class": {
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr"
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr"
                 }
             },
             "semi_supervised": {
                 "multi_class": {
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr",
-                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_semisl/unlabeled",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr"
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr",
+                    "--unlabeled-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_semisl/unlabeled",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr"
                 }
             },
             "supervised": {
                 "multi_class": {
-                    "--input": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr/test/images",
-                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr",
-                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr",
-                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/segmentation/regression_voc_cls_decr"
+                    "--input": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr/test/images",
+                    "--test-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr",
+                    "--train-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr",
+                    "--val-data-roots": "/storageserver/pvd_data/otx_data_archive/regression_datasets/segmentation/regression_voc_cls_decr"
                 }
             }
         }
     },
     "kpi_e2e_eval_time_criteria": {
         "action_classification": {
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "X3D": 0.0
+                        "MoViNet": 0.0,
+                        "X3D": 384.374
                     }
                 }
             }
         },
         "action_detection": {
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "X3D_FAST_RCNN": 0.0
+                        "X3D_FAST_RCNN": 289.228
                     }
                 }
             }
         },
         "anomaly_classification": {
-            "deploy": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "export": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "nncf": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "pot": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 18.455,
+                    "STFPM": 15.642
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.792,
+                    "STFPM": 18.392
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.181,
+                    "STFPM": 17.804
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 22.427,
+                    "STFPM": 17.077
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 17.446,
+                    "STFPM": 17.394
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 23.72,
+                    "STFPM": 23.11
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 19.211,
+                    "STFPM": 18.26
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 20.524,
+                    "STFPM": 21.384
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 15.948,
+                    "STFPM": 22.02
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.325,
+                    "STFPM": 16.735
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 17.233,
+                    "STFPM": 19.721
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.595,
+                    "STFPM": 19.855
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 19.858,
+                    "STFPM": 18.758
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 23.046,
+                    "STFPM": 19.183
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 15.467,
+                    "STFPM": 17.853
                 }
             }
         },
         "anomaly_detection": {
-            "deploy": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "export": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "nncf": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "pot": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 17.691,
+                    "STFPM": 15.482
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 22.65,
+                    "STFPM": 23.461
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 20.122,
+                    "STFPM": 21.189
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 19.355,
+                    "STFPM": 22.601
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.811,
+                    "STFPM": 17.123
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 20.818,
+                    "STFPM": 18.379
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 19.309,
+                    "STFPM": 19.115
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 18.315,
+                    "STFPM": 16.946
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 21.151,
+                    "STFPM": 22.808
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 24.962,
+                    "STFPM": 20.324
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 17.563,
+                    "STFPM": 18.517
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 16.785,
+                    "STFPM": 17.988
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 17.293,
+                    "STFPM": 19.241
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 18.066,
+                    "STFPM": 20.676
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 22.77,
+                    "STFPM": 19.993
                 }
             }
         },
         "anomaly_segmentation": {
-            "deploy": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "export": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "nncf": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
-            "pot": {
-                "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                },
-                "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
-                }
-            },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 31.495,
+                    "STFPM": 39.449
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 40.103,
+                    "STFPM": 48.302
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 38.647,
+                    "STFPM": 41.977
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 30.966,
+                    "STFPM": 27.533
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 36.005,
+                    "STFPM": 28.542
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 40.583,
+                    "STFPM": 49.986
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 32.192,
+                    "STFPM": 32.621
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 35.058,
+                    "STFPM": 43.693
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 51.866,
+                    "STFPM": 51.913
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 28.663,
+                    "STFPM": 46.137
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 52.074,
+                    "STFPM": 51.027
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 28.637,
+                    "STFPM": 31.896
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 38.587,
+                    "STFPM": 42.772
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 40.225,
+                    "STFPM": 43.555
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 39.517,
+                    "STFPM": 42.113
                 }
             }
         },
         "classification": {
             "class_incr": {
                 "h_label": {
                     "train": {
                         "EfficientNet-B0": 0.0,
                         "EfficientNet-V2-S": 0.0,
                         "MobileNet-V3-large-1x": 0.0
                     }
                 },
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 15.488,
+                        "EfficientNet-V2-S": 16.715,
+                        "MobileNet-V3-large-1x": 16.722
                     }
                 },
                 "multi_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 17.046,
+                        "EfficientNet-V2-S": 19.618,
+                        "MobileNet-V3-large-1x": 20.686
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 15.179,
+                        "EfficientNet-V2-S": 15.552,
+                        "MobileNet-V3-large-1x": 14.267
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 15.107,
+                        "EfficientNet-V2-S": 16.885,
+                        "MobileNet-V3-large-1x": 17.905
                     }
                 }
             },
             "supervised": {
                 "h_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 13.558,
+                        "EfficientNet-V2-S": 17.99,
+                        "MobileNet-V3-large-1x": 18.068
                     }
                 },
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 15.145,
+                        "EfficientNet-V2-S": 17.8,
+                        "MobileNet-V3-large-1x": 16.453
                     }
                 },
                 "multi_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 19.497,
+                        "EfficientNet-V2-S": 18.706,
+                        "MobileNet-V3-large-1x": 20.311
                     }
                 },
                 "supcon": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 14.586,
+                        "EfficientNet-V2-S": 17.1,
+                        "MobileNet-V3-large-1x": 17.988
                     }
                 }
             }
         },
         "detection": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 62.492,
+                        "SSD": 89.412,
+                        "YOLOX": 59.154
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 50.34,
+                        "SSD": 76.703,
+                        "YOLOX": 47.199
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 73.888,
+                        "SSD": 86.989,
+                        "YOLOX": 82.169
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 84.882,
+                        "SSD": 169.937,
+                        "YOLOX": 146.561
                     }
                 }
             }
         },
         "instance_segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 118.353,
+                        "MaskRCNN-ResNet50": 103.552
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 109.647,
+                        "MaskRCNN-ResNet50": 121.861
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 321.017,
+                        "MaskRCNN-ResNet50": 522.271
                     }
                 }
             }
         },
         "segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 43.817,
+                        "Lite-HRNet-18-mod2": 48.536,
+                        "Lite-HRNet-s-mod2": 43.425,
+                        "Lite-HRNet-x-mod3": 74.163
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 44.935,
+                        "Lite-HRNet-18-mod2": 36.786,
+                        "Lite-HRNet-s-mod2": 37.616,
+                        "Lite-HRNet-x-mod3": 52.59
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 47.816,
+                        "Lite-HRNet-18-mod2": 51.605,
+                        "Lite-HRNet-s-mod2": 43.347,
+                        "Lite-HRNet-x-mod3": 56.125
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 43.046,
+                        "Lite-HRNet-18-mod2": 42.2,
+                        "Lite-HRNet-s-mod2": 36.656,
+                        "Lite-HRNet-x-mod3": 59.053
                     }
                 }
             }
         }
     },
     "kpi_e2e_train_time_criteria": {
         "action_classification": {
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "X3D": 0.0
+                        "MoViNet": 0.0,
+                        "X3D": 3604.046
                     }
                 }
             }
         },
         "action_detection": {
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "X3D_FAST_RCNN": 0.0
+                        "X3D_FAST_RCNN": 11349.635
                     }
                 }
             }
         },
         "anomaly_classification": {
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 113.547,
+                    "STFPM": 719.611
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 81.765,
+                    "STFPM": 777.212
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 74.779,
+                    "STFPM": 737.924
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 115.933,
+                    "STFPM": 915.018
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 78.714,
+                    "STFPM": 880.849
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 444.225,
+                    "STFPM": 612.339
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 130.234,
+                    "STFPM": 976.283
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 133.969,
+                    "STFPM": 602.296
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 349.457,
+                    "STFPM": 1612.218
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 89.838,
+                    "STFPM": 479.455
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 90.505,
+                    "STFPM": 812.539
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 103.921,
+                    "STFPM": 729.418
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 100.966,
+                    "STFPM": 559.613
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 120.205,
+                    "STFPM": 645.307
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 85.425,
+                    "STFPM": 1094.092
                 }
             }
         },
         "anomaly_detection": {
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 70.212,
+                    "STFPM": 616.724
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 77.289,
+                    "STFPM": 1099.243
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 79.647,
+                    "STFPM": 442.791
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 76.309,
+                    "STFPM": 672.606
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 70.806,
+                    "STFPM": 466.608
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 75.02,
+                    "STFPM": 442.13
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 78.943,
+                    "STFPM": 665.451
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 72.459,
+                    "STFPM": 841.626
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 77.902,
+                    "STFPM": 1048.111
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 80.394,
+                    "STFPM": 916.603
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 72.959,
+                    "STFPM": 967.902
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 70.768,
+                    "STFPM": 552.189
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 74.005,
+                    "STFPM": 556.002
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 74.659,
+                    "STFPM": 897.382
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 79.349,
+                    "STFPM": 1778.595
                 }
             }
         },
         "anomaly_segmentation": {
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 162.997,
+                    "STFPM": 1604.738
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 192.818,
+                    "STFPM": 966.757
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 181.064,
+                    "STFPM": 1468.992
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 147.889,
+                    "STFPM": 1609.069
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 152.668,
+                    "STFPM": 1080.058
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 312.687,
+                    "STFPM": 1083.441
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 166.385,
+                    "STFPM": 2060.551
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 163.375,
+                    "STFPM": 968.054
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 445.256,
+                    "STFPM": 2116.461
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 209.651,
+                    "STFPM": 3076.376
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 205.008,
+                    "STFPM": 2123.952
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 198.668,
+                    "STFPM": 1351.298
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 169.985,
+                    "STFPM": 1619.98
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 191.44,
+                    "STFPM": 1040.837
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 186.099,
+                    "STFPM": 2514.32
                 }
             }
         },
         "classification": {
             "class_incr": {
                 "h_label": {
                     "train": {
                         "EfficientNet-B0": 0.0,
                         "EfficientNet-V2-S": 0.0,
                         "MobileNet-V3-large-1x": 0.0
                     }
                 },
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 74.543,
+                        "EfficientNet-V2-S": 106.703,
+                        "MobileNet-V3-large-1x": 80.603
                     }
                 },
                 "multi_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 163.371,
+                        "EfficientNet-V2-S": 179.346,
+                        "MobileNet-V3-large-1x": 163.404
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 27.623,
+                        "EfficientNet-V2-S": 34.063,
+                        "MobileNet-V3-large-1x": 27.925
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 230.227,
+                        "EfficientNet-V2-S": 423.184,
+                        "MobileNet-V3-large-1x": 227.445
                     }
                 }
             },
             "supervised": {
                 "h_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 73.195,
+                        "EfficientNet-V2-S": 92.564,
+                        "MobileNet-V3-large-1x": 76.041
                     }
                 },
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 70.02,
+                        "EfficientNet-V2-S": 93.257,
+                        "MobileNet-V3-large-1x": 72.732
                     }
                 },
                 "multi_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 144.651,
+                        "EfficientNet-V2-S": 163.202,
+                        "MobileNet-V3-large-1x": 148.559
                     }
                 },
                 "supcon": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 105.109,
+                        "EfficientNet-V2-S": 122.369,
+                        "MobileNet-V3-large-1x": 115.94
                     }
                 }
             }
         },
         "detection": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 1531.103,
+                        "SSD": 1439.16,
+                        "YOLOX": 3059.355
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 6263.435,
+                        "SSD": 6410.017,
+                        "YOLOX": 4962.307
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 1843.627,
+                        "SSD": 1992.196,
+                        "YOLOX": 4226.84
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 2074.501,
+                        "SSD": 2052.821,
+                        "YOLOX": 1689.117
                     }
                 }
             }
         },
         "instance_segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 4342.104,
+                        "MaskRCNN-ResNet50": 4367.131
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 4869.547,
+                        "MaskRCNN-ResNet50": 5857.729
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 7274.234,
+                        "MaskRCNN-ResNet50": 8086.079
                     }
                 }
             }
         },
         "segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 486.038,
+                        "Lite-HRNet-18-mod2": 474.511,
+                        "Lite-HRNet-s-mod2": 447.762,
+                        "Lite-HRNet-x-mod3": 759.906
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 750.812,
+                        "Lite-HRNet-18-mod2": 756.383,
+                        "Lite-HRNet-s-mod2": 727.372,
+                        "Lite-HRNet-x-mod3": 1017.624
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 601.665,
+                        "Lite-HRNet-18-mod2": 715.882,
+                        "Lite-HRNet-s-mod2": 564.257,
+                        "Lite-HRNet-x-mod3": 902.047
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 446.99,
+                        "Lite-HRNet-18-mod2": 443.94,
+                        "Lite-HRNet-s-mod2": 393.137,
+                        "Lite-HRNet-x-mod3": 667.493
                     }
                 }
             }
         }
     },
     "regression_criteria": {
         "action_classification": {
             "supervised": {
                 "multi_class": {
                     "export": {
-                        "X3D": 0.0
+                        "MoViNet": 0.0,
+                        "X3D": 0.589
                     },
                     "pot": {
-                        "X3D": 0.0
+                        "MoViNet": 0.0,
+                        "X3D": 0.58
                     },
                     "train": {
-                        "X3D": 0.0
+                        "MoViNet": 0.0,
+                        "X3D": 0.612
                     }
                 }
             }
         },
         "action_detection": {
             "supervised": {
                 "multi_class": {
                     "train": {
-                        "X3D_FAST_RCNN": 0.0
+                        "X3D_FAST_RCNN": 0.59
                     }
                 }
             }
         },
         "anomaly_classification": {
             "deploy": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.823,
+                    "STFPM": 0.759
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.615,
+                    "STFPM": 0.613
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.848,
+                    "STFPM": 0.826
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.786,
+                    "STFPM": 0.771
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.731,
+                    "STFPM": 0.745
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.727,
+                    "STFPM": 0.642
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.847,
+                    "STFPM": 0.795
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.812,
+                    "STFPM": 0.809
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.844,
+                    "STFPM": 0.844
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.746,
+                    "STFPM": 0.761
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.718,
+                    "STFPM": 0.74
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.718,
+                    "STFPM": 0.714
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.424,
+                    "STFPM": 0.4
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.825,
+                    "STFPM": 0.832
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.834,
+                    "STFPM": 0.815
                 }
             },
             "export": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.823,
+                    "STFPM": 0.759
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.615,
+                    "STFPM": 0.613
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.848,
+                    "STFPM": 0.826
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.786,
+                    "STFPM": 0.771
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.731,
+                    "STFPM": 0.745
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.727,
+                    "STFPM": 0.642
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.847,
+                    "STFPM": 0.795
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.812,
+                    "STFPM": 0.809
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.844,
+                    "STFPM": 0.844
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.746,
+                    "STFPM": 0.761
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.718,
+                    "STFPM": 0.74
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.718,
+                    "STFPM": 0.714
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.424,
+                    "STFPM": 0.4
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.825,
+                    "STFPM": 0.832
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.834,
+                    "STFPM": 0.815
                 }
             },
             "nncf": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.94,
+                    "STFPM": 0.867
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.673,
+                    "STFPM": 0.707
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.856,
+                    "STFPM": 0.871
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.812,
+                    "STFPM": 0.846
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.731,
+                    "STFPM": 0.756
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.909,
+                    "STFPM": 0.764
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.911,
+                    "STFPM": 0.944
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.817,
+                    "STFPM": 0.826
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.844,
+                    "STFPM": 0.844
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.744,
+                    "STFPM": 0.762
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.786,
+                    "STFPM": 0.872
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.857,
+                    "STFPM": 0.714
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.81,
+                    "STFPM": 0.55
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.937,
+                    "STFPM": 0.937
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.834,
+                    "STFPM": 0.821
                 }
             },
             "pot": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.88,
+                    "STFPM": 0.759
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.626,
+                    "STFPM": 0.613
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.833,
+                    "STFPM": 0.826
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.812,
+                    "STFPM": 0.761
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.731,
+                    "STFPM": 0.742
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.73,
+                    "STFPM": 0.636
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.903,
+                    "STFPM": 0.776
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.809,
+                    "STFPM": 0.809
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.844,
+                    "STFPM": 0.844
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.744,
+                    "STFPM": 0.744
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.721,
+                    "STFPM": 0.739
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.75,
+                    "STFPM": 0.714
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.436,
+                    "STFPM": 0.4
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.835,
+                    "STFPM": 0.822
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.755,
+                    "STFPM": 0.788
                 }
             },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.952,
+                    "STFPM": 0.771
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.64,
+                    "STFPM": 0.627
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.871,
+                    "STFPM": 0.826
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.769,
+                    "STFPM": 0.821
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.744,
+                    "STFPM": 0.731
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.873,
+                    "STFPM": 0.664
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.863,
+                    "STFPM": 0.871
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.843,
+                    "STFPM": 0.817
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.844,
+                    "STFPM": 0.844
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.75,
+                    "STFPM": 0.762
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.752,
+                    "STFPM": 0.872
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.81,
+                    "STFPM": 0.714
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.69,
+                    "STFPM": 0.4
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.937,
+                    "STFPM": 0.949
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.841,
+                    "STFPM": 0.815
                 }
             }
         },
         "anomaly_detection": {
             "deploy": {
                 "bottle": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.404,
                     "STFPM": 0.0
                 },
                 "cable": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.053,
                     "STFPM": 0.0
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.088,
+                    "STFPM": 0.015
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.221,
+                    "STFPM": 0.019
                 },
                 "grid": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.011,
                     "STFPM": 0.0
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.22,
                     "STFPM": 0.0
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.108,
+                    "STFPM": 0.039
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.089,
                     "STFPM": 0.0
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.047,
+                    "STFPM": 0.051
                 },
                 "screw": {
                     "PADIM": 0.0,
                     "STFPM": 0.0
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.143,
+                    "STFPM": 0.014
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.11,
+                    "STFPM": 0.059
                 },
                 "transistor": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.184,
                     "STFPM": 0.0
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.139,
+                    "STFPM": 0.022
                 },
                 "zipper": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.127,
                     "STFPM": 0.0
                 }
             },
             "export": {
                 "bottle": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.404,
                     "STFPM": 0.0
                 },
                 "cable": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.053,
                     "STFPM": 0.0
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.088,
+                    "STFPM": 0.015
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.221,
+                    "STFPM": 0.019
                 },
                 "grid": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.011,
                     "STFPM": 0.0
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.22,
                     "STFPM": 0.0
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.108,
+                    "STFPM": 0.039
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.089,
                     "STFPM": 0.0
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.047,
+                    "STFPM": 0.051
                 },
                 "screw": {
                     "PADIM": 0.0,
                     "STFPM": 0.0
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.143,
+                    "STFPM": 0.014
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.11,
+                    "STFPM": 0.059
                 },
                 "transistor": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.184,
                     "STFPM": 0.0
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.139,
+                    "STFPM": 0.022
                 },
                 "zipper": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.127,
                     "STFPM": 0.0
                 }
             },
             "nncf": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.276,
+                    "STFPM": 0.056
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.083,
+                    "STFPM": 0.122
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.146,
+                    "STFPM": 0.017
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.238,
+                    "STFPM": 0.155
                 },
                 "grid": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.014,
                     "STFPM": 0.0
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.192,
                     "STFPM": 0.0
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.131,
+                    "STFPM": 0.121
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.103,
+                    "STFPM": 0.021
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.094,
+                    "STFPM": 0.044
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.029,
+                    "STFPM": 0.014
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.07,
+                    "STFPM": 0.065
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.125,
+                    "STFPM": 0.066
                 },
                 "transistor": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.038,
                     "STFPM": 0.0
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.181,
+                    "STFPM": 0.075
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.123,
+                    "STFPM": 0.195
                 }
             },
             "pot": {
                 "bottle": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.306,
                     "STFPM": 0.0
                 },
                 "cable": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.038,
                     "STFPM": 0.0
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.127,
+                    "STFPM": 0.012
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.202,
+                    "STFPM": 0.026
                 },
                 "grid": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.02,
                     "STFPM": 0.0
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.24,
+                    "STFPM": 0.007
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.101,
+                    "STFPM": 0.038
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.147,
                     "STFPM": 0.0
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.085,
+                    "STFPM": 0.041
                 },
                 "screw": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.004,
                     "STFPM": 0.0
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.143,
+                    "STFPM": 0.013
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.184,
+                    "STFPM": 0.015
                 },
                 "transistor": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.209,
                     "STFPM": 0.0
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.201,
+                    "STFPM": 0.031
                 },
                 "zipper": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.158,
                     "STFPM": 0.0
                 }
             },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.12,
                     "STFPM": 0.0
                 },
                 "cable": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.104,
                     "STFPM": 0.0
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.108,
+                    "STFPM": 0.015
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.241,
+                    "STFPM": 0.113
                 },
                 "grid": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.009,
                     "STFPM": 0.0
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.106,
                     "STFPM": 0.0
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.145,
+                    "STFPM": 0.092
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.18,
+                    "STFPM": 0.043
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.023,
+                    "STFPM": 0.058
                 },
                 "screw": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.019,
                     "STFPM": 0.0
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.038,
+                    "STFPM": 0.014
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
+                    "PADIM": 0.178,
                     "STFPM": 0.0
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.051,
+                    "STFPM": 0.048
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.18,
+                    "STFPM": 0.137
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.078,
+                    "STFPM": 0.183
                 }
             }
         },
         "anomaly_segmentation": {
             "deploy": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.573,
+                    "STFPM": 0.26
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.126,
+                    "STFPM": 0.094
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.31,
+                    "STFPM": 0.077
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.328,
+                    "STFPM": 0.262
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.014,
+                    "STFPM": 0.019
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.371,
+                    "STFPM": 0.077
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.308,
+                    "STFPM": 0.158
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.358,
+                    "STFPM": 0.386
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.223,
+                    "STFPM": 0.154
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.033,
+                    "STFPM": 0.036
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.181,
+                    "STFPM": 0.393
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.147,
+                    "STFPM": 0.088
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.285,
+                    "STFPM": 0.15
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.349,
+                    "STFPM": 0.559
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.165,
+                    "STFPM": 0.118
                 }
             },
             "export": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.573,
+                    "STFPM": 0.26
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.126,
+                    "STFPM": 0.094
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.31,
+                    "STFPM": 0.077
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.328,
+                    "STFPM": 0.262
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.014,
+                    "STFPM": 0.019
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.371,
+                    "STFPM": 0.077
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.308,
+                    "STFPM": 0.158
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.358,
+                    "STFPM": 0.386
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.223,
+                    "STFPM": 0.154
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.033,
+                    "STFPM": 0.036
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.181,
+                    "STFPM": 0.393
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.147,
+                    "STFPM": 0.088
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.285,
+                    "STFPM": 0.15
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.349,
+                    "STFPM": 0.559
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.165,
+                    "STFPM": 0.118
                 }
             },
             "nncf": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.616,
+                    "STFPM": 0.309
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.264,
+                    "STFPM": 0.215
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.317,
+                    "STFPM": 0.14
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.344,
+                    "STFPM": 0.463
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.015,
+                    "STFPM": 0.091
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.513,
+                    "STFPM": 0.292
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.394,
+                    "STFPM": 0.395
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.41,
+                    "STFPM": 0.358
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.281,
+                    "STFPM": 0.228
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.051,
+                    "STFPM": 0.085
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.181,
+                    "STFPM": 0.467
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.464,
+                    "STFPM": 0.282
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.351,
+                    "STFPM": 0.187
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.355,
+                    "STFPM": 0.517
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.273,
+                    "STFPM": 0.289
                 }
             },
             "pot": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.555,
+                    "STFPM": 0.253
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.141,
+                    "STFPM": 0.096
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.296,
+                    "STFPM": 0.072
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.307,
+                    "STFPM": 0.247
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.014,
+                    "STFPM": 0.02
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.383,
+                    "STFPM": 0.073
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.347,
+                    "STFPM": 0.141
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.353,
+                    "STFPM": 0.387
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.241,
+                    "STFPM": 0.135
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.037,
+                    "STFPM": 0.036
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.184,
+                    "STFPM": 0.382
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.198,
+                    "STFPM": 0.084
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.34,
+                    "STFPM": 0.148
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.349,
+                    "STFPM": 0.556
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.141,
+                    "STFPM": 0.128
                 }
             },
             "train": {
                 "bottle": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.598,
+                    "STFPM": 0.323
                 },
                 "cable": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.228,
+                    "STFPM": 0.15
                 },
                 "capsule": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.294,
+                    "STFPM": 0.121
                 },
                 "carpet": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.367,
+                    "STFPM": 0.455
                 },
                 "grid": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.014,
+                    "STFPM": 0.068
                 },
                 "hazelnut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.452,
+                    "STFPM": 0.098
                 },
                 "leather": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.379,
+                    "STFPM": 0.307
                 },
                 "metal_nut": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.454,
+                    "STFPM": 0.367
                 },
                 "pill": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.255,
+                    "STFPM": 0.203
                 },
                 "screw": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.06,
+                    "STFPM": 0.038
                 },
                 "tile": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.232,
+                    "STFPM": 0.449
                 },
                 "toothbrush": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.478,
+                    "STFPM": 0.246
                 },
                 "transistor": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.417,
+                    "STFPM": 0.179
                 },
                 "wood": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.35,
+                    "STFPM": 0.561
                 },
                 "zipper": {
-                    "PADIM": 0.0,
-                    "STFPM": 0.0
+                    "PADIM": 0.328,
+                    "STFPM": 0.259
                 }
             }
         },
         "classification": {
             "class_incr": {
                 "h_label": {
                     "train": {
                         "EfficientNet-B0": 0.0,
                         "EfficientNet-V2-S": 0.0,
                         "MobileNet-V3-large-1x": 0.0
                     }
                 },
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.81,
+                        "EfficientNet-V2-S": 0.79,
+                        "MobileNet-V3-large-1x": 0.76
                     }
                 },
                 "multi_label": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.964,
+                        "EfficientNet-V2-S": 0.97,
+                        "MobileNet-V3-large-1x": 0.97
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.794,
+                        "EfficientNet-V2-S": 0.767,
+                        "MobileNet-V3-large-1x": 0.744
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.797,
+                        "EfficientNet-V2-S": 0.822,
+                        "MobileNet-V3-large-1x": 0.764
                     }
                 }
             },
             "supervised": {
                 "h_label": {
                     "deploy": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.742,
+                        "EfficientNet-V2-S": 0.714,
+                        "MobileNet-V3-large-1x": 0.647
                     },
                     "export": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.742,
+                        "EfficientNet-V2-S": 0.714,
+                        "MobileNet-V3-large-1x": 0.647
                     },
                     "nncf": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.758,
+                        "EfficientNet-V2-S": 0.731,
+                        "MobileNet-V3-large-1x": 0.622
                     },
                     "pot": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.739,
+                        "EfficientNet-V2-S": 0.653,
+                        "MobileNet-V3-large-1x": 0.633
                     },
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.742,
+                        "EfficientNet-V2-S": 0.714,
+                        "MobileNet-V3-large-1x": 0.647
                     }
                 },
                 "multi_class": {
                     "deploy": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.806,
+                        "EfficientNet-V2-S": 0.772,
+                        "MobileNet-V3-large-1x": 0.728
                     },
                     "export": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.806,
+                        "EfficientNet-V2-S": 0.772,
+                        "MobileNet-V3-large-1x": 0.728
                     },
                     "nncf": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.742,
+                        "EfficientNet-V2-S": 0.764,
+                        "MobileNet-V3-large-1x": 0.733
                     },
                     "pot": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.808,
+                        "EfficientNet-V2-S": 0.711,
+                        "MobileNet-V3-large-1x": 0.692
                     },
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.806,
+                        "EfficientNet-V2-S": 0.772,
+                        "MobileNet-V3-large-1x": 0.728
                     }
                 },
                 "multi_label": {
                     "deploy": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.965,
+                        "EfficientNet-V2-S": 0.968,
+                        "MobileNet-V3-large-1x": 0.965
                     },
                     "export": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.965,
+                        "EfficientNet-V2-S": 0.968,
+                        "MobileNet-V3-large-1x": 0.965
                     },
                     "nncf": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.965,
+                        "EfficientNet-V2-S": 0.967,
+                        "MobileNet-V3-large-1x": 0.965
                     },
                     "pot": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.964,
+                        "EfficientNet-V2-S": 0.968,
+                        "MobileNet-V3-large-1x": 0.965
                     },
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.965,
+                        "EfficientNet-V2-S": 0.968,
+                        "MobileNet-V3-large-1x": 0.966
                     }
                 },
                 "supcon": {
                     "train": {
-                        "EfficientNet-B0": 0.0,
-                        "EfficientNet-V2-S": 0.0,
-                        "MobileNet-V3-large-1x": 0.0
+                        "EfficientNet-B0": 0.772,
+                        "EfficientNet-V2-S": 0.783,
+                        "MobileNet-V3-large-1x": 0.728
                     }
                 }
             }
         },
         "detection": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.443,
+                        "SSD": 0.2,
+                        "YOLOX": 0.532
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.414,
+                        "SSD": 0.142,
+                        "YOLOX": 0.398
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "deploy": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.455,
+                        "SSD": 0.179,
+                        "YOLOX": 0.534
                     },
                     "export": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.455,
+                        "SSD": 0.179,
+                        "YOLOX": 0.534
                     },
                     "nncf": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.446,
+                        "SSD": 0.181,
+                        "YOLOX": 0.517
                     },
                     "pot": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.458,
+                        "SSD": 0.18,
+                        "YOLOX": 0.531
                     },
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.446,
+                        "SSD": 0.179,
+                        "YOLOX": 0.537
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "deploy": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.469,
+                        "SSD": 0.19,
+                        "YOLOX": 0.549
                     },
                     "export": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.469,
+                        "SSD": 0.19,
+                        "YOLOX": 0.549
                     },
                     "nncf": {
                         "ATSS": 0.0,
                         "SSD": 0.0,
                         "YOLOX": 0.0
                     },
                     "pot": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.459,
+                        "SSD": 0.192,
+                        "YOLOX": 0.531
                     },
                     "train": {
-                        "ATSS": 0.0,
-                        "SSD": 0.0,
-                        "YOLOX": 0.0
+                        "ATSS": 0.459,
+                        "SSD": 0.19,
+                        "YOLOX": 0.545
                     }
                 }
             }
         },
         "instance_segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 0.307,
+                        "MaskRCNN-ResNet50": 0.481
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "deploy": {
                         "MaskRCNN-EfficientNetB2B": 0.0,
                         "MaskRCNN-ResNet50": 0.0
                     },
                     "export": {
                         "MaskRCNN-EfficientNetB2B": 0.0,
                         "MaskRCNN-ResNet50": 0.0
                     },
                     "nncf": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 0.286,
+                        "MaskRCNN-ResNet50": 0.437
                     },
                     "pot": {
                         "MaskRCNN-EfficientNetB2B": 0.0,
                         "MaskRCNN-ResNet50": 0.0
                     },
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 0.27,
+                        "MaskRCNN-ResNet50": 0.466
                     }
                 }
             },
             "tiling": {
                 "multi_class": {
                     "deploy": {
                         "MaskRCNN-EfficientNetB2B": 0.0,
@@ -2926,81 +2187,81 @@
                         "MaskRCNN-ResNet50": 0.0
                     },
                     "pot": {
                         "MaskRCNN-EfficientNetB2B": 0.0,
                         "MaskRCNN-ResNet50": 0.0
                     },
                     "train": {
-                        "MaskRCNN-EfficientNetB2B": 0.0,
-                        "MaskRCNN-ResNet50": 0.0
+                        "MaskRCNN-EfficientNetB2B": 0.304,
+                        "MaskRCNN-ResNet50": 0.471
                     }
                 }
             }
         },
         "segmentation": {
             "class_incr": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.795,
+                        "Lite-HRNet-18-mod2": 0.768,
+                        "Lite-HRNet-s-mod2": 0.792,
+                        "Lite-HRNet-x-mod3": 0.805
                     }
                 }
             },
             "self_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.782,
+                        "Lite-HRNet-18-mod2": 0.798,
+                        "Lite-HRNet-s-mod2": 0.785,
+                        "Lite-HRNet-x-mod3": 0.785
                     }
                 }
             },
             "semi_supervised": {
                 "multi_class": {
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.833,
+                        "Lite-HRNet-18-mod2": 0.837,
+                        "Lite-HRNet-s-mod2": 0.818,
+                        "Lite-HRNet-x-mod3": 0.802
                     }
                 }
             },
             "supervised": {
                 "multi_class": {
                     "deploy": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.8,
+                        "Lite-HRNet-18-mod2": 0.808,
+                        "Lite-HRNet-s-mod2": 0.786,
+                        "Lite-HRNet-x-mod3": 0.795
                     },
                     "export": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.8,
+                        "Lite-HRNet-18-mod2": 0.808,
+                        "Lite-HRNet-s-mod2": 0.786,
+                        "Lite-HRNet-x-mod3": 0.795
                     },
                     "nncf": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.79,
+                        "Lite-HRNet-18-mod2": 0.8,
+                        "Lite-HRNet-s-mod2": 0.787,
+                        "Lite-HRNet-x-mod3": 0.779
                     },
                     "pot": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.302,
+                        "Lite-HRNet-18-mod2": 0.087,
+                        "Lite-HRNet-s-mod2": 0.725,
+                        "Lite-HRNet-x-mod3": 0.041
                     },
                     "train": {
-                        "Lite-HRNet-18": 0.0,
-                        "Lite-HRNet-18-mod2": 0.0,
-                        "Lite-HRNet-s-mod2": 0.0,
-                        "Lite-HRNet-x-mod3": 0.0
+                        "Lite-HRNet-18": 0.801,
+                        "Lite-HRNet-18-mod2": 0.808,
+                        "Lite-HRNet-s-mod2": 0.787,
+                        "Lite-HRNet-x-mod3": 0.795
                     }
                 }
             }
         }
     }
 }
```

### Comparing `otx-1.1.2rc1/tests/regression/regression_test_helpers.py` & `otx-1.2.0rc1/tests/regression/regression_test_helpers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/regression/segmentation/test_segmentation.py` & `otx-1.2.0rc1/tests/regression/semantic_segmentation/test_segmentation.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,28 +17,31 @@
     get_result_dict,
     get_template_performance,
     load_regression_configuration,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_component
 from tests.test_suite.run_test_command import (
     get_template_dir,
-    nncf_eval_testing,
     nncf_optimize_testing,
     otx_deploy_openvino_testing,
-    otx_eval_compare,
-    otx_eval_deployment_testing,
-    otx_eval_e2e_eval_time,
-    otx_eval_e2e_train_time,
-    otx_eval_openvino_testing,
     otx_export_testing,
     otx_train_testing,
-    pot_eval_testing,
     pot_optimize_testing,
 )
 
+from tests.regression.regression_command import (
+    regression_eval_testing,
+    regression_openvino_testing,
+    regression_deployment_testing,
+    regression_nncf_eval_testing,
+    regression_pot_eval_testing,
+    regression_train_time_testing,
+    regression_eval_time_testing,
+)
+
 # Configurations for regression test.
 TASK_TYPE = "segmentation"
 TRAIN_TYPE = "supervised"
 LABEL_TYPE = "multi_class"
 
 otx_dir = os.getcwd()
 templates = Registry(f"otx/algorithms/{TASK_TYPE}").filter(task_type=TASK_TYPE.upper()).templates
@@ -69,97 +72,109 @@
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, segmentation_data_args)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             segmentation_data_args,
             segmentation_regression_config["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE][TRAIN_TYPE]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_kpi_test(self, template):
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=segmentation_regression_config["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=segmentation_regression_config["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         sl_template_work_dir = get_template_dir(template, tmp_dir_path / TASK_TYPE)
 
         tmp_dir_path = tmp_dir_path / "seg_incr"
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         args_cls_incr = config_cls_incr["data_path"]
-        args_cls_incr["--load-weights"] = f"{sl_template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_cls_incr[
+            "--load-weights"
+        ] = f"{sl_template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         args_cls_incr["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
 
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_cls_incr)
         train_elapsed_time = timer() - train_start_time
 
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_cls_incr,
             config_cls_incr["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["class_incr"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_cls_incr_kpi_test(self, template):
         config_cls_incr = load_regression_configuration(otx_dir, TASK_TYPE, "class_incr", self.label_type)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_cls_incr["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_cls_incr["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / f"{TASK_TYPE}/test_semisl"
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", LABEL_TYPE)
@@ -174,47 +189,52 @@
         ]
         train_start_time = timer()
         otx_train_testing(template, tmp_dir_path, otx_dir, args_semisl)
         train_elapsed_time = timer() - train_start_time
 
         args_semisl.pop("train_params")
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             args_semisl,
             config_semisl["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][LABEL_TYPE]["semi_supervised"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_semisl_kpi_test(self, template):
         config_semisl = load_regression_configuration(otx_dir, TASK_TYPE, "semi_supervised", LABEL_TYPE)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_semisl["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_semisl["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_selfsl(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / f"{TASK_TYPE}/test_selfsl"
         config_selfsl = load_regression_configuration(otx_dir, TASK_TYPE, "self_supervised", LABEL_TYPE)
@@ -230,155 +250,168 @@
 
         # Supervised Training
         template_work_dir = get_template_dir(template, tmp_dir_path)
         new_tmp_dir_path = tmp_dir_path / "test_supervised"
         args_selfsl["train_params"] = ["params", "--learning_parameters.num_iters", REGRESSION_TEST_EPOCHS]
         args_selfsl["--val-data-roots"] = segmentation_data_args["--val-data-roots"]
         args_selfsl["--test-data-roots"] = segmentation_data_args["--test-data-roots"]
-        args_selfsl["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/weights.pth"
+        args_selfsl["--load-weights"] = f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth"
         otx_train_testing(template, new_tmp_dir_path, otx_dir, args_selfsl)
 
         # Evaluation with self + supervised training model
         args_selfsl.pop("--load-weights")
         infer_start_time = timer()
-        otx_eval_compare(
+        test_result = regression_eval_testing(
             template,
             new_tmp_dir_path,
             otx_dir,
             args_selfsl,
             config_selfsl["regression_criteria"]["train"],
             self.performance[template.name],
         )
         infer_elapsed_time = timer() - infer_start_time
 
         self.performance[template.name][TIME_LOG["train_time"]] = round(train_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["infer_time"]] = round(infer_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type]["self_supervised"]["train"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_train_selfsl_kpi_test(self, template):
         config_selfsl = load_regression_configuration(otx_dir, TASK_TYPE, "self_supervised", LABEL_TYPE)
         results = result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["train"]
         performance = get_template_performance(results, template)
 
-        otx_eval_e2e_train_time(
+        kpi_train_result = regression_train_time_testing(
             train_time_criteria=config_selfsl["kpi_e2e_train_time_criteria"]["train"],
             e2e_train_time=performance[template.name][TIME_LOG["train_time"]],
             template=template,
         )
 
-        otx_eval_e2e_eval_time(
+        kpi_eval_result = regression_eval_time_testing(
             eval_time_criteria=config_selfsl["kpi_e2e_eval_time_criteria"]["train"],
             e2e_eval_time=performance[template.name][TIME_LOG["infer_time"]],
             template=template,
         )
 
+        assert kpi_train_result["passed"] is True, kpi_train_result["log"]
+        assert kpi_eval_result["passed"] is True, kpi_eval_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_export_eval_openvino(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         export_start_time = timer()
         otx_export_testing(template, tmp_dir_path)
         export_elapsed_time = timer() - export_start_time
 
         export_eval_start_time = timer()
-        otx_eval_openvino_testing(
+        test_result = regression_openvino_testing(
             template,
             tmp_dir_path,
             otx_dir,
             segmentation_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=segmentation_regression_config["regression_criteria"]["export"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         export_eval_elapsed_time = timer() - export_eval_start_time
 
         self.performance[template.name][TIME_LOG["export_time"]] = round(export_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["export_eval_time"]] = round(export_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["export"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_otx_deploy_eval_deployment(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         deploy_start_time = timer()
         otx_deploy_openvino_testing(template, tmp_dir_path, otx_dir, segmentation_data_args)
         deploy_elapsed_time = timer() - deploy_start_time
 
         deploy_eval_start_time = timer()
-        otx_eval_deployment_testing(
+        test_result = regression_deployment_testing(
             template,
             tmp_dir_path,
             otx_dir,
             segmentation_data_args,
-            threshold=1.0,
+            threshold=0.02,
             criteria=segmentation_regression_config["regression_criteria"]["deploy"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         deploy_eval_elapsed_time = timer() - deploy_eval_start_time
 
         self.performance[template.name][TIME_LOG["deploy_time"]] = round(deploy_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["deploy_eval_time"]] = round(deploy_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["deploy"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_nncf_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         if template.entrypoints.nncf is None:
             pytest.skip("nncf entrypoint is none")
 
         nncf_start_time = timer()
         nncf_optimize_testing(template, tmp_dir_path, otx_dir, segmentation_data_args)
         nncf_elapsed_time = timer() - nncf_start_time
 
         nncf_eval_start_time = timer()
-        nncf_eval_testing(
+        test_result = regression_nncf_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             segmentation_data_args,
-            threshold=1.0,
+            threshold=0.001,
             criteria=segmentation_regression_config["regression_criteria"]["nncf"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         nncf_eval_elapsed_time = timer() - nncf_eval_start_time
 
         self.performance[template.name][TIME_LOG["nncf_time"]] = round(nncf_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["nncf_eval_time"]] = round(nncf_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["nncf"].append(self.performance)
 
+        assert test_result["passed"] is True, test_result["log"]
+
     @e2e_pytest_component
     @pytest.mark.parametrize("template", templates, ids=templates_ids)
     def test_pot_optimize_eval(self, template, tmp_dir_path):
         self.performance[template.name] = {}
 
         tmp_dir_path = tmp_dir_path / TASK_TYPE
         pot_start_time = timer()
         pot_optimize_testing(template, tmp_dir_path, otx_dir, segmentation_data_args)
         pot_elapsed_time = timer() - pot_start_time
 
         pot_eval_start_time = timer()
-        pot_eval_testing(
+        test_result = regression_pot_eval_testing(
             template,
             tmp_dir_path,
             otx_dir,
             segmentation_data_args,
             criteria=segmentation_regression_config["regression_criteria"]["pot"],
             reg_threshold=0.10,
             result_dict=self.performance[template.name],
         )
         pot_eval_elapsed_time = timer() - pot_eval_start_time
 
         self.performance[template.name][TIME_LOG["pot_time"]] = round(pot_elapsed_time, 3)
         self.performance[template.name][TIME_LOG["pot_eval_time"]] = round(pot_eval_elapsed_time, 3)
         result_dict[TASK_TYPE][self.label_type][TRAIN_TYPE]["pot"].append(self.performance)
+
+        assert test_result["passed"] is True, test_result["log"]
```

### Comparing `otx-1.1.2rc1/tests/regression/summarize_test_results.py` & `otx-1.2.0rc1/tests/regression/summarize_test_results.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/run_code_checks.sh` & `otx-1.2.0rc1/tests/run_code_checks.sh`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/run_model_templates_tests.py` & `otx-1.2.0rc1/tests/run_model_templates_tests.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_helpers.py` & `otx-1.2.0rc1/tests/test_helpers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/ARCHITECTURE.md` & `otx-1.2.0rc1/tests/test_suite/ARCHITECTURE.md`

 * *Files 0% similar despite different names*

```diff
@@ -1343,17 +1343,17 @@
              test_parameters,
              test_case_fx, data_collector_fx,
              cur_test_expected_metrics_callback_fx):
         test_case_fx.run_stage(test_parameters['test_stage'], data_collector_fx,
                                cur_test_expected_metrics_callback_fx)
   ```
 
-## VIII. Connecting algo backend with test suite. Pytest magic and fixtures.
+## VIII. Connecting algo backend with test suite. Pytest magic and fixtures
 
-## VIII.1. Connecting algo backend with test suite. Pytest magic.
+## VIII.1. Connecting algo backend with test suite. Pytest magic
 
 As stated above in the previous section the direct connection between the training test in an algo
 backend and the test suite is made, particularly, by
 
 > - Algo backend implementation of some fixtures required for test suite
 >   -- see about that in the next section TODO
 > - Insertions that is made in the special algo backend file `tests/conftest.py` that is loaded by
@@ -1407,15 +1407,15 @@
   ```
 - parametrize the current test method by the call
   ```python
     metafunc.parametrize(argnames, argvalues, ids=ids, scope="class")
   ```
   Note that the scope "class" is used, it is required.
 
-## VIII.2. Connecting algo backend with test suite. Pytest fixtures and others.
+## VIII.2. Connecting algo backend with test suite. Pytest fixtures and others
 
 To connect an algo backend with the test suite the following fixtures should be implemented
 in the file `tests/conftest.py` of the algo backend.
 
 - the fixture `otx_test_domain_fx` -- it should return the string name of the
   current algo backend domain
 - the fixture `otx_test_scenario_fx` -- it should return the string on the
```

### Comparing `otx-1.1.2rc1/tests/test_suite/QUICK_HOWTO.md` & `otx-1.2.0rc1/tests/test_suite/QUICK_HOWTO.md`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/e2e_test_system.py` & `otx-1.2.0rc1/tests/test_suite/e2e_test_system.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/fixtures.py` & `otx-1.2.0rc1/tests/test_suite/fixtures.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/logging.py` & `otx-1.2.0rc1/tests/test_suite/logging.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/pytest_insertions.py` & `otx-1.2.0rc1/tests/test_suite/pytest_insertions.py`

 * *Files 1% similar despite different names*

```diff
@@ -79,15 +79,15 @@
         "--template-paths",
         action="store",
         default=None,
         help="Obsolete parameter. Should be removed when CI is changed.",
     )
 
     parser.addoption(
-        "--test-work-dir",
+        "--test-workspace",
         type=str,
         default=None,
         help="OTX test requires a certain amount of storage in the test work directory. "
         "If you don't have enough space on the drive where the default path is located (e.g. /tmp on linux), "
         "you can use this option to change the test work directory path to a different drive.",
     )
```

### Comparing `otx-1.1.2rc1/tests/test_suite/run_test_command.py` & `otx-1.2.0rc1/tests/test_suite/run_test_command.py`

 * *Files 6% similar despite different names*

```diff
@@ -126,27 +126,27 @@
         "--val-data-roots",
         "--unlabeled-data-roots",
         "--unlabeled-file-list",
     ]:
         arg_value = args.get(arg, None)
         if arg_value:
             command_line.extend([arg, os.path.join(otx_dir, arg_value)])
-    command_line.extend(["--save-model-to", f"{template_work_dir}/trained_{template.model_template_id}"])
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--output", f"{template_work_dir}/trained_{template.model_template_id}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     if "--load-weights" in args:
         command_line.extend(["--load-weights", args["--load-weights"]])
     if "--gpus" in args:
         command_line.extend(["--gpus", args["--gpus"]])
         if "--multi-gpu-port" in args:
             command_line.extend(["--multi-gpu-port", args["--multi-gpu-port"]])
     if "train_params" in args:
         command_line.extend(args["train_params"])
     check_run(command_line)
-    assert os.path.exists(f"{template_work_dir}/trained_{template.model_template_id}/weights.pth")
-    assert os.path.exists(f"{template_work_dir}/trained_{template.model_template_id}/label_schema.json")
+    assert os.path.exists(f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth")
+    assert os.path.exists(f"{template_work_dir}/trained_{template.model_template_id}/models/label_schema.json")
 
 
 def otx_resume_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "train",
@@ -160,161 +160,169 @@
         "--unlabeled-data-roots",
         "--unlabeled-file-list",
         "--resume-from",
     ]:
         if option in args:
             command_line.extend([option, f"{os.path.join(otx_dir, args[option])}"])
 
-    command_line.extend(["--save-model-to", f"{template_work_dir}/trained_for_resume_{template.model_template_id}"])
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--output", f"{template_work_dir}/trained_for_resume_{template.model_template_id}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     command_line.extend(args["train_params"])
     check_run(command_line)
-    assert os.path.exists(f"{template_work_dir}/trained_for_resume_{template.model_template_id}/weights.pth")
-    assert os.path.exists(f"{template_work_dir}/trained_for_resume_{template.model_template_id}/label_schema.json")
+    assert os.path.exists(f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/weights.pth")
+    assert os.path.exists(
+        f"{template_work_dir}/trained_for_resume_{template.model_template_id}/models/label_schema.json"
+    )
 
 
 def otx_hpo_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     if os.path.exists(f"{template_work_dir}/hpo"):
         shutil.rmtree(f"{template_work_dir}/hpo")
 
     command_line = ["otx", "train", template.model_template_path]
 
     for arg in ["--train-data-roots", "--val-data-roots"]:
         arg_value = args.get(arg, None)
         if arg_value:
             command_line.extend([arg, os.path.join(otx_dir, arg_value)])
-    command_line.extend(["--save-model-to", f"{template_work_dir}/hpo_trained_{template.model_template_id}"])
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--output", f"{template_work_dir}/hpo_trained_{template.model_template_id}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     command_line.extend(["--enable-hpo", "--hpo-time-ratio", "1"])
 
     command_line.extend(args["train_params"])
     check_run(command_line)
     trials_json = list(
-        filter(lambda x: x.name.split(".")[0].isnumeric(), Path(f"{template_work_dir}/hpo/").rglob("*.json"))
+        filter(
+            lambda x: x.name.split(".")[0].isnumeric(),
+            Path(f"{template_work_dir}/hpo_trained_{template.model_template_id}/hpo/").rglob("*.json"),
+        )
     )
     assert trials_json
     for trial_json in trials_json:
         with trial_json.open("r") as f:
             trial_result = json.load(f)
         assert trial_result.get("score")
 
-    assert os.path.exists(f"{template_work_dir}/hpo_trained_{template.model_template_id}/weights.pth")
-    assert os.path.exists(f"{template_work_dir}/hpo_trained_{template.model_template_id}/label_schema.json")
+    assert os.path.exists(f"{template_work_dir}/hpo_trained_{template.model_template_id}/models/weights.pth")
+    assert os.path.exists(f"{template_work_dir}/hpo_trained_{template.model_template_id}/models/label_schema.json")
 
 
-def otx_export_testing(template, root):
+def otx_export_testing(template, root, dump_features=False, half_precision=False):
     template_work_dir = get_template_dir(template, root)
+    save_path = f"{template_work_dir}/exported_{template.model_template_id}"
     command_line = [
         "otx",
         "export",
         template.model_template_path,
         "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
-        "--save-model-to",
-        f"{template_work_dir}/exported_{template.model_template_id}",
-    ]
-    check_run(command_line)
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}/openvino.xml")
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}/openvino.bin")
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}/label_schema.json")
-
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
+        "--output",
+        save_path,
+    ]
+
+    if dump_features:
+        command_line[-1] += "_w_features"
+        save_path = command_line[-1]
+        command_line.append("--dump-features")
+    if half_precision:
+        command_line[-1] += "_fp16"
+        save_path = command_line[-1]
+        command_line.append("--half-precision")
 
-def otx_export_testing_w_features(template, root):
-    template_work_dir = get_template_dir(template, root)
-    command_line = [
-        "otx",
-        "export",
-        template.model_template_path,
-        "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
-        "--save-model-to",
-        f"{template_work_dir}/exported_{template.model_template_id}_w_features",
-        "--dump-features",
-    ]
     check_run(command_line)
-
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.bin")
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}_w_features/label_schema.json")
-
-    path_to_xml = f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml"
+    path_to_xml = os.path.join(save_path, "openvino.xml")
     assert os.path.exists(path_to_xml)
-    with open(path_to_xml, encoding="utf-8") as stream:
-        xml_model = stream.read()
-    assert "feature_vector" in xml_model
+    assert os.path.exists(os.path.join(save_path, "openvino.bin"))
+    assert os.path.exists(os.path.join(save_path, "model.onnx"))
+    assert os.path.exists(os.path.join(save_path, "label_schema.json"))
+
+    if dump_features:
+        with open(path_to_xml, encoding="utf-8") as stream:
+            xml_model = stream.read()
+            assert "feature_vector" in xml_model
+
+    if half_precision:
+        with open(path_to_xml, encoding="utf-8") as stream:
+            xml_model = stream.read()
+            assert "FP16" in xml_model
 
 
 def otx_eval_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
 
     command_line = [
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
-        "--save-performance",
-        f"{template_work_dir}/trained_{template.model_template_id}/performance.json",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
+        "--output",
+        f"{template_work_dir}/trained_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     command_line.extend(args.get("eval_params", []))
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/trained_{template.model_template_id}/performance.json")
 
 
 def otx_eval_openvino_testing(
-    template, root, otx_dir, args, threshold=0.0, criteria=None, reg_threshold=0.10, result_dict=None
+    template,
+    root,
+    otx_dir,
+    args,
+    threshold=0.0,
+    half_precision=False,
 ):
     template_work_dir = get_template_dir(template, root)
+    weights_path = f"{template_work_dir}/exported_{template.model_template_id}/openvino.xml"
+    output_path = f"{template_work_dir}/exported_{template.model_template_id}"
+    perf_path = f"{template_work_dir}/exported_{template.model_template_id}/performance.json"
+
+    if half_precision:
+        weights_path = f"{template_work_dir}/exported_{template.model_template_id}_fp16/openvino.xml"
+        output_path = f"{template_work_dir}/exported_{template.model_template_id}_fp16"
+        perf_path = f"{template_work_dir}/exported_{template.model_template_id}_fp16/performance.json"
+
     command_line = [
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
-        f"{template_work_dir}/exported_{template.model_template_id}/openvino.xml",
-        "--save-performance",
-        f"{template_work_dir}/exported_{template.model_template_id}/performance.json",
+        weights_path,
+        "--output",
+        output_path,
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
-    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}/performance.json")
+    assert os.path.exists(perf_path)
     with open(f"{template_work_dir}/trained_{template.model_template_id}/performance.json") as read_file:
         trained_performance = json.load(read_file)
-    with open(f"{template_work_dir}/exported_{template.model_template_id}/performance.json") as read_file:
+    with open(perf_path) as read_file:
         exported_performance = json.load(read_file)
 
-    if isinstance(criteria, dict) and template.name in criteria.keys():
-        model_criteria = criteria[template.name]
-        modified_criteria = model_criteria - (model_criteria * reg_threshold)
-
     for k in trained_performance.keys():
-        if isinstance(criteria, dict) and template.name in criteria.keys():
-            result_dict[k] = round(exported_performance[k], 3)
-            assert (
-                exported_performance[k] >= modified_criteria
-            ), f"Current exported model performance: ({exported_performance[k]}) < criteria: ({modified_criteria})."
-
         assert (
             exported_performance[k] >= trained_performance[k]
             or abs(trained_performance[k] - exported_performance[k]) / (trained_performance[k] + 1e-10) <= threshold
         ), f"{trained_performance[k]=}, {exported_performance[k]=}"
 
 
 def otx_demo_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "demo",
         template.model_template_path,
         "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
         "--input",
         os.path.join(otx_dir, args["--input"]),
         "--delay",
         "-1",
     ]
     check_run(command_line)
 
@@ -340,15 +348,15 @@
     deployment_dir = f"{template_work_dir}/deployed_{template.model_template_id}"
     command_line = [
         "otx",
         "deploy",
         template.model_template_path,
         "--load-weights",
         f"{template_work_dir}/exported_{template.model_template_id}/openvino.xml",
-        "--save-model-to",
+        "--output",
         deployment_dir,
     ]
     check_run(command_line)
     check_run(["unzip", "-o", "openvino.zip"], cwd=deployment_dir)
     # TODO: Need to check Requirements.txt & new environment is working
     # check_run(
     #     ["python3", "-m", "venv", "venv"],
@@ -387,47 +395,36 @@
             os.path.join(otx_dir, args["--input"]),
             "--no_show",
         ],
         cwd=os.path.join(deployment_dir, "python"),
     )
 
 
-def otx_eval_deployment_testing(
-    template, root, otx_dir, args, threshold=0.0, criteria=None, reg_threshold=0.10, result_dict=None
-):
+def otx_eval_deployment_testing(template, root, otx_dir, args, threshold=0.0):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
         f"{template_work_dir}/deployed_{template.model_template_id}/openvino.zip",
-        "--save-performance",
-        f"{template_work_dir}/deployed_{template.model_template_id}/performance.json",
+        "--output",
+        f"{template_work_dir}/deployed_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/deployed_{template.model_template_id}/performance.json")
     with open(f"{template_work_dir}/exported_{template.model_template_id}/performance.json") as read_file:
         exported_performance = json.load(read_file)
     with open(f"{template_work_dir}/deployed_{template.model_template_id}/performance.json") as read_file:
         deployed_performance = json.load(read_file)
 
-    if isinstance(criteria, dict) and template.name in criteria.keys():
-        model_criteria = criteria[template.name]
-        modified_criteria = model_criteria - (model_criteria * reg_threshold)
-
     for k in exported_performance.keys():
-        if isinstance(criteria, dict) and template.name in criteria.keys():
-            result_dict[k] = round(deployed_performance[k], 3)
-            assert (
-                exported_performance[k] >= modified_criteria
-            ), f"Current deployed model performance: ({deployed_performance[k]}) < criteria: ({modified_criteria})."
         assert (
             deployed_performance[k] >= exported_performance[k]
             or abs(exported_performance[k] - deployed_performance[k]) / (exported_performance[k] + 1e-10) <= threshold
         ), f"{exported_performance[k]=}, {deployed_performance[k]=}"
 
 
 def otx_demo_deployment_testing(template, root, otx_dir, args):
@@ -454,18 +451,18 @@
         template.model_template_path,
         "--train-data-roots",
         f'{os.path.join(otx_dir, args["--train-data-roots"])}',
         "--val-data-roots",
         f'{os.path.join(otx_dir, args["--val-data-roots"])}',
         "--load-weights",
         f"{template_work_dir}/exported_{template.model_template_id}/openvino.xml",
-        "--save-model-to",
+        "--output",
         f"{template_work_dir}/pot_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/pot_{template.model_template_id}/openvino.xml")
     assert os.path.exists(f"{template_work_dir}/pot_{template.model_template_id}/openvino.bin")
     assert os.path.exists(f"{template_work_dir}/pot_{template.model_template_id}/label_schema.json")
 
 
 def _validate_fq_in_xml(xml_path, path_to_ref_data, compression_type, test_name):
@@ -483,79 +480,66 @@
     xml_path = f"{template_work_dir}/pot_{template.model_template_id}/openvino.xml"
     path_to_ref_data = os.path.join(
         otx_dir, "tests", "e2e/cli", task_type, "reference", template.model_template_id, "compressed_model.yml"
     )
     _validate_fq_in_xml(xml_path, path_to_ref_data, "pot", test_name)
 
 
-def pot_eval_testing(template, root, otx_dir, args, criteria=None, reg_threshold=0.10, result_dict=None):
+def pot_eval_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
         f"{template_work_dir}/pot_{template.model_template_id}/openvino.xml",
-        "--save-performance",
-        f"{template_work_dir}/pot_{template.model_template_id}/performance.json",
+        "--output",
+        f"{template_work_dir}/pot_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/pot_{template.model_template_id}/performance.json")
 
     with open(f"{template_work_dir}/pot_{template.model_template_id}/performance.json") as read_file:
         pot_performance = json.load(read_file)
 
-    if isinstance(criteria, dict) and template.name in criteria.keys():
-        model_criteria = criteria[template.name]
-        modified_criteria = model_criteria - (model_criteria * reg_threshold)
-
-    for k in pot_performance.keys():
-        if isinstance(criteria, dict) and template.name in criteria.keys():
-            result_dict[k] = round(pot_performance[k], 3)
-            assert (
-                pot_performance[k] >= modified_criteria
-            ), f"Current POT model performance: ({pot_performance[k]}) < criteria: ({modified_criteria})."
-
 
 def nncf_optimize_testing(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "optimize",
         template.model_template_path,
         "--train-data-roots",
         f'{os.path.join(otx_dir, args["--train-data-roots"])}',
         "--val-data-roots",
         f'{os.path.join(otx_dir, args["--val-data-roots"])}',
         "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
-        "--save-model-to",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
+        "--output",
         f"{template_work_dir}/nncf_{template.model_template_id}",
-        "--save-performance",
-        f"{template_work_dir}/nncf_{template.model_template_id}/train_performance.json",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     command_line.extend(args["train_params"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/nncf_{template.model_template_id}/weights.pth")
     assert os.path.exists(f"{template_work_dir}/nncf_{template.model_template_id}/label_schema.json")
 
 
 def nncf_export_testing(template, root):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "export",
         template.model_template_path,
         "--load-weights",
         f"{template_work_dir}/nncf_{template.model_template_id}/weights.pth",
-        "--save-model-to",
+        "--output",
         f"{template_work_dir}/exported_nncf_{template.model_template_id}",
     ]
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/exported_nncf_{template.model_template_id}/openvino.xml")
     assert os.path.exists(f"{template_work_dir}/exported_nncf_{template.model_template_id}/openvino.bin")
     assert os.path.exists(f"{template_work_dir}/exported_nncf_{template.model_template_id}/label_schema.json")
     original_bin_size = os.path.getsize(f"{template_work_dir}/exported_{template.model_template_id}/openvino.bin")
@@ -571,47 +555,36 @@
     path_to_ref_data = os.path.join(
         otx_dir, "tests", "e2e/cli", task_type, "reference", template.model_template_id, "compressed_model.yml"
     )
 
     _validate_fq_in_xml(xml_path, path_to_ref_data, "nncf", test_name)
 
 
-def nncf_eval_testing(
-    template, root, otx_dir, args, threshold=0.001, criteria=None, reg_threshold=0.10, result_dict=None
-):
+def nncf_eval_testing(template, root, otx_dir, args, threshold=0.01):
     template_work_dir = get_template_dir(template, root)
     command_line = [
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
         f"{template_work_dir}/nncf_{template.model_template_id}/weights.pth",
-        "--save-performance",
-        f"{template_work_dir}/nncf_{template.model_template_id}/performance.json",
+        "--output",
+        f"{template_work_dir}/nncf_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/nncf_{template.model_template_id}/performance.json")
-    with open(f"{template_work_dir}/nncf_{template.model_template_id}/train_performance.json") as read_file:
+    with open(f"{template_work_dir}/nncf_{template.model_template_id}/nncf_performance.json") as read_file:
         trained_performance = json.load(read_file)
     with open(f"{template_work_dir}/nncf_{template.model_template_id}/performance.json") as read_file:
         evaluated_performance = json.load(read_file)
 
-    if isinstance(criteria, dict) and template.name in criteria.keys():
-        model_criteria = criteria[template.name]
-        modified_criteria = model_criteria - (model_criteria * reg_threshold)
-
     for k in trained_performance.keys():
-        if isinstance(criteria, dict) and template.name in criteria.keys():
-            result_dict[k] = round(evaluated_performance[k], 3)
-            assert (
-                evaluated_performance[k] >= modified_criteria
-            ), f"Current nncf model performance: ({evaluated_performance[k]}) < criteria: ({modified_criteria})."
         assert (
             evaluated_performance[k] >= trained_performance[k]
             or abs(trained_performance[k] - evaluated_performance[k]) / (trained_performance[k] + 1e-10) <= threshold
         ), f"{trained_performance[k]=}, {evaluated_performance[k]=}"
 
 
 def nncf_eval_openvino_testing(template, root, otx_dir, args):
@@ -620,18 +593,18 @@
         "otx",
         "eval",
         template.model_template_path,
         "--test-data-roots",
         f'{os.path.join(otx_dir, args["--test-data-roots"])}',
         "--load-weights",
         f"{template_work_dir}/exported_nncf_{template.model_template_id}/openvino.xml",
-        "--save-performance",
-        f"{template_work_dir}/exported_nncf_{template.model_template_id}/performance.json",
+        "--output",
+        f"{template_work_dir}/exported_nncf_{template.model_template_id}",
     ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
+    command_line.extend(["--workspace", f"{template_work_dir}"])
     check_run(command_line)
     assert os.path.exists(f"{template_work_dir}/exported_nncf_{template.model_template_id}/performance.json")
 
 
 def xfail_templates(templates, xfail_template_ids_reasons):
     xfailed_templates = []
     for template in templates:
@@ -645,15 +618,15 @@
         else:
             raise RuntimeError(
                 "More than one reason for template. If you have more than one Jira tickets, list them in one reason."
             )
     return xfailed_templates
 
 
-def otx_explain_testing(template, root, otx_dir, args):
+def otx_explain_testing(template, root, otx_dir, args, trained=False):
     template_work_dir = get_template_dir(template, root)
     if "RCNN" in template.model_template_id:
         test_algorithm = "ActivationMap"
     else:
         test_algorithm = "ClassWiseSaliencyMap"
 
     train_ann_file = args.get("--train-ann-file", "")
@@ -662,66 +635,240 @@
     elif "multilabel" in train_ann_file:
         train_type = "multilabel"
     else:
         train_type = "default"
 
     save_dir = f"explain_{template.model_template_id}/{test_algorithm}/{train_type}/"
     output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
     command_line = [
         "otx",
         "explain",
         template.model_template_path,
         "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
         "--explain-data-root",
-        os.path.join(otx_dir, args["--input"]),
+        explain_data_root,
         "--save-explanation-to",
         output_dir,
         "--explain-algorithm",
         test_algorithm,
     ]
     check_run(command_line)
     assert os.path.exists(output_dir)
-    assert len(os.listdir(output_dir)) > 0
+    if trained:
+        assert len(os.listdir(output_dir)) > 0
+        assert all([os.path.splitext(fname)[1] == ".tiff" for fname in os.listdir(output_dir)])
 
 
-def otx_explain_openvino_testing(template, root, otx_dir, args):
+def otx_explain_testing_all_classes(template, root, otx_dir, args):
     template_work_dir = get_template_dir(template, root)
     if "RCNN" in template.model_template_id:
         test_algorithm = "ActivationMap"
     else:
         test_algorithm = "ClassWiseSaliencyMap"
 
     train_ann_file = args.get("--train-ann-file", "")
     if "hierarchical" in train_ann_file:
         train_type = "hierarchical"
     elif "multilabel" in train_ann_file:
         train_type = "multilabel"
     else:
         train_type = "default"
 
-    save_dir = f"explain_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    save_dir = f"explain_all_classes_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
+    command_line = [
+        "otx",
+        "explain",
+        template.model_template_path,
+        "--load-weights",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
+        "--explain-data-root",
+        explain_data_root,
+        "--save-explanation-to",
+        output_dir,
+        "--explain-algorithm",
+        test_algorithm,
+        "--explain-all-classes",
+    ]
+    check_run(command_line)
+    assert os.path.exists(output_dir)
+
+    save_dir_explain_only_predicted_classes = f"explain_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir_explain_only_predicted_classes = os.path.join(template_work_dir, save_dir_explain_only_predicted_classes)
+    if test_algorithm == "ActivationMap":
+        assert len(os.listdir(output_dir)) == len(os.listdir(output_dir_explain_only_predicted_classes))
+    else:
+        assert len(os.listdir(output_dir)) >= len(os.listdir(output_dir_explain_only_predicted_classes))
+    assert all([os.path.splitext(fname)[1] == ".tiff" for fname in os.listdir(output_dir)])
+
+
+def otx_explain_testing_process_saliency_maps(template, root, otx_dir, args, trained=False):
+    template_work_dir = get_template_dir(template, root)
+    if "RCNN" in template.model_template_id:
+        test_algorithm = "ActivationMap"
+    else:
+        test_algorithm = "ClassWiseSaliencyMap"
+
+    train_ann_file = args.get("--train-ann-file", "")
+    if "hierarchical" in train_ann_file:
+        train_type = "hierarchical"
+    elif "multilabel" in train_ann_file:
+        train_type = "multilabel"
+    else:
+        train_type = "default"
+
+    save_dir = f"explain_process_saliency_maps_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
+    command_line = [
+        "otx",
+        "explain",
+        template.model_template_path,
+        "--load-weights",
+        f"{template_work_dir}/trained_{template.model_template_id}/models/weights.pth",
+        "--explain-data-root",
+        explain_data_root,
+        "--save-explanation-to",
+        output_dir,
+        "--explain-algorithm",
+        test_algorithm,
+        "--process-saliency-maps",
+    ]
+    check_run(command_line)
+    assert os.path.exists(output_dir)
+    if trained:
+        assert len(os.listdir(output_dir)) > 0
+        assert all([os.path.splitext(fname)[1] == ".png" for fname in os.listdir(output_dir)])
+
+
+def otx_explain_openvino_testing(template, root, otx_dir, args, trained=False):
+    template_work_dir = get_template_dir(template, root)
+    if "RCNN" in template.model_template_id:
+        test_algorithm = "ActivationMap"
+    else:
+        test_algorithm = "ClassWiseSaliencyMap"
+
+    train_ann_file = args.get("--train-ann-file", "")
+    if "hierarchical" in train_ann_file:
+        train_type = "hierarchical"
+    elif "multilabel" in train_ann_file:
+        train_type = "multilabel"
+    else:
+        train_type = "default"
+
+    save_dir = f"explain_ov_{template.model_template_id}/{test_algorithm}/{train_type}/"
     output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
     command_line = [
         "otx",
         "explain",
         template.model_template_path,
         "--load-weights",
         f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml",
         "--explain-data-root",
-        os.path.join(otx_dir, args["--input"]),
+        explain_data_root,
+        "--save-explanation-to",
+        output_dir,
+        "--explain-algorithm",
+        test_algorithm,
+    ]
+    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml")
+    check_run(command_line)
+    assert os.path.exists(output_dir)
+    if trained:
+        assert len(os.listdir(output_dir)) > 0
+        assert all([os.path.splitext(fname)[1] == ".tiff" for fname in os.listdir(output_dir)])
+
+
+def otx_explain_all_classes_openvino_testing(template, root, otx_dir, args):
+    template_work_dir = get_template_dir(template, root)
+    if "RCNN" in template.model_template_id:
+        test_algorithm = "ActivationMap"
+    else:
+        test_algorithm = "ClassWiseSaliencyMap"
+
+    train_ann_file = args.get("--train-ann-file", "")
+    if "hierarchical" in train_ann_file:
+        train_type = "hierarchical"
+    elif "multilabel" in train_ann_file:
+        train_type = "multilabel"
+    else:
+        train_type = "default"
+
+    save_dir = f"explain_ov_all_classes_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
+    command_line = [
+        "otx",
+        "explain",
+        template.model_template_path,
+        "--load-weights",
+        f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml",
+        "--explain-data-root",
+        explain_data_root,
+        "--save-explanation-to",
+        output_dir,
+        "--explain-algorithm",
+        test_algorithm,
+        "--explain-all-classes",
+    ]
+    assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml")
+    check_run(command_line)
+    assert os.path.exists(output_dir)
+
+    save_dir_explain_only_predicted_classes = f"explain_ov_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir_explain_only_predicted_classes = os.path.join(template_work_dir, save_dir_explain_only_predicted_classes)
+    if test_algorithm == "ActivationMap":
+        assert len(os.listdir(output_dir)) == len(os.listdir(output_dir_explain_only_predicted_classes))
+    else:
+        assert len(os.listdir(output_dir)) >= len(os.listdir(output_dir_explain_only_predicted_classes))
+    assert all([os.path.splitext(fname)[1] == ".tiff" for fname in os.listdir(output_dir)])
+
+
+def otx_explain_process_saliency_maps_openvino_testing(template, root, otx_dir, args, trained=False):
+    template_work_dir = get_template_dir(template, root)
+    if "RCNN" in template.model_template_id:
+        test_algorithm = "ActivationMap"
+    else:
+        test_algorithm = "ClassWiseSaliencyMap"
+
+    train_ann_file = args.get("--train-ann-file", "")
+    if "hierarchical" in train_ann_file:
+        train_type = "hierarchical"
+    elif "multilabel" in train_ann_file:
+        train_type = "multilabel"
+    else:
+        train_type = "default"
+
+    save_dir = f"explain_ov_process_saliency_maps_{template.model_template_id}/{test_algorithm}/{train_type}/"
+    output_dir = os.path.join(template_work_dir, save_dir)
+    explain_data_root = os.path.join(otx_dir, args["--input"])
+    command_line = [
+        "otx",
+        "explain",
+        template.model_template_path,
+        "--load-weights",
+        f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml",
+        "--explain-data-root",
+        explain_data_root,
         "--save-explanation-to",
         output_dir,
         "--explain-algorithm",
         test_algorithm,
+        "--process-saliency-maps",
     ]
     assert os.path.exists(f"{template_work_dir}/exported_{template.model_template_id}_w_features/openvino.xml")
     check_run(command_line)
     assert os.path.exists(output_dir)
-    assert len(os.listdir(output_dir)) > 0
+    if trained:
+        assert len(os.listdir(output_dir)) > 0
+        assert all([os.path.splitext(fname)[1] == ".png" for fname in os.listdir(output_dir)])
 
 
 def otx_find_testing():
     """Performs several options of available otx find."""
     # Find all model template
     command_line = ["otx", "find", "--template"]
     check_run(command_line)
@@ -749,15 +896,15 @@
     """
     # Build otx-workspace per tasks check - Default Model Template only
     command_line = [
         "otx",
         "build",
         "--task",
         task,
-        "--work-dir",
+        "--workspace",
         os.path.join(root, f"otx-workspace-{task}"),
     ]
     check_run(command_line)
 
 
 def otx_build_backbone_testing(root, backbone_args):
     """Build backbone & Update model testing.
@@ -771,27 +918,27 @@
     task, backbone = backbone_args
     task_workspace = os.path.join(root, f"otx-workspace-{task}")
     command_line = [
         "otx",
         "build",
         "--task",
         f"{task}",
-        "--work-dir",
+        "--workspace",
         task_workspace,
     ]
     check_run(command_line)
     assert os.path.exists(task_workspace)
 
     # Build model.py from backbone type
     command_line = [
         "otx",
         "build",
         "--backbone",
         backbone,
-        "--work-dir",
+        "--workspace",
         task_workspace,
     ]
     check_run(command_line)
     from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
 
     model_config = MPAConfig.fromfile(os.path.join(task_workspace, "model.py"))
     assert os.path.exists(os.path.join(task_workspace, "model.py"))
@@ -799,15 +946,15 @@
     assert (
         model_config["model"]["backbone"]["type"] == backbone
     ), f"{model_config['model']['backbone']['type']} != {backbone}"
 
 
 def otx_build_testing(root, args: Dict[str, str], expected: Dict[str, str]):
     workspace_root = os.path.join(root, "otx-workspace")
-    command_line = ["otx", "build", "--work-dir", workspace_root]
+    command_line = ["otx", "build", "--workspace", workspace_root]
     for option, value in args.items():
         command_line.extend([option, value])
     check_run(command_line)
     from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
 
     template_config = MPAConfig.fromfile(os.path.join(workspace_root, "template.yaml"))
     assert template_config.name == expected["model"]
@@ -815,101 +962,31 @@
         template_config.hyper_parameters.parameter_overrides.algo_backend.train_type.default_value
         == expected["train_type"]
     )
 
 
 def otx_build_auto_config(root, otx_dir: str, args: Dict[str, str]):
     workspace_root = os.path.join(root, "otx-workspace")
-    command_line = ["otx", "build", "--work-dir", workspace_root]
+    command_line = ["otx", "build", "--workspace", workspace_root]
 
     for option, value in args.items():
         if option in ["--train-data-roots", "--val-data-roots"]:
             command_line.extend([option, f"{os.path.join(otx_dir, value)}"])
         elif option in ["--task"]:
             command_line.extend([option, args[option]])
     check_run(command_line)
 
 
-def otx_train_auto_config(root, otx_dir: str, args: Dict[str, str]):
+def otx_train_auto_config(root, otx_dir: str, args: Dict[str, str], use_output: bool = True):
     work_dir = os.path.join(root, "otx-workspace")
     command_line = ["otx", "train"]
 
     for option, value in args.items():
         if option == "template":
             command_line.extend([args[option]])
         elif option in ["--train-data-roots", "--val-data-roots"]:
             command_line.extend([option, f"{os.path.join(otx_dir, value)}"])
-    command_line.extend(["--save-model-to", f"{work_dir}"])
-    command_line.extend(["--work-dir", f"{work_dir}"])
+    if use_output:
+        command_line.extend(["--output", f"{work_dir}"])
+    command_line.extend(["--workspace", f"{work_dir}"])
     command_line.extend(args["train_params"])
     check_run(command_line)
-
-
-def otx_eval_compare(
-    template,
-    root,
-    otx_dir,
-    args,
-    criteria,
-    result_dict,
-    threshold=0.10,
-):
-    template_work_dir = get_template_dir(template, root)
-
-    command_line = [
-        "otx",
-        "eval",
-        template.model_template_path,
-        "--test-data-roots",
-        f'{os.path.join(otx_dir, args["--test-data-roots"])}',
-        "--load-weights",
-        f"{template_work_dir}/trained_{template.model_template_id}/weights.pth",
-        "--save-performance",
-        f"{template_work_dir}/trained_{template.model_template_id}/performance.json",
-    ]
-    command_line.extend(["--work-dir", f"{template_work_dir}"])
-    command_line.extend(args.get("eval_params", []))
-    check_run(command_line)
-
-    performance_json_path = f"{template_work_dir}/trained_{template.model_template_id}/performance.json"
-    assert os.path.exists(performance_json_path)
-
-    with open(performance_json_path) as read_file:
-        trained_performance = json.load(read_file)
-
-    model_criteria = criteria[template.name]
-    modified_criteria = model_criteria - (model_criteria * threshold)
-    for k in trained_performance.keys():
-        result_dict[k] = round(trained_performance[k], 3)
-        assert (
-            trained_performance[k] >= modified_criteria
-        ), f"Current model performance: ({trained_performance[k]}) < criteria: ({modified_criteria})."
-
-    result_dict["Model size (MB)"] = round(
-        os.path.getsize(f"{template_work_dir}/trained_{template.model_template_id}/weights.pth") / 1e6, 2
-    )
-
-
-def otx_eval_e2e_train_time(train_time_criteria, e2e_train_time, template, threshold=0.10):
-    """Measure train+val time and comapre with test criteria.
-
-    Test criteria was set by previous measurement.
-    """
-    e2e_train_time_criteria = train_time_criteria[template.name]
-    modified_train_criteria = e2e_train_time_criteria - (e2e_train_time_criteria * threshold)
-
-    assert (
-        e2e_train_time >= modified_train_criteria
-    ), f"Current model e2e time: ({e2e_train_time}) < criteria: ({modified_train_criteria})."
-
-
-def otx_eval_e2e_eval_time(eval_time_criteria, e2e_eval_time, template, threshold=0.10):
-    """Measure evaluation time and comapre with test criteria.
-
-    Test criteria was set by previous measurement.
-    """
-    e2e_eval_time_criteria = eval_time_criteria[template.name]
-    modified_eval_criteria = e2e_eval_time_criteria - (e2e_eval_time_criteria * threshold)
-
-    assert (
-        e2e_eval_time >= modified_eval_criteria
-    ), f"Current model e2e time: ({e2e_eval_time}) < criteria: ({modified_eval_criteria})."
```

### Comparing `otx-1.1.2rc1/tests/test_suite/training_test_case.py` & `otx-1.2.0rc1/tests/test_suite/training_test_case.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/training_tests_actions.py` & `otx-1.2.0rc1/tests/test_suite/training_tests_actions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/training_tests_common.py` & `otx-1.2.0rc1/tests/test_suite/training_tests_common.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/training_tests_helper.py` & `otx-1.2.0rc1/tests/test_suite/training_tests_helper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/test_suite/training_tests_stage.py` & `otx-1.2.0rc1/tests/test_suite/training_tests_stage.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/test_action_loading.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/pipelines/test_action_loading.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_cls_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_cls_dataset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_det_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/data/test_action_det_dataset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_movinet.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_movinet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_register_backbone.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/backbones/test_action_register_backbone.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/test_action_fast_rcnn.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/detectors/test_action_fast_rcnn.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_movinet_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_movinet_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_roi_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/heads/test_action_roi_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/test_action_movinet_recognizer.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/models/recognizers/test_action_movinet_recognizer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_det_eval_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_det_eval_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_export_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/mmaction/utils/test_action_export_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/test_action_dataloader.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_action_dataloader.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/adapters/openvino/test_action_openvino_models.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_action_openvino_models.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_inference.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/adapters/openvino/test_task.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,406 +1,396 @@
-"""Unit Test for otx.algorithms.action.tasks.inference."""
+"""Unit Test for otx.algorithms.action.adapters.openvino.task."""
 
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import os
 from typing import Any, Dict
 
 import numpy as np
 import pytest
-import torch
-from mmcv.utils import Config
-from torch import nn
+from openvino.model_zoo.model_api.adapters import OpenvinoAdapter
 
+from otx.algorithms.action.adapters.openvino import ActionOVClsDataLoader
 from otx.algorithms.action.configs.base.configuration import ActionConfig
-from otx.algorithms.action.tasks.inference import ActionInferenceTask
+from otx.algorithms.action.adapters.openvino.task import (
+    ActionOpenVINOInferencer,
+    ActionOpenVINOTask,
+    DataLoaderWrapper,
+)
 from otx.api.configuration import ConfigurableParameters
-from otx.api.entities.dataset_item import DatasetItemEntity
-from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.inference_parameters import InferenceParameters
+from otx.api.entities.annotation import (
+    Annotation,
+    AnnotationSceneEntity,
+    AnnotationSceneKind,
+)
 from otx.api.entities.label import Domain
 from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
 from otx.api.entities.model import (
     ModelConfiguration,
     ModelEntity,
     ModelFormat,
     ModelOptimizationType,
     ModelPrecision,
+    OptimizationMethod,
 )
 from otx.api.entities.model_template import InstantiationType, TaskFamily, TaskType
+from otx.api.entities.optimization_parameters import OptimizationParameters
 from otx.api.entities.resultset import ResultSetEntity
+from otx.api.entities.scored_label import ScoredLabel
+from otx.api.entities.shapes.rectangle import Rectangle
 from otx.api.entities.task_environment import TaskEnvironment
-from otx.api.usecases.tasks.interfaces.export_interface import ExportType
+from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
+from otx.api.usecases.exportable_code.inference import BaseInferencer
+from otx.api.usecases.exportable_code.prediction_to_annotation_converter import (
+    ClassificationToAnnotationConverter,
+    DetectionBoxToAnnotationConverter,
+)
+from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.action.test_helpers import (
     MockModelTemplate,
     generate_action_cls_otx_dataset,
-    generate_action_det_otx_dataset,
     generate_labels,
-    return_inputs,
+    return_args,
 )
 
 
-class MockModule(nn.Module):
-    """Mock class for nn.Module."""
-
-    def forward(self, inputs: Any):
-        return inputs
-
+class MockOVInferencer(BaseInferencer):
+    """Mock class for OV inferencer."""
 
-class MockModel(nn.Module):
-    """Mock class for pytorch model."""
+    def __init__(self, *args, **kwargs):
+        self.model = MockModel()
+        self.model.t = 8
+        self.model.w = 256
+        self.model.h = 256
+        self.labels = generate_labels(1, Domain.ACTION_CLASSIFICATION)
+        self.configuration: Dict[Any, Any] = {}
 
-    def __init__(self, task_type):
-        super().__init__()
-        self.module = MockModule()
-        self.module.backbone = MockModule()
-        self.backbone = MockModule()
-        self.task_type = task_type
+    def predict(self, data):
+        return AnnotationSceneEntity(
+            annotations=[Annotation(shape=Rectangle(0, 0, 1, 1), labels=[ScoredLabel(self.labels[0], 1.0)])],
+            kind=AnnotationSceneKind.PREDICTION,
+        )
 
-    def forward(self, return_loss: bool, imgs: DatasetItemEntity):
-        forward_hooks = list(self.module.backbone._forward_hooks.values())
-        for hook in forward_hooks:
-            hook(1, 2, 3)
-        if self.task_type == "cls":
-            return np.array([[0, 0, 1]])
-        return [[np.array([[0, 0, 1, 1, 0.1]]), np.array([[0, 0, 1, 1, 0.2]]), np.array([[0, 0, 1, 1, 0.7]])]]
+    def pre_process(self, item):
+        return item, {"dummy_meta": "dummy_info"}
 
-    @staticmethod
-    def named_parameters():
-        return {"name": torch.Tensor([0.5])}.items()
+    def forward(self, item):
+        pass
 
+    def post_process(self, item):
+        pass
 
-class MockDataset(DatasetEntity):
-    """Mock class for mm_dataset."""
 
-    def __init__(self, dataset: DatasetEntity, task_type: str):
-        self.dataset = dataset
-        self.task_type = task_type
+class MockModel:
+    """Mock class for OV model."""
 
-    def evaluate(self, prediction, *args, **kwargs):
-        if self.task_type == "cls":
-            return {"accuracy": 1.0}
-        else:
-            return {"mAP@0.5IOU": 1.0}
+    def preprocess(self, image):
+        return "Preprocess function is called"
 
+    def postprocess(self, prediction, metadata):
+        return "Postprocess function is called"
 
-class MockDataLoader:
-    """Mock class for data loader."""
+    def infer_sync(self, image):
+        return "Funtion infer_sync is called"
 
-    def __init__(self, dataset: DatasetEntity):
-        self.dataset = dataset
-        self.iter = iter(self.dataset)
 
-    def __len__(self) -> int:
-        return len(self.dataset)
+class MockOpenvinoAdapter(OpenvinoAdapter):
+    """Mock class for OpenvinoAdapter."""
 
-    def __next__(self) -> Dict[str, DatasetItemEntity]:
-        return {"imgs": next(self.iter)}
+    def __init__(self, *args, **kwargs):
+        pass
 
-    def __iter__(self):
-        return self
 
+class MockDataloader(ActionOVClsDataLoader):
+    """Mock class for dataloader for OpenVINO inference."""
 
-class MockExporter:
-    """Mock class for Exporter."""
+    def __init__(self, dataset, *args, **kwargs):
+        self.dataset = dataset
 
-    def __init__(self, recipe_cfg, weights, deploy_cfg, work_dir, half_precision):
-        self.work_dir = work_dir
+    def __len__(self):
+        return 1
 
-    def export(self):
-        dummy_data = np.ndarray((1, 1, 1))
-        with open(self.work_dir + ".bin", "wb") as f:
-            f.write(dummy_data)
-        with open(self.work_dir + ".xml", "wb") as f:
-            f.write(dummy_data)
+    def __getitem__(self, index):
+        if index >= len(self):
+            raise StopIteration
+        return self.dataset._items
 
+    def add_prediction(self, dataset, data, prediction):
+        for dataset_item in dataset:
+            dataset_item.append_labels(prediction.annotations[0].get_labels())
 
-class TestActionInferenceTask:
-    """Test class for ActionInferenceTask.
 
-    Details are explained in each test function.
-    """
+class TestActionOVInferencer:
+    """Test class for ActionOpenVINOInferencer."""
 
     @pytest.fixture(autouse=True)
-    def setup(self) -> None:
-        self.video_len = 3
-        self.frame_len = 3
-
-        cls_labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
-        self.cls_label_schema = LabelSchemaEntity()
-        cls_label_group = LabelGroup(
+    def setup(self, mocker) -> None:
+        self.labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
+        self.label_schema = LabelSchemaEntity()
+        label_group = LabelGroup(
             name="labels",
-            labels=cls_labels,
+            labels=self.labels,
             group_type=LabelGroupType.EXCLUSIVE,
         )
-        self.cls_label_schema.add_group(cls_label_group)
-        cls_template = MockModelTemplate(
-            model_template_id="template_id",
-            model_template_path="template_path",
-            name="template",
-            task_family=TaskFamily.VISION,
-            task_type=TaskType.ACTION_CLASSIFICATION,
-            instantiation=InstantiationType.CLASS,
+        self.label_schema.add_group(label_group)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.OpenvinoAdapter.__init__", return_value=None)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.Model.create_model", return_value=MockModel())
+        self.inferencer = ActionOpenVINOInferencer(
+            "ACTION_CLASSIFICATION",
+            ActionConfig(),
+            self.label_schema,
+            "openvino.xml",
+            "openvino.bin",
         )
-        self.cls_task_environment = TaskEnvironment(
-            model=None,
-            hyper_parameters=ConfigurableParameters(header="h-params"),
-            label_schema=self.cls_label_schema,
-            model_template=cls_template,
+
+    @e2e_pytest_unit
+    def test_init(self) -> None:
+        """Test __init__ function."""
+        inferencer = ActionOpenVINOInferencer(
+            "ACTION_CLASSIFICATION",
+            ActionConfig(),
+            self.label_schema,
+            "openvino.xml",
+            "openvino.bin",
+        )
+        assert inferencer.task_type == "ACTION_CLASSIFICATION"
+        assert inferencer.label_schema == self.label_schema
+        assert isinstance(inferencer.model, MockModel)
+        assert isinstance(inferencer.converter, ClassificationToAnnotationConverter)
+
+        inferencer = ActionOpenVINOInferencer(
+            "ACTION_DETECTION",
+            ActionConfig(),
+            self.label_schema,
+            "openvino.xml",
+            "openvino.bin",
+        )
+        assert inferencer.task_type == "ACTION_DETECTION"
+        assert isinstance(inferencer.converter, DetectionBoxToAnnotationConverter)
+
+    @e2e_pytest_unit
+    def test_pre_process(self) -> None:
+        """Test pre_process funciton."""
+        dataset = generate_action_cls_otx_dataset(1, 10, self.labels)
+        inputs = dataset._items
+        assert self.inferencer.pre_process(inputs) == "Preprocess function is called"
+
+    @e2e_pytest_unit
+    def test_post_process(self, mocker) -> None:
+        """Test post_process function."""
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ClassificationToAnnotationConverter.convert_to_annotation",
+            side_effect=return_args,
+        )
+        assert (
+            self.inferencer.post_process({"dummy": np.ndarray(1)}, {"dummy": "meta"})[0][0]
+            == "Postprocess function is called"
+        )
+
+    @e2e_pytest_unit
+    def test_forward(self) -> None:
+        """Test forward function."""
+
+        assert self.inferencer.forward({"dummy": np.ndarray(1)}) == "Funtion infer_sync is called"
+
+    @e2e_pytest_unit
+    def test_predict(self, mocker) -> None:
+        """Test predict function."""
+
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOInferencer.pre_process",
+            return_value=("data", "metadata"),
         )
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOInferencer.forward",
+            return_value="raw_predictions",
+        )
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOInferencer.post_process",
+            return_value="predictions",
+        )
+
+        dataset = generate_action_cls_otx_dataset(1, 10, self.labels)
+        inputs = dataset._items
+        assert self.inferencer.predict(inputs) == "predictions"
 
-        self.cls_dataset = generate_action_cls_otx_dataset(self.video_len, self.frame_len, cls_labels)
-        self.cls_task = ActionInferenceTask(task_environment=self.cls_task_environment)
 
-        det_labels = generate_labels(3, Domain.ACTION_DETECTION)
-        self.det_label_schema = LabelSchemaEntity()
-        det_label_group = LabelGroup(
+class TestActionOVTask:
+    """Test class for ActionOpenVINOTask."""
+
+    @pytest.fixture(autouse=True)
+    def setup(self, mocker) -> None:
+        self.video_len = 1
+        self.frame_len = 10
+
+        labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
+        self.label_schema = LabelSchemaEntity()
+        label_group = LabelGroup(
             name="labels",
-            labels=det_labels,
+            labels=labels,
             group_type=LabelGroupType.EXCLUSIVE,
         )
-        self.det_label_schema.add_group(det_label_group)
-        det_template = MockModelTemplate(
+        self.label_schema.add_group(label_group)
+        template = MockModelTemplate(
             model_template_id="template_id",
             model_template_path="template_path",
             name="template",
             task_family=TaskFamily.VISION,
-            task_type=TaskType.ACTION_DETECTION,
+            task_type=TaskType.ACTION_CLASSIFICATION,
             instantiation=InstantiationType.CLASS,
         )
-        self.det_task_environment = TaskEnvironment(
-            model=None,
+
+        config = ModelConfiguration(ActionConfig(), self.label_schema)
+        self.dataset = generate_action_cls_otx_dataset(1, 10, labels)
+        self.model = ModelEntity(self.dataset, config)
+        self.model.set_data("openvino.xml", np.ndarray([1]).tobytes())
+        self.model.set_data("openvino.bin", np.ndarray([1]).tobytes())
+
+        self.task_environment = TaskEnvironment(
+            model=self.model,
             hyper_parameters=ConfigurableParameters(header="h-params"),
-            label_schema=self.det_label_schema,
-            model_template=det_template,
+            label_schema=self.label_schema,
+            model_template=template,
         )
 
-        self.det_dataset = generate_action_det_otx_dataset(self.video_len, self.frame_len, det_labels)[0]
-        self.det_task = ActionInferenceTask(task_environment=self.det_task_environment)
-
     @e2e_pytest_unit
-    # TODO Sepearate add prediction function test and infer funciton test
-    def test_infer(self, mocker) -> None:
-        """Test infer function.
+    def test_load_inferencer(self, mocker) -> None:
+        """Test load_inferencer function."""
 
-        <Steps>
-            1. Create mock model for action classification
-            2. Create mock recipe for action classification
-            3. Run infer funciton
-            4. Check whether inference results are added to output
-            5. Do 1 - 4 for action detection
-        """
-
-        mocker.patch(
-            "otx.algorithms.action.tasks.inference.build_dataset", return_value=MockDataset(self.cls_dataset, "cls")
-        )
-        mocker.patch(
-            "otx.algorithms.action.tasks.inference.build_dataloader", return_value=MockDataLoader(self.cls_dataset)
-        )
-        mocker.patch("otx.algorithms.action.tasks.inference.MMDataParallel", return_value=MockModel("cls"))
-        self.cls_task._model = MockModel("cls")
-        self.cls_task._recipe_cfg = Config(
-            {
-                "data": {"test": {"otx_dataset": None}, "workers_per_gpu": 1},
-                "gpu_ids": [0],
-                "evaluation": {"final_metric": "accuracy"},
-            }
-        )
-        inference_parameters = InferenceParameters(is_evaluation=True)
-        outputs = self.cls_task.infer(self.cls_dataset, inference_parameters)
-        for output in outputs:
-            assert len(output.get_annotations()[0].get_labels()) == 2
-
-        mocker.patch(
-            "otx.algorithms.action.tasks.inference.build_dataset", return_value=MockDataset(self.det_dataset, "det")
-        )
-        mocker.patch(
-            "otx.algorithms.action.tasks.inference.build_dataloader", return_value=MockDataLoader(self.det_dataset)
-        )
-        mocker.patch("otx.algorithms.action.tasks.inference.MMDataParallel", return_value=MockModel("det"))
-        self.det_task._model = MockModel("det")
-        self.det_task._recipe_cfg = Config(
-            {
-                "data": {"test": {"otx_dataset": None}, "workers_per_gpu": 1},
-                "gpu_ids": [0],
-                "evaluation": {"final_metric": "mAP@0.5IOU"},
-            }
-        )
-        inference_parameters = InferenceParameters(is_evaluation=True)
-        outputs = self.det_task.infer(self.det_dataset, inference_parameters)
-        for output in outputs:
-            assert len(output.get_annotations()) == 4
-
-    @e2e_pytest_unit
-    def test_evaluate(self) -> None:
-        """Test evaluate function.
-
-        <Steps>
-            1. Create model entity
-            2. Create result set entity
-            3. Run evaluate function with same dataset, this should give 100% accuracy
-            4. Run evaluate function with empty dataset, this should give 0% accuracy
-            5. Do 1 - 4 for action detection
-        """
-        _config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        _model = ModelEntity(self.cls_dataset, _config)
-        resultset = ResultSetEntity(_model, self.cls_dataset, self.cls_dataset)
-        self.cls_task.evaluate(resultset)
-        assert resultset.performance.score.value == 1.0
-
-        resultset = ResultSetEntity(_model, self.cls_dataset, self.cls_dataset.with_empty_annotations())
-        self.cls_task.evaluate(resultset)
-        assert resultset.performance.score.value == 0.0
-
-        _config = ModelConfiguration(ActionConfig(), self.det_label_schema)
-        _model = ModelEntity(self.det_dataset, _config)
-        resultset = ResultSetEntity(_model, self.det_dataset, self.det_dataset)
-        self.det_task.evaluate(resultset)
-        assert resultset.performance.score.value == 0.0
-
-    @e2e_pytest_unit
-    def test_initialize_post_hook(self) -> None:
-        """Test _initialize_post_hook funciton."""
-
-        options = None
-        assert self.cls_task._initialize_post_hook(options) is None
-
-        options = {"deploy_cfg": Config()}
-        self.cls_task._initialize_post_hook(options)
-        assert isinstance(self.cls_task.deploy_cfg, Config)
-
-    @pytest.mark.parametrize("precision", [ModelPrecision.FP16, ModelPrecision.FP32])
-    @e2e_pytest_unit
-    def test_export(self, mocker, precision: ModelPrecision) -> None:
-        """Test export function.
-
-        <Steps>
-            1. Create model entity
-            2. Run export function
-            3. Check output model attributes
-        """
-        _config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        _model = ModelEntity(self.cls_dataset, _config)
-        self.cls_task._model = nn.Module()
-        self.cls_task._recipe_cfg = None
-        self.cls_task.deploy_cfg = Config(
-            dict(codebase_config=dict(type="mmdet", task="ObjectDetection"), backend_config=dict(type="openvino"))
-        )
-        mocker.patch("otx.algorithms.action.tasks.inference.ActionInferenceTask._init_task", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.inference.Exporter", side_effect=MockExporter)
-        self.cls_task.export(ExportType.OPENVINO, _model, precision)
-
-        assert _model.model_format == ModelFormat.OPENVINO
-        assert _model.optimization_type == ModelOptimizationType.MO
-        assert _model.precision[0] == precision
-        assert _model.get_data("openvino.bin") is not None
-        assert _model.get_data("openvino.xml") is not None
-        assert _model.get_data("confidence_threshold") is not None
-        assert _model.precision == self.cls_task._precision
-        assert _model.optimization_methods == self.cls_task._optimization_methods
-        assert _model.get_data("label_schema.json") is not None
-
-    @e2e_pytest_unit
-    def test_init_task(self, mocker) -> None:
-        """Test _init_task function.
-
-        Check model is generated from _init_task function.
-        """
-        mocker.patch("otx.algorithms.action.tasks.inference.ActionInferenceTask._initialize", return_value=True)
         mocker.patch(
-            "otx.algorithms.action.tasks.inference.ActionInferenceTask._load_model", return_value=MockModel("cls")
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOInferencer", return_value=MockOVInferencer()
         )
-        with pytest.raises(RuntimeError):
-            self.cls_task._init_task()
+        task = ActionOpenVINOTask(self.task_environment)
+        assert isinstance(task.inferencer, MockOVInferencer)
 
-        self.cls_task._recipe_cfg = Config()
-        self.cls_task._init_task()
-        assert isinstance(self.cls_task._model, MockModel)
+        self.task_environment.model = None
+        with pytest.raises(RuntimeError):
+            task = ActionOpenVINOTask(self.task_environment)
 
     @e2e_pytest_unit
-    def test_load_model(self, mocker) -> None:
-        """Test _load_model function.
-
-        Check _load_model function can run _create_model function under various situations
-        """
+    def test_infer(self, mocker) -> None:
+        """Test infer function."""
 
         mocker.patch(
-            "otx.algorithms.action.tasks.inference.ActionInferenceTask._create_model", return_value=MockModel("cls")
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask.load_inferencer",
+            return_value=MockOVInferencer(),
         )
-        mocker.patch("otx.algorithms.action.tasks.inference.load_state_dict", return_value=True)
         mocker.patch(
-            "otx.algorithms.action.tasks.inference.torch.load",
-            return_value={"confidence_threshold": 0.01, "model": np.array([0.01])},
+            "otx.algorithms.action.adapters.openvino.task.get_ovdataloader", return_value=MockDataloader(self.dataset)
         )
+        task = ActionOpenVINOTask(self.task_environment)
+        output = task.infer(self.dataset.with_empty_annotations())
+        assert output[0].annotation_scene.kind == AnnotationSceneKind.PREDICTION
 
-        with pytest.raises(Exception):
-            self.cls_task._load_model(None)
-
-        _config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        _model_entity = ModelEntity(self.cls_dataset, _config)
-        _model_entity.set_data("weights.pth", np.ndarray((1, 1, 1)).tobytes())
-
-        self.cls_task._recipe_cfg = Config({"load_from": "weights.pth"})
-        model = self.cls_task._load_model(_model_entity)
-        assert isinstance(model, MockModel)
-
-        model = self.cls_task._load_model(None)
-        assert isinstance(model, MockModel)
-
-    def test_create_model(self, mocker) -> None:
-        """Test _create_model function.
+    @e2e_pytest_unit
+    def test_evaluate(self, mocker) -> None:
+        """Test evaluate function."""
 
-        Check _create_model function can run build_model funciton under various situations
-        """
-        mocker.patch("otx.algorithms.action.tasks.inference.build_model", return_value=MockModel("cls"))
-        mocker.patch("otx.algorithms.action.tasks.inference.load_checkpoint", return_value=True)
+        class MockPerformance:
+            def get_performance(self):
+                return 1.0
 
-        _config = Config({"model": Config(), "load_from": "weights.pth"})
-        model = self.cls_task._create_model(_config, False)
-        assert isinstance(model, MockModel)
-        model = self.cls_task._create_model(_config, True)
-        assert isinstance(model, MockModel)
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask.load_inferencer",
+            return_value=MockOVInferencer(),
+        )
+        task = ActionOpenVINOTask(self.task_environment)
 
-    def test_unload(self) -> None:
-        """Test unload function."""
-        self.cls_task.unload()
+        resultset = ResultSetEntity(
+            self.model,
+            self.dataset,
+            self.dataset,
+        )
+
+        mocker.patch.object(MetricsHelper, "compute_accuracy", return_value=MockPerformance())
+        task.evaluate(resultset, "Accuracy")
+        assert resultset.performance == 1.0
+
+        mocker.patch.object(MetricsHelper, "compute_f_measure", return_value=MockPerformance())
+        self.task_environment.model_template.task_type = TaskType.ACTION_DETECTION
+        task = ActionOpenVINOTask(self.task_environment)
+        task.evaluate(resultset, "Accuracy")
+        assert resultset.performance == 1.0
 
-    def test_init_recipe_hparam(self, mocker) -> None:
-        """Test _init_recipe_hparam function."""
+    @e2e_pytest_unit
+    def test_deploy(self, mocker) -> None:
+        """Test function for deploy function."""
 
         mocker.patch(
-            "otx.algorithms.action.tasks.inference.BaseTask._init_recipe_hparam",
-            return_value=Config(
-                {"data": {"samples_per_gpu": 4}, "lr_config": {"warmup_iters": 3}, "runner": {"max_epochs": 10}}
-            ),
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask.load_inferencer",
+            return_value=MockOVInferencer(),
         )
+        task = ActionOpenVINOTask(self.task_environment)
+        assert self.model.exportable_code is None
+        task.deploy(self.model)
+        assert self.model.exportable_code is not None
+
+    @e2e_pytest_unit
+    def test_optimize(self, mocker) -> None:
+        """Test optimization function."""
 
-        self.cls_task._recipe_cfg = Config({"lr_config": Config()})
-        out = self.cls_task._init_recipe_hparam()
+        class MockPipeline:
+            """Mock class for POT pipeline"""
 
-        assert self.cls_task._recipe_cfg.lr_config.warmup == "linear"
-        assert self.cls_task._recipe_cfg.lr_config.warmup_by_epoch is True
-        assert self.cls_task._recipe_cfg.total_epochs == 10
-        assert out.data.videos_per_gpu == 4
-        assert out.use_adaptive_interval == self.cls_task._hyperparams.learning_parameters.use_adaptive_interval
+            def run(self, model):
+                return model
 
-    def test_init_recipe(self, mocker) -> None:
-        """Test _init_recipe funciton."""
+        def mock_save_model(model, tempdir, model_name):
+            """Mock function for save_model function."""
+            with open(os.path.join(tempdir, "model.xml"), "wb") as f:
+                f.write(np.ndarray(1).tobytes())
+            with open(os.path.join(tempdir, "model.bin"), "wb") as f:
+                f.write(np.ndarray(1).tobytes())
 
-        mocker.patch("otx.algorithms.action.tasks.inference.Config.fromfile", side_effect=return_inputs)
-        mocker.patch("otx.algorithms.action.tasks.inference.patch_config", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.inference.set_data_classes", return_value=True)
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.get_ovdataloader", return_value=MockDataloader(self.dataset)
+        )
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.DataLoaderWrapper", return_value=MockDataloader(self.dataset)
+        )
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.load_model", return_value=self.model)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.get_nodes_by_type", return_value=False)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.IEEngine", return_value=True)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.create_pipeline", return_value=MockPipeline())
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.compress_model_weights", return_value=True)
+        mocker.patch("otx.algorithms.action.adapters.openvino.task.save_model", side_effect=mock_save_model)
+        mocker.patch(
+            "otx.algorithms.action.adapters.openvino.task.ActionOpenVINOTask.load_inferencer",
+            return_value=MockOVInferencer(),
+        )
+        task = ActionOpenVINOTask(self.task_environment)
+        task.optimize(OptimizationType.POT, self.dataset, self.model, OptimizationParameters())
+        assert self.model.get_data("openvino.xml") is not None
+        assert self.model.get_data("openvino.bin") is not None
+        assert self.model.model_format == ModelFormat.OPENVINO
+        assert self.model.optimization_type == ModelOptimizationType.POT
+        assert self.model.optimization_methods == [OptimizationMethod.QUANTIZATION]
+        assert self.model.precision == [ModelPrecision.INT8]
+
+
+class TestDataLoaderWrapper:
+    """Test class for DataLoaderWrapper"""
+
+    def setup(self, mocker) -> None:
+        labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
+        self.dataset = generate_action_cls_otx_dataset(1, 10, labels)
+        ovdataloader = MockDataloader(self.dataset)
+        inferencer = MockOVInferencer()
+        self.dataloader = DataLoaderWrapper(ovdataloader, inferencer)
 
-        self.cls_task._init_recipe()
-        recipe_root = os.path.abspath(os.path.dirname(self.cls_task.template_file_path))
-        assert self.cls_task._recipe_cfg == os.path.join(recipe_root, "model.py")
+    @e2e_pytest_unit
+    def test_len(self) -> None:
+        """Test __len__ function."""
 
-    def test_init_model_cfg(self, mocker) -> None:
-        """Test _init_model_cfg function."""
+        assert len(self.dataloader) == 1
 
-        mocker.patch("otx.algorithms.action.tasks.inference.Config.fromfile", side_effect=return_inputs)
+    def test_getitem(self) -> None:
+        """Test __getitem__ function."""
 
-        model_cfg = self.cls_task._init_model_cfg()
-        assert model_cfg == os.path.join(self.cls_task._model_dir, "model.py")
+        out = self.dataloader[0]
+        assert out[0][0] == 0
+        assert isinstance(out[0][1], AnnotationSceneEntity)
+        assert len(out[1]) == 10
+        assert isinstance(out[2], dict)
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_openvino.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/test_task.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,384 +1,362 @@
-"""Unit Test for otx.algorithms.action.tasks.openvino."""
+"""Unit Test for otx.algorithms.detection.adapters.mmdet.task."""
 
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import os
+import json
+from contextlib import nullcontext
+from copy import deepcopy
 from typing import Any, Dict
 
 import numpy as np
 import pytest
-from openvino.model_zoo.model_api.adapters import OpenvinoAdapter
-
-from otx.algorithms.action.adapters.openvino import ActionOVClsDataLoader
-from otx.algorithms.action.configs.base.configuration import ActionConfig
-from otx.algorithms.action.tasks.openvino import (
-    ActionOpenVINOInferencer,
-    ActionOpenVINOTask,
-    DataLoaderWrapper,
-)
+import torch
+from mmcv.utils import Config
+from torch import nn
+
+from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
+from otx.algorithms.detection.adapters.mmdet.task import MMDetectionTask
+from otx.algorithms.detection.adapters.mmdet.models.detectors.custom_atss_detector import CustomATSS
+from otx.algorithms.detection.configs.base import DetectionConfig
 from otx.api.configuration import ConfigurableParameters
-from otx.api.entities.annotation import (
-    Annotation,
-    AnnotationSceneEntity,
-    AnnotationSceneKind,
-)
+from otx.api.configuration.helper import create
+from otx.api.entities.dataset_item import DatasetItemEntity
+from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.explain_parameters import ExplainParameters
+from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.label import Domain
 from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
 from otx.api.entities.model import (
     ModelConfiguration,
     ModelEntity,
     ModelFormat,
     ModelOptimizationType,
     ModelPrecision,
-    OptimizationMethod,
 )
-from otx.api.entities.model_template import InstantiationType, TaskFamily, TaskType
-from otx.api.entities.optimization_parameters import OptimizationParameters
+from otx.api.entities.model_template import InstantiationType, parse_model_template, TaskFamily, TaskType
 from otx.api.entities.resultset import ResultSetEntity
-from otx.api.entities.scored_label import ScoredLabel
-from otx.api.entities.shapes.rectangle import Rectangle
-from otx.api.entities.task_environment import TaskEnvironment
-from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.exportable_code.inference import BaseInferencer
-from otx.api.usecases.exportable_code.prediction_to_annotation_converter import (
-    ClassificationToAnnotationConverter,
-    DetectionBoxToAnnotationConverter,
-)
-from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
+from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
-from tests.unit.algorithms.action.test_helpers import (
-    MockModelTemplate,
-    generate_action_cls_otx_dataset,
-    generate_labels,
-    return_args,
+from tests.unit.algorithms.detection.test_helpers import (
+    DEFAULT_DET_TEMPLATE_DIR,
+    DEFAULT_ISEG_TEMPLATE_DIR,
+    init_environment,
+    generate_det_dataset,
 )
 
 
-class MockOVInferencer(BaseInferencer):
-    """Mock class for OV inferencer."""
+class MockModule(nn.Module):
+    """Mock class for nn.Module."""
 
-    def __init__(self, *args, **kwargs):
-        self.model = MockModel()
-        self.model.t = 8
-        self.model.w = 256
-        self.model.h = 256
-        self.labels = generate_labels(1, Domain.ACTION_CLASSIFICATION)
-        self.configuration: Dict[Any, Any] = {}
+    def forward(self, inputs: Any):
+        return inputs
 
-    def predict(self, data):
-        return AnnotationSceneEntity(
-            annotations=[Annotation(shape=Rectangle(0, 0, 1, 1), labels=[ScoredLabel(self.labels[0], 1.0)])],
-            kind=AnnotationSceneKind.PREDICTION,
-        )
 
-    def pre_process(self, item):
-        return item, {"dummy_meta": "dummy_info"}
+class MockModel(nn.Module):
+    """Mock class for pytorch model."""
 
-    def forward(self, item):
-        pass
+    def __init__(self, task_type):
+        super().__init__()
+        self.module = MockModule()
+        self.module.backbone = MockModule()
+        self.backbone = MockModule()
+        self.task_type = task_type
 
-    def post_process(self, item):
-        pass
+    def forward(self, *args, **kwargs):
+        forward_hooks = list(self.module.backbone._forward_hooks.values())
+        for hook in forward_hooks:
+            hook(1, 2, 3)
+        return [[np.array([[0, 0, 1, 1, 0.1]]), np.array([[0, 0, 1, 1, 0.2]]), np.array([[0, 0, 1, 1, 0.7]])]]
 
+    @staticmethod
+    def named_parameters():
+        return {"name": torch.Tensor([0.5])}.items()
 
-class MockModel:
-    """Mock class for OV model."""
 
-    def preprocess(self, image):
-        return "Preprocess function is called"
+class MockDataset(DatasetEntity):
+    """Mock class for mm_dataset."""
 
-    def postprocess(self, prediction, metadata):
-        return "Postprocess function is called"
+    def __init__(self, dataset: DatasetEntity, task_type: str):
+        self.dataset = dataset
+        self.task_type = task_type
+        self.CLASSES = ["1", "2", "3"]
 
-    def infer_sync(self, image):
-        return "Funtion infer_sync is called"
+    def __len__(self):
+        return len(self.dataset)
 
+    def evaluate(self, prediction, *args, **kwargs):
+        if self.task_type == "det":
+            return {"mAP": 1.0}
+        else:
+            return {"mAP": 1.0}
 
-class MockOpenvinoAdapter(OpenvinoAdapter):
-    """Mock class for OpenvinoAdapter."""
 
-    def __init__(self, *args, **kwargs):
-        pass
+class MockDataLoader:
+    """Mock class for data loader."""
 
+    def __init__(self, dataset: DatasetEntity):
+        self.dataset = dataset
+        self.iter = iter(self.dataset)
 
-class MockDataloader(ActionOVClsDataLoader):
-    """Mock class for dataloader for OpenVINO inference."""
+    def __len__(self) -> int:
+        return len(self.dataset)
 
-    def __init__(self, dataset, *args, **kwargs):
-        self.dataset = dataset
+    def __next__(self) -> Dict[str, DatasetItemEntity]:
+        return {"imgs": next(self.iter)}
 
-    def __len__(self):
-        return 1
+    def __iter__(self):
+        return self
+
+
+class MockExporter:
+    """Mock class for Exporter."""
+
+    def __init__(self, task):
+        self._output_path = task._output_path
+
+    def run(self, *args, **kwargs):
+        with open(os.path.join(self._output_path, "openvino.bin"), "wb") as f:
+            f.write(np.ndarray([0]))
+        with open(os.path.join(self._output_path, "openvino.xml"), "wb") as f:
+            f.write(np.ndarray([0]))
+        with open(os.path.join(self._output_path, "model.onnx"), "wb") as f:
+            f.write(np.ndarray([0]))
 
-    def __getitem__(self, index):
-        if index >= len(self):
-            raise StopIteration
-        return self.dataset._items
+        return {
+            "outputs": {
+                "bin": os.path.join(self._output_path, "openvino.bin"),
+                "xml": os.path.join(self._output_path, "openvino.xml"),
+                "onnx": os.path.join(self._output_path, "model.onnx"),
+            }
+        }
 
-    def add_prediction(self, dataset, data, prediction):
-        for dataset_item in dataset:
-            dataset_item.append_labels(prediction.annotations[0].get_labels())
 
+class TestMMActionTask:
+    """Test class for MMActionTask.
 
-class TestActionOVInferencer:
-    """Test class for ActionOpenVINOInferencer."""
+    Details are explained in each test function.
+    """
 
     @pytest.fixture(autouse=True)
-    def setup(self, mocker) -> None:
-        self.labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
-        self.label_schema = LabelSchemaEntity()
-        label_group = LabelGroup(
+    def setup(self) -> None:
+        model_template = parse_model_template(os.path.join(DEFAULT_DET_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        task_env = init_environment(hyper_parameters, model_template, task_type=TaskType.DETECTION)
+
+        self.det_task = MMDetectionTask(task_env)
+
+        self.det_dataset, self.det_labels = generate_det_dataset(TaskType.DETECTION, 100)
+        self.det_label_schema = LabelSchemaEntity()
+        det_label_group = LabelGroup(
             name="labels",
-            labels=self.labels,
+            labels=self.det_labels,
             group_type=LabelGroupType.EXCLUSIVE,
         )
-        self.label_schema.add_group(label_group)
-        mocker.patch("otx.algorithms.action.tasks.openvino.OpenvinoAdapter.__init__", return_value=None)
-        mocker.patch("otx.algorithms.action.tasks.openvino.Model.create_model", return_value=MockModel())
-        self.inferencer = ActionOpenVINOInferencer(
-            "ACTION_CLASSIFICATION",
-            ActionConfig(),
-            self.label_schema,
-            "openvino.xml",
-            "openvino.bin",
-        )
+        self.det_label_schema.add_group(det_label_group)
 
-    @e2e_pytest_unit
-    def test_init(self) -> None:
-        """Test __init__ function."""
-        inferencer = ActionOpenVINOInferencer(
-            "ACTION_CLASSIFICATION",
-            ActionConfig(),
-            self.label_schema,
-            "openvino.xml",
-            "openvino.bin",
-        )
-        assert inferencer.task_type == "ACTION_CLASSIFICATION"
-        assert inferencer.label_schema == self.label_schema
-        assert isinstance(inferencer.model, MockModel)
-        assert isinstance(inferencer.converter, ClassificationToAnnotationConverter)
-
-        inferencer = ActionOpenVINOInferencer(
-            "ACTION_DETECTION",
-            ActionConfig(),
-            self.label_schema,
-            "openvino.xml",
-            "openvino.bin",
-        )
-        assert inferencer.task_type == "ACTION_DETECTION"
-        assert isinstance(inferencer.converter, DetectionBoxToAnnotationConverter)
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        task_env = init_environment(hyper_parameters, model_template, task_type=TaskType.INSTANCE_SEGMENTATION)
 
-    @e2e_pytest_unit
-    def test_pre_process(self) -> None:
-        """Test pre_process funciton."""
-        dataset = generate_action_cls_otx_dataset(1, 10, self.labels)
-        inputs = dataset._items
-        assert self.inferencer.pre_process(inputs) == "Preprocess function is called"
+        self.iseg_task = MMDetectionTask(task_env)
 
-    @e2e_pytest_unit
-    def test_post_process(self, mocker) -> None:
-        """Test post_process function."""
-        mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ClassificationToAnnotationConverter.convert_to_annotation",
-            side_effect=return_args,
-        )
-        assert (
-            self.inferencer.post_process({"dummy": np.ndarray(1)}, {"dummy": "meta"})[0][0]
-            == "Postprocess function is called"
+        self.iseg_dataset, self.iseg_labels = generate_det_dataset(TaskType.INSTANCE_SEGMENTATION, 100)
+        self.iseg_label_schema = LabelSchemaEntity()
+        iseg_label_group = LabelGroup(
+            name="labels",
+            labels=self.iseg_labels,
+            group_type=LabelGroupType.EXCLUSIVE,
         )
+        self.iseg_label_schema.add_group(iseg_label_group)
 
     @e2e_pytest_unit
-    def test_forward(self) -> None:
-        """Test forward function."""
-
-        assert self.inferencer.forward({"dummy": np.ndarray(1)}) == "Funtion infer_sync is called"
+    def test_build_model(self, mocker) -> None:
+        """Test build_model function."""
+        _mock_recipe_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_DET_TEMPLATE_DIR, "model.py"))
+        model = self.det_task.build_model(_mock_recipe_cfg, True)
+        assert isinstance(model, CustomATSS)
 
     @e2e_pytest_unit
-    def test_predict(self, mocker) -> None:
-        """Test predict function."""
+    def test_train(self, mocker) -> None:
+        """Test train function."""
+
+        def _mock_train_detector_det(*args, **kwargs):
+            with open(os.path.join(self.det_task._output_path, "latest.pth"), "wb") as f:
+                torch.save({"dummy": torch.randn(1, 3, 3, 3)}, f)
+
+        def _mock_train_detector_iseg(*args, **kwargs):
+            with open(os.path.join(self.iseg_task._output_path, "latest.pth"), "wb") as f:
+                torch.save({"dummy": torch.randn(1, 3, 3, 3)}, f)
 
         mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOInferencer.pre_process",
-            return_value=("data", "metadata"),
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataset",
+            return_value=MockDataset(self.det_dataset, "det"),
         )
         mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOInferencer.forward", return_value="raw_predictions"
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataloader",
+            return_value=MockDataLoader(self.det_dataset),
         )
         mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOInferencer.post_process", return_value="predictions"
+            "otx.algorithms.detection.adapters.mmdet.task.patch_data_pipeline",
+            return_value=True,
         )
-
-        dataset = generate_action_cls_otx_dataset(1, 10, self.labels)
-        inputs = dataset._items
-        assert self.inferencer.predict(inputs) == "predictions"
-
-
-class TestActionOVTask:
-    """Test class for ActionOpenVINOTask."""
-
-    @pytest.fixture(autouse=True)
-    def setup(self, mocker) -> None:
-        self.video_len = 1
-        self.frame_len = 10
-
-        labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
-        self.label_schema = LabelSchemaEntity()
-        label_group = LabelGroup(
-            name="labels",
-            labels=labels,
-            group_type=LabelGroupType.EXCLUSIVE,
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.train_detector",
+            side_effect=_mock_train_detector_det,
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.single_gpu_test",
+            return_value=[
+                np.array([np.array([[0, 0, 1, 1, 0.1]]), np.array([[0, 0, 1, 1, 0.2]]), np.array([[0, 0, 1, 1, 0.7]])])
+            ]
+            * 100,
         )
-        self.label_schema.add_group(label_group)
-        template = MockModelTemplate(
-            model_template_id="template_id",
-            model_template_path="template_path",
-            name="template",
-            task_family=TaskFamily.VISION,
-            task_type=TaskType.ACTION_CLASSIFICATION,
-            instantiation=InstantiationType.CLASS,
-        )
-
-        config = ModelConfiguration(ActionConfig(), self.label_schema)
-        self.dataset = generate_action_cls_otx_dataset(1, 10, labels)
-        self.model = ModelEntity(self.dataset, config)
-        self.model.set_data("openvino.xml", np.ndarray([1]).tobytes())
-        self.model.set_data("openvino.bin", np.ndarray([1]).tobytes())
-
-        self.task_environment = TaskEnvironment(
-            model=self.model,
-            hyper_parameters=ConfigurableParameters(header="h-params"),
-            label_schema=self.label_schema,
-            model_template=template,
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.FeatureVectorHook",
+            return_value=nullcontext(),
         )
 
-    @e2e_pytest_unit
-    def test_load_inferencer(self, mocker) -> None:
-        """Test load_inferencer function."""
+        _config = ModelConfiguration(DetectionConfig(), self.det_label_schema)
+        output_model = ModelEntity(self.det_dataset, _config)
+        self.det_task.train(self.det_dataset, output_model)
+        output_model.performance == 1.0
 
-        mocker.patch("otx.algorithms.action.tasks.openvino.ActionOpenVINOInferencer", return_value=MockOVInferencer())
-        task = ActionOpenVINOTask(self.task_environment)
-        assert isinstance(task.inferencer, MockOVInferencer)
-
-        self.task_environment.model = None
-        with pytest.raises(RuntimeError):
-            task = ActionOpenVINOTask(self.task_environment)
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.train_detector",
+            side_effect=_mock_train_detector_iseg,
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.single_gpu_test",
+            return_value=[(np.array([[[0, 0, 1, 1, 1]]]), np.array([[[0, 0, 1, 1, 1, 1, 1]]]))] * 100,
+        )
+        _config = ModelConfiguration(DetectionConfig(), self.iseg_label_schema)
+        output_model = ModelEntity(self.iseg_dataset, _config)
+        self.iseg_task.train(self.iseg_dataset, output_model)
+        output_model.performance == 1.0
 
     @e2e_pytest_unit
     def test_infer(self, mocker) -> None:
         """Test infer function."""
 
         mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOTask.load_inferencer", return_value=MockOVInferencer()
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataset",
+            return_value=MockDataset(self.det_dataset, "det"),
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataloader",
+            return_value=MockDataLoader(self.det_dataset),
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.patch_data_pipeline",
+            return_value=True,
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.single_gpu_test",
+            return_value=[
+                np.array([np.array([[0, 0, 1, 1, 0.1]]), np.array([[0, 0, 1, 1, 0.2]]), np.array([[0, 0, 1, 1, 0.7]])])
+            ]
+            * 100,
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.FeatureVectorHook",
+            return_value=nullcontext(),
         )
-        mocker.patch("otx.algorithms.action.tasks.openvino.get_ovdataloader", return_value=MockDataloader(self.dataset))
-        task = ActionOpenVINOTask(self.task_environment)
-        output = task.infer(self.dataset.with_empty_annotations())
-        assert output[0].annotation_scene.kind == AnnotationSceneKind.PREDICTION
+
+        inference_parameters = InferenceParameters(is_evaluation=True)
+        outputs = self.det_task.infer(self.det_dataset, inference_parameters)
+        for output in outputs:
+            assert output.get_annotations()[-1].get_labels()[0].probability == 0.7
 
     @e2e_pytest_unit
-    def test_evaluate(self, mocker) -> None:
-        """Test evaluate function."""
+    def test_det_evaluate(self) -> None:
+        """Test evaluate function for detection."""
 
-        class MockPerformance:
-            def get_performance(self):
-                return 1.0
+        _config = ModelConfiguration(DetectionConfig(), self.det_label_schema)
+        _model = ModelEntity(self.det_dataset, _config)
+        resultset = ResultSetEntity(_model, self.det_dataset, self.det_dataset)
+        self.det_task.evaluate(resultset)
+        assert resultset.performance.score.value == 1.0
 
-        mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOTask.load_inferencer", return_value=MockOVInferencer()
-        )
-        task = ActionOpenVINOTask(self.task_environment)
+    @e2e_pytest_unit
+    def test_det_evaluate_with_empty_annotations(self) -> None:
+        """Test evaluate function for detection with empty predictions."""
 
-        resultset = ResultSetEntity(
-            self.model,
-            self.dataset,
-            self.dataset,
-        )
+        _config = ModelConfiguration(DetectionConfig(), self.det_label_schema)
+        _model = ModelEntity(self.det_dataset, _config)
+        resultset = ResultSetEntity(_model, self.det_dataset, self.det_dataset.with_empty_annotations())
+        self.det_task.evaluate(resultset)
+        assert resultset.performance.score.value == 0.0
 
-        mocker.patch.object(MetricsHelper, "compute_accuracy", return_value=MockPerformance())
-        task.evaluate(resultset, "Accuracy")
-        assert resultset.performance == 1.0
+    @e2e_pytest_unit
+    def test_iseg_evaluate(self) -> None:
+        """Test evaluate function for instance segmentation."""
 
-        mocker.patch.object(MetricsHelper, "compute_f_measure", return_value=MockPerformance())
-        self.task_environment.model_template.task_type = TaskType.ACTION_DETECTION
-        task = ActionOpenVINOTask(self.task_environment)
-        task.evaluate(resultset, "Accuracy")
-        assert resultset.performance == 1.0
+        _config = ModelConfiguration(DetectionConfig(), self.iseg_label_schema)
+        _model = ModelEntity(self.iseg_dataset, _config)
+        resultset = ResultSetEntity(_model, self.iseg_dataset, self.iseg_dataset)
+        self.iseg_task.evaluate(resultset)
+        assert resultset.performance.score.value == 1.0
 
+    @pytest.mark.parametrize("precision", [ModelPrecision.FP16, ModelPrecision.FP32])
     @e2e_pytest_unit
-    def test_deploy(self, mocker) -> None:
-        """Test function for deploy function."""
+    def test_export(self, mocker, precision: ModelPrecision) -> None:
+        """Test export function.
+
+        <Steps>
+            1. Create model entity
+            2. Run export function
+            3. Check output model attributes
+        """
+        _config = ModelConfiguration(DetectionConfig(), self.det_label_schema)
+        _model = ModelEntity(self.det_dataset, _config)
 
         mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOTask.load_inferencer", return_value=MockOVInferencer()
+            "otx.algorithms.detection.adapters.mmdet.task.DetectionExporter",
+            return_value=MockExporter(self.det_task),
+        )
+        mocker.patch(
+            "otx.algorithms.detection.task.embed_ir_model_data",
+            return_value=True,
         )
-        task = ActionOpenVINOTask(self.task_environment)
-        assert self.model.exportable_code is None
-        task.deploy(self.model)
-        assert self.model.exportable_code is not None
-
-    @e2e_pytest_unit
-    def test_optimize(self, mocker) -> None:
-        """Test optimization function."""
-
-        class MockPipeline:
-            """Mock class for POT pipeline"""
 
-            def run(self, model):
-                return model
+        self.det_task.export(ExportType.OPENVINO, _model, precision, False)
 
-        def mock_save_model(model, tempdir, model_name):
-            """Mock function for save_model function."""
-            with open(os.path.join(tempdir, "model.xml"), "wb") as f:
-                f.write(np.ndarray(1).tobytes())
-            with open(os.path.join(tempdir, "model.bin"), "wb") as f:
-                f.write(np.ndarray(1).tobytes())
-
-        mocker.patch("otx.algorithms.action.tasks.openvino.get_ovdataloader", return_value=MockDataloader(self.dataset))
-        mocker.patch(
-            "otx.algorithms.action.tasks.openvino.DataLoaderWrapper", return_value=MockDataloader(self.dataset)
-        )
-        mocker.patch("otx.algorithms.action.tasks.openvino.load_model", return_value=self.model)
-        mocker.patch("otx.algorithms.action.tasks.openvino.get_nodes_by_type", return_value=False)
-        mocker.patch("otx.algorithms.action.tasks.openvino.IEEngine", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.openvino.create_pipeline", return_value=MockPipeline())
-        mocker.patch("otx.algorithms.action.tasks.openvino.compress_model_weights", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.openvino.save_model", side_effect=mock_save_model)
-        mocker.patch(
-            "otx.algorithms.action.tasks.openvino.ActionOpenVINOTask.load_inferencer", return_value=MockOVInferencer()
-        )
-        task = ActionOpenVINOTask(self.task_environment)
-        task.optimize(OptimizationType.POT, self.dataset, self.model, OptimizationParameters())
-        assert self.model.get_data("openvino.xml") is not None
-        assert self.model.get_data("openvino.bin") is not None
-        assert self.model.model_format == ModelFormat.OPENVINO
-        assert self.model.optimization_type == ModelOptimizationType.POT
-        assert self.model.optimization_methods == [OptimizationMethod.QUANTIZATION]
-        assert self.model.precision == [ModelPrecision.INT8]
-
-
-class TestDataLoaderWrapper:
-    """Test class for DataLoaderWrapper"""
-
-    def setup(self, mocker) -> None:
-        labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
-        self.dataset = generate_action_cls_otx_dataset(1, 10, labels)
-        ovdataloader = MockDataloader(self.dataset)
-        inferencer = MockOVInferencer()
-        self.dataloader = DataLoaderWrapper(ovdataloader, inferencer)
+        assert _model.model_format == ModelFormat.OPENVINO
+        assert _model.optimization_type == ModelOptimizationType.MO
+        assert _model.precision[0] == precision
+        assert _model.get_data("openvino.bin") is not None
+        assert _model.get_data("openvino.xml") is not None
+        assert _model.get_data("confidence_threshold") is not None
+        assert _model.precision == self.det_task._precision
+        assert _model.optimization_methods == self.det_task._optimization_methods
+        assert _model.get_data("label_schema.json") is not None
 
     @e2e_pytest_unit
-    def test_len(self) -> None:
-        """Test __len__ function."""
-
-        assert len(self.dataloader) == 1
+    def test_explain(self, mocker):
+        """Test explain function."""
 
-    def test_getitem(self) -> None:
-        """Test __getitem__ function."""
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataset",
+            return_value=MockDataset(self.det_dataset, "det"),
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.build_dataloader",
+            return_value=MockDataLoader(self.det_dataset),
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.patch_data_pipeline",
+            return_value=True,
+        )
+        mocker.patch(
+            "otx.algorithms.detection.adapters.mmdet.task.build_data_parallel",
+            return_value=MockModel(TaskType.DETECTION),
+        )
 
-        out = self.dataloader[0]
-        assert out[0][0] == 0
-        assert isinstance(out[0][1], AnnotationSceneEntity)
-        assert len(out[1]) == 10
-        assert isinstance(out[2], dict)
+        explain_parameters = ExplainParameters(
+            explainer="ClassWiseSaliencyMap",
+            process_saliency_maps=False,
+            explain_predicted_classes=True,
+        )
+        outputs = self.det_task.explain(self.det_dataset, explain_parameters)
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/tasks/test_action_train.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/test_openvino_task.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,204 +1,185 @@
-"""Unit Test for otx.algorithms.action.tasks.train."""
-
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
+import copy
 import os
 
+import numpy as np
 import pytest
-import torch
-from mmcv.utils import Config
+from openvino.model_zoo.model_api.models import Model
+
+import otx.algorithms.segmentation.adapters.openvino
 
-from otx.algorithms.action.configs.base.configuration import ActionConfig
-from otx.algorithms.action.tasks.train import ActionTrainTask
-from otx.api.configuration import ConfigurableParameters
-from otx.api.entities.label import Domain
-from otx.api.entities.label_schema import LabelGroup, LabelGroupType, LabelSchemaEntity
-from otx.api.entities.metrics import (
-    BarMetricsGroup,
-    LineMetricsGroup,
-    Performance,
-    ScoreMetric,
+from otx.algorithms.segmentation.configs.base import SegmentationConfig
+from otx.algorithms.segmentation.adapters.openvino import (
+    OpenVINOSegmentationInferencer,
+    OpenVINOSegmentationTask,
+)
+from otx.api.configuration.helper import create
+from otx.api.entities.annotation import (
+    Annotation,
+    AnnotationSceneEntity,
+    AnnotationSceneKind,
 )
-from otx.api.entities.model import ModelConfiguration, ModelEntity
-from otx.api.entities.model_template import InstantiationType, TaskFamily, TaskType
-from otx.api.entities.task_environment import TaskEnvironment
+from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.label import LabelEntity
+from otx.api.entities.metrics import Performance, ScoreMetric
+from otx.api.entities.model_template import parse_model_template
+from otx.api.entities.resultset import ResultSetEntity
+from otx.api.entities.scored_label import ScoredLabel
+from otx.api.entities.shapes.polygon import Point, Polygon
+from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
+from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
+from otx.api.utils.shape_factory import ShapeFactory
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
-from tests.unit.algorithms.action.test_helpers import (
-    MockModelTemplate,
-    generate_action_cls_otx_dataset,
-    generate_labels,
+from tests.unit.algorithms.segmentation.test_helpers import (
+    DEFAULT_SEG_TEMPLATE_DIR,
+    generate_otx_dataset,
+    generate_otx_label_schema,
+    init_environment,
 )
 
 
-class TestActionTrainTask:
-    """Test class for ActionTrainTask class."""
-
+class TestOpenVINOSegmentationInferencer:
     @pytest.fixture(autouse=True)
-    def setup(self) -> None:
-        self.video_len = 3
-        self.frame_len = 3
-
-        cls_labels = generate_labels(3, Domain.ACTION_CLASSIFICATION)
-        self.cls_label_schema = LabelSchemaEntity()
-        cls_label_group = LabelGroup(
-            name="labels",
-            labels=cls_labels,
-            group_type=LabelGroupType.EXCLUSIVE,
-        )
-        self.cls_label_schema.add_group(cls_label_group)
-        cls_template = MockModelTemplate(
-            model_template_id="template_id",
-            model_template_path="template_path",
-            name="template",
-            task_family=TaskFamily.VISION,
-            task_type=TaskType.ACTION_CLASSIFICATION,
-            instantiation=InstantiationType.CLASS,
+    def setup(self, mocker) -> None:
+        model_template = parse_model_template(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        seg_params = SegmentationConfig(header=hyper_parameters.header)
+        label_schema = generate_otx_label_schema()
+        mocker.patch("otx.algorithms.segmentation.adapters.openvino.task.OpenvinoAdapter")
+        mocker.patch.object(Model, "create_model")
+        self.seg_ov_inferencer = OpenVINOSegmentationInferencer(seg_params, label_schema, "")
+        self.seg_ov_inferencer.model = mocker.patch("openvino.model_zoo.model_api.models.Model", autospec=True)
+
+        self.fake_input = np.full((5, 1), 0.1)
+
+    @e2e_pytest_unit
+    def test_pre_process(self):
+        self.seg_ov_inferencer.model.preprocess.return_value = {"foo": "bar"}
+        returned_value = self.seg_ov_inferencer.pre_process(self.fake_input)
+
+        assert returned_value == {"foo": "bar"}
+
+    @e2e_pytest_unit
+    def test_post_process(self):
+        fake_prediction = {"pred": self.fake_input}
+        fake_metadata = {"soft_prediction": self.fake_input, "feature_vector": None}
+        self.seg_ov_inferencer.model.postprocess.return_value = np.ones((5, 1))
+        returned_value = self.seg_ov_inferencer.post_process(fake_prediction, fake_metadata)
+
+        assert len(returned_value) == 3
+        assert np.array_equal(returned_value[2], self.fake_input)
+
+    @e2e_pytest_unit
+    def test_predict(self, mocker):
+        fake_output = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=[])
+        mock_pre_process = mocker.patch.object(OpenVINOSegmentationInferencer, "pre_process", return_value=("", ""))
+        mock_forward = mocker.patch.object(OpenVINOSegmentationInferencer, "forward")
+        mock_post_process = mocker.patch.object(
+            OpenVINOSegmentationInferencer, "post_process", return_value=fake_output
         )
-        self.cls_task_environment = TaskEnvironment(
-            model=None,
-            hyper_parameters=ConfigurableParameters(header="h-params"),
-            label_schema=self.cls_label_schema,
-            model_template=cls_template,
-        )
-
-        self.cls_dataset = generate_action_cls_otx_dataset(self.video_len, self.frame_len, cls_labels)
-        self.cls_task = ActionTrainTask(task_environment=self.cls_task_environment)
-
-    @e2e_pytest_unit
-    def test_save_model(self, mocker) -> None:
-        """Test save_model function."""
-
-        mocker.patch("otx.algorithms.action.tasks.train.torch.load", return_value={"state_dict": None})
+        returned_value = self.seg_ov_inferencer.predict(self.fake_input)
 
-        config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        output_model = ModelEntity(self.cls_dataset, config)
-        self.cls_task.save_model(output_model)
-        assert output_model.get_data("weights.pth") is not None
-        assert output_model.get_data("label_schema.json") is not None
-        assert output_model.precision == self.cls_task._precision
+        mock_pre_process.assert_called_once()
+        mock_forward.assert_called_once()
+        mock_post_process.assert_called_once()
+        assert returned_value == fake_output
 
     @e2e_pytest_unit
-    def test_cancel_training(self) -> None:
-        """Test cance_trainng function."""
-
-        class _MockCanceInterface:
-            def cancel(self):
-                raise RuntimeError("Checking for calling this function")
+    def test_forward(self):
+        fake_output = {"pred": np.full((5, 1), 0.9)}
+        self.seg_ov_inferencer.model.infer_sync.return_value = fake_output
+        returned_value = self.seg_ov_inferencer.forward({"image": self.fake_input})
 
-        self.cls_task.cancel_training()
-        assert self.cls_task.reserved_cancel is True
+        assert returned_value == fake_output
 
-        self.cls_task.cancel_interface = _MockCanceInterface()
-        with pytest.raises(RuntimeError):
-            self.cls_task.cancel_training()
-
-    @e2e_pytest_unit
-    def test_train(self, mocker) -> None:
-        """Test train function."""
-
-        config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        output_model = ModelEntity(self.cls_dataset, config)
-        self.cls_task._should_stop = True
-        self.cls_task.train(self.cls_dataset, output_model)
-        assert self.cls_task._should_stop is False
-        assert self.cls_task._is_training is False
-
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._init_task", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._train_model", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._get_output_model", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._get_final_eval_results", return_value=0.5)
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask.save_model", return_value=True)
-
-        self.cls_task._recipe_cfg = None
-        self.cls_task._should_stop = False
-        with pytest.raises(Exception):
-            self.cls_task.train(self.cls_dataset, output_model)
-        self.cls_task._recipe_cfg = Config()
-        self.cls_task.train(self.cls_dataset, output_model)
-        assert output_model.performance == 0.5
-        assert self.cls_task._is_training is False
-
-    @e2e_pytest_unit
-    def test_train_model(self, mocker) -> None:
-        """Test _train_model function."""
-
-        with pytest.raises(Exception):
-            self.cls_task._train_model(self.cls_dataset)
-
-        self.cls_task._recipe_cfg = Config({"work_dir": self.cls_task._output_path})
-        self.cls_task._model = torch.nn.Module()
-
-        def _mock_train_model(*args, **kwargs):
-            with open(os.path.join(self.cls_task._recipe_cfg.work_dir, "best.pth"), "wb") as f:
-                torch.save(torch.randn(1), f)
 
+class TestOpenVINOSegmentationTask:
+    @pytest.fixture(autouse=True)
+    def setup(self, mocker, otx_model) -> None:
+        model_template = parse_model_template(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        label_schema = generate_otx_label_schema()
+        task_env = init_environment(hyper_parameters, model_template)
+        seg_params = SegmentationConfig(header=hyper_parameters.header)
+        mocker.patch("otx.algorithms.segmentation.adapters.openvino.task.OpenvinoAdapter")
+        mocker.patch.object(Model, "create_model")
+        seg_ov_inferencer = OpenVINOSegmentationInferencer(seg_params, label_schema, "")
+
+        task_env.model = otx_model
+        mocker.patch.object(OpenVINOSegmentationTask, "load_inferencer", return_value=seg_ov_inferencer)
+        self.seg_ov_task = OpenVINOSegmentationTask(task_env)
+
+    @e2e_pytest_unit
+    def test_infer(self, mocker):
+        self.dataset = generate_otx_dataset()
+        fake_annotation = [
+            Annotation(
+                Polygon(points=[Point(0, 0)]),
+                id=0,
+                labels=[ScoredLabel(LabelEntity(name="fake", domain="SEGMENTATION"), probability=1.0)],
+            )
+        ]
+        fake_ann_scene = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=fake_annotation)
+        fake_input = mocker.MagicMock()
+        mock_predict = mocker.patch.object(
+            OpenVINOSegmentationInferencer, "predict", return_value=(fake_ann_scene, None, fake_input)
+        )
         mocker.patch(
-            "otx.algorithms.action.tasks.train.prepare_for_training", return_value=Config({"data": {"train": None}})
+            "otx.algorithms.segmentation.adapters.openvino.task.get_activation_map", return_value=np.zeros((5, 1))
         )
-        mocker.patch("otx.algorithms.action.tasks.train.build_dataset", return_value=True)
-        mocker.patch("otx.algorithms.action.tasks.train.train_model", side_effect=_mock_train_model)
+        mocker.patch.object(ShapeFactory, "shape_produces_valid_crop", return_value=True)
+        updated_dataset = self.seg_ov_task.infer(self.dataset)
 
-        out = self.cls_task._train_model(self.cls_dataset)
-        assert out["final_ckpt"] is not None
-        assert out["final_ckpt"].split("/")[-1] == "best.pth"
+        mock_predict.assert_called()
+        for updated in updated_dataset:
+            assert updated.annotation_scene.contains_any([LabelEntity(name="fake", domain="SEGMENTATION")])
 
     @e2e_pytest_unit
-    def test_get_output_model(self, mocker) -> None:
-        """Test _get_output_model function."""
-
-        self.cls_task._model = torch.nn.Module()
-        sample_results = {"final_ckpt": None}
-        self.cls_task._get_output_model(sample_results)
+    def test_evaluate(self, mocker):
+        result_set = ResultSetEntity(
+            model=None,
+            ground_truth_dataset=DatasetEntity(),
+            prediction_dataset=DatasetEntity(),
+        )
+        fake_metrics = mocker.patch("otx.api.usecases.evaluation.dice.DiceAverage", autospec=True)
+        fake_metrics.get_performance.return_value = Performance(
+            score=ScoreMetric(name="fake", value=0.1), dashboard_metrics="mDice"
+        )
+        mocker.patch.object(MetricsHelper, "compute_dice_averaged_over_pixels", return_value=fake_metrics)
+        self.seg_ov_task.evaluate(result_set)
 
-        mocker.patch("otx.algorithms.action.tasks.train.torch.load", return_value={"state_dict": {}})
-        sample_results = {"final_ckpt": "checkpoint_file_path"}
-        self.cls_task._get_output_model(sample_results)
+        assert result_set.performance.score.value == 0.1
 
     @e2e_pytest_unit
-    def test_get_final_eval_results(self, mocker) -> None:
-        """Test _get_final_eval_results."""
-
-        class _mock_metric:
-            def __init__(self):
-                self.performance = Performance(ScoreMetric("accuracy", 1.0))
-
-            def get_performance(self):
-                return self.performance
-
-        config = ModelConfiguration(ActionConfig(), self.cls_label_schema)
-        output_model = ModelEntity(self.cls_dataset, config)
-
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._infer_model", return_value=(True, True))
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._add_predictions_to_dataset", return_value=True)
-        mocker.patch(
-            "otx.algorithms.action.tasks.train.ActionTrainTask._add_det_predictions_to_dataset", return_value=True
-        )
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._generate_training_metrics", return_value=[])
-
-        mocker.patch("otx.algorithms.action.tasks.train.ActionTrainTask._get_metric", return_value=_mock_metric())
-        self.cls_task._recipe_cfg = Config({"evaluation": {"final_metric": "accuracy"}})
-        performance = self.cls_task._get_final_eval_results(self.cls_dataset, output_model)
-        assert performance.score.name == "accuracy"
-        assert performance.score.value == 1.0
-
-        self.cls_task._task_type = TaskType.ACTION_DETECTION
-        performance = self.cls_task._get_final_eval_results(self.cls_dataset, output_model)
-
-    @e2e_pytest_unit
-    def test_generate_training_metrics(self) -> None:
-        """Test _generate_training_metrics fucntion."""
-
-        class MockCurve:
-            def __init__(self, x: list, y: list):
-                self.x = x
-                self.y = y
-
-        sample_learning_curve = {
-            "dummy0": MockCurve([0, 1, 2], [2, 1, 0]),
-            "dummy1": MockCurve([0, 1, 2], [2, 1]),
-        }
-        output = self.cls_task._generate_training_metrics(sample_learning_curve, 1.0, "accuracy")
-        assert isinstance(output[0], LineMetricsGroup)
-        assert isinstance(output[-1], BarMetricsGroup)
+    def test_deploy(self, otx_model):
+        output_model = copy.deepcopy(otx_model)
+        self.seg_ov_task.model.set_data("openvino.bin", b"foo")
+        self.seg_ov_task.model.set_data("openvino.xml", b"bar")
+        self.seg_ov_task.deploy(output_model)
+
+        assert output_model.exportable_code is not None
+
+    @e2e_pytest_unit
+    def test_optimize(self, mocker, otx_model):
+        def patch_save_model(model, dir_path, model_name):
+            with open(f"{dir_path}/{model_name}.xml", "wb") as f:
+                f.write(b"foo")
+            with open(f"{dir_path}/{model_name}.bin", "wb") as f:
+                f.write(b"bar")
+
+        dataset = generate_otx_dataset()
+        output_model = copy.deepcopy(otx_model)
+        self.seg_ov_task.model.set_data("openvino.bin", b"foo")
+        self.seg_ov_task.model.set_data("openvino.xml", b"bar")
+        mocker.patch("otx.algorithms.segmentation.adapters.openvino.task.load_model", autospec=True)
+        mocker.patch("otx.algorithms.segmentation.adapters.openvino.task.create_pipeline", autospec=True)
+        mocker.patch("otx.algorithms.segmentation.adapters.openvino.task.save_model", new=patch_save_model)
+        spy_compress = mocker.spy(otx.algorithms.segmentation.adapters.openvino.task, "compress_model_weights")
+        self.seg_ov_task.optimize(OptimizationType.POT, dataset=dataset, output_model=output_model)
+
+        spy_compress.assert_called_once()
+        assert self.seg_ov_task.model.get_data("openvino.bin")
+        assert self.seg_ov_task.model.get_data("openvino.xml")
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/test_helpers.py`

 * *Files 16% similar despite different names*

```diff
@@ -18,14 +18,16 @@
 from otx.api.entities.id import ID
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.metadata import MetadataItemEntity, VideoMetadata
 from otx.api.entities.model_template import ModelTemplate
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.rectangle import Rectangle
+from otx.api.entities.subset import Subset
+from otx.api.entities.task_environment import TaskEnvironment
 
 
 class MockImage(Image):
     """Mock class for Image entity."""
 
     def __init__(self, file_path):
         self.__file_path = file_path
@@ -53,53 +55,64 @@
 
 
 def generate_action_cls_otx_dataset(video_len: int, frame_len: int, labels: List[LabelEntity]) -> DatasetEntity:
     """Generate otx_dataset for action classification task."""
 
     items: List[DatasetItemEntity] = []
     for video_id in range(video_len):
+        if video_id > 1:
+            subset = Subset.VALIDATION
+        else:
+            subset = Subset.TRAINING
         for frame_idx in range(frame_len):
             item = DatasetItemEntity(
                 media=MockImage(f"{video_id}_{frame_idx}.png"),
                 annotation_scene=AnnotationSceneEntity(
                     annotations=[Annotation(Rectangle.generate_full_box(), [ScoredLabel(labels[video_id])])],
                     kind=AnnotationSceneKind.ANNOTATION,
                 ),
                 metadata=[MetadataItemEntity(data=VideoMetadata(video_id, frame_idx, is_empty_frame=False))],
+                subset=subset,
             )
             items.append(item)
     dataset = DatasetEntity(items=items)
     return dataset
 
 
 def generate_action_det_otx_dataset(video_len: int, frame_len: int, labels: List[LabelEntity]) -> DatasetEntity:
     """Generate otx_dataset for action detection task."""
 
     items: List[DatasetItemEntity] = []
     proposals: Dict[str, List[float]] = {}
     for video_id in range(video_len):
+        if video_id > 1:
+            subset = Subset.VALIDATION
+        else:
+            subset = Subset.TRAINING
         for frame_idx in range(frame_len):
             if frame_idx % 2 == 0:
                 item = DatasetItemEntity(
                     media=MockImage(f"{video_id}_{frame_idx}.png"),
                     annotation_scene=AnnotationSceneEntity(
                         annotations=[Annotation(Rectangle.generate_full_box(), [ScoredLabel(labels[video_id])])],
                         kind=AnnotationSceneKind.ANNOTATION,
                     ),
                     metadata=[MetadataItemEntity(data=VideoMetadata(str(video_id), frame_idx, is_empty_frame=False))],
+                    subset=subset,
                 )
                 proposals[f"{video_id},{frame_idx:04d}"] = [0.0, 0.0, 1.0, 1.0]
             else:
                 item = DatasetItemEntity(
                     media=MockImage(f"{video_id}_{frame_idx}.png"),
                     annotation_scene=AnnotationSceneEntity(
                         annotations=[Annotation(Rectangle.generate_full_box(), [ScoredLabel(labels[video_id])])],
                         kind=AnnotationSceneKind.ANNOTATION,
                     ),
                     metadata=[MetadataItemEntity(data=VideoMetadata(str(video_id), frame_idx, is_empty_frame=True))],
+                    subset=subset,
                 )
             items.append(item)
     dataset = DatasetEntity(items=items)
     return dataset, proposals
 
 
 class MockModelTemplate(ModelTemplate):
@@ -113,7 +126,18 @@
     """This function returns its args."""
     return args, kwargs
 
 
 def return_inputs(inputs):
     """This function returns its input."""
     return inputs
+
+
+def init_environment(params, model_template, label_schema):
+    """Initialize environment."""
+    environment = TaskEnvironment(
+        model=None,
+        hyper_parameters=params,
+        label_schema=label_schema,
+        model_template=model_template,
+    )
+    return environment
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/tools/test_action_sample_classification.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/tools/test_action_sample_detection.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,16 +1,17 @@
-"""Unit Test for otx.algorithms.action.tools.sample_classification."""
+"""Unit Test for otx.algorithms.action.tools.sample_detection."""
 
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
+import pytest
 from mmcv.utils import Config
 
-from otx.algorithms.action.tools.sample_classification import (
+from otx.algorithms.action.tools.sample_detection import (
     load_test_dataset,
     main,
     parse_args,
 )
 from otx.algorithms.common.configs.training_base import TrainType
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import Domain
@@ -33,26 +34,26 @@
 
         def add_argument(self, name, *args, **kwargs):
             setattr(self, name.split("--")[-1], True)
 
         def parse_args(self):
             return self
 
-    mocker.patch("otx.algorithms.action.tools.sample_classification.argparse.ArgumentParser", side_effect=MockArgParser)
+    mocker.patch("otx.algorithms.action.tools.sample_detection.argparse.ArgumentParser", side_effect=MockArgParser)
     parser = parse_args()
     assert parser.template_file_path is not None
     assert parser.export is not None
 
 
 @e2e_pytest_unit
 def test_load_test_dataset() -> None:
     """Test laod_test_dataset function."""
 
     class MockTemplate:
-        task_type = TaskType.ACTION_CLASSIFICATION
+        task_type = TaskType.ACTION_DETECTION
         hyper_parameters = Config(
             {"parameter_overrides": {"algo_backend": {"train_type": {"default_value": TrainType.Incremental.value}}}}
         )
 
     dataset, label_schema = load_test_dataset(MockTemplate())
     isinstance(dataset, DatasetEntity)
     isinstance(label_schema, LabelSchemaEntity)
@@ -89,32 +90,33 @@
         def export(self, export_type, model):
             return model
 
         def optimize(self, optimization_type, dataset, modle, params):
             pass
 
     mocker.patch(
-        "otx.algorithms.action.tools.sample_classification.parse_model_template",
+        "otx.algorithms.action.tools.sample_detection.parse_model_template",
         return_value=Config(
             {
                 "hyper_parameters": {"data": "dummy_data"},
                 "entrypoints": {"base": "dummy_base", "openvino": "dummy_base"},
             }
         ),
     )
     mocker.patch(
-        "otx.algorithms.action.tools.sample_classification.load_test_dataset",
+        "otx.algorithms.action.tools.sample_detection.load_test_dataset",
         return_value=(
-            generate_action_cls_otx_dataset(3, 3, generate_labels(3, Domain.ACTION_CLASSIFICATION)),
+            generate_action_cls_otx_dataset(3, 3, generate_labels(3, Domain.ACTION_DETECTION)),
             "dummy_label_schema",
         ),
     )
     mocker.patch(
-        "otx.algorithms.action.tools.sample_classification.create",
+        "otx.algorithms.action.tools.sample_detection.create",
         return_value=Config({"learning_parameters": {"num_iters": 4}}),
     )
-    mocker.patch("otx.algorithms.action.tools.sample_classification.TaskEnvironment", side_effect=MockTaskEnvironment)
-    mocker.patch("otx.algorithms.action.tools.sample_classification.get_task_class", return_value=MockTestCls)
+    mocker.patch("otx.algorithms.action.tools.sample_detection.TaskEnvironment", side_effect=MockTaskEnvironment)
+    mocker.patch("otx.algorithms.action.tools.sample_detection.get_task_class", return_value=MockTestCls)
     main(MockArgs())
 
     MockArgs.export = True
-    main(MockArgs())
+    with pytest.raises(Exception):
+        main(MockArgs())
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/utils/test_action_convert_public_data_to_cvat.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/utils/test_action_convert_public_data_to_cvat.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/action/utils/test_action_data.py` & `otx-1.2.0rc1/tests/unit/algorithms/action/utils/test_action_data.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_inference_callback.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_inference_callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_progress_callback.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/callbacks/test_progress_callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/adapters/data/test_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/adapters/data/test_dataset.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,25 +2,25 @@
 
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
 import pytest
 
 from otx.api.entities.model_template import TaskType
-from tests.unit.algorithms.anomaly.helpers.dummy_dataset import ShapesDataModule
+from tests.unit.algorithms.anomaly.helpers.dummy_dataset import HazelnutDataModule
 
 
 @pytest.mark.parametrize("stage", ["predict", "fit", "validate", "test"])
 @pytest.mark.parametrize("task_type", [TaskType.ANOMALY_CLASSIFICATION, TaskType.ANOMALY_DETECTION])
 def test_dataloaders(task_type, stage):
     """Tests whether the datamodule can load the data correctly.
 
     For all the test stages and the task types, the datamodule should return the correct keys.
     """
-    datamodule = ShapesDataModule(task_type)
+    datamodule = HazelnutDataModule(task_type)
     datamodule.setup(stage)
     if stage == "fit":
         batch = next(iter(datamodule.train_dataloader()))
     elif stage == "validate":
         batch = next(iter(datamodule.val_dataloader()))
     elif stage == "test":
         batch = next(iter(datamodule.test_dataloader()))
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/config/test_model_config_load.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/config/test_model_config_load.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/conftest.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/conftest.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 
 import pytest
 
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.task_environment import TaskEnvironment
-from tests.unit.algorithms.anomaly.helpers.dummy_dataset import get_shapes_dataset
+from tests.unit.algorithms.anomaly.helpers.dummy_dataset import get_hazelnut_dataset
 from tests.unit.algorithms.anomaly.helpers.utils import create_task_environment
 
 
 @dataclass(frozen=True)  # this ensures that the objects are immutable across tests
 class TestEnvironment:
     """Test environment for anomaly tests."""
 
@@ -26,15 +26,15 @@
 
 @pytest.fixture(
     scope="session", params=[TaskType.ANOMALY_CLASSIFICATION, TaskType.ANOMALY_DETECTION, TaskType.ANOMALY_SEGMENTATION]
 )
 def setup_task_environment(request):
     """Returns a task environment, a model and datset."""
     task_type = request.param
-    dataset: DatasetEntity = get_shapes_dataset(task_type, one_each=True)
+    dataset: DatasetEntity = get_hazelnut_dataset(task_type, one_each=True)
     task_environment = create_task_environment(dataset, task_type)
     output_model = ModelEntity(
         dataset,
         task_environment.get_model_configuration(),
     )
     environment = TestEnvironment(task_environment, output_model, dataset, task_type)
     return environment
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/dummy_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/dummy_dataset.py`

 * *Files 3% similar despite different names*

```diff
@@ -36,16 +36,16 @@
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.scored_label import ScoredLabel
 from otx.api.entities.shapes.polygon import Point, Polygon
 from otx.api.entities.shapes.rectangle import Rectangle
 from otx.api.entities.subset import Subset
 
 
-def get_shapes_dataset(task_type: TaskType, one_each: bool = False) -> DatasetEntity:
-    """Get shapes dataset.
+def get_hazelnut_dataset(task_type: TaskType, one_each: bool = False) -> DatasetEntity:
+    """Get hazelnut dataset.
 
     Args:
         task_type (TaskType): Task type.
         one_each (bool): If this flag is true then it will sample one normal and one abnormal image for each split.
             The training split will have only one normal image. Defaults to False.
     """
     dataset: DatasetEntity
@@ -140,16 +140,16 @@
     def val_dataloader(self) -> DataLoader:
         return DataLoader(self.dataset, pin_memory=True)
 
     def predict_dataloader(self) -> DataLoader:
         return DataLoader(self.dataset, shuffle=False, pin_memory=True)
 
 
-class ShapesDataModule(OTXAnomalyDataModule):
-    """Creates datamodule with shapes dataset.
+class HazelnutDataModule(OTXAnomalyDataModule):
+    """Creates datamodule with hazelnut dataset.
 
     Args:
         task_type (TaskType): Task type (classification, detection, segmentation)
     """
 
     def __init__(self, task_type: TaskType):
         self.config = OmegaConf.create(
@@ -160,21 +160,20 @@
                     "test_batch_size": 32,
                     "num_workers": 2,
                     "image_size": [32, 32],
                     "transform_config": {"train": None},
                 }
             }
         )
-        # self.dataset = ShapesDataset(get_shapes_dataset(task_type), task_type, self.config)
-        self.dataset = get_shapes_dataset(task_type)
+        self.dataset = get_hazelnut_dataset(task_type)
         super().__init__(config=self.config, dataset=self.dataset, task_type=task_type)
 
 
 def _get_annotations(task: str) -> Tuple[Dict, Dict, Dict]:
     ann_file_root = Path("tests", "assets", "anomaly", task)
-    data_root = Path("tests", "assets", "anomaly", "shapes")
+    data_root = Path("tests", "assets", "anomaly", "hazelnut")
 
     train_subset = {"ann_file": str(ann_file_root / "train.json"), "data_root": str(data_root)}
     test_subset = {"ann_file": str(ann_file_root / "test.json"), "data_root": str(data_root)}
 
     val_subset = {"ann_file": str(ann_file_root / "val.json"), "data_root": str(data_root)}
     return train_subset, test_subset, val_subset
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/dummy_model.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/dummy_model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/helpers/utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/helpers/utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_inference.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_inference.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,33 @@
 """Tests the methods in the Inference task."""
 
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
+import pytest
+
 from copy import deepcopy
 
 from otx.algorithms.anomaly.tasks.inference import InferenceTask
 from otx.algorithms.anomaly.tasks.train import TrainingTask
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.inference_parameters import InferenceParameters
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.resultset import ResultSetEntity
 from otx.api.entities.subset import Subset
 from otx.api.usecases.tasks.interfaces.export_interface import ExportType
-from tests.unit.algorithms.anomaly.helpers.dummy_dataset import get_shapes_dataset
+from tests.unit.algorithms.anomaly.helpers.dummy_dataset import get_hazelnut_dataset
 from tests.unit.algorithms.anomaly.helpers.utils import create_task_environment
 
 
 class TestInferenceTask:
     """Tests the methods in the inference task."""
 
+    @pytest.mark.skip(reason="CVS-107918 FAIL code -11 in anomaly unit test on python3.10")
     def test_inference(self, tmpdir, setup_task_environment):
         """Tests the inference method."""
         root = str(tmpdir.mkdir("anomaly_inference_test"))
 
         # Get task environment
         setup_task_environment = deepcopy(setup_task_environment)  # since fixture is mutable
         task_environment = setup_task_environment.task_environment
@@ -37,15 +40,15 @@
         train_task = TrainingTask(task_environment, output_path=root)
         dataset = train_task.infer(dataset.with_empty_annotations(), InferenceParameters(is_evaluation=True))
         train_task.save_model(output_model)
         # 2. check if the model is saved correctly
         assert output_model.get_data("weights.pth") is not None  # Should not raise an error
 
         # 3. Create new task environment and inference task and test inference
-        new_dataset: DatasetEntity = get_shapes_dataset(task_type, one_each=True)
+        new_dataset: DatasetEntity = get_hazelnut_dataset(task_type, one_each=True)
         gt_val_dataset = new_dataset.get_subset(Subset.VALIDATION)
         new_task_environment = create_task_environment(gt_val_dataset, task_type)
         # this loads the output model from the previous training task when creating the new InferenceTask
         new_task_environment.model = output_model
         inference_task = InferenceTask(new_task_environment, output_path=root)
         pred_val_dataset = inference_task.infer(
             gt_val_dataset.with_empty_annotations(), InferenceParameters(is_evaluation=True)
@@ -69,9 +72,10 @@
         inference_task.evaluate(result_set)
         if task_type in (TaskType.ANOMALY_CLASSIFICATION, TaskType.ANOMALY_DETECTION):
             assert result_set.performance.score.name == "f-measure"
         elif task_type == TaskType.ANOMALY_SEGMENTATION:
             assert result_set.performance.score.name == "Dice Average"
 
         # 5. Check if OpenVINO model can be generated
-        inference_task.export(ExportType.OPENVINO, output_model)
+        inference_task.export(ExportType.OPENVINO, output_model, dump_features=False)
         assert output_model.get_data("openvino.bin") is not None  # Should not raise an error
+        assert not output_model.has_xai
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_nncf.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_nncf.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,25 +1,27 @@
 """Tests the methods in the NNCF task."""
 
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
+import pytest
 from copy import deepcopy
 
 from otx.algorithms.anomaly.tasks.nncf import NNCFTask
 from otx.algorithms.anomaly.tasks.train import TrainingTask
 from otx.api.entities.model import ModelEntity, ModelOptimizationType
 from otx.api.entities.train_parameters import TrainParameters
 from otx.api.usecases.tasks.interfaces.export_interface import ExportType
 from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
 
 
 class TestNNCFTask:
     """Tests methods in the NNCF task."""
 
+    @pytest.mark.skip(reason="CVS-107918 FAIL code -11 in anomaly unit test on python3.10")
     def test_nncf(self, tmpdir, setup_task_environment):
         """Tests the NNCF optimize method."""
         root = str(tmpdir.mkdir("anomaly_nncf_test"))
 
         # Get task environment
         setup_task_environment = deepcopy(setup_task_environment)  # since fixture is mutable
         task_environment = setup_task_environment.task_environment
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_openvino.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_openvino.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """Tests the methods in the OpenVINO task."""
 
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
+import pytest
 from copy import deepcopy
 
 import numpy as np
 
 from otx.algorithms.anomaly.tasks.openvino import OpenVINOTask
 from otx.algorithms.anomaly.tasks.train import TrainingTask
 from otx.api.entities.datasets import DatasetEntity
@@ -29,14 +30,15 @@
         This is needed as untrained model might have nan values for normalization parameters which will raise an error.
         """
         output_model.set_data("image_threshold", np.float32(0.5).tobytes())
         output_model.set_data("pixel_threshold", np.float32(0.5).tobytes())
         output_model.set_data("min", np.float32(0).tobytes())
         output_model.set_data("max", np.float32(1).tobytes())
 
+    @pytest.mark.skip(reason="CVS-107918 FAIL code -11 in anomaly unit test on python3.10")
     def test_openvino(self, tmpdir, setup_task_environment):
         """Tests the OpenVINO optimize method."""
         root = str(tmpdir.mkdir("anomaly_openvino_test"))
 
         setup_task_environment = deepcopy(setup_task_environment)  # since fixture is mutable
         task_type = setup_task_environment.task_type
         dataset: DatasetEntity = setup_task_environment.dataset
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/anomaly/tasks/test_train.py` & `otx-1.2.0rc1/tests/unit/algorithms/anomaly/tasks/test_train.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,14 @@
 """Tests the methods in the train task."""
 
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 
+import pytest
+
 from copy import deepcopy
 
 from torch import nn
 
 from otx.algorithms.anomaly.tasks.train import TrainingTask
 from otx.api.entities.train_parameters import TrainParameters
 from tests.unit.algorithms.anomaly.helpers.utils import create_task_environment
@@ -20,14 +22,15 @@
         state_dict1 = model1.state_dict()
         state_dict2 = model2.state_dict()
         for (key1, param1), (key2, param2) in zip(state_dict1.items(), state_dict2.items()):
             assert key1 == key2
             if not param1.data.isnan().any() and "bn" not in key1:
                 assert param1.data.allclose(param2.data)
 
+    @pytest.mark.skip(reason="CVS-107918 FAIL code -11 in anomaly unit test on python3.10")
     def test_train_and_load(self, tmpdir, setup_task_environment):
         """Tests the train method and check if it can be loaded correctly."""
         root = str(tmpdir.mkdir("anomaly_training_test"))
 
         # Get task environment
         setup_task_environment = deepcopy(setup_task_environment)  # since fixture is mutable
         task_environment = setup_task_environment.task_environment
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_datasets.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_datasets.py`

 * *Files 10% similar despite different names*

```diff
@@ -53,35 +53,14 @@
         self.otx_dataset, _ = create_cls_dataset()
         self.pipeline = {
             "view0": [dict(type="ImageToTensor", keys=["img"])],
             "view1": [dict(type="ImageToTensor", keys=["img"])],
         }
 
     @e2e_pytest_unit
-    def test_self_sl_dataset_init_params_validation(self):
-        """Test SelfSLDataset initialization parameters validation."""
-        correct_values_dict = {
-            "otx_dataset": self.otx_dataset,
-            "pipeline": self.pipeline,
-        }
-        unexpected_str = "unexpected string"
-        unexpected_values = [
-            # Unexpected string is specified as "otx_dataset" parameter
-            ("otx_dataset", unexpected_str),
-            # Unexpected string is specified as "pipeline" parameter
-            ("pipeline", unexpected_str),
-        ]
-
-        check_value_error_exception_raised(
-            correct_parameters=correct_values_dict,
-            unexpected_values=unexpected_values,
-            class_or_function=SelfSLDataset,
-        )
-
-    @e2e_pytest_unit
     def test_getitem(self):
         """Test __getitem__ method."""
         dataset = SelfSLDataset(otx_dataset=self.otx_dataset, pipeline=self.pipeline)
 
         data_item = dataset[0]
         for i in range(1, 3):
             assert f"dataset_item{i}" in data_item
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_pipelines.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/data/test_pipelines.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_byol.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_byol.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_classifier.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_mlc_classifier.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_semisl_mlc_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_supcon_classifier.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/classifiers/test_supcon_classifier.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_contrastive_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_contrastive_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_cls_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_hierarchical_cls_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_hierarchical_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_multilabel_cls_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_custom_multilabel_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_multilabel_semisl.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_multilabel_semisl.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_semisl_cls_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/heads/test_semisl_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_asymmetric_multilabel.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_asymmetric_multilabel.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_cross_entropy.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/losses/test_cross_entropy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/test_selfsl_mlp.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/models/necks/test_selfsl_mlp.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_builder.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_builder.py`

 * *Files 4% similar despite different names*

```diff
@@ -28,14 +28,15 @@
     create_dataset(lib="mmcls")
 
     with tempfile.TemporaryDirectory() as tempdir:
         model_path = os.path.join(tempdir, "model.bin")
         state_to_build = model.state_dict()
         torch.save(state_to_build, model_path)
         mock_config.load_from = model_path
+        mock_config.nncf_config.log_dir = tempdir
         ctrl, model = build_nncf_classifier(mock_config)
         assert isinstance(model, NNCFNetwork)
         assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
         mock_config.pop("custom_hooks")
 
         torch.save(
             {
@@ -47,10 +48,11 @@
                         state_to_build=state_to_build,
                     ),
                 },
                 "state_dict": model.state_dict(),
             },
             model_path,
         )
+        mock_config.nncf_config.log_dir = tempdir
         ctrl, model = build_nncf_classifier(mock_config, model_path)
         assert isinstance(model, NNCFNetwork)
         assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_registers.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/nncf/test_mmcls_nncf_registers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/test_lars.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/optimizer/test_lars.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/mmcls/test_cls_config_builder.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/mmcls/test_cls_config_builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/adapters/openvino/test_openvino_models.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/adapters/openvino/test_openvino_models.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_nncf.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/test_classification_nncf.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import pytest
 from mmcv.utils import Config
 
-from otx.algorithms.classification.tasks import ClassificationNNCFTask
-from otx.algorithms.common.tasks import BaseTask
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
+from otx.algorithms.classification.adapters.mmcls.nncf.task import (
+    ClassificationNNCFTask,
+)
 from otx.api.configuration.configurable_parameters import ConfigurableParameters
 from otx.api.configuration.helper import create
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.metrics import NullPerformance
 from otx.api.entities.model import ModelConfiguration, ModelEntity
 from otx.api.entities.model_template import parse_model_template
@@ -56,23 +56,21 @@
         from otx.algorithms.common.adapters.mmcv.hooks import OTXLoggerHook
 
         # generate some dummy learning curves
         mock_lcurve_val = OTXLoggerHook.Curve()
         mock_lcurve_val.x = [0, 1]
         mock_lcurve_val.y = [0.1, 0.2]
         # patch training process
-        mocker.patch.object(BaseTask, "_run_task", return_value={"final_ckpt": ""})
         self.cls_nncf_task._learning_curves = {"val/accuracy_top-1": mock_lcurve_val}
         mocker.patch.object(ClassificationNNCFTask, "save_model")
+        mocker.patch.object(ClassificationNNCFTask, "_train_model")
+        mocker.patch(
+            "otx.algorithms.classification.adapters.mmcls.nncf.task.build_nncf_classifier",
+            return_value=(
+                mocker.MagicMock(),
+                mocker.MagicMock(),
+            ),
+        )
         self.cls_nncf_task.optimize(OptimizationType.NNCF, self.dataset, self.model)
 
         assert self.model.performance != NullPerformance()
         assert self.model.performance.score.value == 0.2
-
-    @e2e_pytest_unit
-    def test_initialize(self, mocker):
-        """Test initialize method in OTXDetTaskNNCF."""
-        options = {}
-        self.cls_nncf_task._initialize(options)
-
-        assert "model_builder" in options
-        assert NNCFBaseTask.model_builder == options["model_builder"].func
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_openvino_task.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/tasks/test_classification_openvino_task.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 
 import copy
 
 import numpy as np
 import pytest
 from openvino.model_zoo.model_api.models import Model
 
-import otx.algorithms.classification.tasks.openvino
-from otx.algorithms.classification.configs.base import ClassificationConfig
-from otx.algorithms.classification.tasks.openvino import (
+import otx.algorithms.classification.adapters.openvino.task
+from otx.algorithms.classification.adapters.openvino.task import (
     ClassificationOpenVINOInferencer,
     ClassificationOpenVINOTask,
 )
+from otx.algorithms.classification.configs.base import ClassificationConfig
 from otx.api.configuration.configurable_parameters import ConfigurableParameters
 from otx.api.entities.annotation import (
     Annotation,
     AnnotationSceneEntity,
     AnnotationSceneKind,
 )
 from otx.api.entities.datasets import DatasetEntity
@@ -50,15 +50,15 @@
 class TestOpenVINOClassificationInferencer:
     @pytest.fixture(autouse=True)
     def setup(self, mocker) -> None:
         hyper_parameters, model_template = setup_configurable_parameters(DEFAULT_CLS_TEMPLATE)
         cls_params = ClassificationConfig(header=hyper_parameters.header)
         environment, dataset = init_environment(hyper_parameters, model_template)
         self.label_schema = environment.label_schema
-        mocker.patch("otx.algorithms.classification.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.classification.adapters.openvino.task.OpenvinoAdapter")
         mocker.patch.object(Model, "create_model")
         self.cls_ov_inferencer = ClassificationOpenVINOInferencer(cls_params, self.label_schema, "")
         model_path = "otx.algorithms.classification.adapters.openvino.model_wrappers.openvino_models.OTXClassification"
         self.cls_ov_inferencer.model = mocker.patch(model_path, autospec=True)
         self.fake_input = np.random.rand(3, 224, 224)
 
     @e2e_pytest_unit
@@ -111,15 +111,15 @@
 class TestOpenVINOClassificationTask:
     @pytest.fixture(autouse=True)
     def setup(self, mocker, otx_model) -> None:
         hyper_parameters, model_template = setup_configurable_parameters(DEFAULT_CLS_TEMPLATE)
         cls_params = ClassificationConfig(header=hyper_parameters.header)
         self.task_env, self.dataset = init_environment(params=hyper_parameters, model_template=model_template)
         self.label_schema = self.task_env.label_schema
-        mocker.patch("otx.algorithms.classification.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.classification.adapters.openvino.task.OpenvinoAdapter")
         mocker.patch.object(Model, "create_model")
         cls_ov_inferencer = ClassificationOpenVINOInferencer(cls_params, self.label_schema, "")
         self.task_env.model = otx_model
         mocker.patch.object(ClassificationOpenVINOTask, "load_inferencer", return_value=cls_ov_inferencer)
         self.cls_ov_task = ClassificationOpenVINOTask(self.task_env)
         self.labels = self.label_schema.get_labels(include_empty=True)
         fake_annotation = [
@@ -197,16 +197,16 @@
                 f.write(b"foo")
             with open(f"{dir_path}/{model_name}.bin", "wb") as f:
                 f.write(b"bar")
 
         output_model = copy.deepcopy(otx_model)
         self.cls_ov_task.model.set_data("openvino.bin", b"foo")
         self.cls_ov_task.model.set_data("openvino.xml", b"bar")
-        mocker.patch("otx.algorithms.classification.tasks.openvino.load_model", autospec=True)
-        mocker.patch("otx.algorithms.classification.tasks.openvino.create_pipeline", autospec=True)
-        mocker.patch("otx.algorithms.classification.tasks.openvino.save_model", new=patch_save_model)
-        spy_compress = mocker.spy(otx.algorithms.classification.tasks.openvino, "compress_model_weights")
+        mocker.patch("otx.algorithms.classification.adapters.openvino.task.load_model", autospec=True)
+        mocker.patch("otx.algorithms.classification.adapters.openvino.task.create_pipeline", autospec=True)
+        mocker.patch("otx.algorithms.classification.adapters.openvino.task.save_model", new=patch_save_model)
+        spy_compress = mocker.spy(otx.algorithms.classification.adapters.openvino.task, "compress_model_weights")
         self.cls_ov_task.optimize(OptimizationType.POT, dataset=self.dataset, output_model=output_model)
 
         spy_compress.assert_called_once()
         assert self.cls_ov_task.model.get_data("openvino.bin")
         assert self.cls_ov_task.model.get_data("openvino.xml")
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/tasks/test_classification_train_task.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/test_otx_segmentation_task.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,68 +1,67 @@
+"""Test MMSegmentationTask."""
 # Copyright (C) 2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
+import os
+import torch
 import pytest
+from mmcv import ConfigDict
 
-from otx.algorithms.classification.tasks import ClassificationTrainTask
-from otx.algorithms.common.tasks import BaseTask
-from otx.api.configuration.configurable_parameters import ConfigurableParameters
-from otx.api.entities.datasets import DatasetEntity
-from otx.api.entities.label_schema import LabelSchemaEntity
-from otx.api.entities.metrics import NullPerformance
-from otx.api.entities.model import ModelConfiguration, ModelEntity
+from otx.algorithms.segmentation.adapters.mmseg.task import MMSegmentationTask
+from otx.api.configuration.helper import create
+from otx.api.entities.model_template import (
+    parse_model_template,
+)
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
-from tests.unit.algorithms.classification.test_helper import (
-    DEFAULT_CLS_TEMPLATE,
+from tests.unit.algorithms.segmentation.test_helpers import (
+    DEFAULT_SEG_TEMPLATE_DIR,
     init_environment,
-    setup_configurable_parameters,
 )
 
 
-@pytest.fixture
-def otx_model():
-    model_configuration = ModelConfiguration(
-        configurable_parameters=ConfigurableParameters(header="header", description="description"),
-        label_schema=LabelSchemaEntity(),
-    )
-    return ModelEntity(train_dataset=DatasetEntity(), configuration=model_configuration)
-
-
-class TestOTXClsTaskTrain:
+class TestMMSegmentationTask:
     @pytest.fixture(autouse=True)
-    def setup(self, otx_model, tmp_dir_path) -> None:
-        hyper_parameters, model_template = setup_configurable_parameters(DEFAULT_CLS_TEMPLATE)
-        self.task_env, self.dataset = init_environment(params=hyper_parameters, model_template=model_template)
-        self.model = otx_model
-        self.cls_train_task = ClassificationTrainTask(self.task_env, output_path=str(tmp_dir_path))
+    def setup(self, mocker):
+        model_template = parse_model_template(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        task_env = init_environment(hyper_parameters, model_template)
+        self.mmseg_task = MMSegmentationTask(task_env)
+        self.mmseg_task._init_task()
 
     @e2e_pytest_unit
-    def test_save_model(self, mocker):
-        mocker.patch("torch.load", return_value="")
-        self.cls_train_task.save_model(self.model)
-
-        assert self.model.get_data("weights.pth")
-        assert self.model.get_data("label_schema.json")
+    def test_configure(self):
+        cfg = self.mmseg_task.configure()
+        assert "work_dir" in cfg
+        assert "resume" in cfg
 
     @e2e_pytest_unit
-    def test_train(self, mocker):
-        from otx.algorithms.common.adapters.mmcv.hooks import OTXLoggerHook
-
-        # generate some dummy learning curves
-        mock_lcurve_val = OTXLoggerHook.Curve()
-        mock_lcurve_val.x = [0, 1]
-        mock_lcurve_val.y = [0.1, 0.2]
-        # patch training process
-        mocker.patch.object(BaseTask, "_run_task", return_value={"final_ckpt": ""})
-        self.cls_train_task._learning_curves = {"val/accuracy_top-1": mock_lcurve_val}
-        mocker.patch.object(ClassificationTrainTask, "save_model")
-        self.cls_train_task.train(self.dataset, self.model)
+    def test_build_model(self, mocker):
+        mocker.patch("otx.algorithms.segmentation.adapters.mmseg.utils.builder.build_segmentor")
+        self.mmseg_task._recipe_cfg.model.decode_head.type = "CustomFCNHead"
+        self.mmseg_task._recipe_cfg.model.task_adapt = ConfigDict(
+            op="REPLACE",
+            type="mpa",
+            final=["background", "target"],
+            src_classes=[],
+            dst_classes=["background", "target"],
+        )
+        model = self.mmseg_task.build_model(self.mmseg_task._recipe_cfg, fp16=True)
+        assert isinstance(model, torch.nn.Module)
+        assert model.fp16_enabled
 
-        assert self.model.performance != NullPerformance()
-        assert self.model.performance.score.value == 0.2
+    @e2e_pytest_unit
+    def test_update_override_configurations(self):
+        cfg = ConfigDict(fake_key="fake_value")
+        self.mmseg_task.update_override_configurations(cfg)
+        assert "fake_key" in self.mmseg_task.override_configs
+        assert self.mmseg_task.override_configs == dict(fake_key="fake_value")
 
     @e2e_pytest_unit
-    def test_cancel_training(self):
-        self.cls_train_task.cancel_training()
+    def test_save_model(self, otx_model, mocker):
+        mocker_load = mocker.patch("torch.load", return_value="foo")
+        mocker_save = mocker.patch("torch.save")
+        self.mmseg_task.save_model(otx_model)
 
-        assert self.cls_train_task._should_stop is True
+        mocker_load.assert_called_once()
+        mocker_save.assert_called_once()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/test_helper.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/test_helper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/classification/utils/test_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/classification/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_adaptive_training_hooks.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_adaptive_training_hooks.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_cancel_interface_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_cancel_interface_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_checkpoint_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_checkpoint_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_composed_dataloader_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_composed_dataloader_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_early_stopping_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_early_stopping_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ema_v2_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ema_v2_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_eval_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_eval_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_fp16_sam_optimizer_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_fp16_sam_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ib_loss_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_ib_loss_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_logger_replace_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_logger_replace_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_model_ema_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_model_ema_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_no_bias_decay_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_no_bias_decay_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_recording_forward_hooks.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_recording_forward_hooks.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_save_initial_weight_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_save_initial_weight_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_semisl_cls_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_semisl_cls_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_task_adapt_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_task_adapt_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_unbiased_teacher_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_unbiased_teacher_hook.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_helpers.py`

 * *Files 1% similar despite different names*

```diff
@@ -252,21 +252,22 @@
         for data in loader:
             out.append(torch.sigmoid(model(**data)))
         return torch.cat(out)
 
     return evaluate_fn
 
 
-def create_nncf_model():
+def create_nncf_model(workdir):
     mock_model = create_model()
     mock_config = create_config()
     mock_eval_fn = create_eval_fn()
     dataloader = create_dataloader()
 
     mock_config = create_config()
+    mock_config.nncf_config.log_dir = workdir
     pipeline = Compose(mock_config.data.val.pipeline)
     get_fake_input_fn = partial(get_fake_input, pipeline)
 
     model_eval_fn = partial(
         model_eval,
         config=mock_config,
         val_dataloader=dataloader,
@@ -284,15 +285,15 @@
     )
     return ctrl, model
 
 
 def create_nncf_runner(work_dir):
     mock_config = create_config()
     dataloader = create_dataloader()
-    ctrl, model = create_nncf_model()
+    ctrl, model = create_nncf_model(work_dir)
 
     runner = AccuracyAwareRunner(
         build_data_parallel(model, mock_config),
         logger=get_logger("mmcv"),
         work_dir=work_dir,
         nncf_config=mock_config["nncf_config"],
         optimizer=SGD(model.parameters(), lr=0.01),
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_hooks.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_hooks.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
+import tempfile
 from mmcv.utils import get_logger
 
 from otx.algorithms.common.adapters.mmcv.nncf.hooks import CompressionHook
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.common.adapters.mmcv.nncf.test_helpers import (
     create_nncf_model,
 )
@@ -16,34 +17,37 @@
     def test_after_train_iter(self):
         class SimpleRunner:
             def __init__(self):
                 self.logger = get_logger("mmcv")
                 self.rank = 0
 
         runner = SimpleRunner()
-        ctrl, _ = create_nncf_model()
+        with tempfile.TemporaryDirectory() as tempdir:
+            ctrl, _ = create_nncf_model(tempdir)
         compression_hook = CompressionHook(ctrl)
         compression_hook.after_train_iter(runner)
 
     @e2e_pytest_unit
     def test_after_train_epoch(self):
         class SimpleRunner:
             def __init__(self):
                 self.logger = get_logger("mmcv")
                 self.rank = 0
 
         runner = SimpleRunner()
-        ctrl, _ = create_nncf_model()
+        with tempfile.TemporaryDirectory() as tempdir:
+            ctrl, _ = create_nncf_model(tempdir)
         compression_hook = CompressionHook(ctrl)
         compression_hook.after_train_epoch(runner)
 
     @e2e_pytest_unit
     def test_before_run(self):
         class SimpleRunner:
             def __init__(self):
                 self.logger = get_logger("mmcv")
                 self.rank = 0
 
         runner = SimpleRunner()
-        ctrl, _ = create_nncf_model()
+        with tempfile.TemporaryDirectory() as tempdir:
+            ctrl, _ = create_nncf_model(tempdir)
         compression_hook = CompressionHook(ctrl)
         compression_hook.before_run(runner)
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_runners.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_runners.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/nncf/test_mmcv_nncf_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -101,34 +101,39 @@
         model_eval,
         config=mock_config,
         val_dataloader=dataloader,
         evaluate_fn=mock_eval_fn,
         distributed=False,
     )
 
-    ctrl, model = wrap_nncf_model(
-        mock_config,
-        mock_model,
-        model_eval_fn=model_eval_fn,
-        get_fake_input_fn=get_fake_input_fn,
-        dataloader_for_init=dataloader,
-        is_accuracy_aware=True,
-    )
+    with tempfile.TemporaryDirectory() as tempdir:
+        mock_config.nncf_config.log_dir = tempdir
+        ctrl, model = wrap_nncf_model(
+            mock_config,
+            mock_model,
+            model_eval_fn=model_eval_fn,
+            get_fake_input_fn=get_fake_input_fn,
+            dataloader_for_init=dataloader,
+            is_accuracy_aware=True,
+        )
     assert isinstance(model, NNCFNetwork)
 
     mock_model = create_model()
     mock_config.nncf_config["input_info"] = {"sample_size": (1, 3, 128, 128)}
-    ctrl, model = wrap_nncf_model(
-        mock_config,
-        mock_model,
-        model_eval_fn=model_eval_fn,
-        get_fake_input_fn=get_fake_input_fn,
-        dataloader_for_init=dataloader,
-        is_accuracy_aware=True,
-    )
+
+    with tempfile.TemporaryDirectory() as tempdir:
+        mock_config.nncf_config.log_dir = tempdir
+        ctrl, model = wrap_nncf_model(
+            mock_config,
+            mock_model,
+            model_eval_fn=model_eval_fn,
+            get_fake_input_fn=get_fake_input_fn,
+            dataloader_for_init=dataloader,
+            is_accuracy_aware=True,
+        )
     assert isinstance(model, NNCFNetwork)
     mock_config.nncf_config.pop("input_info")
 
     with tempfile.TemporaryDirectory() as tempdir:
         mock_model = create_model()
         model_path = os.path.join(tempdir, "model.bin")
         torch.save(mock_model.state_dict(), model_path)
@@ -150,14 +155,17 @@
             "meta": {
                 "nncf_enable_compression": True,
                 "nncf_meta": NNCFMetaState(compression_ctrl=ctrl.get_compression_state()),
             },
             "state_dict": model.state_dict(),
         }
         mock_model = create_model()
+
+    with tempfile.TemporaryDirectory() as tempdir:
+        mock_config.nncf_config.log_dir = tempdir
         ctrl, model = wrap_nncf_model(
             mock_config,
             mock_model,
             model_eval_fn=model_eval_fn,
             get_fake_input_fn=get_fake_input_fn,
             dataloader_for_init=dataloader,
             init_state_dict=init_state_dict,
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augments.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augments.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augmix.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_augmix.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_otx_transforms.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_otx_transforms.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_random_augment.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_random_augment.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_twocrop_transform.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/pipelines/transforms/test_twocrop_transform.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_export_mixin.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_exporter.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,73 +1,68 @@
 import mmcv
 import pytest
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
-class TestExporterMixin:
+class TestExporter:
     @pytest.fixture(autouse=True)
     def setup(self, mocker):
         def mock_init_logger():
             pass
 
         def mock_configure(model_cfg, model_ckpt, data_cfg, training=False, **kwargs):
             return mmcv.ConfigDict()
 
-        self.exporter = ExporterMixin()
+        self.exporter = Exporter()
         self.exporter._init_logger = mock_init_logger
-        self.exporter.configure = mock_configure
-        self.exporter.mode = ["mock_mode", "train"]
-        fake_config = mmcv.ConfigDict(work_dir="/path/work_dir", data=dict(test=dict(dataset=mocker.MagicMock())))
-        mocker.patch.object(self.exporter, "configure", return_value=fake_config)
+        self.fake_config = mmcv.ConfigDict(work_dir="/path/work_dir", data=dict(test=dict(dataset=mocker.MagicMock())))
         mocker.patch("os.listdir")
 
     @e2e_pytest_unit
     def test_run_with_error_raise(self):
-        return_value = self.exporter.run({}, "", {}, mode="mock_mode")
+        return_value = self.exporter.run(self.fake_config)
 
         assert "outputs" in return_value
         assert return_value["outputs"] is None
         assert "msg" in return_value
 
     @e2e_pytest_unit
     def test_run_without_deploy_cfg(self, mocker):
         def mock_naive_export(output_dir, model_builder, precision, cfg, model_name="model"):
             pass
 
         self.exporter.naive_export = mock_naive_export
-        return_value = self.exporter.run({}, "", {}, mode="mock_mode", model_builder=mocker.MagicMock())
+        return_value = self.exporter.run(self.fake_config)
 
         assert "outputs" in return_value
         assert return_value["outputs"]["bin"] == "/path/work_dir/model.bin"
         assert return_value["outputs"]["xml"] == "/path/work_dir/model.xml"
         assert "msg" in return_value
         assert return_value["msg"] == ""
 
     @e2e_pytest_unit
     def test_run_with_deploy_cfg(self, mocker):
         def mock_mmdeploy_export(output_dir, model_builder, precision, cfg, deploy_cfg, model_name="model"):
             pass
 
         self.exporter.mmdeploy_export = mock_mmdeploy_export
-        return_value = self.exporter.run(
-            {}, "", {}, mode="mock_mode", model_builder=mocker.MagicMock(), deploy_cfg=mmcv.ConfigDict(deploy=True)
-        )
+        return_value = self.exporter.run(self.fake_config, deploy_cfg=mmcv.ConfigDict())
 
         assert "outputs" in return_value
         assert return_value["outputs"]["bin"] == "/path/work_dir/model.bin"
         assert return_value["outputs"]["xml"] == "/path/work_dir/model.xml"
         assert "msg" in return_value
         assert return_value["msg"] == ""
 
     @e2e_pytest_unit
     def test_mmdeploy_export(self, mocker):
         from otx.algorithms.common.adapters.mmdeploy.apis import MMdeployExporter
 
         mock_export_openvino = mocker.patch.object(MMdeployExporter, "export2openvino")
 
-        ExporterMixin.mmdeploy_export(
+        Exporter.mmdeploy_export(
             "", None, "FP16", dict(), mmcv.ConfigDict(backend_config=dict(mo_options=dict(flags=[])))
         )
 
         mock_export_openvino.assert_called_once()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/tasks/test_helpers.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,15 +10,15 @@
         batch (int, optional): A size of batch. Defaults to 1.
         width (int, optional): the image width. Defaults to 224.
         height (int, optional): the image height. Defaults to 224.
         channels (int, optional): the image channel. Defaults to 3.
         channel_last (bool, optional): if this is True, image shape will follow BHWC. Defaults to True.
 
     Returns:
-        _type_: _description_
+        torch.tensor: random image tensor.
     """
     if channel_last is False:
         img = torch.rand(batch, channels, height, width)
     else:
         img = torch.rand(batch, height, width, channels)
     return img
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmcv/test_hooks.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/test_hooks.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_deploy_apis.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_deploy_apis.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/test_helpers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_mmdeploy.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_mmdeploy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_onnx.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_onnx.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import os
 import tempfile
 
 import onnx
+import pytest
 import torch
 
 from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
 from otx.algorithms.common.adapters.mmdeploy.utils.onnx import (
     prepare_onnx_for_openvino,
     remove_nodes_by_op_type,
 )
@@ -33,21 +34,19 @@
         onnx_model = remove_nodes_by_op_type(onnx_model, "Gemm")
         nodes = []
         for node in onnx_model.graph.node:
             if node.op_type == "Gemm":
                 nodes.append(node)
         assert not nodes
 
-        onnx_model = onnx.load(onnx_path)
-        onnx_model = remove_nodes_by_op_type(onnx_model, "Conv")
-        nodes = []
-        for node in onnx_model.graph.node:
-            if node.op_type == "Conv":
-                nodes.append(node)
-        assert not nodes
+        # NOTE: Currently does not work for multiple op_types
+        with pytest.raises(AssertionError) as e:
+            onnx_model = onnx.load(onnx_path)
+            onnx_model = remove_nodes_by_op_type(onnx_model, "Conv")
+            assert e.type == Exception, f"{e}"
 
 
 @e2e_pytest_unit
 def test_prepare_onnx_for_openvino():
 
     model = create_model("mmcls")
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmdeploy/utils/test_deploy_utils_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_compression.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_compression.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_config.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_config.py`

 * *Files 0% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     nncf_config = {
         "base": {
             "find_unused_parameters": True,
             "nncf_config": {
                 "target_metric_name": "mAP",
                 "input_info": {"sample_size": [1, 3, 864, 864]},
                 "compression": [],
-                "log_dir": ".",
+                "log_dir": "/tmp",
                 "accuracy_aware_training": {
                     "mode": "early_exit",
                 },
             },
         },
         "nncf_quantization": {
             "optimizer": {"lr": 0.0005},
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_patches.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_patches.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/nncf/test_nncf_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_balanced_sampler.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_balanced_sampler.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_cls_incr_sampler.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/torch/dataloaders/samplers/test_cls_incr_sampler.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/__init__.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/test_torchvision2mmdet.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/pipelines/test_torchvision2mmdet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/test_detection_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/datasets/test_detection_dataset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_saliency_map_hook.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/hooks/test_det_class_probability_map_hook.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import pytest
 import torch
 
-from otx.algorithms.detection.adapters.mmdet.hooks.det_saliency_map_hook import (
-    DetSaliencyMapHook,
+from otx.algorithms.detection.adapters.mmdet.hooks.det_class_probability_map_hook import (
+    DetClassProbabilityMapHook,
 )
 from otx.algorithms.detection.adapters.mmdet.models.heads.custom_atss_head import (
     CustomATSSHead,
 )
 from otx.algorithms.detection.adapters.mmdet.models.heads.custom_ssd_head import (
     CustomSSDHead,
 )
@@ -15,16 +15,16 @@
 )
 from otx.algorithms.detection.adapters.mmdet.models.heads.custom_yolox_head import (
     CustomYOLOXHead,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
-class TestDetSaliencyMapHook:
-    """Test class for DetSaliencyMapHook."""
+class TestDetClassProbabilityMapHook:
+    """Test class for DetClassProbabilityMapHook."""
 
     @pytest.fixture(autouse=True)
     def setup(self) -> None:
         class _MockModule(torch.nn.Module):
             def __init__(self) -> None:
                 super().__init__()
                 self.with_neck = True
@@ -33,48 +33,68 @@
                 self.bbox_head = torch.nn.Module()
                 self.bbox_head.cls_out_channels = 3
 
             def forward(self, x):
                 return x
 
         self.module = _MockModule()
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
 
     @e2e_pytest_unit
     def test_func(self, mocker) -> None:
         """Test func function."""
 
         mocker.patch.object(
-            DetSaliencyMapHook, "_get_cls_scores_from_feature_map", return_value=[torch.randn(1, 3, 14, 14)]
+            DetClassProbabilityMapHook, "_get_cls_scores_from_feature_map", return_value=[torch.randn(1, 3, 14, 14)]
         )
         assert self.hook.func(torch.randn(1, 3, 14, 14)) is not None
 
     @e2e_pytest_unit
-    def test_get_cls_scores_from_feature_map(self) -> None:
+    def test_get_cls_scores_from_feature_map_atss(self) -> None:
         """Test _get_cls_scores_from_feature_map function."""
 
         self.module.bbox_head = CustomATSSHead(num_classes=3, in_channels=64)
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
         assert self.hook._get_cls_scores_from_feature_map(torch.Tensor(1, 3, 64, 32, 32)) is not None
+
+    @e2e_pytest_unit
+    def test_get_cls_scores_from_feature_map_yolox(self) -> None:
+        """Test _get_cls_scores_from_feature_map function."""
+
         self.module.bbox_head = CustomYOLOXHead(num_classes=3, in_channels=64)
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
         assert self.hook._get_cls_scores_from_feature_map(torch.Tensor(1, 3, 64, 32, 32)) is not None
+
+    @e2e_pytest_unit
+    def test_get_cls_scores_from_feature_map_vfnet(self) -> None:
+        """Test _get_cls_scores_from_feature_map function."""
+
         self.module.bbox_head = CustomVFNetHead(num_classes=3, in_channels=64)
         self.module.bbox_head.anchor_generator.num_base_anchors = 1
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
         assert self.hook._get_cls_scores_from_feature_map(torch.Tensor(1, 3, 64, 32, 32)) is not None
+
+    @e2e_pytest_unit
+    def test_get_cls_scores_from_feature_map_ssd(self) -> None:
+        """Test _get_cls_scores_from_feature_map function."""
+
         self.module.bbox_head = CustomSSDHead(
             anchor_generator=dict(
                 type="SSDAnchorGenerator",
                 basesize_ratio_range=(0.15, 0.9),
                 strides=(16, 32, 48),
                 ratios=[[0.5], [0.1], [0.3]],
             ),
             act_cfg={},
         )
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
         assert self.hook._get_cls_scores_from_feature_map(torch.Tensor(1, 3, 512, 32, 32)) is not None
+
+    @e2e_pytest_unit
+    def test_get_cls_scores_from_feature_map_not_implemented_head(self) -> None:
+        """Test _get_cls_scores_from_feature_map function."""
+
         self.module.bbox_head = torch.nn.Module()
         self.module.bbox_head.cls_out_channels = 3
-        self.hook = DetSaliencyMapHook(self.module)
+        self.hook = DetClassProbabilityMapHook(self.module)
         with pytest.raises(NotImplementedError):
             self.hook._get_cls_scores_from_feature_map(torch.Tensor(1, 3, 512, 32, 32))
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/backones/test_ov_mmdet_mmov_backbone.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_mmseg_mmov_backbone.py`

 * *Files 12% similar despite different names*

```diff
@@ -3,32 +3,30 @@
 #
 
 import numpy as np
 import openvino.runtime as ov
 import pytest
 import torch
 
-from otx.algorithms.detection.adapters.mmdet.models.backbones.mmov_backbone import (
-    MMOVBackbone,
-)
+from otx.algorithms.segmentation.adapters.mmseg.models.backbones import MMOVBackbone
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
 class TestMMOVBackbone:
     @pytest.fixture(autouse=True)
     def setup(self):
-
         param = ov.opset10.parameter([1, 3, 64, 64], ov.Type.f32, name="in")
         filter = ov.opset10.constant(np.random.normal(size=(1, 3, 64, 64)), ov.Type.f32)
         mul = ov.opset10.matmul(param, filter, False, False)
         result = ov.opset10.result(mul, name="out")
-        ov_model = ov.Model([result], [param], "det_backbone")
+        ov_model = ov.Model([result], [param], "seg_backbone")
 
         self.model = MMOVBackbone(
             model_path_or_model=ov_model,
+            outputs=["out"],
             remove_normalize=True,
             merge_bn=True,
             paired_bn=True,
         )
 
     @e2e_pytest_unit
     def test_init_weights(self):
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_rpn_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_rpn_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_ssd_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_ssd_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_yolov3_head.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/dense_heads/test_ov_mmdet_mmov_yolov3_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_atss_detector.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_atss_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_single_stage_detector.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_single_stage_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_two_stage_detector.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_two_stage_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_vfnet_detector.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/detectors/test_custom_vfnet_detector.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_cross_focal_loss.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_cross_focal_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_l2sp_loss.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/losses/test_l2sp_loss.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/test_ov_mmdet_mmov_ssd_neck.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/necks/test_ov_mmdet_mmov_ssd_neck.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/test_ov_mmdet_single_level_roi_extractor.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/models/roi_heads/roi_extractors/test_ov_mmdet_single_level_roi_extractor.py`

 * *Files 15% similar despite different names*

```diff
@@ -14,17 +14,7 @@
     def test_build_roi_layers(self):
         extractor = SingleRoIExtractor(
             roi_layer=dict(type="RoIInterpolationPool", output_size=14, mode="bilinear"),
             out_channels=1024,
             featmap_strides=[8],
         )
         assert all(isinstance(layer, RoIInterpolationPool) for layer in extractor.roi_layers)
-
-
-#  class TestRoIInterpolationPool:
-#      @pytest.fixture(autouse=True)
-#      def setup(self):
-#          self.pool = RoIInterpolationPool(14, 1/8)
-#
-#      @e2e_pytest_unit
-#      def test_forward(self):
-#          self.pool()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_builder.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_builder.py`

 * *Files 12% similar despite different names*

```diff
@@ -6,56 +6,50 @@
 import tempfile
 
 import numpy as np
 import torch
 from nncf.torch.nncf_network import NNCFNetwork
 
 from otx.algorithms.common.adapters.nncf.compression import NNCFMetaState
-from otx.algorithms.detection.adapters.mmdet.nncf.builder import build_nncf_detector
+from otx.algorithms.segmentation.adapters.mmseg.nncf.builder import build_nncf_segmentor
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.common.adapters.mmcv.nncf.test_helpers import (
     create_config,
     create_dataset,
     create_model,
 )
 
 
 @e2e_pytest_unit
-def test_build_nncf_detector():
-    mock_config = create_config(lib="mmdet")
-    model = create_model(lib="mmdet")
-    create_dataset(lib="mmdet")
+def test_build_nncf_segmentor():
+    mock_config = create_config(lib="mmseg")
+    model = create_model(lib="mmseg")
+    create_dataset(lib="mmseg")
 
     with tempfile.TemporaryDirectory() as tempdir:
         model_path = os.path.join(tempdir, "model.bin")
         state_to_build = model.state_dict()
         torch.save(state_to_build, model_path)
         mock_config.load_from = model_path
-        ctrl, model = build_nncf_detector(mock_config)
+        mock_config.nncf_config.log_dir = tempdir
+        ctrl, model = build_nncf_segmentor(mock_config)
         assert isinstance(model, NNCFNetwork)
         assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
         mock_config.pop("custom_hooks")
 
-        mock_config.nncf_compress_postprocessing = False
-        ctrl, model = build_nncf_detector(mock_config)
-        assert isinstance(model, NNCFNetwork)
-        assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
-        mock_config.pop("custom_hooks")
-        mock_config.pop("nncf_compress_postprocessing")
-
         torch.save(
             {
                 "meta": {
                     "nncf_enable_compression": True,
                     "nncf_meta": NNCFMetaState(
                         data_to_build=np.zeros((50, 50, 3)),
                         compression_ctrl=ctrl.get_compression_state(),
                         state_to_build=state_to_build,
                     ),
                 },
                 "state_dict": model.state_dict(),
             },
             model_path,
         )
-        ctrl, model = build_nncf_detector(mock_config, model_path)
+        ctrl, model = build_nncf_segmentor(mock_config, model_path)
         assert isinstance(model, NNCFNetwork)
         assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/tasks/test_det_exporter.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_exporter.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import os
 
 import pytest
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
 from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
 from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
-from otx.algorithms.detection.adapters.mmdet.tasks.exporter import DetectionExporter
 from otx.algorithms.detection.adapters.mmdet.utils.builder import build_detector
+from otx.algorithms.detection.adapters.mmdet.utils.exporter import DetectionExporter
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.detection.test_helpers import (
     DEFAULT_DET_RECIPE_CONFIG_PATH,
     DEFAULT_DET_TEMPLATE_DIR,
     DEFAULT_ISEG_RECIPE_CONFIG_PATH,
     DEFAULT_ISEG_TEMPLATE_DIR,
 )
@@ -21,33 +21,31 @@
     "recipe_cfg, template_dir",
     [
         (DEFAULT_DET_RECIPE_CONFIG_PATH, DEFAULT_DET_TEMPLATE_DIR),
         (DEFAULT_ISEG_RECIPE_CONFIG_PATH, DEFAULT_ISEG_TEMPLATE_DIR),
     ],
 )
 def test_run(recipe_cfg, template_dir, mocker):
-    cfg = MPAConfig.fromfile(recipe_cfg)
-    exporter = DetectionExporter(name="", mode="train", config=cfg, common_cfg=None, index=0)
+    exporter = DetectionExporter()
     model_cfg = MPAConfig.fromfile(os.path.join(template_dir, "model.py"))
-    data_cfg = MPAConfig.fromfile(os.path.join(template_dir, "data_pipeline.py"))
+    model_cfg.work_dir = "/tmp/"
     args = {"precision": "FP32", "model_builder": build_detector}
-    mocker.patch.object(ExporterMixin, "run", return_value=True)
-    returned_value = exporter.run(model_cfg, "", data_cfg, **args)
+    mocker.patch.object(Exporter, "run", return_value=True)
+    returned_value = exporter.run(model_cfg)
     assert "model_builder" in args
     assert returned_value is True
 
 
 @e2e_pytest_unit
 @pytest.mark.parametrize(
     "recipe_cfg, template_dir",
     [
         (DEFAULT_DET_RECIPE_CONFIG_PATH, DEFAULT_DET_TEMPLATE_DIR),
         (DEFAULT_ISEG_RECIPE_CONFIG_PATH, DEFAULT_ISEG_TEMPLATE_DIR),
     ],
 )
 def test_naive_export(recipe_cfg, template_dir, mocker):
-    cfg = MPAConfig.fromfile(recipe_cfg)
-    exporter = DetectionExporter(name="", mode="train", config=cfg, common_cfg=None, index=0)
+    exporter = DetectionExporter()
     data_cfg = MPAConfig.fromfile(os.path.join(template_dir, "data_pipeline.py"))
     mock_export_ov = mocker.patch.object(NaiveExporter, "export2openvino")
     exporter.naive_export("", build_detector, "FP32", data_cfg)
     mock_export_ov.assert_called_once()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_builder.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_config_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/utils/test_detection_config_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/test_detection_openvino_models.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/model_wrappers/test_detection_openvino_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -49,15 +49,15 @@
             "masks": Config({"names": "masks", "shape": [1, 0, 28, 28]}),
             "feature_vector": Config({"names": "feature_vector", "shape": [1, 1, 1, 1]}),
             "saliency_map": Config({"names": "saliency_map", "shape": [1, 1, 1]}),
         }
         self.is_segmentoly = len(self.inputs) == 2
         self.output_blob_name = self._get_outputs()
         self.confidence_threshold = 0.5
-        super().__init__(MockOpenvinoAdapter)
+        super().__init__(MockOpenvinoAdapter, {})
 
 
 class MockOTXSSDModel(OTXSSDModel):
     """Mock class for OTXSSDModel."""
 
     def __init__(self, *args):
         self.inputs: Dict[str, np.ndarray] = {
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/conftest.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/conftest.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_nncf.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_task.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,17 +5,15 @@
 import os
 
 import numpy as np
 import pytest
 from mmcv.utils import Config
 
 from otx.algorithms.common.adapters.mmcv.hooks import OTXLoggerHook
-from otx.algorithms.common.tasks import BaseTask
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
-from otx.algorithms.detection.tasks import DetectionNNCFTask
+from otx.algorithms.detection.adapters.mmdet.nncf.task import DetectionNNCFTask
 from otx.api.configuration.helper import create
 from otx.api.entities.metrics import NullPerformance, Performance, ScoreMetric
 from otx.api.entities.model_template import TaskType, parse_model_template
 from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
 from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.detection.test_helpers import (
@@ -59,39 +57,37 @@
     @e2e_pytest_unit
     def test_optimize(self, mocker):
         """Test optimize method in OTXDetTaskNNCF."""
         self.dataset, _ = generate_det_dataset(task_type=TaskType.DETECTION)
         mock_lcurve_val = OTXLoggerHook.Curve()
         mock_lcurve_val.x = [0, 1]
         mock_lcurve_val.y = [0.1, 0.2]
-        mock_run_task = mocker.patch.object(BaseTask, "_run_task", return_value={"final_ckpt": ""})
+        mock_run_task = mocker.patch.object(DetectionNNCFTask, "_train_model", return_value={"final_ckpt": ""})
         self.det_nncf_task._learning_curves = {"val/mAP": mock_lcurve_val}
         mocker.patch.object(DetectionNNCFTask, "save_model")
 
         fake_prediction = [[np.array([[0, 0, 32, 24, 0.55]], dtype=np.float32)]]
         fake_feature_vectors = [np.zeros((1, 1, 1))]
         fake_saliency_maps = [None]
         mocker.patch.object(
             DetectionNNCFTask,
-            "_infer_detector",
+            "_infer_model",
             return_value=(zip(fake_prediction, fake_feature_vectors, fake_saliency_maps), 1.0),
         )
         fake_metrics = mocker.patch("otx.api.usecases.evaluation.f_measure.FMeasure", autospec=True)
         fake_metrics.get_performance.return_value = Performance(
             score=ScoreMetric(name="fake", value=0.1), dashboard_metrics=["mAP"]
         )
         mocker.patch.object(MetricsHelper, "compute_f_measure", return_value=fake_metrics)
 
+        mocker.patch.object(DetectionNNCFTask, "_init_task")
+
         self.det_nncf_task.optimize(OptimizationType.NNCF, self.dataset, self.model)
 
         mock_run_task.assert_called_once()
         assert self.model.performance != NullPerformance()
         assert self.model.performance.score.value == 0.1
 
     @e2e_pytest_unit
     def test_initialize(self, mocker):
         """Test initialize method in OTXDetTaskNNCF."""
-        options = {}
-        self.det_nncf_task._initialize(options)
-
-        assert "model_builder" in options
-        assert NNCFBaseTask.model_builder == options["model_builder"].func
+        self.det_nncf_task._init_task()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/tasks/test_detection_openvino.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/openvino/test_task.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,22 +5,22 @@
 import copy
 import os
 
 import numpy as np
 import pytest
 from openvino.model_zoo.model_api.models import Model
 
-import otx.algorithms.detection.tasks.openvino
-from otx.algorithms.detection.configs.base import DetectionConfig
-from otx.algorithms.detection.tasks.openvino import (
+import otx.algorithms.detection.adapters.openvino.task
+from otx.algorithms.detection.adapters.openvino.task import (
     OpenVINODetectionInferencer,
     OpenVINODetectionTask,
     OpenVINOMaskInferencer,
     OpenVINORotatedRectInferencer,
 )
+from otx.algorithms.detection.configs.base import DetectionConfig
 from otx.algorithms.detection.utils import generate_label_schema
 from otx.api.configuration.helper import create
 from otx.api.entities.annotation import AnnotationSceneEntity, AnnotationSceneKind
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import LabelEntity
 from otx.api.entities.metrics import Performance, ScoreMetric
 from otx.api.entities.model_template import (
@@ -46,15 +46,15 @@
         classes = ("rectangle", "ellipse", "triangle")
         self.ov_inferencer = dict()
         task_type = TaskType.DETECTION
         model_template = parse_model_template(os.path.join(DEFAULT_DET_TEMPLATE_DIR, "template.yaml"))
         hyper_parameters = create(model_template.hyper_parameters.data)
         params = DetectionConfig(header=hyper_parameters.header)
         label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
-        mocker.patch("otx.algorithms.detection.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.OpenvinoAdapter")
         mocked_model = mocker.patch.object(Model, "create_model")
         mocked_model.return_value = mocker.MagicMock(spec=Model)
         self.ov_inferencer = OpenVINODetectionInferencer(params, label_schema, "")
         self.fake_input = np.full((5, 1), 0.1)
 
     @e2e_pytest_unit
     def test_pre_process(self):
@@ -105,15 +105,15 @@
         classes = ("rectangle", "ellipse", "triangle")
         self.ov_inferencer = dict()
         task_type = TaskType.INSTANCE_SEGMENTATION
         model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
         hyper_parameters = create(model_template.hyper_parameters.data)
         params = DetectionConfig(header=hyper_parameters.header)
         label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
-        mocker.patch("otx.algorithms.detection.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.OpenvinoAdapter")
         mocked_model = mocker.patch.object(Model, "create_model")
         mocked_model.return_value = mocker.MagicMock(spec=Model)
         self.ov_inferencer = OpenVINOMaskInferencer(params, label_schema, "")
         self.fake_input = np.full((5, 1), 0.1)
 
     @e2e_pytest_unit
     def test_pre_process(self):
@@ -129,15 +129,15 @@
         classes = ("rectangle", "ellipse", "triangle")
         self.ov_inferencer = dict()
         task_type = TaskType.DETECTION
         model_template = parse_model_template(os.path.join(DEFAULT_DET_TEMPLATE_DIR, "template.yaml"))
         hyper_parameters = create(model_template.hyper_parameters.data)
         params = DetectionConfig(header=hyper_parameters.header)
         label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
-        mocker.patch("otx.algorithms.detection.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.OpenvinoAdapter")
         mocked_model = mocker.patch.object(Model, "create_model")
         mocked_model.return_value = mocker.MagicMock(spec=Model)
         self.ov_inferencer = OpenVINORotatedRectInferencer(params, label_schema, "")
         self.fake_input = np.full((5, 1), 0.1)
 
     @e2e_pytest_unit
     def test_pre_process(self):
@@ -156,22 +156,21 @@
         task_type = TaskType.DETECTION
 
         model_template = parse_model_template(os.path.join(DEFAULT_DET_TEMPLATE_DIR, "template.yaml"))
         hyper_parameters = create(model_template.hyper_parameters.data)
         label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
         task_env = init_environment(hyper_parameters, model_template, task_type=task_type)
         params = DetectionConfig(header=hyper_parameters.header)
-        mocker.patch("otx.algorithms.detection.tasks.openvino.OpenvinoAdapter")
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.OpenvinoAdapter")
         mocked_model = mocker.patch.object(Model, "create_model")
         mocked_model.return_value = mocker.MagicMock(spec=Model)
         ov_inferencer = OpenVINODetectionInferencer(params, label_schema, "")
         ov_inferencer.model.__model__ = "OTX_SSD"
         task_env.model = otx_model
         mocker.patch.object(OpenVINODetectionTask, "load_inferencer", return_value=ov_inferencer)
-        mocker.patch.object(OpenVINODetectionTask, "load_config", return_value={})
 
         self.ov_task = OpenVINODetectionTask(task_env)
 
     @e2e_pytest_unit
     def test_infer(self, mocker):
         """Test infer method in OpenVINODetectionTask."""
         self.dataset, labels = generate_det_dataset(task_type=TaskType.DETECTION)
@@ -204,15 +203,14 @@
 
     @e2e_pytest_unit
     def test_deploy(self, otx_model):
         """Test deploy method in OpenVINODetectionTask."""
         output_model = copy.deepcopy(otx_model)
         self.ov_task.model.set_data("openvino.bin", b"foo")
         self.ov_task.model.set_data("openvino.xml", b"bar")
-        self.ov_task.config = {"tiling_parameters": None}
         self.ov_task.deploy(output_model)
 
         assert output_model.exportable_code is not None
 
     @e2e_pytest_unit
     def test_optimize(self, mocker, otx_model):
         """Test optimize method in OpenVINODetectionTask."""
@@ -223,16 +221,16 @@
             with open(f"{dir_path}/{model_name}.bin", "wb") as f:
                 f.write(b"bar")
 
         dataset, _ = generate_det_dataset(task_type=TaskType.DETECTION)
         output_model = copy.deepcopy(otx_model)
         self.ov_task.model.set_data("openvino.bin", b"foo")
         self.ov_task.model.set_data("openvino.xml", b"bar")
-        mocker.patch("otx.algorithms.detection.tasks.openvino.load_model", autospec=True)
-        mocker.patch("otx.algorithms.detection.tasks.openvino.create_pipeline", autospec=True)
-        mocker.patch("otx.algorithms.detection.tasks.openvino.save_model", new=patch_save_model)
-        spy_compress = mocker.spy(otx.algorithms.detection.tasks.openvino, "compress_model_weights")
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.load_model", autospec=True)
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.create_pipeline", autospec=True)
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.save_model", new=patch_save_model)
+        spy_compress = mocker.spy(otx.algorithms.detection.adapters.openvino.task, "compress_model_weights")
         self.ov_task.optimize(OptimizationType.POT, dataset=dataset, output_model=output_model)
 
         spy_compress.assert_called_once()
         assert self.ov_task.model.get_data("openvino.bin")
         assert self.ov_task.model.get_data("openvino.xml")
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/test_helpers.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 from otx.api.entities.annotation import AnnotationSceneEntity, AnnotationSceneKind
 from otx.api.entities.dataset_item import DatasetItemEntity
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.id import ID
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.model_template import TaskType, task_type_to_label_domain
+from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.api.utils.shape_factory import ShapeFactory
 from tests.test_helpers import generate_random_annotated_image
 
 DEFAULT_DET_MODEL_CONFIG_PATH = "otx/algorithms/detection/configs/detection/mobilenetv2_atss/model.py"
 DEFAULT_ISEG_MODEL_CONFIG_PATH = (
     "otx/algorithms/detection/configs/instance_segmentation/efficientnetb2b_maskrcnn/model.py"
@@ -68,29 +69,33 @@
 
 
 def generate_det_dataset(task_type, number_of_images=1):
     classes = ("rectangle", "ellipse", "triangle")
     label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
 
     items = []
-    for _ in range(number_of_images):
+    for idx in range(number_of_images):
+        if idx < 30:
+            subset = Subset.VALIDATION
+        else:
+            subset = Subset.TRAINING
         image_numpy, annos = generate_random_annotated_image(
             image_width=640,
             image_height=480,
             labels=label_schema.get_labels(False),
         )
         # Convert shapes according to task
         for anno in annos:
             if task_type == TaskType.DETECTION:
                 anno.shape = ShapeFactory.shape_as_rectangle(anno.shape)
             elif task_type == TaskType.INSTANCE_SEGMENTATION:
                 anno.shape = ShapeFactory.shape_as_polygon(anno.shape)
         image = Image(data=image_numpy)
         annotation_scene = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=annos)
-        items.append(DatasetItemEntity(media=image, annotation_scene=annotation_scene))
+        items.append(DatasetItemEntity(media=image, annotation_scene=annotation_scene, subset=subset))
     dataset = DatasetEntity(items)
     return dataset, dataset.get_labels()
 
 
 def generate_labels(length: int, domain: Domain) -> List[LabelEntity]:
     """Generate list of LabelEntity given length and domain."""
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/tiling/test_tiling_detection_unittest.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/test_tiling_detection.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,26 +1,39 @@
-import unittest
+# Copyright (C) 2023 Intel Corporation
+#
+# SPDX-License-Identifier: MIT
+
+import os
 from typing import List
 
 import numpy as np
+import pytest
 import torch
 from mmcv import ConfigDict
 from mmdet.datasets import build_dataloader, build_dataset
 
-from otx.algorithms.detection.adapters.mmdet.datasets import (  # noqa: F401
-    ImageTilingDataset,
-)
+from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
+from otx.algorithms.detection.adapters.mmdet.task import MMDetectionTask
+from otx.algorithms.detection.adapters.mmdet.utils import build_detector, patch_tiling
+from otx.api.configuration.helper import create
 from otx.api.entities.annotation import AnnotationSceneEntity, AnnotationSceneKind
 from otx.api.entities.dataset_item import DatasetItemEntity
-from otx.api.entities.datasets import DatasetEntity
+from otx.api.entities.datasets import DatasetEntity, DatasetPurpose
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
+from otx.api.entities.model import ModelEntity
+from otx.api.entities.model_template import parse_model_template
+from otx.api.usecases.adapters.model_adapter import ModelAdapter
 from otx.api.utils.shape_factory import ShapeFactory
 from tests.test_helpers import generate_random_annotated_image
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
+from tests.unit.algorithms.detection.test_helpers import (
+    DEFAULT_ISEG_TEMPLATE_DIR,
+    init_environment,
+)
 
 
 def create_otx_dataset(height: int, width: int, labels: List[str]):
     """Create a random OTX dataset
 
     Args:
         height (int): The height of the image
@@ -36,17 +49,18 @@
     image, anno_list = generate_random_annotated_image(width, height, labels)
     image = Image(data=image)
     annotation_scene = AnnotationSceneEntity(annotations=anno_list, kind=AnnotationSceneKind.ANNOTATION)
     dataset_item = DatasetItemEntity(media=image, annotation_scene=annotation_scene)
     return DatasetEntity([dataset_item]), labels
 
 
-class TestTilingDetection(unittest.TestCase):
+class TestTilingDetection:
     """Test the tiling functionality"""
 
+    @pytest.fixture(autouse=True)
     def setUp(self) -> None:
         """Setup the test case"""
         self.height = 1024
         self.width = 1024
         self.label_names = ["rectangle", "ellipse", "triangle"]
         self.tile_cfg = dict(
             tile_size=np.random.randint(low=100, high=500),
@@ -119,34 +133,34 @@
     @e2e_pytest_unit
     def test_tiling_train_dataloader(self):
         """Test that the training dataloader is built correctly for tiling"""
 
         dataset = build_dataset(self.train_data_cfg)
         train_dataloader = build_dataloader(dataset, **self.dataloader_cfg)
         for data in train_dataloader:
-            self.assertIsInstance(data["img"].data[0], torch.Tensor)
-            self.assertIsInstance(data["gt_bboxes"].data[0][0], torch.Tensor)
-            self.assertIsInstance(data["gt_labels"].data[0][0], torch.Tensor)
+            assert isinstance(data["img"].data[0], torch.Tensor)
+            assert isinstance(data["gt_bboxes"].data[0][0], torch.Tensor)
+            assert isinstance(data["gt_labels"].data[0][0], torch.Tensor)
 
     @e2e_pytest_unit
     def test_tiling_test_dataloader(self):
         """Test that the testing dataloader is built correctly for tiling"""
 
         dataset = build_dataset(self.test_data_cfg)
         stride = int((1 - self.tile_cfg["overlap_ratio"]) * self.tile_cfg["tile_size"])
         num_tile_rows = ((self.height - self.tile_cfg["tile_size"]) // stride) + 1
         num_tile_cols = ((self.width - self.tile_cfg["tile_size"]) // stride) + 1
         # +1 for the original image
-        self.assertEqual(len(dataset), (num_tile_rows * num_tile_cols) + 1, "Incorrect number of tiles")
+        assert len(dataset) == (num_tile_rows * num_tile_cols) + 1, "Incorrect number of tiles"
 
         test_dataloader = build_dataloader(dataset, **self.dataloader_cfg)
         for data in test_dataloader:
-            self.assertIsInstance(data["img"][0], torch.Tensor)
-            self.assertNotIn("gt_bboxes", data)
-            self.assertNotIn("gt_labels", data)
+            assert isinstance(data["img"][0], torch.Tensor)
+            assert "gt_bboxes" not in data
+            assert "gt_labels" not in data
 
     @e2e_pytest_unit
     def test_inference_merge(self):
         """Test that the inference merge works correctly"""
         dataset = build_dataset(self.test_data_cfg)
 
         # create simulated inference results
@@ -169,8 +183,58 @@
                 bbox = np.array([shape.x1, shape.y1, shape.x2, shape.y2], np.float32)
                 bbox *= np.tile([img_width, img_height], 2)
                 score_bbox = np.array([*bbox, np.random.rand()], np.float32)
                 label_idx = self.label_names.index(anno.get_labels()[0].name)
                 results[i][label_idx] = np.append(results[i][label_idx], [score_bbox], axis=0)
 
         merged_bbox_results = dataset.merge(results)
-        self.assertEqual(len(merged_bbox_results), dataset.num_samples)
+        assert len(merged_bbox_results) == dataset.num_samples
+
+    @e2e_pytest_unit
+    def test_load_tiling_parameters(self, tmp_dir_path):
+        maskrcnn_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "model.py"))
+        detector = build_detector(maskrcnn_cfg)
+
+        # Enable tiling and save weights
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        hyper_parameters.tiling_parameters.enable_tiling = True
+        task_env = init_environment(hyper_parameters, model_template)
+        output_model = ModelEntity(self.otx_dataset, task_env.get_model_configuration())
+        task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
+        model_ckpt = os.path.join(tmp_dir_path, "maskrcnn.pth")
+        torch.save(detector.state_dict(), model_ckpt)
+        task._model_ckpt = model_ckpt
+        task.save_model(output_model)
+        for filename, model_adapter in output_model.model_adapters.items():
+            with open(os.path.join(tmp_dir_path, filename), "wb") as write_file:
+                write_file.write(model_adapter.data)
+
+        # Read tiling parameters from weights
+        with open(os.path.join(tmp_dir_path, "weights.pth"), "rb") as f:
+            bin_data = f.read()
+            model = ModelEntity(
+                self.otx_dataset,
+                configuration=task_env.get_model_configuration(),
+                model_adapters={"weights.pth": ModelAdapter(bin_data)},
+            )
+        task_env.model = model
+        task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
+
+    @e2e_pytest_unit
+    def test_patch_tiling_func(self):
+        """Test that patch_tiling function works correctly"""
+        cfg = MPAConfig.fromfile(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "model.py"))
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        hyper_parameters.tiling_parameters.enable_tiling = True
+
+        self.otx_dataset.purpose = DatasetPurpose.TRAINING
+        patch_tiling(cfg, hyper_parameters, self.otx_dataset)
+
+        self.otx_dataset.purpose = DatasetPurpose.INFERENCE
+        patch_tiling(cfg, hyper_parameters, self.otx_dataset)
+
+    @e2e_pytest_unit
+    def test_openvino(self):
+        # TODO[EUGENE]: implement unittest for tiling prediction with openvino
+        pass
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_data.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/utils/test_detection_data.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/detection/utils/test_detection_mask_to_bbox.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/utils/test_detection_mask_to_bbox.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/__init__.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/__init__.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/__init__.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_compose.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_compose.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_loads.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_loads.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_transforms.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/pipelines/test_transforms.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/datasets/test_dataset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_litehrnet.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_litehrnet.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/backbones/test_mmseg_mmov_backbone.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/heads/test_mmseg_mmov_decode_head.py`

 * *Files 21% similar despite different names*

```diff
@@ -3,46 +3,64 @@
 #
 
 import numpy as np
 import openvino.runtime as ov
 import pytest
 import torch
 
-from otx.algorithms.segmentation.adapters.mmseg.models.backbones import MMOVBackbone
+from otx.algorithms.segmentation.adapters.mmseg.models import MMOVDecodeHead
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
 class TestMMOVBackbone:
     @pytest.fixture(autouse=True)
     def setup(self):
-        param = ov.opset10.parameter([1, 3, 64, 64], ov.Type.f32, name="in")
-        filter = ov.opset10.constant(np.random.normal(size=(1, 3, 64, 64)), ov.Type.f32)
+
+        params = []
+        results = []
+
+        param = ov.opset10.parameter([1, 24, 64, 64], ov.Type.f32, name="in")
+        filter = ov.opset10.constant(np.random.normal(size=(1, 24, 64, 64)), ov.Type.f32)
+        mul = ov.opset10.matmul(param, filter, False, False)
+        result = ov.opset10.result(mul, name="extractor_out")
+        params.append(param)
+        results.append(result)
+
+        filter = ov.opset10.constant(np.random.normal(size=(1, 24, 64, 64)), ov.Type.f32)
         mul = ov.opset10.matmul(param, filter, False, False)
-        result = ov.opset10.result(mul, name="out")
-        ov_model = ov.Model([result], [param], "seg_backbone")
+        result = ov.opset10.result(mul, name="cls_seg_out")
+        results.append(result)
 
-        self.model = MMOVBackbone(
+        ov_model = ov.Model(results, params, "seg_head")
+
+        self.model = MMOVDecodeHead(
             model_path_or_model=ov_model,
-            outputs=["out"],
-            remove_normalize=True,
-            merge_bn=True,
-            paired_bn=True,
+            inputs=dict(
+                extractor="in",
+                cls_seg="in",
+            ),
+            outputs=dict(
+                extractor="extractor_out",
+                cls_seg="cls_seg_out",
+            ),
+            in_channels=320,
+            num_classes=24,
         )
 
     @e2e_pytest_unit
     def test_init_weights(self):
         self.model.init_weights()
 
     @e2e_pytest_unit
     def test_forward(self):
-        assert self.model.inputs == self.model._inputs
-        assert self.model.outputs == self.model._outputs
-        assert self.model.features == self.model._feature_dict
-        assert self.model.input_shapes == self.model._input_shapes
-        assert self.model.output_shapes == self.model._output_shapes
 
         data = {}
-        for key, shape in self.model.input_shapes.items():
+        input_shapes = self.model.conv_seg.input_shapes
+        if getattr(self.model, "extractor", None):
+            input_shapes = self.model.extractor.input_shapes
+
+        for key, shape in input_shapes.items():
             shape = [1 if i == -1 else i for i in shape]
             data[key] = torch.randn(shape)
-        self.model.train()
-        self.model(list(data.values()), torch.tensor([0]))
+
+        output = self.model(list(data.values()))
+        assert output.shape[1] == 24
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/test_detcon_loss.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/losses/test_detcon_loss.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 import pytest
 import torch
 
+from otx.algorithms.segmentation.adapters.mmseg.models.losses import detcon_loss as detcon_loss_file
 from otx.algorithms.segmentation.adapters.mmseg.models.losses.detcon_loss import (
     DetConLoss,
     manual_cross_entropy,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
@@ -50,14 +51,13 @@
                 "tind2": torch.Tensor([[1, 0]]),
             },
             torch.tensor(11.8758),
         )
     ],
 )
 def test_detcon_loss(mocker, inputs, expected):
-    mocker.patch("torch.cuda.device_count", return_value=0)
+    mocker.patch.object(detcon_loss_file, "dist").is_initialized.return_value = False
     detcon_loss = DetConLoss()
 
-    results = detcon_loss(**inputs)
+    loss = detcon_loss(**inputs)
 
-    assert "loss" in results
-    assert torch.allclose(results["loss"], expected)
+    assert torch.allclose(loss, expected)
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/test_selfsl_mlp.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/necks/test_selfsl_mlp.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/test_schedulers.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/scalar_schedulers/test_schedulers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/test_detcon.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/segmentors/test_detcon.py`

 * *Files 2% similar despite different names*

```diff
@@ -35,49 +35,61 @@
     class MockNeck(nn.Sequential):
         def __init__(self):
             super().__init__(nn.Linear(2, 2, bias=False), nn.Linear(2, 2, bias=False))
 
         def init_weights(self, init_linear=None):
             pass
 
+    class MockHead(nn.Sequential):
+        def __init__(self):
+            super().__init__(nn.Linear(2, 2, bias=False), nn.Linear(2, 2, bias=False))
+
+        def init_weights(self, init_linear=None):
+            pass
+
+        def forward(self, *args, **kwargs):
+            return {"loss": torch.tensor(1.0)}
+
     class MockDecodeHead(nn.Module):
         def __init__(self):
             super().__init__()
             self.align_corners = None
             self.num_classes = 1
             self.out_channels = 1
 
         def forward(self, x):
             return x
 
     def build_mock(mock_class, *args, **kwargs):
         return mock_class()
 
+    # DetCon
     monkeypatch.setattr(
         "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.build_backbone",
         partial(build_mock, MockBackbone),
     )
     monkeypatch.setattr(
         "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.build_neck", partial(build_mock, MockNeck)
     )
     monkeypatch.setattr(
-        "mmseg.models.segmentors.encoder_decoder.builder.build_backbone", partial(build_mock, MockBackbone)
-    )
-    monkeypatch.setattr(
-        "mmseg.models.segmentors.encoder_decoder.builder.build_head", partial(build_mock, MockDecodeHead)
-    )
-    mocker.patch(
-        "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.build_loss",
-        return_value=lambda *args, **kwargs: dict(loss=1.0),
+        "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.build_head", partial(build_mock, MockHead)
     )
     mocker.patch(
         "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.DetConB._register_state_dict_hook"
     )
     mocker.patch("otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.DetConB.state_dict_hook")
     mocker.patch("otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.load_checkpoint")
+
+    # SupCon
+    monkeypatch.setattr(
+        "mmseg.models.segmentors.encoder_decoder.builder.build_backbone", partial(build_mock, MockBackbone)
+    )
+    monkeypatch.setattr(
+        "mmseg.models.segmentors.encoder_decoder.builder.build_head", partial(build_mock, MockDecodeHead)
+    )
     mocker.patch(
         "otx.algorithms.segmentation.adapters.mmseg.models.segmentors.detcon.SupConDetConB._decode_head_forward_train",
         return_value=(dict(loss=1.0), None),
     )
 
 
 class TestMaskPooling:
@@ -120,15 +132,15 @@
 
 
 class TestDetConB:
     """Test DetConB."""
 
     @pytest.fixture(autouse=True)
     def setup(self) -> None:
-        self.detconb = DetConB(backbone={}, neck={}, head={}, downsample=1, loss_cfg=dict(type="DetConLoss"))
+        self.detconb = DetConB(backbone={}, neck={}, head={}, downsample=1)
 
     @e2e_pytest_unit
     def test_init_weights(self) -> None:
         """Test init_weights function."""
         for param_ol, param_tgt in zip(
             self.detconb.online_backbone.parameters(), self.detconb.target_backbone.parameters()
         ):
@@ -248,14 +260,13 @@
             backbone={},
             neck={},
             head={},
             decode_head={},
             downsample=1,
             input_transform="resize_concat",
             in_index=[0, 1],
-            loss_cfg=dict(type="DetConLoss"),
             task_adapt=dict(dst_classes=1, src_classes=1),
         )
 
         results = supcon_detconb(img=img, img_metas=[], gt_semantic_seg=gt_semantic_seg)
 
         assert ("loss_detcon" in results) == expected
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/test_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/models/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_builder.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/adapters/mmdet/nncf/test_mmdet_nncf_builder.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,54 +1,97 @@
 # Copyright (C) 2021-2023 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 
 import os
 import tempfile
 
+import pytest
 import numpy as np
 import torch
 from nncf.torch.nncf_network import NNCFNetwork
 
 from otx.algorithms.common.adapters.nncf.compression import NNCFMetaState
-from otx.algorithms.segmentation.adapters.mmseg.nncf.builder import build_nncf_segmentor
+from otx.algorithms.detection.adapters.mmdet.nncf.builder import build_nncf_detector
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.common.adapters.mmcv.nncf.test_helpers import (
     create_config,
     create_dataset,
     create_model,
 )
 
 
+@pytest.fixture(autouse=True)
+def prepare_dataset():
+    create_dataset(lib="mmdet")
+
+
+@pytest.fixture(scope="module")
+def temp_dir():
+    with tempfile.TemporaryDirectory() as tempdir:
+        yield tempdir
+
+
+@pytest.fixture
+def nncf_model_path(temp_dir):
+    return os.path.join(temp_dir, "nncf_model.bin")
+
+
+@pytest.fixture(scope="module")
+def state_to_build():
+    model = create_model(lib="mmdet")
+    return model.state_dict()
+
+
+@pytest.fixture
+def mock_config(temp_dir, state_to_build):
+    model_path = os.path.join(temp_dir, "model.bin")
+    mock_config = create_config(lib="mmdet")
+    torch.save(state_to_build, model_path)
+    mock_config.load_from = model_path
+    return mock_config
+
+
 @e2e_pytest_unit
-def test_build_nncf_segmentor():
-    mock_config = create_config(lib="mmseg")
-    model = create_model(lib="mmseg")
-    create_dataset(lib="mmseg")
+def test_build_nncf_detector(mock_config):
+    with tempfile.TemporaryDirectory() as tempdir:
+        mock_config.nncf_config.log_dir = tempdir
+        _, model = build_nncf_detector(mock_config)
+
+    assert isinstance(model, NNCFNetwork)
+    assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
 
+
+@e2e_pytest_unit
+def test_build_nncf_detector_not_compress_postprocessing(mock_config, state_to_build, nncf_model_path):
     with tempfile.TemporaryDirectory() as tempdir:
-        model_path = os.path.join(tempdir, "model.bin")
-        state_to_build = model.state_dict()
-        torch.save(state_to_build, model_path)
-        mock_config.load_from = model_path
-        ctrl, model = build_nncf_segmentor(mock_config)
-        assert isinstance(model, NNCFNetwork)
-        assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
-        mock_config.pop("custom_hooks")
-
-        torch.save(
-            {
-                "meta": {
-                    "nncf_enable_compression": True,
-                    "nncf_meta": NNCFMetaState(
-                        data_to_build=np.zeros((50, 50, 3)),
-                        compression_ctrl=ctrl.get_compression_state(),
-                        state_to_build=state_to_build,
-                    ),
-                },
-                "state_dict": model.state_dict(),
+        mock_config.nncf_config.log_dir = tempdir
+        mock_config.nncf_compress_postprocessing = False
+        ctrl, model = build_nncf_detector(mock_config)
+
+    assert isinstance(model, NNCFNetwork)
+    assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
+
+    # save a model for next test
+    torch.save(
+        {
+            "meta": {
+                "nncf_enable_compression": True,
+                "nncf_meta": NNCFMetaState(
+                    data_to_build=np.zeros((50, 50, 3)),
+                    compression_ctrl=ctrl.get_compression_state(),
+                    state_to_build=state_to_build,
+                ),
             },
-            model_path,
-        )
-        ctrl, model = build_nncf_segmentor(mock_config, model_path)
-        assert isinstance(model, NNCFNetwork)
-        assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
+            "state_dict": model.state_dict(),
+        },
+        nncf_model_path,
+    )
+
+
+@e2e_pytest_unit
+def test_build_nncf_detector_with_nncf_ckpt(mock_config, nncf_model_path):
+    with tempfile.TemporaryDirectory() as tempdir:
+        mock_config.nncf_config.log_dir = tempdir
+        _, model = build_nncf_detector(mock_config, nncf_model_path)
+    assert isinstance(model, NNCFNetwork)
+    assert len([hook for hook in mock_config.custom_hooks if hook.type == "CompressionHook"]) == 1
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_hooks.py` & `otx-1.2.0rc1/tests/unit/algorithms/common/adapters/mmcv/hooks/test_lr_updater_hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import tempfile
 
 from mmcv.runner import EpochBasedRunner
 from mmcv.utils import get_logger
 from torch.optim import SGD
 
 from otx.algorithms.common.adapters.mmcv.utils import build_data_parallel
-from otx.algorithms.segmentation.adapters.mmseg.nncf.hooks import (
+from otx.algorithms.common.adapters.mmcv.hooks import (
     CustomstepLrUpdaterHook,
 )
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.common.adapters.mmcv.nncf.test_helpers import (
     create_config,
     create_model,
 )
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/tasks/test_seg_exporter.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_exporter.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,39 +1,36 @@
-import os
+# Copyright (C) 2023 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
+#
 
-import pytest
+import os
 
-from otx.algorithms.common.adapters.mmcv.tasks.exporter_mixin import ExporterMixin
-from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
-from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
-from otx.algorithms.segmentation.adapters.mmseg.tasks.exporter import SegExporter
 from otx.algorithms.segmentation.adapters.mmseg.utils.builder import build_segmentor
+from otx.algorithms.common.adapters.mmdeploy.apis import NaiveExporter
+from otx.algorithms.common.adapters.mmcv.tasks.exporter import Exporter
+from otx.algorithms.segmentation.adapters.mmseg.utils.exporter import SegmentationExporter
+from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.segmentation.test_helpers import (
-    DEFAULT_RECIPE_CONFIG_PATH,
     DEFAULT_SEG_TEMPLATE_DIR,
 )
 
 
-class TestOTXSegExporter:
-    @pytest.fixture(autouse=True)
-    def setup(self) -> None:
-        cfg = MPAConfig.fromfile(DEFAULT_RECIPE_CONFIG_PATH)
-        self.exporter = SegExporter(name="", mode="train", config=cfg, common_cfg=None, index=0)
-        self.model_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "model.py"))
-        self.data_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "data_pipeline.py"))
-
-    @e2e_pytest_unit
-    def test_run(self, mocker):
-        args = {"precision": "FP32", "model_builder": build_segmentor}
-        mocker.patch.object(ExporterMixin, "run", return_value=True)
-        returned_value = self.exporter.run(self.model_cfg, "", self.data_cfg, **args)
-
-        assert "model_builder" in args
-        assert returned_value is True
-
-    @e2e_pytest_unit
-    def test_naive_export(self, mocker):
-        mock_export_ov = mocker.patch.object(NaiveExporter, "export2openvino")
-        self.exporter.naive_export("", build_segmentor, "FP32", self.data_cfg)
-
-        mock_export_ov.assert_called_once()
+@e2e_pytest_unit
+def test_run(mocker):
+    exporter = SegmentationExporter()
+    model_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "model.py"))
+    model_cfg.work_dir = "/tmp/"
+    args = {"precision": "FP32", "model_builder": build_segmentor}
+    mocker.patch.object(Exporter, "run", return_value=True)
+    returned_value = exporter.run(model_cfg)
+    assert "model_builder" in args
+    assert returned_value is True
+
+
+@e2e_pytest_unit
+def test_naive_export(mocker):
+    exporter = SegmentationExporter()
+    data_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "data_pipeline.py"))
+    mock_export_ov = mocker.patch.object(NaiveExporter, "export2openvino")
+    exporter.naive_export("", build_segmentor, "FP32", data_cfg)
+    mock_export_ov.assert_called_once()
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_config_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/utils/test_data_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/test_blur.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/openvino/model_wrappers/test_blur.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/conftest.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/conftest.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_nncf.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/adapters/mmseg/nncf/test_mmseg_nncf_task.py`

 * *Files 26% similar despite different names*

```diff
@@ -3,17 +3,15 @@
 #
 
 import os
 
 import pytest
 from mmcv.utils import Config
 
-from otx.algorithms.common.tasks import BaseTask
-from otx.algorithms.common.tasks.nncf_base import NNCFBaseTask
-from otx.algorithms.segmentation.tasks import SegmentationNNCFTask
+from otx.algorithms.segmentation.adapters.mmseg.nncf.task import SegmentationNNCFTask
 from otx.api.configuration.helper import create
 from otx.api.entities.metrics import NullPerformance
 from otx.api.entities.model_template import parse_model_template
 from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 from tests.unit.algorithms.segmentation.test_helpers import (
     DEFAULT_SEG_TEMPLATE_DIR,
@@ -46,24 +44,21 @@
 
         self.dataset = generate_otx_dataset()
 
         mock_lcurve_val = OTXLoggerHook.Curve()
         mock_lcurve_val.x = [0, 1]
         mock_lcurve_val.y = [0.1, 0.2]
 
-        mock_run_task = mocker.patch.object(BaseTask, "_run_task", return_value={"final_ckpt": ""})
         self.seg_nncf_task._learning_curves = {f"val/{self.seg_nncf_task.metric}": mock_lcurve_val}
         mocker.patch.object(SegmentationNNCFTask, "save_model")
+        mocker.patch.object(SegmentationNNCFTask, "_train_model")
+        mocker.patch(
+            "otx.algorithms.segmentation.adapters.mmseg.nncf.task.build_nncf_segmentor",
+            return_value=(
+                mocker.MagicMock(),
+                mocker.MagicMock(),
+            ),
+        )
         self.seg_nncf_task.optimize(OptimizationType.NNCF, self.dataset, self.model)
 
-        mock_run_task.assert_called_once()
         assert self.model.performance != NullPerformance()
         assert self.model.performance.score.value == 0.2
-
-    @e2e_pytest_unit
-    def test_initialize(self, mocker):
-        """Test initialize method in OTXDetTaskNNCF."""
-        options = {}
-        self.seg_nncf_task._initialize(options)
-
-        assert "model_builder" in options
-        assert NNCFBaseTask.model_builder == options["model_builder"].func
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/tasks/test_segmentation_openvino.py` & `otx-1.2.0rc1/tests/unit/algorithms/detection/tiling/test_tiling_tile_classifier.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,182 +1,185 @@
 # Copyright (C) 2023 Intel Corporation
-# SPDX-License-Identifier: Apache-2.0
 #
+# SPDX-License-Identifier: MIT
 
 import copy
 import os
+from functools import partial
 
 import numpy as np
 import pytest
+import torch
 from openvino.model_zoo.model_api.models import Model
 
-import otx.algorithms.segmentation.tasks.openvino
-from otx.algorithms.segmentation.configs.base import SegmentationConfig
-from otx.algorithms.segmentation.tasks.openvino import (
-    OpenVINOSegmentationInferencer,
-    OpenVINOSegmentationTask,
+from otx.algorithms.common.adapters.mmcv.utils.config_utils import MPAConfig
+from otx.algorithms.detection.adapters.mmdet.task import MMDetectionTask
+from otx.algorithms.detection.adapters.mmdet.utils import build_detector, patch_tiling
+from otx.algorithms.detection.adapters.openvino.model_wrappers import OTXMaskRCNNModel
+from otx.algorithms.detection.adapters.openvino.task import (
+    OpenVINODetectionTask,
+    OpenVINOMaskInferencer,
+    OpenVINOTileClassifierWrapper,
 )
+from otx.algorithms.detection.configs.base import DetectionConfig
+from otx.algorithms.detection.utils import generate_label_schema
 from otx.api.configuration.helper import create
-from otx.api.entities.annotation import (
-    Annotation,
-    AnnotationSceneEntity,
-    AnnotationSceneKind,
-)
-from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.label import LabelEntity
-from otx.api.entities.metrics import Performance, ScoreMetric
-from otx.api.entities.model_template import parse_model_template
-from otx.api.entities.resultset import ResultSetEntity
-from otx.api.entities.scored_label import ScoredLabel
-from otx.api.entities.shapes.polygon import Point, Polygon
-from otx.api.usecases.evaluation.metrics_helper import MetricsHelper
-from otx.api.usecases.tasks.interfaces.optimization_interface import OptimizationType
-from otx.api.utils.shape_factory import ShapeFactory
+from otx.api.entities.model import ModelEntity
+from otx.api.entities.model_template import (
+    TaskType,
+    parse_model_template,
+    task_type_to_label_domain,
+)
+from otx.api.usecases.adapters.model_adapter import ModelAdapter
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
-from tests.unit.algorithms.segmentation.test_helpers import (
-    DEFAULT_SEG_TEMPLATE_DIR,
-    generate_otx_dataset,
-    generate_otx_label_schema,
+from tests.unit.algorithms.detection.test_helpers import (
+    DEFAULT_ISEG_TEMPLATE_DIR,
+    generate_det_dataset,
     init_environment,
 )
 
 
-class TestOpenVINOSegmentationInferencer:
-    @pytest.fixture(autouse=True)
-    def setup(self, mocker) -> None:
-        model_template = parse_model_template(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "template.yaml"))
-        hyper_parameters = create(model_template.hyper_parameters.data)
-        seg_params = SegmentationConfig(header=hyper_parameters.header)
-        label_schema = generate_otx_label_schema()
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.OpenvinoAdapter")
-        mocker.patch.object(Model, "create_model")
-        self.seg_ov_inferencer = OpenVINOSegmentationInferencer(seg_params, label_schema, "")
-        self.seg_ov_inferencer.model = mocker.patch("openvino.model_zoo.model_api.models.Model", autospec=True)
-
-        self.fake_input = np.full((5, 1), 0.1)
-
-    @e2e_pytest_unit
-    def test_pre_process(self):
-        self.seg_ov_inferencer.model.preprocess.return_value = {"foo": "bar"}
-        returned_value = self.seg_ov_inferencer.pre_process(self.fake_input)
-
-        assert returned_value == {"foo": "bar"}
-
-    @e2e_pytest_unit
-    def test_post_process(self):
-        fake_prediction = {"pred": self.fake_input}
-        fake_metadata = {"soft_prediction": self.fake_input, "feature_vector": None}
-        self.seg_ov_inferencer.model.postprocess.return_value = np.ones((5, 1))
-        returned_value = self.seg_ov_inferencer.post_process(fake_prediction, fake_metadata)
-
-        assert len(returned_value) == 3
-        assert np.array_equal(returned_value[2], self.fake_input)
-
-    @e2e_pytest_unit
-    def test_predict(self, mocker):
-        fake_output = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=[])
-        mock_pre_process = mocker.patch.object(OpenVINOSegmentationInferencer, "pre_process", return_value=("", ""))
-        mock_forward = mocker.patch.object(OpenVINOSegmentationInferencer, "forward")
-        mock_post_process = mocker.patch.object(
-            OpenVINOSegmentationInferencer, "post_process", return_value=fake_output
-        )
-        returned_value = self.seg_ov_inferencer.predict(self.fake_input)
-
-        mock_pre_process.assert_called_once()
-        mock_forward.assert_called_once()
-        mock_post_process.assert_called_once()
-        assert returned_value == fake_output
+class TestTilingTileClassifier:
+    """Test the tile classifier"""
 
-    @e2e_pytest_unit
-    def test_forward(self):
-        fake_output = {"pred": np.full((5, 1), 0.9)}
-        self.seg_ov_inferencer.model.infer_sync.return_value = fake_output
-        returned_value = self.seg_ov_inferencer.forward({"image": self.fake_input})
-
-        assert returned_value == fake_output
-
-
-class TestOpenVINOSegmentationTask:
     @pytest.fixture(autouse=True)
-    def setup(self, mocker, otx_model) -> None:
-        model_template = parse_model_template(os.path.join(DEFAULT_SEG_TEMPLATE_DIR, "template.yaml"))
-        hyper_parameters = create(model_template.hyper_parameters.data)
-        label_schema = generate_otx_label_schema()
-        task_env = init_environment(hyper_parameters, model_template)
-        seg_params = SegmentationConfig(header=hyper_parameters.header)
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.OpenvinoAdapter")
-        mocker.patch.object(Model, "create_model")
-        seg_ov_inferencer = OpenVINOSegmentationInferencer(seg_params, label_schema, "")
-
-        task_env.model = otx_model
-        mocker.patch.object(OpenVINOSegmentationTask, "load_inferencer", return_value=seg_ov_inferencer)
-        self.seg_ov_task = OpenVINOSegmentationTask(task_env)
+    def setUp(self, otx_model) -> None:
+        """Set up the test
 
-    @e2e_pytest_unit
-    def test_infer(self, mocker):
-        self.dataset = generate_otx_dataset()
-        fake_annotation = [
-            Annotation(
-                Polygon(points=[Point(0, 0)]),
-                id=0,
-                labels=[ScoredLabel(LabelEntity(name="fake", domain="SEGMENTATION"), probability=1.0)],
-            )
-        ]
-        fake_ann_scene = AnnotationSceneEntity(kind=AnnotationSceneKind.ANNOTATION, annotations=fake_annotation)
-        fake_input = mocker.MagicMock()
+        Args:
+            otx_model (mocker): Mocked model
+        """
+        classes = ("rectangle", "ellipse", "triangle")
+        self.ov_inferencer = dict()
+        task_type = TaskType.INSTANCE_SEGMENTATION
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        self.hyper_parameters = create(model_template.hyper_parameters.data)
+        self.hyper_parameters.tiling_parameters.enable_tiling = True
+        self.hyper_parameters.tiling_parameters.enable_tile_classifier = True
+        self.label_schema = generate_label_schema(classes, task_type_to_label_domain(task_type))
+        self.task_env = init_environment(self.hyper_parameters, model_template, task_type=task_type)
+        self.task_env.model = otx_model
+        dataset, labels = generate_det_dataset(task_type=TaskType.INSTANCE_SEGMENTATION)
+        self.dataset = dataset
+        self.labels = labels
+
+    @e2e_pytest_unit
+    def test_openvino_sync(self, mocker):
+        """Test OpenVINO tile classifier
+
+        Args:
+            mocker (_type_): pytest mocker from fixture
+        """
+        mocker.patch("otx.algorithms.detection.adapters.openvino.task.OpenvinoAdapter")
+        mocker.patch.object(Model, "create_model", return_value=mocker.MagicMock(spec=OTXMaskRCNNModel))
+        params = DetectionConfig(header=self.hyper_parameters.header)
+        ov_mask_inferencer = OpenVINOMaskInferencer(params, self.label_schema, "")
+        ov_mask_inferencer.model.resize_mask = False
+        ov_mask_inferencer.model.preprocess.return_value = ({"foo": "bar"}, {"baz": "qux"})
+        ov_mask_inferencer.model.postprocess.return_value = (
+            np.array([], dtype=np.float32),
+            np.array([], dtype=np.uint32),
+            np.zeros((0, 4), dtype=np.float32),
+            [],
+        )
+        ov_inferencer = OpenVINOTileClassifierWrapper(
+            ov_mask_inferencer, tile_classifier_model_file="", tile_classifier_weight_file="", mode="sync"
+        )
+        ov_inferencer.model.__model__ = "OTX_MaskRCNN"
         mock_predict = mocker.patch.object(
-            OpenVINOSegmentationInferencer, "predict", return_value=(fake_ann_scene, None, fake_input)
+            ov_inferencer.tiler.classifier, "infer_sync", return_value={"tile_prob": 0.5}
         )
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.get_activation_map", return_value=np.zeros((5, 1)))
-        mocker.patch.object(ShapeFactory, "shape_produces_valid_crop", return_value=True)
-        updated_dataset = self.seg_ov_task.infer(self.dataset)
+        mocker.patch.object(OpenVINODetectionTask, "load_inferencer", return_value=ov_inferencer)
+        ov_task = OpenVINODetectionTask(self.task_env)
+        ov_task.inferencer.predict = partial(ov_task.inferencer.predict, mode="sync")
+        updated_dataset = ov_task.infer(self.dataset)
 
         mock_predict.assert_called()
         for updated in updated_dataset:
-            assert updated.annotation_scene.contains_any([LabelEntity(name="fake", domain="SEGMENTATION")])
+            assert updated.annotation_scene.contains_any([LabelEntity(name=self.labels[0].name, domain="DETECTION")])
+
+        output_model = copy.deepcopy(self.task_env.model)
+        ov_task.model.set_data("openvino.bin", b"foo")
+        ov_task.model.set_data("openvino.xml", b"bar")
+        ov_task.model.set_data("tile_classifier.bin", b"foo")
+        ov_task.model.set_data("tile_classifier.xml", b"bar")
+        ov_task.deploy(output_model)
+        assert output_model.exportable_code is not None
 
     @e2e_pytest_unit
-    def test_evaluate(self, mocker):
-        result_set = ResultSetEntity(
-            model=None,
-            ground_truth_dataset=DatasetEntity(),
-            prediction_dataset=DatasetEntity(),
-        )
-        fake_metrics = mocker.patch("otx.api.usecases.evaluation.dice.DiceAverage", autospec=True)
-        fake_metrics.get_performance.return_value = Performance(
-            score=ScoreMetric(name="fake", value=0.1), dashboard_metrics="mDice"
-        )
-        mocker.patch.object(MetricsHelper, "compute_dice_averaged_over_pixels", return_value=fake_metrics)
-        self.seg_ov_task.evaluate(result_set)
+    def test_load_tile_classifier_parameters(self, tmp_dir_path):
+        """Test loading tile classifier parameters
 
-        assert result_set.performance.score.value == 0.1
+        Args:
+            tmp_dir_path (str): Path to temporary directory
+        """
+        maskrcnn_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "model.py"))
+        detector = build_detector(maskrcnn_cfg)
+        model_ckpt = os.path.join(tmp_dir_path, "maskrcnn_without_tile_classifier.pth")
+        torch.save({"state_dict": detector.state_dict()}, model_ckpt)
 
-    @e2e_pytest_unit
-    def test_deploy(self, otx_model):
-        output_model = copy.deepcopy(otx_model)
-        self.seg_ov_task.model.set_data("openvino.bin", b"foo")
-        self.seg_ov_task.model.set_data("openvino.xml", b"bar")
-        self.seg_ov_task.deploy(output_model)
+        # Enable tiling and save weights
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        hyper_parameters.tiling_parameters.enable_tiling = True
+        hyper_parameters.tiling_parameters.enable_tile_classifier = True
+        task_env = init_environment(hyper_parameters, model_template)
+        output_model = ModelEntity(self.dataset, task_env.get_model_configuration())
+        task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
+        task._model_ckpt = model_ckpt
+        task.save_model(output_model)
+        for filename, model_adapter in output_model.model_adapters.items():
+            with open(os.path.join(tmp_dir_path, filename), "wb") as write_file:
+                write_file.write(model_adapter.data)
+
+        # Read tiling parameters from weights
+        with open(os.path.join(tmp_dir_path, "weights.pth"), "rb") as f:
+            bin_data = f.read()
+            model = ModelEntity(
+                self.dataset,
+                configuration=task_env.get_model_configuration(),
+                model_adapters={"weights.pth": ModelAdapter(bin_data)},
+            )
+        task_env.model = model
+        with pytest.raises(RuntimeError) as e:
+            task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
+            assert (
+                str(e.value)
+                == "Tile classifier is enabled but not found in the trained model. Please retrain your model."
+            )
 
-        assert output_model.exportable_code is not None
+        maskrcnn_classifier_cfg = MPAConfig.fromfile(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "model.py"))
+        maskrcnn_classifier_cfg.model.type = "CustomMaskRCNNTileOptimized"
+        tile_classifier_detector = build_detector(maskrcnn_classifier_cfg)
+        tile_classifier_ckpt = os.path.join(tmp_dir_path, "maskrcnn_with_tile_classifier.pth")
+        torch.save({"state_dict": tile_classifier_detector.state_dict()}, tile_classifier_ckpt)
+
+        task_env = init_environment(hyper_parameters, model_template)
+        output_model = ModelEntity(self.dataset, task_env.get_model_configuration())
+        task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
+        task._model_ckpt = tile_classifier_ckpt
+        task.save_model(output_model)
+        for filename, model_adapter in output_model.model_adapters.items():
+            with open(os.path.join(tmp_dir_path, filename), "wb") as write_file:
+                write_file.write(model_adapter.data)
+
+        # Read tiling parameters from weights
+        with open(os.path.join(tmp_dir_path, "weights.pth"), "rb") as f:
+            bin_data = f.read()
+            model = ModelEntity(
+                self.dataset,
+                configuration=task_env.get_model_configuration(),
+                model_adapters={"weights.pth": ModelAdapter(bin_data)},
+            )
+        task_env.model = model
+        task = MMDetectionTask(task_env, output_path=str(tmp_dir_path))
 
     @e2e_pytest_unit
-    def test_optimize(self, mocker, otx_model):
-        def patch_save_model(model, dir_path, model_name):
-            with open(f"{dir_path}/{model_name}.xml", "wb") as f:
-                f.write(b"foo")
-            with open(f"{dir_path}/{model_name}.bin", "wb") as f:
-                f.write(b"bar")
-
-        dataset = generate_otx_dataset()
-        output_model = copy.deepcopy(otx_model)
-        self.seg_ov_task.model.set_data("openvino.bin", b"foo")
-        self.seg_ov_task.model.set_data("openvino.xml", b"bar")
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.load_model", autospec=True)
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.create_pipeline", autospec=True)
-        mocker.patch("otx.algorithms.segmentation.tasks.openvino.save_model", new=patch_save_model)
-        spy_compress = mocker.spy(otx.algorithms.segmentation.tasks.openvino, "compress_model_weights")
-        self.seg_ov_task.optimize(OptimizationType.POT, dataset=dataset, output_model=output_model)
-
-        spy_compress.assert_called_once()
-        assert self.seg_ov_task.model.get_data("openvino.bin")
-        assert self.seg_ov_task.model.get_data("openvino.xml")
+    def test_patch_tiling_func(self):
+        """Test that patch_tiling function works correctly"""
+        cfg = MPAConfig.fromfile(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "model.py"))
+        model_template = parse_model_template(os.path.join(DEFAULT_ISEG_TEMPLATE_DIR, "template.yaml"))
+        hyper_parameters = create(model_template.hyper_parameters.data)
+        hyper_parameters.tiling_parameters.enable_tiling = True
+        hyper_parameters.tiling_parameters.enable_tile_classifier = True
+        patch_tiling(cfg, hyper_parameters, self.dataset)
```

### Comparing `otx-1.1.2rc1/tests/unit/algorithms/segmentation/test_helpers.py` & `otx-1.2.0rc1/tests/unit/algorithms/segmentation/test_helpers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/dummy_broken_config.yaml` & `otx-1.2.0rc1/tests/unit/api/configuration/dummy_broken_config.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/dummy_config.py` & `otx-1.2.0rc1/tests/unit/api/configuration/dummy_config.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/dummy_config.yaml` & `otx-1.2.0rc1/tests/unit/api/configuration/dummy_config.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/elements/test_elements_utils.py` & `otx-1.2.0rc1/tests/unit/api/configuration/elements/test_elements_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/elements/test_metadata_keys.py` & `otx-1.2.0rc1/tests/unit/api/configuration/elements/test_metadata_keys.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/elements/test_primitive_parameters.py` & `otx-1.2.0rc1/tests/unit/api/configuration/elements/test_primitive_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/enums/test_config_element_type.py` & `otx-1.2.0rc1/tests/unit/api/configuration/enums/test_config_element_type.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/enums/test_enum_utils.py` & `otx-1.2.0rc1/tests/unit/api/configuration/enums/test_enum_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/enums/test_model_lifecycle.py` & `otx-1.2.0rc1/tests/unit/api/configuration/enums/test_model_lifecycle.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/helper/test_config_element_mapping.py` & `otx-1.2.0rc1/tests/unit/api/configuration/helper/test_config_element_mapping.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/helper/test_create.py` & `otx-1.2.0rc1/tests/unit/api/configuration/helper/test_create.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/helper/test_helper_utils.py` & `otx-1.2.0rc1/tests/unit/api/configuration/helper/test_helper_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/test_configurable_parameters.py` & `otx-1.2.0rc1/tests/unit/api/configuration/test_configurable_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/test_configuration_helper.py` & `otx-1.2.0rc1/tests/unit/api/configuration/test_configuration_helper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/configuration/test_model_configuration.py` & `otx-1.2.0rc1/tests/unit/api/configuration/test_model_configuration.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/dummy_config.yaml` & `otx-1.2.0rc1/tests/unit/api/entities/dummy_config.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/dummy_template.yaml` & `otx-1.2.0rc1/tests/unit/api/entities/dummy_template.yaml`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/interfaces/test_graph_interface.py` & `otx-1.2.0rc1/tests/unit/api/entities/interfaces/test_graph_interface.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/shapes/test_ellipse.py` & `otx-1.2.0rc1/tests/unit/api/entities/shapes/test_ellipse.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/shapes/test_polygon.py` & `otx-1.2.0rc1/tests/unit/api/entities/shapes/test_polygon.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/shapes/test_rectangle.py` & `otx-1.2.0rc1/tests/unit/api/entities/shapes/test_rectangle.py`

 * *Files 0% similar despite different names*

```diff
@@ -621,19 +621,19 @@
         <b>Expected results:</b>
         Test passes if diagonal method returns expected value of Rectangle diagonal
 
         <b>Steps</b>
         1. Check diagonal method for Rectangle instance
         """
         for rectangle, expected_diagonal in [
-            (self.horizontal_rectangle(), 0.360555127546399),
-            (self.vertical_rectangle(), 0.3605551275463989),
+            (self.horizontal_rectangle(), 0.36055512754639896),
+            (self.vertical_rectangle(), 0.36055512754639896),
             (self.square(), 0.282842712474619),
         ]:
-            assert rectangle.diagonal == expected_diagonal
+            np.testing.assert_approx_equal(rectangle.diagonal, expected_diagonal)
 
     @pytest.mark.priority_medium
     @pytest.mark.unit
     @pytest.mark.reqids(Requirements.REQ_1)
     def test_rectangle_get_area(self):
         """
         <b>Description:</b>
```

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/shapes/test_shape.py` & `otx-1.2.0rc1/tests/unit/api/entities/shapes/test_shape.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_annotation.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_annotation.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_color.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_color.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_coordinate.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_coordinate.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_dataset_item.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_dataset_item.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 # Copyright (C) 2021-2022 Intel Corporation
 # SPDX-License-Identifier: Apache-2.0
 #
 import datetime
 from copy import deepcopy
-from typing import List
+from typing import List, Union
 
 import numpy as np
 import pytest
 
 from otx.api.configuration import ConfigurableParameters
 from otx.api.entities.annotation import (
     Annotation,
     AnnotationSceneEntity,
     AnnotationSceneKind,
 )
 from otx.api.entities.color import Color
-from otx.api.entities.dataset_item import DatasetItemEntity
+from otx.api.entities.dataset_item import DatasetItemEntity, DatasetItemEntityWithID
 from otx.api.entities.datasets import DatasetEntity
 from otx.api.entities.id import ID
 from otx.api.entities.image import Image
 from otx.api.entities.label import Domain, LabelEntity
 from otx.api.entities.label_schema import LabelSchemaEntity
 from otx.api.entities.metadata import MetadataItemEntity
 from otx.api.entities.model import ModelConfiguration, ModelEntity
@@ -142,14 +142,25 @@
             annotation_scene=self.annotations_entity(),
             roi=self.roi(),
             metadata=self.metadata(),
             subset=Subset.TESTING,
             ignored_labels={self.labels()[1]},
         )
 
+    def dataset_item_with_id(self) -> DatasetItemEntityWithID:
+        return DatasetItemEntityWithID(
+            id_=ID("test"),
+            media=self.generate_random_image(),
+            annotation_scene=self.annotations_entity(),
+            roi=self.roi(),
+            metadata=self.metadata(),
+            subset=Subset.TESTING,
+            ignored_labels={self.labels()[1]},
+        )
+
 
 @pytest.mark.components(OtxSdkComponent.OTX_API)
 class TestDatasetItemEntity:
     @staticmethod
     def compare_denormalized_annotations(actual_annotations, expected_annotations) -> None:
         assert len(actual_annotations) == len(expected_annotations)
         for index in range(len(expected_annotations)):
@@ -948,7 +959,36 @@
         assert dataset_item.subset == new_subset
         # Checking value returned by annotation_scene property after using @annotation_scene.setter
         new_annotation_label = ScoredLabel(LabelEntity("new annotation label", Domain.CLASSIFICATION))
         new_annotation = Annotation(Rectangle(x1=0.1, y1=0, x2=0.9, y2=1.0), [new_annotation_label])
         new_annotation_scene = AnnotationSceneEntity([new_annotation], AnnotationSceneKind.PREDICTION)
         dataset_item.annotation_scene = new_annotation_scene
         assert dataset_item.annotation_scene == new_annotation_scene
+
+    @pytest.mark.priority_medium
+    @pytest.mark.unit
+    @pytest.mark.reqids(Requirements.REQ_1)
+    @pytest.mark.parametrize("func_name", ["dataset_item", "dataset_item_with_id"])
+    def test_wrap(self, func_name):
+        constructor = DatasetItemParameters()
+        func = getattr(constructor, func_name)
+        item: DatasetItemEntity = func()
+
+        new_media = DatasetItemParameters().generate_random_image()
+        assert item.media != new_media
+
+        new_subset = Subset.PSEUDOLABELED
+        assert item.subset != new_subset
+
+        new_metadata = DatasetItemParameters().metadata()
+        assert item.get_metadata() != new_metadata
+
+        new_item = item.wrap(media=new_media, subset=new_subset, metadata=new_metadata)
+        assert new_item.media == new_media
+        assert new_item.subset == new_subset
+        assert new_item.get_metadata() == new_metadata
+
+        if hasattr(item, "id_"):
+            new_id = ID("new_id")
+            assert item.id_ != new_id
+            item = item.wrap(id_=new_id)
+            assert item.id_ == new_id
```

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_datasets.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_datasets.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_graph.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_graph.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_id.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_id.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_image.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_image.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_inference_parameters.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_inference_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_label.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_label.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_label_schema.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_label_schema.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_media.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_media.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_metadata.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_metadata.py`

 * *Files 1% similar despite different names*

```diff
@@ -52,15 +52,15 @@
         1. Create IMetadata
         2. Check default value of class field
         3. Change value of the field
         """
 
         test_instance = IMetadata()
         assert isinstance(test_instance, IMetadata)
-        assert str(test_instance.name) == "typing.Union[str, NoneType]"
+        assert str(test_instance.name) in ["typing.Union[str, NoneType]", "typing.Optional[str]"]
 
         test_instance.name = "String"
         assert test_instance.name == "String"
 
 
 @pytest.mark.components(OtxSdkComponent.OTX_API)
 class TestFloatType:
```

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_metrics.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_metrics.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_model.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_model_template.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_model_template.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_optimization_parameters.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_optimization_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_pickle.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_pickle.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_result_media.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_result_media.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_resultset.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_resultset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_scored_label.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_scored_label.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_subset.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_subset.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_task_environment.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_task_environment.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_tensor.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_tensor.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_train_parameters.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_train_parameters.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/entities/test_url.py` & `otx-1.2.0rc1/tests/unit/api/entities/test_url.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/parameters_validation/validation_helper.py` & `otx-1.2.0rc1/tests/unit/api/parameters_validation/validation_helper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/serialization/test_datetime_mapper.py` & `otx-1.2.0rc1/tests/unit/api/serialization/test_datetime_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/serialization/test_id_mapper.py` & `otx-1.2.0rc1/tests/unit/api/serialization/test_id_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/serialization/test_label_mapper.py` & `otx-1.2.0rc1/tests/unit/api/serialization/test_label_mapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/adapters/test_model_adapter.py` & `otx-1.2.0rc1/tests/unit/api/usecases/adapters/test_model_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_accuracy.py` & `otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_accuracy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_basic_operations.py` & `otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_basic_operations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_dice.py` & `otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_dice.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/evaluation/test_f_measure.py` & `otx-1.2.0rc1/tests/unit/api/usecases/evaluation/test_f_measure.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_prediction_to_annotation_converter.py` & `otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_prediction_to_annotation_converter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_streamer.py` & `otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_streamer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/exportable_code/test_visualization.py` & `otx-1.2.0rc1/tests/unit/api/usecases/exportable_code/test_visualization.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/reporting/test_callback.py` & `otx-1.2.0rc1/tests/unit/api/usecases/reporting/test_callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/reporting/test_time_monitor_callback.py` & `otx-1.2.0rc1/tests/unit/api/usecases/reporting/test_time_monitor_callback.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/usecases/tasks/interfaces/test_interfaces.py` & `otx-1.2.0rc1/tests/unit/api/usecases/tasks/interfaces/test_interfaces.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/utils/test_segmentation_utils.py` & `otx-1.2.0rc1/tests/unit/api/utils/test_segmentation_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/utils/test_shape_drawer.py` & `otx-1.2.0rc1/tests/unit/api/utils/test_shape_drawer.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/api/utils/test_shape_factory.py` & `otx-1.2.0rc1/tests/unit/api/utils/test_shape_factory.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/builder/test_cli_builder.py` & `otx-1.2.0rc1/tests/unit/cli/builder/test_cli_builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/manager/test_config_manager.py` & `otx-1.2.0rc1/tests/unit/cli/manager/test_config_manager.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/registry/test_cli_registry.py` & `otx-1.2.0rc1/tests/unit/cli/registry/test_cli_registry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_build.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_build.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,15 @@
         "--train-data-roots": "train/data/root",
         "--val-data-roots": "val/data/root",
         "--test-data-roots": "test/data/root",
         "--unlabeled-data-roots": "unlabeled/data/root",
         "--unlabeled-file-list": "unlabeled/file/list",
         "--task": "detection",
         "--train-type": "Semisupervised",
-        "--work-dir": "work/dir/path",
+        "--workspace": "work/dir/path",
         "--model": "SSD",
         "--backbone": "torchvision.resnet18",
     }
     mock_command = ["otx"]
     for key, value in mock_options.items():
         mock_command.extend([key, value])
 
@@ -31,15 +31,15 @@
     parsed_args = get_args()
 
     assert parsed_args.train_data_roots == "train/data/root"
     assert parsed_args.val_data_roots == "val/data/root"
     assert parsed_args.test_data_roots == "test/data/root"
     assert parsed_args.unlabeled_data_roots == "unlabeled/data/root"
     assert parsed_args.unlabeled_file_list == "unlabeled/file/list"
-    assert parsed_args.work_dir == "work/dir/path"
+    assert parsed_args.workspace == "work/dir/path"
     assert parsed_args.task == "detection"
     assert parsed_args.train_type == "Semisupervised"
     assert parsed_args.model == "SSD"
     assert parsed_args.backbone == "torchvision.resnet18"
 
 
 @pytest.fixture
@@ -48,15 +48,15 @@
     mock_args.train_data_roots = None
     mock_args.val_data_roots = None
     mock_args.test_data_roots = None
     mock_args.unlabeled_data_roots = None
     mock_args.unlabeled_file_list = None
     mock_args.task = ""
     mock_args.train_type = "incremental"
-    mock_args.work_dir = tmp_path / "work_dir"
+    mock_args.workspace = tmp_path / "work_dir"
     mock_args.model = ""
     mock_args.backbone = "torchvision.resnet18"
 
     def mock_contains(self, val):
         return val in self.__dict__
 
     mock_args.__contains__ = mock_contains
@@ -88,15 +88,15 @@
     # Call main function
     result = main()
 
     # Check return value
     assert result == {"retcode": 0, "task_type": ""}
 
     # Check ConfigManager constructor call
-    mock_config_manager.assert_called_once_with(mock_args, mode="build")
+    mock_config_manager.assert_called_once()
 
     # Check ConfigManager method calls
     mock_config_manager.return_value.configure_template.assert_called_once_with(model="")
     mock_config_manager.return_value.build_workspace.assert_called_once()
     mock_config_manager.return_value.configure_data_config.assert_called_once_with()
 
     # Check Builder constructor call
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_cli.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_cli.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_deploy.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_deploy.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,30 +6,30 @@
 from otx.cli.tools import deploy as target_package
 from otx.cli.tools.deploy import get_args, main
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
 @e2e_pytest_unit
 def test_get_args(mocker):
-    mocker.patch("sys.argv", ["otx", "--load-weights", "load_weights", "--save-model-to", "save_model_to"])
+    mocker.patch("sys.argv", ["otx", "--load-weights", "load_weights", "--output", "output"])
     mocker.patch.object(
         target_package, "get_parser_and_hprams_data", return_value=[argparse.ArgumentParser(), "fake", "fake"]
     )
 
     parsed_args = get_args()
 
     assert parsed_args.load_weights == "load_weights"
-    assert parsed_args.save_model_to == "save_model_to"
+    assert parsed_args.output == "output"
 
 
 @pytest.fixture
 def mock_args(mocker, tmp_dir):
     mock_args = mocker.MagicMock()
     mock_args.load_weights = "fake.bin"
-    mock_args.save_model_to = tmp_dir
+    mock_args.output = tmp_dir
 
     def mock_contains(self, val):
         return val in self.__dict__
 
     mock_args.__contains__ = mock_contains
     mock_get_args = mocker.patch("otx.cli.tools.deploy.get_args")
     mock_get_args.return_value = mock_args
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_eval.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_eval.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 
 
 @e2e_pytest_unit
 def test_get_args(mocker):
     mock_options = {
         "--test-data-roots": "test/data/root",
         "--load-weights": "weight/path",
-        "--save-performance": "save/path",
-        "--work-dir": "work/dir/path",
+        "--output": "save/path",
+        "--workspace": "work/dir/path",
     }
     mock_command = ["otx"]
     for key, value in mock_options.items():
         mock_command.extend([key, value])
 
     mocker.patch("sys.argv", mock_command)
     mocker.patch.object(
@@ -25,25 +25,23 @@
     )
     mocker.patch.object(target_package, "add_hyper_parameters_sub_parser", return_value=argparse.ArgumentParser())
 
     parsed_args, _ = get_args()
 
     assert parsed_args.test_data_roots == "test/data/root"
     assert parsed_args.load_weights == "weight/path"
-    assert parsed_args.save_performance == "save/path"
-    assert parsed_args.work_dir == "work/dir/path"
+    assert parsed_args.workspace == "work/dir/path"
 
 
 @pytest.fixture
 def mock_args(mocker, tmp_path):
     mock_args = mocker.MagicMock()
     mock_args.test_data_roots = "fake_test_data_root"
     mock_args.load_weights = "fake_load_weights.xml"
-    mock_args.save_performance = tmp_path / "save/performance.json"
-    mock_args.work_dir = tmp_path / "work_dir"
+    mock_args.workspace = tmp_path / "work_dir"
 
     def mock_contains(self, val):
         return val in self.__dict__
 
     mock_args.__contains__ = mock_contains
     mock_get_args = mocker.patch("otx.cli.tools.eval.get_args")
     mock_get_args.return_value = [mock_args, []]
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_export.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_export.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,30 +6,30 @@
 from otx.cli.tools import export as target_package
 from otx.cli.tools.export import get_args, main
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
 @e2e_pytest_unit
 def test_get_args(mocker):
-    mocker.patch("sys.argv", ["otx", "--load-weights", "load_weights", "--save-model-to", "save_model_to"])
+    mocker.patch("sys.argv", ["otx", "--load-weights", "load_weights", "--output", "output"])
     mocker.patch.object(
         target_package, "get_parser_and_hprams_data", return_value=[argparse.ArgumentParser(), "fake", "fake"]
     )
 
     parsed_args = get_args()
 
     assert parsed_args.load_weights == "load_weights"
-    assert parsed_args.save_model_to == "save_model_to"
+    assert parsed_args.output == "output"
 
 
 @pytest.fixture
 def mock_args(mocker, tmp_dir):
     mock_args = mocker.MagicMock()
     mock_args.load_weights = "fake.bin"
-    mock_args.save_model_to = tmp_dir
+    mock_args.output = tmp_dir
 
     def mock_contains(self, val):
         return val in self.__dict__
 
     mock_args.__contains__ = mock_contains
     mock_get_args = mocker.patch("otx.cli.tools.export.get_args")
     mock_get_args.return_value = mock_args
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_find.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_find.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/tools/test_optimize.py` & `otx-1.2.0rc1/tests/unit/cli/tools/test_train.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,137 +1,134 @@
 import argparse
 
 import pytest
 
-from otx.cli.tools import optimize as target_package
-from otx.cli.tools.optimize import get_args, main
+from otx.cli.tools import train as target_package
+from otx.cli.tools.train import get_args, main
 from tests.test_suite.e2e_test_system import e2e_pytest_unit
 
 
 @e2e_pytest_unit
 def test_get_args(mocker):
     mock_options = {
-        "--train-data-roots": "train_data_roots_path",
-        "--val-data-roots": "val_data_roots_path",
-        "--load-weights": "load_weights_path",
-        "--save-model-to": "save_model_path",
-        "--save-performance": "save_performance_path",
-        "--work-dir": "work_dir_path",
+        "--train-data-roots": "train/data/root",
+        "--val-data-roots": "val/data/root",
+        "--unlabeled-data-roots": "unlabeled/data/root",
+        "--unlabeled-file-list": "unlabeled/file/list",
+        "--load-weights": "weight/path",
+        "--resume-from": "resume/path",
+        "--output": "save/path",
+        "--workspace": "work/dir/path",
+        "--hpo-time-ratio": "2",
+        "--gpus": "0,1",
+        "--rdzv-endpoint": "localhost:1",
+        "--base-rank": "1",
+        "--world-size": "1",
+        "--data": "data/yaml",
     }
     mock_command = ["otx"]
     for key, value in mock_options.items():
         mock_command.extend([key, value])
 
     mocker.patch("sys.argv", mock_command)
     mocker.patch.object(
         target_package, "get_parser_and_hprams_data", return_value=[argparse.ArgumentParser(), {"param": "test"}, []]
     )
     mocker.patch.object(target_package, "add_hyper_parameters_sub_parser", return_value=argparse.ArgumentParser())
 
     parsed_args, _ = get_args()
 
-    assert parsed_args.train_data_roots == "train_data_roots_path"
-    assert parsed_args.val_data_roots == "val_data_roots_path"
-    assert parsed_args.load_weights == "load_weights_path"
-    assert parsed_args.save_model_to == "save_model_path"
-    assert parsed_args.save_performance == "save_performance_path"
-    assert parsed_args.work_dir == "work_dir_path"
+    assert parsed_args.train_data_roots == "train/data/root"
+    assert parsed_args.val_data_roots == "val/data/root"
+    assert parsed_args.unlabeled_data_roots == "unlabeled/data/root"
+    assert parsed_args.unlabeled_file_list == "unlabeled/file/list"
+    assert parsed_args.load_weights == "weight/path"
+    assert parsed_args.resume_from == "resume/path"
+    assert parsed_args.output == "save/path"
+    assert parsed_args.workspace == "work/dir/path"
+    assert parsed_args.hpo_time_ratio == 2.0
+    assert parsed_args.gpus == "0,1"
+    assert parsed_args.rdzv_endpoint == "localhost:1"
+    assert parsed_args.base_rank == 1
+    assert parsed_args.world_size == 1
+    assert parsed_args.data == "data/yaml"
 
 
 @pytest.fixture
 def mock_args(mocker, tmp_path):
     mock_args = mocker.MagicMock()
-    mock_args.train_data_roots = "fake_train_data_roots_path"
-    mock_args.val_data_roots = "fake_val_data_roots_path"
-    mock_args.load_weights = "fake_load_weights_path"
-    mock_args.save_model_to = tmp_path / "save/model"
-    mock_args.save_performance = tmp_path / "save/performance.json"
-    mock_args.work_dir = tmp_path / "work_dir_path"
+    mock_args.train_data_roots = "fake_train_data_root"
+    mock_args.val_data_roots = "fake_val_data_root"
+    mock_args.load_weights = "fake_load_weights"
+    mock_args.resume_from = None
+    mock_args.output = tmp_path / "models"
+    mock_args.workspace = tmp_path / "work_dir"
+    mock_args.enable_hpo = False
+    mock_args.hpo_time_ratio = 4
+    mock_args.gpus = None
+    mock_args.rdzv_endpoint = "localhost:0"
+    mock_args.base_rank = 0
+    mock_args.world_size = 0
+    mock_args.data = None
+    mock_args.unlabeled_data_roots = None
+    mock_args.unlabeled_file_list = None
 
     def mock_contains(self, val):
         return val in self.__dict__
 
     mock_args.__contains__ = mock_contains
-    mock_get_args = mocker.patch("otx.cli.tools.optimize.get_args")
+    mock_get_args = mocker.patch("otx.cli.tools.train.get_args")
     mock_get_args.return_value = [mock_args, []]
 
     return mock_args
 
 
 @pytest.fixture
 def mock_config_manager(mocker):
     mock_config_manager = mocker.patch.object(target_package, "ConfigManager")
     mock_template = mocker.MagicMock()
-    mock_template.name = "fake_template_name"
+    mock_template.name = "fake_name"
     mock_config_manager.return_value.template = mock_template
     mock_config_manager.return_value.check_workspace.return_value = True
     mock_config_manager.return_value.get_dataset_config.return_value = {}
     mock_config_manager.return_value.get_hyparams_config.return_value = {}
 
     return mock_config_manager
 
 
 @pytest.fixture
 def mock_dataset_adapter(mocker):
-    mock_dataset_adapter = mocker.patch("otx.cli.tools.optimize.get_dataset_adapter")
+    mock_dataset_adapter = mocker.patch("otx.cli.tools.train.get_dataset_adapter")
     mock_dataset = mocker.MagicMock()
     mock_label_schema = mocker.MagicMock()
     mock_dataset_adapter.return_value.get_otx_dataset.return_value = mock_dataset
     mock_dataset_adapter.return_value.get_label_schema.return_value = mock_label_schema
 
     return mock_dataset_adapter
 
 
 @pytest.fixture
-def mock_task_class(mocker):
-    return mocker.patch.object(target_package, "get_impl_class")
+def mock_task(mocker):
+    mock_task_class = mocker.MagicMock()
+    mock_task = mocker.MagicMock()
+    mock_task_class.return_value = mock_task
+    mocker.patch.object(target_package, "get_impl_class", return_value=mock_task_class)
 
-
-@pytest.fixture
-def mock_task(mocker, mock_task_class, mock_dataset_adapter):
-    mock_task_class.return_value.return_value = mocker.MagicMock()
-    mocker.patch.object(target_package, "get_dataset_adapter", return_value=mock_dataset_adapter)
+    return mock_task
 
 
 @e2e_pytest_unit
-def test_main(
-    mocker,
-    mock_args,
-    mock_config_manager,
-    mock_dataset_adapter,
-    mock_task,
-):
-    mocker.patch.object(target_package, "read_model", return_value=mocker.MagicMock())
-
-    mocker.patch("otx.cli.tools.optimize.save_model_data")
-
-    mocker.patch.object(
-        target_package,
-        "ResultSetEntity",
-        return_value=mocker.MagicMock(),
-    )
-
-    mocker.patch.object(
-        target_package,
-        "InferenceParameters",
-        return_value=mocker.MagicMock(),
-    )
-
+def test_main(mocker, mock_args, mock_config_manager, mock_dataset_adapter, mock_task):
+    mocker.patch.object(target_package, "read_label_schema")
+    mocker.patch.object(target_package, "read_binary")
+    mocker.patch("otx.cli.tools.train.Path.symlink_to")
+    mocker.patch("otx.cli.tools.train.get_otx_report")
     mocker.patch.object(
         target_package,
-        "Subset",
+        "run_hpo",
         return_value=mocker.MagicMock(),
     )
-
-    mocker.patch.object(
-        target_package,
-        "TaskEnvironment",
-        return_value=mocker.MagicMock(),
-    )
-    mocker.patch("json.dump")
-    mocker.patch("builtins.open")
-
-    mock_get_args = mocker.patch("otx.cli.tools.optimize.get_args")
-    mock_get_args.return_value = [mock_args, []]
+    mocker.patch.object(target_package, "save_model_data")
 
     ret = main()
+
     assert ret["retcode"] == 0
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_config.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_config.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_hpo.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_hpo.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 import otx
 from otx.api.configuration.helper import create as create_conf_hp
 from otx.api.entities.model import ModelEntity
 from otx.api.entities.model_template import TaskType
 from otx.api.entities.subset import Subset
 from otx.api.entities.task_environment import TaskEnvironment
 from otx.cli.registry import find_and_parse_model_template
+from otx.cli.utils import hpo
 from otx.cli.utils.hpo import (
     HpoCallback,
     HpoDataset,
     HpoRunner,
     TaskEnvironmentManager,
     TaskManager,
     Trainer,
@@ -609,16 +610,15 @@
             pass
 
 
 @e2e_pytest_unit
 def test_run_hpo(mocker, mock_environment):
     with TemporaryDirectory() as tmp_dir:
         # prepare
-        save_model_to_path = Path(tmp_dir) / "fake"
-
+        output = Path(tmp_dir) / "fake"
         mock_get_best_hpo_weight = mocker.patch("otx.cli.utils.hpo.get_best_hpo_weight")
         mock_get_best_hpo_weight.return_value = "mock_best_weight_path"
 
         def mock_run_hpo(*args, **kwargs):
             return {"config": {"a.b": 1, "c.d": 2}, "id": "1"}
 
         mock_hpo_runner_instance = mocker.MagicMock()
@@ -627,38 +627,54 @@
         mock_hpo_runner_class.return_value = mock_hpo_runner_instance
 
         def mock_read_model(args1, path, arg2):
             return path
 
         mocker.patch("otx.cli.utils.hpo.read_model", mock_read_model)
 
-        mock_args = mocker.MagicMock()
-        mock_args.hpo_time_ratio = "4"
-        mock_args.save_model_to = save_model_to_path
-
+        hpo_time_ratio = "4"
         mock_environment.model_template.task_type = TaskType.CLASSIFICATION
 
         # run
-        environment = run_hpo(mock_args, mock_environment, mocker.MagicMock(), mocker.MagicMock())
+        environment = run_hpo(hpo_time_ratio, output, mock_environment, mocker.MagicMock(), mocker.MagicMock())
 
         # check
         mock_hpo_runner_instance.run_hpo.assert_called()  # Check that HpoRunner.run_hpo is called
         env_hp = environment.get_hyper_parameters()  # Check that best HP is applied well.
         assert env_hp.a.b == 1
         assert env_hp.c.d == 2
         assert environment.model == "mock_best_weight_path"  # check that best model weight is used
 
 
 @e2e_pytest_unit
 def test_run_hpo_not_supported_task(mocker, action_task_env):
     mock_hpo_runner_instance = mocker.MagicMock()
     mock_hpo_runner_class = mocker.patch("otx.cli.utils.hpo.HpoRunner")
     mock_hpo_runner_class.return_value = mock_hpo_runner_instance
+    hpo_time_ratio = "4"
+    output = "fake"
+
+    run_hpo(hpo_time_ratio, output, action_task_env, mocker.MagicMock(), mocker.MagicMock())
+    mock_hpo_runner_instance.run_hpo.assert_not_called()
+
+
+@e2e_pytest_unit
+def test_run_hpo_with_torchrun(mocker, mock_environment):
+    # prepare
+    output = "fake"
+    mock_hpo_runner_instance = mocker.MagicMock()
+    mock_hpo_runner_class = mocker.patch("otx.cli.utils.hpo.HpoRunner")
+    mock_hpo_runner_class.return_value = mock_hpo_runner_instance
+    hpo_time_ratio = "4"
+    mock_environment.model_template.task_type = TaskType.CLASSIFICATION
+    mock_os = mocker.patch.object(hpo, "os", return_value={"TORCHELASTIC_RUN_ID": "1234"})
+    mock_os.environ = {"TORCHELASTIC_RUN_ID": "1234"}
 
-    run_hpo(mocker.MagicMock(), action_task_env, mocker.MagicMock(), mocker.MagicMock())
+    # run
+    run_hpo(hpo_time_ratio, output, mock_environment, mocker.MagicMock(), mocker.MagicMock())
     mock_hpo_runner_instance.run_hpo.assert_not_called()
 
 
 @e2e_pytest_unit
 def test_get_best_hpo_weight():
     with TemporaryDirectory() as tmp_dir:
         # prepare
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_importing.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_importing.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_io.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_io.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_multi_gpu.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_multi_gpu.py`

 * *Files 2% similar despite different names*

```diff
@@ -64,14 +64,23 @@
     other_val = "other_val"
     set_arguments_to_argv("--a_key", other_val)
 
     assert mock_argv_without_params[1] == other_val
 
 
 @e2e_pytest_unit
+def test_set_arguments_to_argv_keys_exist(mock_argv_without_params):
+    """Test a case where key already exists and value exists."""
+    other_val = "other_val"
+    set_arguments_to_argv(["--a_key", "-a"], other_val)
+
+    assert mock_argv_without_params[1] == other_val
+
+
+@e2e_pytest_unit
 def test_set_arguments_to_argv_key_exist_none_val(mock_argv_without_params):
     """Test a case where key already exists in argv and value doesn't exists."""
     expected_result = deepcopy(mock_argv_without_params)
     set_arguments_to_argv("--a_key")
 
     assert mock_argv_without_params == expected_result
 
@@ -164,15 +173,15 @@
     @pytest.fixture
     def process_arr(self, mocker):
         """List consists of normal process excpet last one. Last element is a process which exit abnormally."""
         normal_process = mocker.MagicMock()
         normal_process.is_alive.return_value = True
         wrong_process = mocker.MagicMock()
         wrong_process.is_alive.return_value = False
-        wrong_process.exit_code = 1
+        wrong_process.exitcode = 1
         process_arr = []
         for _ in range(self.num_gpu - 2):
             process_arr.append(deepcopy(normal_process))
         process_arr.append(wrong_process)
 
         return process_arr
 
@@ -194,14 +203,22 @@
         mock_torch = mocker.patch.object(multi_gpu, "torch")
         mock_torch.cuda.device_count.return_value = 0
         multigpu_manager = MultiGPUManager(mocker.MagicMock(), ",".join([str(i) for i in range(4)]), "localhost:0")
 
         assert not multigpu_manager.is_available()
 
     @e2e_pytest_unit
+    def test_is_unavailable_by_torchrun(self, mocker):
+        mock_os = mocker.patch.object(multi_gpu, "os")
+        mock_os.environ = {"TORCHELASTIC_RUN_ID": "1234"}
+        multigpu_manager = MultiGPUManager(mocker.MagicMock(), ",".join([str(i) for i in range(4)]), "localhost:0")
+
+        assert not multigpu_manager.is_available()
+
+    @e2e_pytest_unit
     def test_setup_multi_gpu_train(self, mocker):
         # prepare
         mock_initialize_multigpu_train = mocker.patch.object(MultiGPUManager, "initialize_multigpu_train")
         mock_hyper_parameters = mocker.MagicMock()
         mock_hyper_parameters.learning_parameters.learning_rate = 0.01
         mock_hyper_parameters.learning_parameters.batch_size = 8
         mock_sys = mocker.patch.object(multi_gpu, "sys")
@@ -307,30 +324,46 @@
         self.multigpu_manager.finalize()
 
         # check
         for p in process_arr:
             p.join.assert_called_once()
 
     @e2e_pytest_unit
+    def test_finalize_still_running_child_process(self, mocker, process_arr):
+        # prepare
+        mocker.patch.object(MultiGPUManager, "initialize_multigpu_train")
+        self.mock_process.side_effect = process_arr
+        for p in process_arr:
+            p.exitcode = None
+            p.join.return_value = None
+
+        # run
+        self.multigpu_manager.setup_multi_gpu_train("fake")
+        self.multigpu_manager.finalize()
+
+        # check
+        for p in process_arr:
+            p.join.assert_called_once()
+            p.kill.assert_called_once()
+
+    @e2e_pytest_unit
     def test_finalize_before_spawn(self, mocker, process_arr):
         # prepare
         mocker.patch.object(MultiGPUManager, "initialize_multigpu_train")
         self.mock_process.side_effect = process_arr
 
         # run
         self.multigpu_manager.setup_multi_gpu_train("fake")
         self.multigpu_manager.finalize()
 
     @e2e_pytest_unit
     def test_initialize_multigpu_train(self, mocker):
         # prepare
         mock_os = mocker.patch.object(multi_gpu, "os")
         mock_os.environ = {}
-        mock_set_device = mocker.patch.object(multi_gpu.torch.cuda, "set_device")
-        mock_init_process_group = mocker.patch.object(multi_gpu.dist, "init_process_group")
         mocker.patch.object(multi_gpu.dist, "get_world_size", return_value=2)
         mocker.patch.object(multi_gpu.dist, "get_rank", return_value=0)
 
         # run
         MultiGPUManager.initialize_multigpu_train(
             rdzv_endpoint="localhost:1234",
             rank=0,
@@ -342,16 +375,14 @@
         # check
         assert mock_os.environ["MASTER_ADDR"] == "localhost"
         assert mock_os.environ["MASTER_PORT"] == "1234"
         assert mock_os.environ["LOCAL_WORLD_SIZE"] == "2"
         assert mock_os.environ["WORLD_SIZE"] == "2"
         assert mock_os.environ["LOCAL_RANK"] == "0"
         assert mock_os.environ["RANK"] == "0"
-        mock_set_device.assert_called_once()
-        mock_init_process_group.assert_called_once()
 
     @e2e_pytest_unit
     def test_run_child_process(self, mocker):
         # prepare
         mock_set_start_method = mocker.patch.object(multi_gpu.mp, "set_start_method")
         mock_sys = mocker.patch.object(multi_gpu, "sys")
         mock_sys.argv = ["--gpus", "0,1"]
@@ -371,16 +402,19 @@
             gpu_ids=[0, 1],
             world_size=4,
         )
 
         # check
         assert mock_set_start_method.call_args.kwargs["method"] is None
         assert "--gpus" not in mock_sys.argv
-        assert "--work-dir" in mock_sys.argv
-        assert mock_sys.argv[mock_sys.argv.index("--work-dir") + 1] == output_path
+        for output_arg_key in ["-o", "--output", False]:
+            if output_arg_key in mock_sys.argv:
+                break
+        assert output_arg_key is not False, "There arn't both '-o' and '--output'."
+        assert mock_sys.argv[mock_sys.argv.index(output_arg_key) + 1] == output_path
         assert "--rdzv-endpoint" in mock_sys.argv
         assert mock_sys.argv[mock_sys.argv.index("--rdzv-endpoint") + 1] == rdzv_endpoint
         mock_initialize_multigpu_train.assert_called_once()
         mock_threading.Thread.assert_called_once_with(target=MultiGPUManager.check_parent_processes_alive, daemon=True)
         mock_threading.Thread.call_args.return_value.start.assert_called_once
         mock_train_func.assert_called_once()
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_nncf.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_nncf.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_parser.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -229,22 +229,22 @@
 
 
 @pytest.mark.parametrize(
     "mem_size_arg,expected",
     [
         ("1561", 1561),
         ("121k", 121 * (2**10)),
-        ("121kb", 121 * (2**10)),
-        ("121kib", 121 * (10**3)),
+        ("121kb", 121 * (10**3)),
+        ("121kib", 121 * (2**10)),
         ("121m", 121 * (2**20)),
-        ("121mb", 121 * (2**20)),
-        ("121mib", 121 * (10**6)),
+        ("121mb", 121 * (10**6)),
+        ("121mib", 121 * (2**20)),
         ("121g", 121 * (2**30)),
-        ("121gb", 121 * (2**30)),
-        ("121gib", 121 * (10**9)),
+        ("121gb", 121 * (10**9)),
+        ("121gib", 121 * (2**30)),
         ("121as", None),
         ("121dddd", None),
     ],
 )
 def test_mem_size_parsing(fxt_argparse, mem_size_arg, expected):
     try:
         args = fxt_argparse.parse_args(["--mem-cache-size", mem_size_arg])
```

### Comparing `otx-1.1.2rc1/tests/unit/cli/utils/test_telemetry.py` & `otx-1.2.0rc1/tests/unit/cli/utils/test_telemetry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_action_adapter.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_action_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_anomaly_adapter.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_anomaly_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_classification_adapter.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_classification_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_detection_adapter.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_detection_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_init.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_init.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/adapter/test_segmentation_adapter.py` & `otx-1.2.0rc1/tests/unit/core/data/adapter/test_segmentation_adapter.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/manager/test_dataset_manager.py` & `otx-1.2.0rc1/tests/unit/core/data/manager/test_dataset_manager.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 AVAILABLE_TASKS = ["classification", "detection", "segmentation"]
 AVAILABLE_SUBSETS = ["train", "val"]
 AVAILABLE_DATA_ROOTS = [
     "tests/assets/imagenet_dataset",
     "tests/assets/car_tree_bug",
     "tests/assets/cityscapes_dataset/dataset",
-    "tests/assets/anomaly/shapes",
+    "tests/assets/anomaly/hazelnut",
     "tests/assets/cvat_dataset/action_classification/train",
 ]
 
 DATA_ROOTS2FORMAT = {
     "tests/assets/imagenet_dataset": "imagenet",
     "tests/assets/car_tree_bug": "coco",
     "tests/assets/cityscapes_dataset/dataset": "cityscapes",
```

### Comparing `otx-1.1.2rc1/tests/unit/core/data/test_caching.py` & `otx-1.2.0rc1/tests/unit/core/data/test_caching.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/data/test_helpers.py` & `otx-1.2.0rc1/tests/unit/core/data/test_helpers.py`

 * *Files 6% similar despite different names*

```diff
@@ -49,27 +49,27 @@
     "segmentation": {
         "train": "tests/assets/common_semantic_segmentation_dataset/train",
         "val": "tests/assets/common_semantic_segmentation_dataset/val",
         "test": "tests/assets/common_semantic_segmentation_dataset/val",
         "unlabeled": "tests/assets/common_semantic_segmentation_dataset/val",
     },
     "anomaly_classification": {
-        "train": "tests/assets/anomaly/shapes",
-        "val": "tests/assets/anomaly/shapes",
-        "test": "tests/assets/anomaly/shapes",
+        "train": "tests/assets/anomaly/hazelnut",
+        "val": "tests/assets/anomaly/hazelnut",
+        "test": "tests/assets/anomaly/hazelnut",
     },
     "anomaly_detection": {
-        "train": "tests/assets/anomaly/shapes",
-        "val": "tests/assets/anomaly/shapes",
-        "test": "tests/assets/anomaly/shapes",
+        "train": "tests/assets/anomaly/hazelnut",
+        "val": "tests/assets/anomaly/hazelnut",
+        "test": "tests/assets/anomaly/hazelnut",
     },
     "anomaly_segmentation": {
-        "train": "tests/assets/anomaly/shapes",
-        "val": "tests/assets/anomaly/shapes",
-        "test": "tests/assets/anomaly/shapes",
+        "train": "tests/assets/anomaly/hazelnut",
+        "val": "tests/assets/anomaly/hazelnut",
+        "test": "tests/assets/anomaly/hazelnut",
     },
     "action_classification": {
         "train": "tests/assets/cvat_dataset/action_classification/train",
         "val": "tests/assets/cvat_dataset/action_classification/train",
         "test": "tests/assets/cvat_dataset/action_classification/train",
     },
     "action_detection": {
```

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_cls_parser.py` & `otx-1.2.0rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_cls_parser.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_parser.py` & `otx-1.2.0rc1/tests/unit/core/ov/graph/parsers/test_ov_graph_parser.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/graph/test_ov_graph_grapy.py` & `otx-1.2.0rc1/tests/unit/core/ov/graph/test_ov_graph_grapy.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/graph/test_ov_graph_utils.py` & `otx-1.2.0rc1/tests/unit/core/ov/graph/test_ov_graph_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/backbones/test_ov_mmcls_mmov_backbone.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/backbones/test_ov_mmcls_mmov_backbone.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_cls_head.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_conv_head.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_conv_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_mmcv_cls_head.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/heads/test_ov_mmcls_mmcv_cls_head.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/necks/test_ov_mmcls_mmov_neck.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/necks/test_ov_mmcls_mmov_neck.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/mmcls/test_helpers.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/mmcls/test_helpers.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/models/test_ov_models_ov_model.py` & `otx-1.2.0rc1/tests/unit/core/ov/models/test_ov_models_ov_model.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_activations.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_activations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_arithmetics.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_arithmetics.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_builder.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_builder.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_convolutions.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_convolutions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_generation.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_generation.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_image_processings.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_image_processings.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_infrastructures.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_infrastructures.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_matmuls.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_matmuls.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_module.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_module.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_movements.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_movements.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_normalizations.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_normalizations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_object_detections.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_object_detections.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_op.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_op.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_poolings.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_poolings.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_reductions.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_reductions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_shape_manipulations.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_shape_manipulations.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_sorting_maximization.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_sorting_maximization.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_type_conversions.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_type_conversions.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/ops/test_ov_ops_utils.py` & `otx-1.2.0rc1/tests/unit/core/ov/ops/test_ov_ops_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/test_ov_omz_wrapper.py` & `otx-1.2.0rc1/tests/unit/core/ov/test_ov_omz_wrapper.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/test_ov_registry.py` & `otx-1.2.0rc1/tests/unit/core/ov/test_ov_registry.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/ov/test_ov_utils.py` & `otx-1.2.0rc1/tests/unit/core/ov/test_ov_utils.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/core/test_core_patcher.py` & `otx-1.2.0rc1/tests/unit/core/test_core_patcher.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/hpo/test_hpo_base.py` & `otx-1.2.0rc1/tests/unit/hpo/test_hpo_base.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/hpo/test_hyperband.py` & `otx-1.2.0rc1/tests/unit/hpo/test_hyperband.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/hpo/test_resource_manager.py` & `otx-1.2.0rc1/tests/unit/hpo/test_resource_manager.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/hpo/test_search_space.py` & `otx-1.2.0rc1/tests/unit/hpo/test_search_space.py`

 * *Files identical despite different names*

### Comparing `otx-1.1.2rc1/tests/unit/mpa/test_augments.py` & `otx-1.2.0rc1/tests/unit/mpa/test_augments.py`

 * *Files identical despite different names*

