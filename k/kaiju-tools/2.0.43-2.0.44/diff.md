# Comparing `tmp/kaiju_tools-2.0.43-py3-none-any.whl.zip` & `tmp/kaiju_tools-2.0.44-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,113 +1,113 @@
-Zip file size: 128720 bytes, number of entries: 111
--rw-r--r--  2.0 unx     3424 b- defN 23-Apr-17 19:11 kaiju_tools/CLI.py
--rw-r--r--  2.0 unx      272 b- defN 23-Apr-17 19:11 kaiju_tools/__init__.py
--rw-r--r--  2.0 unx     7473 b- defN 23-Apr-17 19:11 kaiju_tools/class_registry.py
--rw-r--r--  2.0 unx     5923 b- defN 23-Apr-17 19:11 kaiju_tools/exceptions.py
--rw-r--r--  2.0 unx      997 b- defN 23-Apr-17 19:11 kaiju_tools/fixtures.py
--rw-r--r--  2.0 unx     8657 b- defN 23-Apr-17 19:11 kaiju_tools/functions.py
--rw-r--r--  2.0 unx     2172 b- defN 23-Apr-17 19:11 kaiju_tools/init_app.py
--rw-r--r--  2.0 unx    18691 b- defN 23-Apr-17 19:11 kaiju_tools/jsonschema.py
--rw-r--r--  2.0 unx      195 b- defN 23-Apr-17 19:11 kaiju_tools/loop.py
--rw-r--r--  2.0 unx    13521 b- defN 23-Apr-17 19:11 kaiju_tools/mapping.py
--rw-r--r--  2.0 unx      159 b- defN 23-Apr-17 19:11 kaiju_tools/serialization.py
--rw-r--r--  2.0 unx     8221 b- defN 23-Apr-17 19:11 kaiju_tools/services.py
--rw-r--r--  2.0 unx    14345 b- defN 23-Apr-17 19:11 kaiju_tools/templates.py
--rw-r--r--  2.0 unx     4793 b- defN 23-Apr-17 19:11 kaiju_tools/ttl_dict.py
--rw-r--r--  2.0 unx     3691 b- defN 23-Apr-17 19:11 kaiju_tools/types.py
--rw-r--r--  2.0 unx     2595 b- defN 23-Apr-17 19:11 kaiju_tools/cache/__init__.py
--rw-r--r--  2.0 unx    11711 b- defN 23-Apr-17 19:11 kaiju_tools/cache/abc.py
--rw-r--r--  2.0 unx     2373 b- defN 23-Apr-17 19:11 kaiju_tools/cache/local_cache.py
--rw-r--r--  2.0 unx       43 b- defN 23-Apr-17 19:11 kaiju_tools/cache/services.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/cache/tests/__init__.py
--rw-r--r--  2.0 unx     2315 b- defN 23-Apr-17 19:11 kaiju_tools/cache/tests/test_cache.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/commands/__init__.py
--rw-r--r--  2.0 unx      932 b- defN 23-Apr-17 19:11 kaiju_tools/config/__init__.py
--rw-r--r--  2.0 unx     9205 b- defN 23-Apr-17 19:11 kaiju_tools/config/config_loader.py
--rw-r--r--  2.0 unx     2975 b- defN 23-Apr-17 19:11 kaiju_tools/config/configurator.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/config/tests/__init__.py
--rw-r--r--  2.0 unx      586 b- defN 23-Apr-17 19:11 kaiju_tools/config/tests/test_configurator.py
--rw-r--r--  2.0 unx      276 b- defN 23-Apr-17 19:11 kaiju_tools/docker/__init__.py
--rw-r--r--  2.0 unx     9554 b- defN 23-Apr-17 19:11 kaiju_tools/docker/containers.py
--rw-r--r--  2.0 unx     7830 b- defN 23-Apr-17 19:11 kaiju_tools/docker/images.py
--rw-r--r--  2.0 unx      103 b- defN 23-Apr-17 19:11 kaiju_tools/docker/services.py
--rw-r--r--  2.0 unx    11140 b- defN 23-Apr-17 19:11 kaiju_tools/docker/stack.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/docker/tests/__init__.py
--rw-r--r--  2.0 unx     1625 b- defN 23-Apr-17 19:11 kaiju_tools/docker/tests/fixtures.py
--rw-r--r--  2.0 unx      575 b- defN 23-Apr-17 19:11 kaiju_tools/docker/tests/test_containers.py
--rw-r--r--  2.0 unx      359 b- defN 23-Apr-17 19:11 kaiju_tools/docker/tests/test_images.py
--rw-r--r--  2.0 unx      371 b- defN 23-Apr-17 19:11 kaiju_tools/docker/tests/test_stack.py
--rw-r--r--  2.0 unx       65 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/__init__.py
--rw-r--r--  2.0 unx     2996 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/abc.py
--rw-r--r--  2.0 unx      163 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/etc.py
--rw-r--r--  2.0 unx     4440 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/json.py
--rw-r--r--  2.0 unx     4472 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/msgpack.py
--rw-r--r--  2.0 unx      654 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/serializers.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/tests/__init__.py
--rw-r--r--  2.0 unx      335 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/tests/fixtures.py
--rw-r--r--  2.0 unx     1930 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/tests/test_msgpack.py
--rw-r--r--  2.0 unx      325 b- defN 23-Apr-17 19:11 kaiju_tools/encoding/tests/test_serializers.py
--rw-r--r--  2.0 unx       46 b- defN 23-Apr-17 19:11 kaiju_tools/es/__init__.py
--rw-r--r--  2.0 unx    18302 b- defN 23-Apr-17 19:11 kaiju_tools/es/client.py
--rw-r--r--  2.0 unx     5559 b- defN 23-Apr-17 19:11 kaiju_tools/es/loader.py
--rw-r--r--  2.0 unx    17588 b- defN 23-Apr-17 19:11 kaiju_tools/es/schema.py
--rw-r--r--  2.0 unx       66 b- defN 23-Apr-17 19:11 kaiju_tools/es/services.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/es/tests/__init__.py
--rw-r--r--  2.0 unx     3463 b- defN 23-Apr-17 19:11 kaiju_tools/es/tests/fixtures.py
--rw-r--r--  2.0 unx       32 b- defN 23-Apr-17 19:11 kaiju_tools/http/__init__.py
--rw-r--r--  2.0 unx     5774 b- defN 23-Apr-17 19:11 kaiju_tools/http/client.py
--rw-r--r--  2.0 unx     1238 b- defN 23-Apr-17 19:11 kaiju_tools/http/middlewares.py
--rw-r--r--  2.0 unx     2564 b- defN 23-Apr-17 19:11 kaiju_tools/http/views.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/http/tests/__init__.py
--rw-r--r--  2.0 unx     1548 b- defN 23-Apr-17 19:11 kaiju_tools/http/tests/test_client.py
--rw-r--r--  2.0 unx     2392 b- defN 23-Apr-17 19:11 kaiju_tools/http/tests/test_rpc_rest_view.py
--rw-r--r--  2.0 unx     2344 b- defN 23-Apr-17 19:11 kaiju_tools/locks/__init__.py
--rw-r--r--  2.0 unx    10011 b- defN 23-Apr-17 19:11 kaiju_tools/locks/abc.py
--rw-r--r--  2.0 unx      393 b- defN 23-Apr-17 19:11 kaiju_tools/locks/etc.py
--rw-r--r--  2.0 unx      284 b- defN 23-Apr-17 19:11 kaiju_tools/locks/exceptions.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/locks/tests/__init__.py
--rw-r--r--  2.0 unx     1913 b- defN 23-Apr-17 19:11 kaiju_tools/locks/tests/test_locks.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/logging/__init__.py
--rw-r--r--  2.0 unx     3355 b- defN 23-Apr-17 19:11 kaiju_tools/logging/services.py
--rw-r--r--  2.0 unx    10175 b- defN 23-Apr-17 19:11 kaiju_tools/logging/types.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/logging/tests/__init__.py
--rw-r--r--  2.0 unx     1827 b- defN 23-Apr-17 19:11 kaiju_tools/logging/tests/test_loggers.py
--rw-r--r--  2.0 unx       43 b- defN 23-Apr-17 19:11 kaiju_tools/queues/__init__.py
--rw-r--r--  2.0 unx    12777 b- defN 23-Apr-17 19:11 kaiju_tools/queues/abc.py
--rw-r--r--  2.0 unx     3828 b- defN 23-Apr-17 19:11 kaiju_tools/queues/queue.py
--rw-r--r--  2.0 unx       33 b- defN 23-Apr-17 19:11 kaiju_tools/queues/services.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/queues/tests/__init__.py
--rw-r--r--  2.0 unx      722 b- defN 23-Apr-17 19:11 kaiju_tools/queues/tests/fixtures.py
--rw-r--r--  2.0 unx     1371 b- defN 23-Apr-17 19:11 kaiju_tools/queues/tests/test_queue.py
--rw-r--r--  2.0 unx       43 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/__init__.py
--rw-r--r--  2.0 unx    11883 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/abc.py
--rw-r--r--  2.0 unx     8963 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/client.py
--rw-r--r--  2.0 unx     3260 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/client_gen.py
--rw-r--r--  2.0 unx      116 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/context.py
--rw-r--r--  2.0 unx      544 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/etc.py
--rw-r--r--  2.0 unx     1831 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/jsonrpc.py
--rw-r--r--  2.0 unx    18669 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/server.py
--rw-r--r--  2.0 unx       71 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/services.py
--rw-r--r--  2.0 unx     5991 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/sessions.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/tests/__init__.py
--rw-r--r--  2.0 unx     4207 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/tests/fixtures.py
--rw-r--r--  2.0 unx     7956 b- defN 23-Apr-17 19:11 kaiju_tools/rpc/tests/test_rpc_server.py
--rw-r--r--  2.0 unx       38 b- defN 23-Apr-17 19:11 kaiju_tools/streams/__init__.py
--rw-r--r--  2.0 unx    24393 b- defN 23-Apr-17 19:11 kaiju_tools/streams/abc.py
--rw-r--r--  2.0 unx      152 b- defN 23-Apr-17 19:11 kaiju_tools/streams/etc.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/streams/tests/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/streams/tests/fixtures.py
--rw-r--r--  2.0 unx     5975 b- defN 23-Apr-17 19:11 kaiju_tools/streams/tests/test_streams.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 19:11 kaiju_tools/tests/__init__.py
--rw-r--r--  2.0 unx     2016 b- defN 23-Apr-17 19:11 kaiju_tools/tests/fixtures.py
--rw-r--r--  2.0 unx     1408 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_class_registry.py
--rw-r--r--  2.0 unx     3385 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_mapping.py
--rw-r--r--  2.0 unx      481 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_serialization.py
--rw-r--r--  2.0 unx     2787 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_services.py
--rw-r--r--  2.0 unx     1554 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_templates.py
--rw-r--r--  2.0 unx      796 b- defN 23-Apr-17 19:11 kaiju_tools/tests/test_ttl_dict.py
--rw-rw-rw-  2.0 unx      610 b- defN 23-Apr-17 19:11 kaiju_tools-2.0.43.dist-info/LICENSE
--rw-r--r--  2.0 unx     3236 b- defN 23-Apr-17 19:11 kaiju_tools-2.0.43.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-17 19:11 kaiju_tools-2.0.43.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Apr-17 19:11 kaiju_tools-2.0.43.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     9623 b- defN 23-Apr-17 19:11 kaiju_tools-2.0.43.dist-info/RECORD
-111 files, 400222 bytes uncompressed, 113402 bytes compressed:  71.7%
+Zip file size: 127777 bytes, number of entries: 111
+-rw-r--r--  2.0 unx     3424 b- defN 23-Apr-18 10:50 kaiju_tools/CLI.py
+-rw-r--r--  2.0 unx      272 b- defN 23-Apr-18 10:50 kaiju_tools/__init__.py
+-rw-r--r--  2.0 unx     7473 b- defN 23-Apr-18 10:50 kaiju_tools/class_registry.py
+-rw-r--r--  2.0 unx     5923 b- defN 23-Apr-18 10:50 kaiju_tools/exceptions.py
+-rw-r--r--  2.0 unx      997 b- defN 23-Apr-18 10:50 kaiju_tools/fixtures.py
+-rw-r--r--  2.0 unx     8965 b- defN 23-Apr-18 10:50 kaiju_tools/functions.py
+-rw-r--r--  2.0 unx     2172 b- defN 23-Apr-18 10:50 kaiju_tools/init_app.py
+-rw-r--r--  2.0 unx    18691 b- defN 23-Apr-18 10:50 kaiju_tools/jsonschema.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Apr-18 10:50 kaiju_tools/loop.py
+-rw-r--r--  2.0 unx    13521 b- defN 23-Apr-18 10:50 kaiju_tools/mapping.py
+-rw-r--r--  2.0 unx      159 b- defN 23-Apr-18 10:50 kaiju_tools/serialization.py
+-rw-r--r--  2.0 unx     8221 b- defN 23-Apr-18 10:50 kaiju_tools/services.py
+-rw-r--r--  2.0 unx    14345 b- defN 23-Apr-18 10:50 kaiju_tools/templates.py
+-rw-r--r--  2.0 unx     4793 b- defN 23-Apr-18 10:50 kaiju_tools/ttl_dict.py
+-rw-r--r--  2.0 unx     3691 b- defN 23-Apr-18 10:50 kaiju_tools/types.py
+-rw-r--r--  2.0 unx     2595 b- defN 23-Apr-18 10:50 kaiju_tools/cache/__init__.py
+-rw-r--r--  2.0 unx    11339 b- defN 23-Apr-18 10:50 kaiju_tools/cache/abc.py
+-rw-r--r--  2.0 unx     2373 b- defN 23-Apr-18 10:50 kaiju_tools/cache/local_cache.py
+-rw-r--r--  2.0 unx       43 b- defN 23-Apr-18 10:50 kaiju_tools/cache/services.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/cache/tests/__init__.py
+-rw-r--r--  2.0 unx     2315 b- defN 23-Apr-18 10:50 kaiju_tools/cache/tests/test_cache.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/commands/__init__.py
+-rw-r--r--  2.0 unx      932 b- defN 23-Apr-18 10:50 kaiju_tools/config/__init__.py
+-rw-r--r--  2.0 unx     9205 b- defN 23-Apr-18 10:50 kaiju_tools/config/config_loader.py
+-rw-r--r--  2.0 unx     2975 b- defN 23-Apr-18 10:50 kaiju_tools/config/configurator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/config/tests/__init__.py
+-rw-r--r--  2.0 unx      586 b- defN 23-Apr-18 10:50 kaiju_tools/config/tests/test_configurator.py
+-rw-r--r--  2.0 unx      276 b- defN 23-Apr-18 10:50 kaiju_tools/docker/__init__.py
+-rw-r--r--  2.0 unx     9554 b- defN 23-Apr-18 10:50 kaiju_tools/docker/containers.py
+-rw-r--r--  2.0 unx     7830 b- defN 23-Apr-18 10:50 kaiju_tools/docker/images.py
+-rw-r--r--  2.0 unx      103 b- defN 23-Apr-18 10:50 kaiju_tools/docker/services.py
+-rw-r--r--  2.0 unx    11140 b- defN 23-Apr-18 10:50 kaiju_tools/docker/stack.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/docker/tests/__init__.py
+-rw-r--r--  2.0 unx     1625 b- defN 23-Apr-18 10:50 kaiju_tools/docker/tests/fixtures.py
+-rw-r--r--  2.0 unx      575 b- defN 23-Apr-18 10:50 kaiju_tools/docker/tests/test_containers.py
+-rw-r--r--  2.0 unx      359 b- defN 23-Apr-18 10:50 kaiju_tools/docker/tests/test_images.py
+-rw-r--r--  2.0 unx      371 b- defN 23-Apr-18 10:50 kaiju_tools/docker/tests/test_stack.py
+-rw-r--r--  2.0 unx       65 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/__init__.py
+-rw-r--r--  2.0 unx     2996 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/abc.py
+-rw-r--r--  2.0 unx      163 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/etc.py
+-rw-r--r--  2.0 unx     4440 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/json.py
+-rw-r--r--  2.0 unx     4472 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/msgpack.py
+-rw-r--r--  2.0 unx      654 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/serializers.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/tests/__init__.py
+-rw-r--r--  2.0 unx      335 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/tests/fixtures.py
+-rw-r--r--  2.0 unx     1930 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/tests/test_msgpack.py
+-rw-r--r--  2.0 unx      325 b- defN 23-Apr-18 10:50 kaiju_tools/encoding/tests/test_serializers.py
+-rw-r--r--  2.0 unx       46 b- defN 23-Apr-18 10:50 kaiju_tools/es/__init__.py
+-rw-r--r--  2.0 unx    18302 b- defN 23-Apr-18 10:50 kaiju_tools/es/client.py
+-rw-r--r--  2.0 unx     5559 b- defN 23-Apr-18 10:50 kaiju_tools/es/loader.py
+-rw-r--r--  2.0 unx    17588 b- defN 23-Apr-18 10:50 kaiju_tools/es/schema.py
+-rw-r--r--  2.0 unx       66 b- defN 23-Apr-18 10:50 kaiju_tools/es/services.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/es/tests/__init__.py
+-rw-r--r--  2.0 unx     3463 b- defN 23-Apr-18 10:50 kaiju_tools/es/tests/fixtures.py
+-rw-r--r--  2.0 unx       32 b- defN 23-Apr-18 10:50 kaiju_tools/http/__init__.py
+-rw-r--r--  2.0 unx     5774 b- defN 23-Apr-18 10:50 kaiju_tools/http/client.py
+-rw-r--r--  2.0 unx     1238 b- defN 23-Apr-18 10:50 kaiju_tools/http/middlewares.py
+-rw-r--r--  2.0 unx     2564 b- defN 23-Apr-18 10:50 kaiju_tools/http/views.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/http/tests/__init__.py
+-rw-r--r--  2.0 unx     1532 b- defN 23-Apr-18 10:50 kaiju_tools/http/tests/test_client.py
+-rw-r--r--  2.0 unx     2392 b- defN 23-Apr-18 10:50 kaiju_tools/http/tests/test_rpc_rest_view.py
+-rw-r--r--  2.0 unx     2344 b- defN 23-Apr-18 10:50 kaiju_tools/locks/__init__.py
+-rw-r--r--  2.0 unx     9911 b- defN 23-Apr-18 10:50 kaiju_tools/locks/abc.py
+-rw-r--r--  2.0 unx      393 b- defN 23-Apr-18 10:50 kaiju_tools/locks/etc.py
+-rw-r--r--  2.0 unx      284 b- defN 23-Apr-18 10:50 kaiju_tools/locks/exceptions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/locks/tests/__init__.py
+-rw-r--r--  2.0 unx     1913 b- defN 23-Apr-18 10:50 kaiju_tools/locks/tests/test_locks.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/logging/__init__.py
+-rw-r--r--  2.0 unx     3355 b- defN 23-Apr-18 10:50 kaiju_tools/logging/services.py
+-rw-r--r--  2.0 unx    10173 b- defN 23-Apr-18 10:50 kaiju_tools/logging/types.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/logging/tests/__init__.py
+-rw-r--r--  2.0 unx     1827 b- defN 23-Apr-18 10:50 kaiju_tools/logging/tests/test_loggers.py
+-rw-r--r--  2.0 unx       43 b- defN 23-Apr-18 10:50 kaiju_tools/queues/__init__.py
+-rw-r--r--  2.0 unx    12777 b- defN 23-Apr-18 10:50 kaiju_tools/queues/abc.py
+-rw-r--r--  2.0 unx     3828 b- defN 23-Apr-18 10:50 kaiju_tools/queues/queue.py
+-rw-r--r--  2.0 unx       33 b- defN 23-Apr-18 10:50 kaiju_tools/queues/services.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/queues/tests/__init__.py
+-rw-r--r--  2.0 unx      722 b- defN 23-Apr-18 10:50 kaiju_tools/queues/tests/fixtures.py
+-rw-r--r--  2.0 unx     1371 b- defN 23-Apr-18 10:50 kaiju_tools/queues/tests/test_queue.py
+-rw-r--r--  2.0 unx       43 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/__init__.py
+-rw-r--r--  2.0 unx    11883 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/abc.py
+-rw-r--r--  2.0 unx     4991 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/client.py
+-rw-r--r--  2.0 unx     3375 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/client_gen.py
+-rw-r--r--  2.0 unx      116 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/context.py
+-rw-r--r--  2.0 unx      544 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/etc.py
+-rw-r--r--  2.0 unx     1831 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/jsonrpc.py
+-rw-r--r--  2.0 unx    18903 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/server.py
+-rw-r--r--  2.0 unx       71 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/services.py
+-rw-r--r--  2.0 unx     6040 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/sessions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/tests/__init__.py
+-rw-r--r--  2.0 unx     4207 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/tests/fixtures.py
+-rw-r--r--  2.0 unx     7972 b- defN 23-Apr-18 10:50 kaiju_tools/rpc/tests/test_rpc_server.py
+-rw-r--r--  2.0 unx       38 b- defN 23-Apr-18 10:50 kaiju_tools/streams/__init__.py
+-rw-r--r--  2.0 unx    24457 b- defN 23-Apr-18 10:50 kaiju_tools/streams/abc.py
+-rw-r--r--  2.0 unx      152 b- defN 23-Apr-18 10:50 kaiju_tools/streams/etc.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/streams/tests/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/streams/tests/fixtures.py
+-rw-r--r--  2.0 unx     5975 b- defN 23-Apr-18 10:50 kaiju_tools/streams/tests/test_streams.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 10:50 kaiju_tools/tests/__init__.py
+-rw-r--r--  2.0 unx     2016 b- defN 23-Apr-18 10:50 kaiju_tools/tests/fixtures.py
+-rw-r--r--  2.0 unx     1408 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_class_registry.py
+-rw-r--r--  2.0 unx     3385 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_mapping.py
+-rw-r--r--  2.0 unx      481 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_serialization.py
+-rw-r--r--  2.0 unx     2787 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_services.py
+-rw-r--r--  2.0 unx     1554 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_templates.py
+-rw-r--r--  2.0 unx      796 b- defN 23-Apr-18 10:50 kaiju_tools/tests/test_ttl_dict.py
+-rw-rw-rw-  2.0 unx      610 b- defN 23-Apr-18 10:50 kaiju_tools-2.0.44.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3236 b- defN 23-Apr-18 10:50 kaiju_tools-2.0.44.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-18 10:50 kaiju_tools-2.0.44.dist-info/WHEEL
+-rw-r--r--  2.0 unx       12 b- defN 23-Apr-18 10:50 kaiju_tools-2.0.44.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     9622 b- defN 23-Apr-18 10:50 kaiju_tools-2.0.44.dist-info/RECORD
+111 files, 396545 bytes uncompressed, 112459 bytes compressed:  71.6%
```

## zipnote {}

```diff
@@ -312,23 +312,23 @@
 
 Filename: kaiju_tools/tests/test_templates.py
 Comment: 
 
 Filename: kaiju_tools/tests/test_ttl_dict.py
 Comment: 
 
-Filename: kaiju_tools-2.0.43.dist-info/LICENSE
+Filename: kaiju_tools-2.0.44.dist-info/LICENSE
 Comment: 
 
-Filename: kaiju_tools-2.0.43.dist-info/METADATA
+Filename: kaiju_tools-2.0.44.dist-info/METADATA
 Comment: 
 
-Filename: kaiju_tools-2.0.43.dist-info/WHEEL
+Filename: kaiju_tools-2.0.44.dist-info/WHEEL
 Comment: 
 
-Filename: kaiju_tools-2.0.43.dist-info/top_level.txt
+Filename: kaiju_tools-2.0.44.dist-info/top_level.txt
 Comment: 
 
-Filename: kaiju_tools-2.0.43.dist-info/RECORD
+Filename: kaiju_tools-2.0.44.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kaiju_tools/__init__.py

```diff
@@ -4,10 +4,10 @@
 from .es import *
 from .queues import *
 from .cache import *
 from .locks import *
 from .streams import *
 from .docker import *
 
-__version__ = '2.0.43'
+__version__ = '2.0.44'
 __python_version__ = '3.8'
 __author__ = 'antonnidhoggr@me.com'
```

## kaiju_tools/functions.py

```diff
@@ -1,36 +1,44 @@
 """Commonly used functions."""
 
 import asyncio
 import ctypes
+import os
 from asyncio import sleep
+from binascii import b2a_hex
 from concurrent.futures import ThreadPoolExecutor
 from concurrent.futures import TimeoutError as ConcurrentTimeoutError
 from secrets import randbits
 from functools import partial
-from time import time
 from typing import TypedDict, Collection, Type, Union
 from uuid import UUID
 
 __all__ = [
     'retry',
     'retry_',
     'RETRY_EXCEPTION_CLASSES',
     'terminate_thread',
     'async_run_in_thread',
     'async_',
     'RetryParams',
     'secure_uuid',
     'not_implemented',
     'timeout',
+    'debug_only',
+    'get_short_uid',
 ]
 
 RETRY_EXCEPTION_CLASSES = frozenset([TimeoutError, asyncio.TimeoutError, asyncio.CancelledError])
 
 
+def get_short_uid() -> str:
+    """Get a short uid string."""
+    return b2a_hex(os.urandom(4)).decode()
+
+
 class RetryParams(TypedDict, total=False):
     """Parameters for the retry function."""
 
     exec_timeout: int
     retries: int
     retry_timeout: float
     multiplier: float
@@ -242,16 +250,21 @@
             raise NotImplementedError(__message)
 
         return _wrap
 
     return __params
 
 
-class _Timeout:
+def debug_only(f):
+    """Decorate a debug-only method (will not be available in the production mode."""
+    f._debug_only_ = True
+    return f
 
+
+class _Timeout:
     __slots__ = ('_timeout', '_loop', '_task', '_handler')
 
     def __init__(self, _timeout: float, loop=None):
         self._timeout = max(0.0, _timeout)
         self._loop = loop
         self._handler = None
```

## kaiju_tools/cache/abc.py

```diff
@@ -46,26 +46,14 @@
         """Remove multiple keys at once."""
 
 
 class BaseCacheService(ContextableService, CacheServiceInterface, abc.ABC):
     """Base class for all shared cache services.
 
     Implements `CacheServiceInterface` interface.
-
-    This is a base class. If you need to implement your own backend you have to
-    program abstract methods:
-
-    - `BaseCacheService._exists`
-    - `BaseCacheService._m_exists`
-    - `BaseCacheService._get`
-    - `BaseCacheService._m_get`
-    - `BaseCacheService._set`
-    - `BaseCacheService._m_set`
-    - `BaseCacheService._delete`
-    - `BaseCacheService._m_delete`
     """
 
     service_name = 'cache'
 
     DELIMITER = ':'  #: used for delimiting sections in a key
     CONNECTION_ERROR_CLASSES = RETRY_EXCEPTION_CLASSES
 
@@ -135,15 +123,15 @@
             self._queue = None
 
     async def exists(self, key: str, ignore_conn_errors=IGNORE_CONN_ERRORS) -> bool:
         """Check if key is present in the cache."""
         _key = self._create_key(key)
         result = await self._wrap_exec(self._exists(_key), ignore_conn_errors)
         if result is None:
-            self.logger.info('Key not found', key=_key)
+            self.logger.info('key not found', key=_key)
         return bool(result)
 
     async def _exists(self, key: str) -> bool:
         """Check if such key present and has not expired."""
 
     async def m_exists(self, keys: list, ignore_conn_errors=IGNORE_CONN_ERRORS) -> frozenset:
         """Return a set of existing keys."""
@@ -167,15 +155,15 @@
         :param ignore_conn_errors: set True to ignore connection errors and skip the operation
         """
         _key = self._create_key(key)
         self.logger.debug('get', key=_key)
         value = await self._wrap_exec(self._get(_key), ignore_conn_errors)
         value = self._load_value(value, use_serializer)
         if value is None:
-            self.logger.info('Key not found', key=_key)
+            self.logger.info('key not found', key=_key)
         return value
 
     @abc.abstractmethod
     async def _get(self, key: str) -> Optional:
         """Return a key value or None if not found."""
 
     async def m_get(self, keys: list, use_serializer=True, ignore_conn_errors=IGNORE_CONN_ERRORS) -> dict:
```

## kaiju_tools/http/tests/test_client.py

```diff
@@ -6,41 +6,35 @@
 from ...rpc.client import RPCClientService
 from ..client import HTTPService
 from ..views import JSONRPCView
 
 
 @pytest.mark.asyncio
 async def test_rpc_http_client(rpc_interface, aiohttp_server, application, rpc_compatible_service, logger):
-
     port = 7677
     application = application(debug=True)
 
     async with rpc_interface as rpc:
-
         service = rpc_compatible_service(logger=logger)
         rpc.register_service('do', service)
         application.router.add_view(JSONRPCView.route, JSONRPCView)
         application.services = SimpleNamespace(rpc=rpc)
         server = await aiohttp_server(application, port=port)
 
         try:
-
             async with HTTPService(application, host=f'http://localhost:{port}', logger=logger) as http_client:
-
                 async with RPCClientService(
                     app=None, transport=http_client, uri=JSONRPCView.route, logger=logger
                 ) as client:
-
                     args, kws = await client.call('do.echo', {'value': True})
                     assert kws['value']
 
                     result = await client.call_multiple(
                         {'method': 'do.echo', 'params': {'value': 1}},
                         {'method': 'do.echo', 'params': {'value': 2}},
                         {'method': 'do.echo', 'params': {'value': 3}},
                     )
 
-                    assert [r['result'][1]['value'] for r in result] == [1, 2, 3]
+                    assert [r[1]['value'] for r in result] == [1, 2, 3]
 
         finally:
-
             await server.close()
```

## kaiju_tools/locks/abc.py

```diff
@@ -123,15 +123,14 @@
 
         if identifier is None:
             identifier = self.app['id']
 
         t0, _key = 0, self._create_key(key)
 
         while 1:
-
             if ttl is None:
                 new_ttl = self.BASE_TTL
             else:
                 new_ttl = min(self.BASE_TTL, int(ttl))
 
             t = int(time()) + 1
 
@@ -261,22 +260,18 @@
 
     async def _loop(self):
         """Daemon which periodically starts a renew task."""
         refresh_interval = self._refresh_interval
         jitter = self.JITTER
 
         while not self._closing:
-
             t = time()
-
             if self._keys:
                 self._task = _task = asyncio.create_task(self._renew_keys())
                 try:
                     await _task
                 except Exception as exc:
-                    self.logger.error(
-                        'An error in the daemon loop: %s', exc, exc_info=(type(exc), exc, exc.__traceback__)
-                    )
+                    self.logger.error('renew locks error', exc_info=exc)
 
             t = time() - t
             dt = max(refresh_interval * (1 + random() * jitter) - t, 0)
             await asyncio.sleep(dt)
```

## kaiju_tools/logging/types.py

```diff
@@ -111,15 +111,15 @@
         level,
         msg,
         args,
         exc_info=None,
         extra=None,
         stack_info=False,
         stacklevel=1,
-        _cid=None,
+        _cid='',
         _sid=None,
         _dline=None,
         **kws,
     ):
         if extra is None:
             extra = {}
         extra['_data'] = kws
```

## kaiju_tools/rpc/client.py

```diff
@@ -1,18 +1,17 @@
 import abc
-from typing import *
+from typing import List, Union, Any
 
-from kaiju_tools.http import HTTPService
-from kaiju_tools.types import REQUEST_CONTEXT
-from . import jsonrpc
-from .abc import AbstractRPCCompatible, AbstractTokenInterface
-from .etc import JSONRPCHeaders
-from ..mapping import get_field, set_field
-from ..exceptions import APIException, ensure_traceback
-from ..services import ContextableService
+from kaiju_tools.functions import get_short_uid
+from kaiju_tools.services import ContextableService
+from kaiju_tools.rpc.abc import AbstractRPCCompatible
+from kaiju_tools.rpc.etc import JSONRPCHeaders
+from kaiju_tools.rpc.jsonrpc import RPCRequest
+from kaiju_tools.http.client import HTTPService
+from kaiju_tools.exceptions import APIException
 
 __all__ = ('RPCClientError', 'RPCClientService', 'BaseRPCClientService')
 
 
 class RPCClientError(APIException):
     """JSON RPC Python exception class."""
 
@@ -20,221 +19,117 @@
         super().__init__(*args, **kws)
         self.response = response
 
     def __str__(self):
         return self.message
 
 
-class BaseRPCClientService(ContextableService, abc.ABC):
-    """Abstract RPC client service.
+class BaseRPCClientService(ContextableService, AbstractRPCCompatible, abc.ABC):
+    """JSONRPC client."""
 
-    To configure the client for your own transport you must set your own
-    `init_session` and `close_session` and `rpc_request` methods.
-
-    :param app: web app
-    :param uri: RPC service default endpoint
-    :param logger: logger instance
-    """
-
-    service_name = 'client'
-    token_service_class = AbstractTokenInterface
-    headers = JSONRPCHeaders
-
-    def __init__(self, app, uri: str = '/rpc', logger=None):
+    def __init__(self, app, uri: str = '/public/rpc', logger=None):
         super().__init__(app=app, logger=logger)
-        self._uri = uri
+        self.base_uri = uri
 
     async def init(self):
         pass
 
-    @classmethod
-    def _process_response_batch(cls, batch: List[dict], unpack_response: bool):
-        errors, responses = [], []
-        for n, data in enumerate(batch):
-            response = cls._process_response(data, unpack_response)
-            if isinstance(response, jsonrpc.RPCError):
-                errors.append((n, response))
-            responses.append(response)
-        return errors, responses
+    async def call(
+        self,
+        method: str,
+        params: Union[dict, None] = None,
+        nowait: bool = False,
+        max_timeout: int = None,
+        use_context: bool = True,
+    ) -> Union[Any, None]:
+        """Make an RPC call.
+
+        :param method: rpc method name
+        :param params: method call arguments
+        :param nowait: create a 'notify' request - do not wait for the result
+        :param max_timeout: request timeout in sec
+        :param use_context: use app request context such as correlation id and request chain deadline
+        """
+        headers = self._create_request_headers(max_timeout, use_context, nowait)
+        _id = None if nowait else 0
+        body = RPCRequest(id=_id, method=method, params=params)
+        response = await self._request(body, headers)
+        result = self._process_response(response)
+        if isinstance(result, Exception):
+            raise result
+        return result
 
-    @staticmethod
-    def _process_response(response: dict, unpack_response: bool):
+    async def call_multiple(
+        self,
+        *requests: dict,
+        raise_exception: bool = True,
+        nowait: bool = False,
+        max_timeout: int = None,
+        use_context: bool = True,
+    ) -> Union[List, None]:
+        """Make an RPC batch call.
+
+        :param requests: list of request dicts
+        :param nowait: create a 'notify' request - do not wait for the result
+        :param max_timeout: request timeout in sec
+        :param use_context: use app request context such as correlation id and request chain deadline
+        :param raise_exception: raise exception instead of returning error objects in the list
+        """
+        headers = self._create_request_headers(max_timeout, use_context, nowait)
+        body = [RPCRequest(id=n, **req) for n, req in enumerate(requests)]
+        response = await self._request(body, headers)
+        if response is None:  # for notify requests
+            return
+        results = []
+        for resp in response:
+            resp = self._process_response(resp)
+            if isinstance(resp, Exception) and raise_exception:
+                raise resp
+            results.append(resp)
+        return results
+
+    @abc.abstractmethod
+    async def _request(self, body: Union[RPCRequest, List[RPCRequest]], headers: dict):
+        """Make an external requests via transport service."""
+
+    def _create_request_headers(self, max_timeout, use_context, nowait) -> dict:
+        headers = {}
+        ctx = self.get_request_context() if use_context else None
+        if ctx:
+            headers[JSONRPCHeaders.CORRELATION_ID_HEADER] = ctx['correlation_id']
+            if not nowait:
+                headers[JSONRPCHeaders.REQUEST_DEADLINE_HEADER] = ctx['request_deadline']
+        else:
+            headers[JSONRPCHeaders.CORRELATION_ID_HEADER] = get_short_uid()
+        if max_timeout:
+            headers[JSONRPCHeaders.REQUEST_TIMEOUT_HEADER] = max_timeout
+        return headers
+
+    def _process_response(self, response: dict):
         if 'error' in response:
-            error = response['error']
-            error_type = error.get('data', {}).get('type', jsonrpc.RPCError.__name__)
-            error_type = getattr(jsonrpc, error_type, jsonrpc.RPCError)
-            response = error_type(id=response['id'], data=error)
+            return self._create_exception(response['error'])
         else:
-            response = jsonrpc.RPCResponse(**response)
-            if unpack_response:
-                response = response.result
-        return response
-
-    def _log_rpc_error(self, url, headers, request, error):
-        def _get_exc_type(response):
-            #: TODO стандартизировать ошибки
-            base_exc = response['error'].get('data', {}).get('data', {}).get('base_exc_type')
-            if not base_exc:
-                base_exc = response['error'].get('data', {}).get('data', {}).get('type')
-            if not base_exc:
-                base_exc = str(error.__class__.__qualname__)
-            return base_exc
-
-        def _get_code(response):
-            code = response.get('code')
-            if not code:
-                code = response['error'].get('data', {}).get('code')
-            return code
-
-        error = ensure_traceback(error)
-        request = request.repr()
-        response = error.repr()
-        base_exc = _get_exc_type(response)
-        code = _get_code(response)
-        t = type(f'{request["method"]}_{base_exc}'.replace('.', '_'), (), {})
-        extra = {
-            'fingerprint': ['rpc_client', request['method'], code, base_exc],
-            'capturer': 'rpc_client',
-            'request': {'method': 'POST', 'url': url, 'headers': headers, 'body': request},
-            'response': {'status': response['error']['code'], 'body': response},
-        }
-        self.logger.error(error, extra=extra, exc_info=(t, error, error.__traceback__))
+            return response['result']
 
     @staticmethod
-    def _set_headers(headers: Optional[dict]) -> dict:
-        """Write an auth token to the headers if required."""
-        if headers is None:
-            headers = {}
-        ctx = REQUEST_CONTEXT.get()
-        if ctx:
-            if ctx['correlation_id']:
-                headers[JSONRPCHeaders.CORRELATION_ID_HEADER] = ctx['correlation_id']
-            # if ctx['request_deadline']:
-            #     headers[JSONRPCHeaders.REQUEST_DEADLINE_HEADER] = ctx['request_deadline']
-        return headers
+    def _create_exception(error_data: dict) -> RPCClientError:
+        exc = RPCClientError(message=error_data['message'], data=error_data['data'])
+        exc.status_code = error_data['code']
+        return exc
 
 
-class RPCClientService(BaseRPCClientService, AbstractRPCCompatible):
-    """RPC client."""
+class RPCClientService(BaseRPCClientService):
+    """HTTP JSONRPC client service."""
 
-    transport_service_class = HTTPService
-
-    def __init__(self, *args, transport: Union[str, transport_service_class], **kws):
+    def __init__(self, *args, transport: HTTPService, **kws):
+        """Initialize."""
         super().__init__(*args, **kws)
-        self._transport = self.discover_service(transport, cls=self.transport_service_class)
-
-    @property
-    def routes(self) -> dict:
-        return {'call': self.call}
+        self._transport = transport
 
-    @property
-    def permissions(self) -> dict:
-        return {'*': self.PermissionKeys.GLOBAL_SYSTEM_PERMISSION}
-
-    async def iter_call(
-        self,
-        method: str,
-        params: Any = None,
-        headers: dict = None,
-        offset: int = 0,
-        limit: int = 10,
-        count_key='count',
-        offset_key='offset',
-        limit_key='limit',
-        raise_exception=True,
-        unpack_response=True,
-    ) -> AsyncGenerator:
-        """Iterate over data."""
-        count = offset + 1
-
-        if params is None:
-            params = {}
-
-        while count > offset:
-            set_field(params, offset_key, offset)
-            set_field(params, limit_key, limit)
-            headers = self._set_headers(headers)
-            data = await self.call(
-                method=method,
-                params=params,
-                headers=headers,
-                raise_exception=raise_exception,
-                unpack_response=unpack_response,
-            )
-            if type(data) is jsonrpc.RPCResponse:
-                count = get_field(data.result, count_key, default=0)
-            elif isinstance(data, jsonrpc.RPCError):
-                count = 0
-            else:
-                count = get_field(data, count_key, default=0)
-            yield data
-
-            offset += limit
-
-    async def call(
-        self,
-        method: str,
-        params: Any = None,
-        id=False,
-        headers: dict = None,
-        uri: str = None,
-        raise_exception=True,
-        unpack_response=True,
-    ) -> Union[jsonrpc.RPCResponse, jsonrpc.RPCError, dict]:
-        """Call a single remote RPC method.
-
-        :param method: RPC method name
-        :param params: any RPC parameters
-        :param headers: headers, see `kaiju.rpc.spec` for a list of available
-            headers
-        :param id: optional request id
-        :param raise_exception: if True, then it will rise an exception if
-            any errors have been returned
-        :param unpack_response: if True, then in case of valid response
-            not RPCResponse objects but actual result data will be returned
-
-        :raises RPCException: if `raise_exception` was set to True and errors
-        have been returned
-        """
-        if uri is None:
-            uri = self._uri
-        request = jsonrpc.RPCRequest(id, method, params)
-        headers = self._set_headers(headers)
-        response = await self._transport.request('post', uri, json=request.repr(), headers=headers)
-        response = self._process_response(response, unpack_response=unpack_response)
-        if isinstance(response, jsonrpc.RPCError) and raise_exception:
-            url = self._transport.resolve(uri)
-            self._log_rpc_error(url, headers, request, response)
-            raise RPCClientError(str(response), response=response)
-        else:
-            return response
-
-    async def call_multiple(
-        self, *requests: dict, headers: dict = None, uri: str = None, raise_exception=True, unpack_response=True
-    ):
-        """Call multiple remote RPC methods in a single batch.
-
-        :param requests: list of request objects (see `JSONRPCHTTPClient.call`
-            for each request parameters)
-        :param headers: headers, see `kaiju.rpc.spec` for a list of available
-            headers
-        :param raise_exception: if True, then it will rise an exception if
-            any errors have been returned
-        :param unpack_response: if True, then in case of valid response
-            not RPCResponse objects but actual result data will be returned
-
-        :raises RPCException: if `raise_exception` was set to True and errors
-            have been returned
-        """
-        if uri is None:
-            uri = self._uri
-        request = [jsonrpc.RPCRequest(**data).repr() for data in requests]
-        headers = self._set_headers(headers)
-        response = await self._transport.request('post', uri, json=request, headers=headers)
-        errors, responses = self._process_response_batch(response, unpack_response=unpack_response)
-        if errors and raise_exception:
-            url = self._transport.resolve(uri)
-            for n, error in errors:
-                self._log_rpc_error(url, headers, request[n], error)
-            raise RPCClientError(str(error), response=error)
-        else:
-            return response
+    async def init(self):
+        """Initialize service."""
+        await super().init()
+        self._transport = self.discover_service(self._transport, cls=HTTPService)
+
+    async def _request(self, body: Union[RPCRequest, List[RPCRequest]], headers: dict):
+        """Make a HTTP request."""
+        return await self._transport.request('post', self.base_uri, json=body, headers=headers)
```

### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

## kaiju_tools/rpc/client_gen.py

```diff
@@ -16,19 +16,21 @@
 from kaiju_tools.rpc.client import RPCClientService
 
 
 class {{ app_name }}Client(RPCClientService):
     {{ service_doc }}
 
     {% for method in methods %}
-    async def {{ method['name'] }}({{ method['signature'] }}):
+    async def {{ method['name'] }}({{ method['signature'] }}, _max_timeout: int = None, _nowait: bool = False):
         {{ method['doc'] }}
         return await self.call(
             method='{{ method['rpc_name'] }}',
-            params={{ method['params'] }}
+            params={{ method['params'] }},
+            max_timeout=_max_timeout,
+            nowait=_nowait
         )
     {% endfor %}
 
 """
 
 
 class RPCClientCodeGenerator(Service):
```

## kaiju_tools/rpc/server.py

```diff
@@ -68,39 +68,42 @@
         app,
         *,
         session_service: BaseSessionService = None,
         max_parallel_tasks: int = 64,
         default_request_time: int = 120,
         max_request_time: int = 600,
         enable_permissions: bool = True,
+        request_logs: bool = True,
         full_request_logs: bool = False,
         blacklist_routes: List[str] = None,
         blacklist_scope: int = Scope.SYSTEM.value - 1,
         logger=None,
     ):
         """Initialize.
 
         :param app: web app
         :param session_service: session backend
         :param max_parallel_tasks: max number of tasks in the loop
         :param default_request_time: (s)
         :param max_request_time: (s)
         :param enable_permissions: enable perm checks in requests
+        :param request_logs: show request logs, only errors are shown if set to False
         :param full_request_logs: enable full request logs (always true for debug mode)
         :param blacklist_routes: wildcard patterns to blacklist certain RPC routes
         :param blacklist_scope: integer value to blacklist permission scopes lower or equal to this value
         :param logger:
         """
         ContextableService.__init__(self, app=app, logger=logger)
         self._sessions = session_service
         self._max_parallel_tasks = max(1, int(max_parallel_tasks))
         self._default_request_time = max(1, int(default_request_time))
         self._max_request_time = max(self._default_request_time, int(max_request_time))
         self._enable_permissions = enable_permissions
         self._debug = self.app.debug
+        self._request_logs = request_logs
         self._full_request_logs = full_request_logs or self._debug
         self._blacklist_routes = blacklist_routes if blacklist_routes else []
         self._blacklist_scope = blacklist_scope
         self._counter = self._max_parallel_tasks
         self._not_full = asyncio.Event()
         self._not_full.set()
         self._empty = asyncio.Event()
@@ -429,16 +432,17 @@
                 )
             ):
                 return RPCError(id=id_, error=PermissionDenied(id=id_, method=request.method))
         try:
             coro = method['f'](**params)
         except Exception as exc:
             return RPCError(id=request.id, error=InvalidParams(base_exc=exc, message=str(exc)))
-        _log_req = request if self._full_request_logs else dict(id=request.id, method=request.method, params='...')
-        self.logger.info('rpc accepted', request=_log_req)
+        if self._request_logs:
+            _log_req = request if self._full_request_logs else dict(id=request.id, method=request.method, params='...')
+            self.logger.info('rpc accepted', request=_log_req)
         _error, _exc = False, None
         try:
             result = await coro
             result = RPCResponse(id=id_, result=result)
         except asyncio.TimeoutError:
             result = RPCError(id=request.id, error=RequestTimeout(id=id_, message='Request timeout'))
             _error = True
@@ -452,23 +456,23 @@
             result = RPCError(
                 id=request.id, error=InternalError(base_exc=exc, debug=self._debug, message='Internal error')
             )
             _error = True
             _exc = exc
         if _error:
             self.logger.info('rpc error', request=request, exc_info=_exc)
-        else:
+        elif self._request_logs:
             _result = result.result if self._full_request_logs else '...'
-            self.logger.info('rpc finished', request=_log_req, result=_result)
+            self.logger.info('rpc finished', request=_log_req, result=_result)  # noqa
         return result
 
     def _request_done_cb(self, task: asyncio.Task) -> None:
         """Increment the counter when a request is finished."""
         self._counter += 1
         if self._counter >= self._max_parallel_tasks:
             self._counter = self._max_parallel_tasks
             self._empty.set()
         if not self._not_full.is_set():
             self._not_full.set()
         exc = task.exception()
         if exc:
-            self.logger.error('Execution error', exc_info=exc)
+            self.logger.error('task execution error', exc_info=exc)
```

## kaiju_tools/rpc/sessions.py

```diff
@@ -48,30 +48,30 @@
         """Create and return a new session (not stored yet).
 
         :param data: session data
         :param user_agent: user agent or client id or hash to match session in subsequent requests
         """
         h_agent = self._get_agent_hash(user_agent) if type(user_agent) is str else user_agent
         session = self._create_new_session(data, h_agent)
-        self.logger.debug('New session: %s', session.id)
+        self.logger.debug('new session', session_id=session.id)
         return session
 
     async def save_session(self, session: Session, /) -> None:
         """Save session to the storage.
 
         The session will be stored only if it is marked as stored, and it has been changed.
         Token-auth sessions and initial sessions without data won't be stored.
         """
         if not session or not session.stored:
             return
 
         key = self._get_session_key(session.id)
         exp = int(time()) + self.session_idle_timeout
         if session.changed:
-            self.logger.info('Saving session: %s', session.id)
+            self.logger.info('saving session', session_id=session.id)
             key = self._get_session_key(session.id)
             await self._cache.set(key, session.repr(), ttl=exp, nowait=True)
             data = session.repr()
             data['expires'] = exp
             await self._save_session(data)
         elif session.loaded and session.expires - time() < self.exp_renew_interval:
             asyncio.create_task(self._cache._transport.expire(key, exp))  # noqa
@@ -84,15 +84,15 @@
     @abc.abstractmethod
     async def _update_session_exp(self, session_id, exp) -> None:
         """Save session in database backend."""
 
     async def delete_session(self, session: Session, /) -> None:
         """Delete session from the storage."""
         if session and session.stored and session.loaded:
-            self.logger.info('Removing session: %s', session.id)
+            self.logger.info('removing session', session_id=session.id)
             key = self._get_session_key(session.id)
             await self._cache.delete(key, nowait=True)
             try:
                 await self._delete_session(session.id)
             except NotFound:
                 pass
 
@@ -109,30 +109,30 @@
         """
         key = self._get_session_key(session_id)
         session = cached = await self._cache.get(key)
         if not session:
             try:
                 session = await self._get_session(session_id)
             except NotFound:
-                self.logger.info('Session not found: %s', session_id)
+                self.logger.info('session not found', session_id=session_id)
                 return
 
             if session['expires'] < time():
-                self.logger.debug('Session expired: %s', session_id)
+                self.logger.debug('session expired', session_id=session_id)
                 await self._cache.delete(key, nowait=True)
                 await self._delete_session(session_id)
                 return
 
         agent_hash = self._get_agent_hash(user_agent)
         session = self.session_cls(**session, _stored=True, _changed=False, _loaded=True)
         if session.h_agent != agent_hash:
-            self.logger.info('User agent mismatch: %s', session_id)
+            self.logger.info('user agent mismatch', session_id=session_id)
             return
 
-        self.logger.debug('Loaded session: %s', session_id)
+        self.logger.debug('session loaded', session_id=session_id)
         if not cached:
             await self._cache.set(key, session.repr(), nowait=True)
         return session
 
     @abc.abstractmethod
     async def _get_session(self, session_id) -> dict:
         """Get session."""
```

## kaiju_tools/rpc/tests/test_rpc_server.py

```diff
@@ -1,8 +1,9 @@
 import asyncio
+import logging
 from time import time
 from types import SimpleNamespace
 from uuid import uuid4
 
 import pytest
 
 from ..services import JSONRPCServer
@@ -11,15 +12,15 @@
 from kaiju_tools.exceptions import *
 from .fixtures import *
 from kaiju_tools.services import Scope
 
 
 @pytest.mark.asyncio
 async def test_rpc_server_performance(system_information, rpc_interface, logger):
-    requests, parallel, n = 1000, 32, 5
+    requests, parallel, n = 3000, 128, 5
     counter = 0
 
     async def _do_call(rpc):
         nonlocal counter
         data = {'id': 0, 'method': 'do.sleep', 'params': {'test': True}}
         while counter < requests:
             await rpc.call(data, {})
```

## kaiju_tools/streams/abc.py

```diff
@@ -111,25 +111,26 @@
         except LockAcquireTimeout:
             # means that the lock exists
             self._unlocked.clear()
             await self._ready.wait()
 
     async def lock(self):
         """Lock the topic (will not consume new messages)."""
-        self.logger.debug('Locking')
+        self.logger.debug('stream locking')
         self._unlocked.clear()
         await self._locks.acquire(self.locking_key, identifier=self.topic)
         await self._ready.wait()
-        self.logger.debug('Locked')
+        self.logger.debug('stream locked')
 
     async def unlock(self):
         """Unlock the topic (will start consuming messages)."""
+        self.logger.info('stream unlocking')
         self._unlocked.set()
         await self._locks.release(self.locking_key, identifier=self.topic)
-        self.logger.info('Unlocked')
+        self.logger.info('stream unlocked')
 
     @classmethod
     def get_topic_key(cls, env: str, namespace: str, topic: str) -> str:
         s = (env, namespace, cls.PREFIX, topic)
         return cls.DELIMITER.join(s)
 
     @classmethod
@@ -151,36 +152,36 @@
 
     @abc.abstractmethod
     async def _process_batch(self, batch):
         """Define your own message processing and commit here."""
 
     async def _loop(self):
         _logger = self.logger
-        _logger.debug('Starting.')
+        _logger.debug('starting')
         await self._init()
 
         # await self.app.services.initialized.wait()
 
-        _logger.debug('Started.')
+        _logger.debug('started')
 
         while not self._closing:
             self._ready.set()
             await self._unlocked.wait()
             try:
                 batch = await self._get_message_batch()
                 self._ready.clear()
                 await self._process_batch(batch)
             except Exception as exc:
                 _logger.error(
                     'There was an exception in the consumer loop: %s', exc, exc_info=(type(exc), exc, exc.__traceback__)
                 )
 
-        self.logger.debug('Closing')
+        self.logger.debug('closing')
         await self._close()
-        self.logger.debug('Closed')
+        self.logger.debug('closed')
 
     def _create_response_object(self, body):
         if isinstance(body, (list, tuple)):
             return [self._create_response_object(item) for item in body]
         else:
             if 'error' in body:
                 return RPCError(**body)
```

## Comparing `kaiju_tools-2.0.43.dist-info/LICENSE` & `kaiju_tools-2.0.44.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `kaiju_tools-2.0.43.dist-info/METADATA` & `kaiju_tools-2.0.44.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kaiju-tools
-Version: 2.0.43
+Version: 2.0.44
 Summary: Base classes and services for a backend application.
 Home-page: https://gitlab.com/kaiju-python/kaiju-tools
 Author: antonnidhoggr@me.com
 Author-email: antonnidhoggr@me.com
 License: Apache Software License 2.0
 Classifier: Development Status :: 3 - Alpha
 Classifier: License :: OSI Approved :: Apache Software License
```

## Comparing `kaiju_tools-2.0.43.dist-info/RECORD` & `kaiju_tools-2.0.44.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 kaiju_tools/CLI.py,sha256=JAggZ74FQZmu-Wr5vYzy0-dMB5zH3vQewDGe2lnW5eo,3424
-kaiju_tools/__init__.py,sha256=k6h_tzCqcPngmTzydelAoS0EUNpBg8lcHzFl8OS23Fg,272
+kaiju_tools/__init__.py,sha256=0hGCPxmzgqBCQz5vIES1HeMp5ozteIRGmXj3PkAs0o0,272
 kaiju_tools/class_registry.py,sha256=sKn9YmblEeTBhcC_ivoGGTlBFXMG2G2WAsztdk1xBcE,7473
 kaiju_tools/exceptions.py,sha256=pHvyYkHQQagiSY2PCba3b4l01pYxrADMZX6uknqjrJ4,5923
 kaiju_tools/fixtures.py,sha256=h1ElRgENikjde-uXvk_exA_SvMPuxqtxo0qaiYDhCWk,997
-kaiju_tools/functions.py,sha256=pwMCiI3bYRAsYEM07iFDB65AdF3Xn3LVsvOGQKblKTM,8657
+kaiju_tools/functions.py,sha256=LVxnviuH2wwif3TChnXOcNOR9WCWMnafqezV27pRBEc,8965
 kaiju_tools/init_app.py,sha256=J5eDuiZqskrBWSjgM2d8CdsYkt28nqgrOLT4Ms8AZjg,2172
 kaiju_tools/jsonschema.py,sha256=1akEqwrcaD7wgvTmEUpkjRrvw7ILWh8iPfn8YRGK0h8,18691
 kaiju_tools/loop.py,sha256=Nkih75UgPen5SvZYSU0XFb9cbH6Zle-Nbto0B_wpn50,195
 kaiju_tools/mapping.py,sha256=JOloXn-etuB0EsaZ6spbZSDK3wlQ-vHIfkt2Za8-AzE,13521
 kaiju_tools/serialization.py,sha256=GHby_IRwIPVypPL4M76nBs_GjezMXU4wvZV6D9LhqNc,159
 kaiju_tools/services.py,sha256=xV4uVv-kH0ee6gtbWDvVdArq3xeJ1uKSSTejAX04Ayk,8221
 kaiju_tools/templates.py,sha256=6NGAT8RSDdvLYbnqqkHWCQ7LRY4K6eQg1vtEA5FFO34,14345
 kaiju_tools/ttl_dict.py,sha256=xdpqj1RgaatJFHE4rl3QMr5bnozu6HIG4jRkchgBxxM,4793
 kaiju_tools/types.py,sha256=jCsHrgFYYm9FcZbYEOP-Jmba32IL4Rxq-7QaTsaN4So,3691
 kaiju_tools/cache/__init__.py,sha256=DOBTuvdFLJH4ZW6F-WeoDKg-jeP2R3MTqxSzRdTpfvc,2595
-kaiju_tools/cache/abc.py,sha256=owZgxXEjAbWSAJofr_mUQZRbFtObB-N4rch1N3FoS6k,11711
+kaiju_tools/cache/abc.py,sha256=8nB7f0KU_hmQbwuotwDvOk6ggfTN5-uZxHifWL4bgTw,11339
 kaiju_tools/cache/local_cache.py,sha256=4EIGa6sVgE_DTpoGWxsxPKUQVE4zuuboiMPfbZePRos,2373
 kaiju_tools/cache/services.py,sha256=fOsRyLPCUL2i8Lb5rwVzCK7C808UIdG-scxYydgwjoE,43
 kaiju_tools/cache/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/cache/tests/test_cache.py,sha256=y0r_F8VxVNDbtWkrPmRGLslN8ySPGYKw3h4t-UqCJl0,2315
 kaiju_tools/commands/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/config/__init__.py,sha256=KbKTvStzFIsCpT2fOcNJBjHQllQbcsP_K4pAjyP78ww,932
 kaiju_tools/config/config_loader.py,sha256=OnCaUcfE209h_0cdZaXWXcQGrZ7nh_RoBNu-DuQnhts,9205
@@ -53,59 +53,59 @@
 kaiju_tools/es/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/es/tests/fixtures.py,sha256=x4kOyRAGt6tqACFbojRNxqNITdE1_V_TRxWybf9h2dE,3463
 kaiju_tools/http/__init__.py,sha256=WjPNiFMweQ3tqGMUeqV4ubNc7GDRicBffNEmyqBhnw4,32
 kaiju_tools/http/client.py,sha256=ueoClU-Zl7ONt58sEix_3b7nMJv6aSzucpI1P-wuHXw,5774
 kaiju_tools/http/middlewares.py,sha256=-mpWy-BnWVvlwliLBgQ8ZG_o2R4m1Mb7PDWmFpAo7Cs,1238
 kaiju_tools/http/views.py,sha256=Ebfs9Ku3sdyTBEmsrv2MuPbaXWDH8V9HvZ1EEo8z0S0,2564
 kaiju_tools/http/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-kaiju_tools/http/tests/test_client.py,sha256=pI6CsacsaVYwkMxEfu_43oULnslipKQqrrHsFVPQj7k,1548
+kaiju_tools/http/tests/test_client.py,sha256=pBmui1LF98Z5v-kadTCvvdDXSfufeuBkraAg4kJ2s_Y,1532
 kaiju_tools/http/tests/test_rpc_rest_view.py,sha256=quDgkyns94NU1fHG2hTqVLcpGDpmiM9cJlR6vLSIpOY,2392
 kaiju_tools/locks/__init__.py,sha256=bkVd3bN1kZCPi3PfnV7ZQLHWjq86vAf-aE2ZVNZF5ug,2344
-kaiju_tools/locks/abc.py,sha256=q6BsYQmUE4rBiXEzsC5xgPI40lilw0a3XyFklU0y5Lg,10011
+kaiju_tools/locks/abc.py,sha256=vgpYLSlPQcMzUO_1mbnOJ3_NHMBtHg_p3mAEULucVxs,9911
 kaiju_tools/locks/etc.py,sha256=TFrcXD-qJg1ZDp6-2Wy6bLC1DCHB9XAji8WQ7oxYt-A,393
 kaiju_tools/locks/exceptions.py,sha256=ZCo4Q8IMbbOe81raMdDi6j-M1kQ2wdv1PbuR9Fsr9x8,284
 kaiju_tools/locks/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/locks/tests/test_locks.py,sha256=ygFVC-BTEgW_G6fBMDGAw2Y5mgZWt7xz9yfrilDKOeM,1913
 kaiju_tools/logging/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/logging/services.py,sha256=Q24V4UVrJJyEVMKkQYrOi4pWsKmuAnKTwKGRAgTypxM,3355
-kaiju_tools/logging/types.py,sha256=FDGek-FrD6DbPRNdDUzFHLBhZYvZeql5Srg89jUgmKA,10175
+kaiju_tools/logging/types.py,sha256=j9W7RV0uwH10fy75Lobi92TVKU-IVdnIebc8RPQHwKs,10173
 kaiju_tools/logging/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/logging/tests/test_loggers.py,sha256=byzlYqRVN7l6ZJ5Ph9_d4tjJx8MyDD75LnCBd_av4jo,1827
 kaiju_tools/queues/__init__.py,sha256=1_nq0D65USGIS2jXxF_88fR-LfaiXXF-PqNBTlpkWkg,43
 kaiju_tools/queues/abc.py,sha256=B_Xz1kOE0doUSDTpQ-Uo_g_V546PZKA296_1xHyMAtc,12777
 kaiju_tools/queues/queue.py,sha256=KZiDqIzDND450GhXvlpHez_NvXtwaM1l1G0V-RdvqjQ,3828
 kaiju_tools/queues/services.py,sha256=OImkKf_9d62qK_OYl51tHPTiwlQo1w545BGMfna-SBg,33
 kaiju_tools/queues/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/queues/tests/fixtures.py,sha256=-9qRWUUnl_3EHnd-leRuDOK16y80sR-H1a5gXw4F4Ws,722
 kaiju_tools/queues/tests/test_queue.py,sha256=v8aD-5JrYj-ByAWI48X1y7MmyOgNE9Bfw2dIJpsRbww,1371
 kaiju_tools/rpc/__init__.py,sha256=1_nq0D65USGIS2jXxF_88fR-LfaiXXF-PqNBTlpkWkg,43
 kaiju_tools/rpc/abc.py,sha256=XfmsF66rP3wvW0_LGPx3JpU4NF_NWqNZg-DLDBb8Nzw,11883
-kaiju_tools/rpc/client.py,sha256=kEZUQgLBgJBZXV62SO1oAVa-jGM5J2jDNLpmQ1i3LGw,8963
-kaiju_tools/rpc/client_gen.py,sha256=OcqgMarqApNAbcrJeDsKTZ9OjhiiFTggkFS_LrIY3-s,3260
+kaiju_tools/rpc/client.py,sha256=wfv0Xt-xV15i7cS0IzIlSfOd6PVOzbzH2fi7QtLbT9Q,4991
+kaiju_tools/rpc/client_gen.py,sha256=IxB5L635djT3NEhlr1ggksAU-rOUwdVHmYrwGAzOzWw,3375
 kaiju_tools/rpc/context.py,sha256=l27TATs8IKs4f_690JRn75WY7TsjXWInDgqUrCP03FU,116
 kaiju_tools/rpc/etc.py,sha256=rUByIq3pv6hQektlthEeyWrRjloWPLuokNMK7frWZ9k,544
 kaiju_tools/rpc/jsonrpc.py,sha256=od8Y9AOsbnhsV5hbilv--TR7F56hbkTgVar69WSsi0I,1831
-kaiju_tools/rpc/server.py,sha256=QzoNaHfep-j-XxufXU2N-LBvVVQIq-F9izXlLkNSZUc,18669
+kaiju_tools/rpc/server.py,sha256=mFJooSpb0c98HuQ6kRofUkpP8SCJheEZEq--nSDe8h0,18903
 kaiju_tools/rpc/services.py,sha256=FgR7DpZTKjYBx7ieXKHkh4Lqrqe910c_iAiKxTOcdIk,71
-kaiju_tools/rpc/sessions.py,sha256=4gqnOuzkBLEESHqTZXH5-emjAMhKb_26TGpVCyu4BPc,5991
+kaiju_tools/rpc/sessions.py,sha256=PfE_EfoP-Ilgp6RI_AvavkVfog8R4FGAQIYuZnv3OoE,6040
 kaiju_tools/rpc/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/rpc/tests/fixtures.py,sha256=6NUdBeZA3a_vrRe5oLTyDGU3FCqD5JwqZlXd1xFpsb8,4207
-kaiju_tools/rpc/tests/test_rpc_server.py,sha256=u5RZikOv9_kca3OrQPcsTfvYI5Q56v2JIxqdZmdtFwk,7956
+kaiju_tools/rpc/tests/test_rpc_server.py,sha256=Lb4SstLkv8Qqw3YDujgRqmUHW3Fnk2SHZOtpv98tGeo,7972
 kaiju_tools/streams/__init__.py,sha256=pHOdZ9DDYEMdr3EjCBCuNqYGY1hLqWwTU2v64vPCHP4,38
-kaiju_tools/streams/abc.py,sha256=c4C0Cn9n1q5eerR0EAzLWJ-lvuuSXjFITucarnM8BAk,24393
+kaiju_tools/streams/abc.py,sha256=K7D3HESwaYNZ_frxFKeTS92sDP4Qul2821T_7Z5hp2I,24457
 kaiju_tools/streams/etc.py,sha256=xAaOal-vRdGluvVOL698eY7TdpV-lboqH39DEFWeP5c,152
 kaiju_tools/streams/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/streams/tests/fixtures.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/streams/tests/test_streams.py,sha256=xB-Dv5RppQMi66U-aZ1IdfJ147ZDdpjM-nCrAjJCdP4,5975
 kaiju_tools/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kaiju_tools/tests/fixtures.py,sha256=k1Ou6JiYt4XM4-6zMVzO23fPyD4yFslrF3gbbwl6SlU,2016
 kaiju_tools/tests/test_class_registry.py,sha256=D9mZu9sgY21gEWE8vp2HN0Vfb5WZqxWTNVRPWEPduhU,1408
 kaiju_tools/tests/test_mapping.py,sha256=HzxgQo-k2cBPE88F4AnhBv_Ixb0YS-dWL5rQtM_MRVE,3385
 kaiju_tools/tests/test_serialization.py,sha256=9ETlE5i8b2WFwKsTrECVuB14Pkxf4QgCc6oFX_yjMZw,481
 kaiju_tools/tests/test_services.py,sha256=fYhWYsp-aAyIYwAcLx0ScZhBLBPEX6Apf2LRVWe-WX8,2787
 kaiju_tools/tests/test_templates.py,sha256=XQfGPY1FEIUhZZg4DZQYGTS887xFlPEfyQf0USjJYOw,1554
 kaiju_tools/tests/test_ttl_dict.py,sha256=HWuoDepQdEWixOBlYhCzR1RVLHz20jXwa4SWrrr0A7o,796
-kaiju_tools-2.0.43.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
-kaiju_tools-2.0.43.dist-info/METADATA,sha256=fI5BhnRkrDzVfZYOEhre6mQn18hPV3EBbJ5DdBM3XC8,3236
-kaiju_tools-2.0.43.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-kaiju_tools-2.0.43.dist-info/top_level.txt,sha256=DIgXUScFnJtRLiRWfjo547JK4rMuTIJoioMPRe1Jn6Y,12
-kaiju_tools-2.0.43.dist-info/RECORD,,
+kaiju_tools-2.0.44.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
+kaiju_tools-2.0.44.dist-info/METADATA,sha256=ewb4iOk1E97W8Aj5OaZSd5bJFIdMEXdPkRrI2cNlF_0,3236
+kaiju_tools-2.0.44.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+kaiju_tools-2.0.44.dist-info/top_level.txt,sha256=DIgXUScFnJtRLiRWfjo547JK4rMuTIJoioMPRe1Jn6Y,12
+kaiju_tools-2.0.44.dist-info/RECORD,,
```

